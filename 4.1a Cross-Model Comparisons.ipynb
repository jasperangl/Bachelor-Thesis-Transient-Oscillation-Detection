{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZa9qbao_gID",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model Comparisons\n",
    "\n",
    "Take the learnings and use 500 seq_len and 16 batch_size\n",
    "\n",
    "1. LSTM Standard\n",
    "2. RNN\n",
    "3. CNN\n",
    "4. GRU\n",
    "5. TCN\n",
    "5. ConvLSTM\n",
    "6. FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9DxWAJ8CcW8L",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1744796113544,
     "user_tz": -120,
     "elapsed": 11506,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     }
    },
    "outputId": "e282f59f-a573-4f23-8a67-5bfbe2976a49",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting neurodsp\n",
      "  Downloading neurodsp-2.3.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from neurodsp) (2.0.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from neurodsp) (1.14.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from neurodsp) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurodsp) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurodsp) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurodsp) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurodsp) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurodsp) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurodsp) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurodsp) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurodsp) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->neurodsp) (1.17.0)\n",
      "Downloading neurodsp-2.3.0-py3-none-any.whl (149 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m149.7/149.7 kB\u001B[0m \u001B[31m3.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: neurodsp\n",
      "Successfully installed neurodsp-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install neurodsp"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from neurodsp.burst import detect_bursts_dual_threshold"
   ],
   "metadata": {
    "id": "PqlKwHLP8pWL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fbxE6nIELL-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1744796270259,
     "user_tz": -120,
     "elapsed": 3646,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e7c6b061-6140-4751-d8cb-1e6afec55017",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting keras-tcn\n",
      "  Downloading keras_tcn-3.5.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras-tcn) (2.0.2)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from keras-tcn) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (75.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (4.13.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (1.71.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-tcn) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->keras-tcn) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->keras-tcn) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->keras-tcn) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->keras-tcn) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-tcn) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-tcn) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-tcn) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-tcn) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->keras-tcn) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->keras-tcn) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->keras-tcn) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow->keras-tcn) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->keras-tcn) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->keras-tcn) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->keras-tcn) (0.1.2)\n",
      "Downloading keras_tcn-3.5.6-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: keras-tcn\n",
      "Successfully installed keras-tcn-3.5.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, confusion_matrix, f1_score, classification_report, matthews_corrcoef, recall_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Bidirectional\n",
    "\n",
    "\n",
    "!pip install keras-tcn\n",
    "from tcn import TCN, tcn_full_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1744796265212,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     },
     "user_tz": -120
    },
    "id": "e-6oNkoR8HkB",
    "outputId": "53e33867-5191-4bca-ddf7-5a9c7e316c4c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26980,
     "status": "ok",
     "timestamp": 1744796299100,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     },
     "user_tz": -120
    },
    "id": "8egAzyeLvEBl",
    "outputId": "41108370-9889-4152-cf64-51e7004c3e23",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Get the current working directory (where your notebook is)\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "\n",
    "# Construct the full path to your data_utils.py file\n",
    "data_utils_path = '/content/drive/MyDrive/Colab Notebooks/Bachelor Thesis/Thesis Files/data_utils.py'  # Replace with the actual path\n",
    "\n",
    "# Add the directory containing data_utils.py to the Python path\n",
    "sys.path.append(os.path.dirname(data_utils_path))  # Add parent directory of data_utils.py\n",
    "# Now you can import the custom module\n",
    "import data_utils as du\n",
    "import analysis_utils as au\n",
    "\n",
    "sys.path = current_directory\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdevXsq95Ji5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Definitions"
   ],
   "metadata": {
    "id": "RJ0T5Ow79cUS",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from scipy.signal import hilbert\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    \"\"\"\n",
    "    Applies a Butterworth bandpass filter to the signal data.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): The input signal.\n",
    "        lowcut (float): Lower cutoff frequency in Hz.\n",
    "        highcut (float): Upper cutoff frequency in Hz.\n",
    "        fs (float): Sampling frequency in Hz.\n",
    "        order (int, optional): Order of the filter. Defaults to 4.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The filtered signal.\n",
    "    \"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    # Applies a butter bandpass filter\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    # Applies digital filter to minimize distortion introduced by the filters.\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "# Step 1: Compute the Hilbert transform amplitude for the signal\n",
    "def compute_hilbert_features(X, fs=250):  # Accepts 3D input X\n",
    "    \"\"\"\n",
    "    Computes Hilbert amplitude features with frequency-dependent filter orders and smoothing.\n",
    "    Flattens the input, computes amplitudes, and reshapes back to the original shape.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): The input signal data (3D array).\n",
    "        fs (int, optional): Sampling frequency. Defaults to 250.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The Hilbert amplitude features (3D array with the same shape as input X).\n",
    "    \"\"\"\n",
    "    original_shape = X.shape\n",
    "\n",
    "    # Flatten the input data\n",
    "    signal_flat = X.flatten()\n",
    "\n",
    "    # Define frequency bands with filter orders and smoothing factors\n",
    "    frequency_bands = {\n",
    "        'theta': (4, 7, 2, 0.0),  # (lowcut, highcut, filter_order, smoothing_factor)\n",
    "        'alpha': (8, 11, 2, 0.0),\n",
    "        'beta': (12, 28, 6, 0.3),\n",
    "        'gamma': (30, 100, 8, 0.4)\n",
    "    }\n",
    "\n",
    "    hilbert_features = []\n",
    "\n",
    "    for band_name, (lowcut, highcut, filter_order, smoothing_factor) in frequency_bands.items():\n",
    "        # Apply bandpass filter with specified order\n",
    "        filtered_signal = butter_bandpass_filter(signal_flat, lowcut, highcut, fs, order=filter_order)\n",
    "\n",
    "        # Compute Hilbert amplitude envelope\n",
    "        amplitude_envelope = np.abs(hilbert(filtered_signal))\n",
    "\n",
    "        # Apply smoothing (e.g., moving average) only if smoothing_factor > 0\n",
    "        if smoothing_factor > 0:\n",
    "            window_size = int(smoothing_factor * fs)  # Adjust window size based on frequency and smoothing factor\n",
    "            amplitude_envelope = np.convolve(amplitude_envelope, np.ones(window_size) / window_size, mode='same')\n",
    "        print(band_name, amplitude_envelope.shape)\n",
    "        hilbert_features.append(amplitude_envelope)\n",
    "\n",
    "    # Reshape the features back to the original 3D shape\n",
    "    hilbert_features_3d = np.column_stack(hilbert_features).reshape(original_shape + (4,))  # Add feature dimension\n",
    "    print(hilbert_features_3d.shape)\n",
    "    return hilbert_features_3d"
   ],
   "metadata": {
    "id": "5Bsdd4mzJXA7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9hU8UrN5LQU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Re-import necessary modules after execution state reset\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Bidirectional, Conv1D, ConvLSTM1D, Reshape, RNN, GRU, SimpleRNN, TimeDistributed, ConvLSTM2D, GlobalAveragePooling1D\n",
    "\n",
    "\n",
    "# Redefine the models\n",
    "def create_lstm_baseline(input_shape, binary):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        LSTM(32, return_sequences=True),\n",
    "        Dense(1 if binary else 5, activation=\"sigmoid\" if binary else \"softmax\", name=\"dense_output\")\n",
    "    ])\n",
    "\n",
    "    loss = \"binary_crossentropy\" if binary else \"sparse_categorical_crossentropy\"\n",
    "    model.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def create_bidirectional_lstm_balanced(input_shape, binary):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Bidirectional(LSTM(22, return_sequences=True)),  # 24 units per direction\n",
    "        Dense(1 if binary else 5, activation=\"sigmoid\" if binary else \"softmax\", name=\"dense_output\")\n",
    "    ])\n",
    "\n",
    "    loss = \"binary_crossentropy\" if binary else \"sparse_categorical_crossentropy\"\n",
    "    model.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Needs Sliding windows as well.\n",
    "def create_cnn_balanced(input_shape, binary):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Conv1D(filters=40, kernel_size=3, activation='relu'),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(1 if binary else 5, activation=\"sigmoid\" if binary else \"softmax\", name=\"dense_output\")\n",
    "    ])\n",
    "\n",
    "    loss = \"binary_crossentropy\" if binary else \"sparse_categorical_crossentropy\"\n",
    "    model.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# CNN Per timestep.\n",
    "def create_cnn_per_timestep(input_shape, binary):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Conv1D(filters=40, kernel_size=3, activation='relu', padding='same'),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'),\n",
    "        TimeDistributed(Dense(1 if binary else 5, activation=\"sigmoid\" if binary else \"softmax\", name=\"dense_output\"))\n",
    "    ])\n",
    "\n",
    "    loss = \"binary_crossentropy\" if binary else \"sparse_categorical_crossentropy\"\n",
    "    model.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def create_gru_balanced(input_shape, binary):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        GRU(37, return_sequences=True),\n",
    "        Dense(1 if binary else 5, activation=\"sigmoid\" if binary else \"softmax\", name=\"dense_output\")\n",
    "    ])\n",
    "\n",
    "    loss = \"binary_crossentropy\" if binary else \"sparse_categorical_crossentropy\"\n",
    "    model.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def create_rnn_balanced(input_shape, binary):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        SimpleRNN(67, return_sequences=True),\n",
    "        Dense(1 if binary else 5, activation=\"sigmoid\" if binary else \"softmax\", name=\"dense_output\")\n",
    "    ])\n",
    "\n",
    "    loss = \"binary_crossentropy\" if binary else \"sparse_categorical_crossentropy\"\n",
    "    model.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def create_tcn_balanced(input_shape, binary, kernel_size=3):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        TCN(kernel_size=kernel_size, nb_filters=15, return_sequences=True, dilations=[1, 2, 4, 8]),\n",
    "        Dense(1 if binary else 5, activation=\"sigmoid\" if binary else \"softmax\", name=\"dense_output\")\n",
    "    ])\n",
    "\n",
    "    loss = \"binary_crossentropy\" if binary else \"sparse_categorical_crossentropy\"\n",
    "    model.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# 1D ConvLSTM needs sliding windows\n",
    "def create_convLSTM_model(input_shape, binary):\n",
    "    # Create ConvLSTM model\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_shape[0],1,1,input_shape[1])),\n",
    "        ConvLSTM2D(filters=32, kernel_size=(1, 1), activation='relu', return_sequences=True),\n",
    "        Dense(1 if binary else 5, activation=\"sigmoid\" if binary else \"softmax\", name=\"dense_output\")\n",
    "    ])\n",
    "\n",
    "    loss = \"binary_crossentropy\" if binary else \"sparse_categorical_crossentropy\"\n",
    "    model.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def create_ffn_balanced(input_shape, binary):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(48, activation='relu'),\n",
    "        Dense(28, activation='relu'),\n",
    "        Dense(1 if binary else 5, activation=\"sigmoid\" if binary else \"softmax\", name=\"dense_output\")\n",
    "    ])\n",
    "    loss = \"binary_crossentropy\" if binary else \"sparse_categorical_crossentropy\"  # Conditional loss\n",
    "    model.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def detect_bursts_neurodsp(X, fs=250, bands=[(4, 8), (8, 12), (12, 30), (30, 50)], amp_low=1, amp_high=2, is_binary=None, n_cycles=3):  # Added n_cycles parameter\n",
    "    \"\"\"\n",
    "    Detect bursts using `detect_bursts_dual_threshold` applied per frequency band.\n",
    "\n",
    "    :param X: Input data of shape (samples, seq_len, n_features)\n",
    "    :param fs: Sampling rate\n",
    "    :param bands: Frequency bands for burst detection\n",
    "    :param amp_low: Lower amplitude threshold\n",
    "    :param amp_high: Higher amplitude threshold\n",
    "    :param is_binary: Auto-detect classification type if None\n",
    "    :param n_cycles: Number of cycles to use for filter design (adjust to shorten filter)\n",
    "    :return: Binary or multiclass burst predictions (samples, seq_len)\n",
    "    \"\"\"\n",
    "    samples, seq_len, n_features = X.shape\n",
    "\n",
    "    if is_binary is None:\n",
    "        is_binary = n_features == 1\n",
    "\n",
    "    num_bands = len(bands)\n",
    "    burst_detections = np.zeros((samples, seq_len, num_bands), dtype=int)\n",
    "\n",
    "    for i, (low_f, high_f) in enumerate(bands):\n",
    "        f_range = (low_f, high_f)\n",
    "        for j in range(samples):\n",
    "            # Pass n_cycles to detect_bursts_dual_threshold to control filter length\n",
    "            burst_detections[j, :, i] = detect_bursts_dual_threshold(X[j,:,0], fs, (amp_low, amp_high), (low_f, high_f))\n",
    "\n",
    "    if is_binary:\n",
    "        return (burst_detections.any(axis=-1)).astype(int)  # Binary: Any band active → 1\n",
    "    else:\n",
    "        return np.argmax(burst_detections, axis=-1)  # Multiclass: Assign highest active bandd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Compute the Hilbert transform amplitude for the signal\n",
    "def compute_hilbert_features(X, fs=250):  # Accepts 3D input X\n",
    "    \"\"\"\n",
    "    Computes Hilbert amplitude features with frequency-dependent filter orders and smoothing.\n",
    "    Flattens the input, computes amplitudes, and reshapes back to the original shape.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): The input signal data (3D array).\n",
    "        fs (int, optional): Sampling frequency. Defaults to 250.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The Hilbert amplitude features (3D array with the same shape as input X).\n",
    "    \"\"\"\n",
    "    original_shape = X.shape\n",
    "\n",
    "\n",
    "    # Flatten the input data\n",
    "    signal_flat = X.flatten()\n",
    "\n",
    "    # Define frequency bands with filter orders and smoothing factors\n",
    "    frequency_bands = {\n",
    "        'theta': (4, 7, 2, 0.0),  # (lowcut, highcut, filter_order, smoothing_factor)\n",
    "        'alpha': (8, 11, 2, 0.0),\n",
    "        'beta': (12, 28, 6, 0.3),\n",
    "        'gamma': (30, 100, 8, 0.4)\n",
    "    }\n",
    "\n",
    "    hilbert_features = []\n",
    "\n",
    "    for band_name, (lowcut, highcut, filter_order, smoothing_factor) in frequency_bands.items():\n",
    "        # Apply bandpass filter with specified order\n",
    "        filtered_signal = butter_bandpass_filter(signal_flat, lowcut, highcut, fs, order=filter_order)\n",
    "\n",
    "        # Compute Hilbert amplitude envelope\n",
    "        amplitude_envelope = np.abs(hilbert(filtered_signal))\n",
    "\n",
    "        # Apply smoothing (e.g., moving average) only if smoothing_factor > 0\n",
    "        if smoothing_factor > 0:\n",
    "            window_size = int(smoothing_factor * fs)  # Adjust window size based on frequency and smoothing factor\n",
    "            amplitude_envelope = np.convolve(amplitude_envelope, np.ones(window_size) / window_size, mode='same')\n",
    "        print(band_name, amplitude_envelope.shape)\n",
    "        hilbert_features.append(amplitude_envelope)\n",
    "\n",
    "    # Reshape the features back to the original 3D shape\n",
    "    hilbert_features_3d = np.column_stack(hilbert_features).reshape(original_shape + (4,))  # Add feature dimension\n",
    "    print(hilbert_features_3d.shape)\n",
    "    return hilbert_features_3d\n",
    "\n",
    "def detect_bursts_hilbert(X, std_factor=1, is_binary=None, fs=250):\n",
    "    \"\"\"\n",
    "    Detect bursts using Hilbert amplitude envelopes with thresholding.\n",
    "\n",
    "    :param X: Precomputed Hilbert envelopes of shape (samples, seq_len, 4: n_features)\n",
    "    :param std_factor: Standard deviation factor for thresholding\n",
    "    :param is_binary: Auto-detect classification type if None\n",
    "    :return: Binary or multiclass burst predictions (samples, seq_len)\n",
    "    \"\"\"\n",
    "    samples, seq_len, n_features = X.shape\n",
    "\n",
    "    if n_features == 1:\n",
    "        X = compute_hilbert_features(X.reshape(samples, seq_len), fs=fs)\n",
    "\n",
    "    else:\n",
    "        X = X[..., 1:5] # Filter out the already existing hilbert amplitudes\n",
    "\n",
    "    # Compute dynamic thresholds for each feature (mean + std_factor * std)\n",
    "    mean_values = np.mean(X, axis=(0, 1))  # Mean per feature\n",
    "    std_values = np.std(X, axis=(0, 1))  # Std per feature\n",
    "    thresholds = mean_values + std_factor * std_values  # Dynamic threshold per feature\n",
    "\n",
    "    # Detect bursts per feature\n",
    "    burst_detections = X > thresholds[None, None, :]  # Boolean mask of detected bursts\n",
    "\n",
    "    # Find the strongest amplitude per timestep across all features\n",
    "    max_amplitude_band = np.argmax(X, axis=-1)  # (samples, seq_len)\n",
    "\n",
    "    # Enforce the highest amplitude rule: Remove all bursts except the strongest one\n",
    "    final_burst_labels = np.zeros((samples, seq_len), dtype=int)  # Default: Noise (0)\n",
    "    for i in range(samples):\n",
    "        for t in range(seq_len):\n",
    "            strongest_band = max_amplitude_band[i, t]  # Identify the strongest amplitude band\n",
    "\n",
    "            # If this band also crosses the burst threshold, assign it as the final label\n",
    "            if burst_detections[i, t, strongest_band]:\n",
    "                final_burst_labels[i, t] = strongest_band + 1  # Shift labels (Theta = 1, Alpha = 2, etc.)\n",
    "\n",
    "    # ALTERNATIVE (FASTER APPROACH) not tested yet\n",
    "    # final_burst_labels = np.zeros((samples, seq_len), dtype=int)  # Initialize with 0 (noise)\n",
    "    # for band_idx in range(X.shape[-1]):  # Iterate over bands (0 to 3 for theta, alpha, beta, gamma)\n",
    "    #     # Create a mask for where this band is the strongest and crosses the threshold\n",
    "    #     band_mask = (max_amplitude_band == band_idx) & burst_detections[..., band_idx]\n",
    "\n",
    "    #     # Assign the band label (band_idx + 1) where the mask is True\n",
    "    #     final_burst_labels = np.where(band_mask, band_idx + 1, final_burst_labels)\n",
    "\n",
    "\n",
    "    if is_binary:\n",
    "        return (final_burst_labels > 0).astype(int)  # Convert to 0/1 for binary classification\n",
    "    else:\n",
    "        return final_burst_labels  # Multiclass classification (0-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNiL1F-2M1XE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Multi Models different output layers (Not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jxq1PfrKM7VP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ordinal cross entropy\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from keras import losses\n",
    "\n",
    "def ordinal_cross_entropy(y_true, y_pred):\n",
    "    weights = K.cast(K.abs(K.argmax(y_true, axis=1) - K.argmax(y_pred, axis=1))/(K.int_shape(y_pred)[1] - 1), dtype='float32')\n",
    "    return (1.0 + weights) * losses.categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "def ordinal_lstm_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)  # Example input shape (timesteps, features)\n",
    "    x = Bidirectional(LSTM(32, return_sequences=True))(inputs)\n",
    "    outputs = Dense(1, activation=\"linear\")(x)  # Single output neuron for ordinal values\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=ordinal_cross_entropy)\n",
    "    return model\n",
    "\n",
    "model = ordinal_lstm_model((500,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54q440JaN9xZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Two Output Neurons (Noise vs. Oscillations)\n",
    "\n",
    "def hybrid_loss(noise_weight=0.5, oscillation_weight=0.5):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true_noise, y_true_oscillation = y_true[..., 0], y_true[..., 1]\n",
    "        y_pred_noise, y_pred_oscillation = y_pred[..., 0], y_pred[..., 1]\n",
    "\n",
    "        # Binary crossentropy for noise\n",
    "        noise_loss = K.binary_crossentropy(y_true_noise, y_pred_noise)\n",
    "\n",
    "        # Ordinal loss for oscillation\n",
    "        ordinal_loss = K.abs(y_true_oscillation - y_pred_oscillation) * K.log(K.maximum(K.epsilon(), y_pred_oscillation))\n",
    "\n",
    "\n",
    "        # Combine losses\n",
    "        return noise_weight * noise_loss + oscillation_weight * K.mean(ordinal_loss)\n",
    "    return loss\n",
    "\n",
    "def hybrid_lstm_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Bidirectional(LSTM(32, return_sequences=True))(inputs)\n",
    "\n",
    "    # Two outputs\n",
    "    noise_output = Dense(1, activation=\"sigmoid\", name=\"noise\")(x)  # Noise vs. oscillations\n",
    "    oscillation_output = Dense(1, activation=\"linear\", name=\"oscillation\")(x)  # Ordinal output for oscillations\n",
    "\n",
    "    model = Model(inputs, [noise_output, oscillation_output])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=hybrid_loss(), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = hybrid_lstm_model((500,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdQ4sP_sOd1N",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Five Output Neurons (Noise Treated Separately)\n",
    "\n",
    "def multioutput_loss(y_true, y_pred):\n",
    "    noise_loss = K.binary_crossentropy(y_true[..., 0], y_pred[..., 0])  # Noise\n",
    "    oscillation_loss = ordinal_cross_entropy(y_true[..., 1:], y_pred[..., 1:])  # Oscillations (1–4)\n",
    "\n",
    "    # Weighted sum of losses\n",
    "    return 0.5 * noise_loss + 0.5 * oscillation_loss\n",
    "\n",
    "def multioutput_lstm_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Bidirectional(LSTM(32, return_sequences=True))(inputs)\n",
    "\n",
    "    # Dense layer with 5 outputs\n",
    "    outputs = Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=multioutput_loss)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = multioutput_lstm_model((500,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eNOkxqV_T-0f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def hierarchical_loss(noise_weight=0.5, oscillation_weight=0.5):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true_noise, y_true_oscillation = y_true[..., 0], y_true[..., 1:]\n",
    "        y_pred_noise, y_pred_oscillation = y_pred[0], y_pred[1]\n",
    "\n",
    "        # Binary cross-entropy for Stage 1\n",
    "        # Reshape y_pred_noise to match y_true_noise\n",
    "        # Take the mean of predictions over the timesteps before squeeze\n",
    "        y_pred_noise = tf.reduce_mean(y_pred_noise, axis=1) # Average over timesteps\n",
    "        y_pred_noise = tf.squeeze(y_pred_noise, axis=-1)  # Squeeze the last dimension of y_pred_noise\n",
    "        noise_loss = K.binary_crossentropy(y_true_noise, y_pred_noise)\n",
    "\n",
    "        # Categorical cross-entropy for Stage 2\n",
    "        # Reshape y_pred_oscillation to match y_true_oscillation if needed\n",
    "        y_pred_oscillation = tf.reshape(y_pred_oscillation, tf.shape(y_true_oscillation))\n",
    "        oscillation_loss = K.categorical_crossentropy(y_true_oscillation, y_pred_oscillation)\n",
    "\n",
    "        # Combine losses\n",
    "        return noise_weight * noise_loss + oscillation_weight * oscillation_loss\n",
    "    return loss\n",
    "\n",
    "# Define the model\n",
    "def hierarchical_lstm_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Bidirectional(LSTM(32, return_sequences=True))(inputs)\n",
    "\n",
    "    # Stage 1: Binary classification (Noise vs. Oscillations)\n",
    "    noise_output = Dense(1, activation=\"sigmoid\", name=\"noise\")(x)\n",
    "\n",
    "    # Stage 2: Multi-class classification (Oscillation types)\n",
    "    oscillation_output = Dense(4, activation=\"softmax\", name=\"oscillation\")(x)\n",
    "\n",
    "    model = Model(inputs, [noise_output, oscillation_output])\n",
    "\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=hierarchical_loss())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "meFmA0PVOpP3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def create_models_ordinal(input_shape):\n",
    "#     \"\"\"\n",
    "#     Creates and compiles all the models, returning them in a dictionary.\n",
    "\n",
    "#     Args:\n",
    "#         input_shape: Tuple specifying the input shape for the models.\n",
    "\n",
    "#     Returns:\n",
    "#         A dictionary where keys are model names and values are dictionaries\n",
    "#         containing the model and an empty 'parameters' subkey.\n",
    "#     \"\"\"\n",
    "#     # Use different variable names to avoid conflicts\n",
    "#     ordinal_lstm = ordinal_lstm_model(input_shape)\n",
    "#     hybrid_lstm = hybrid_lstm_model(input_shape)\n",
    "#     multioutput_lstm = multioutput_lstm_model(input_shape)\n",
    "#     hierarchical_lstm = hierarchical_lstm_model(input_shape)\n",
    "#     models = {\n",
    "#         \"Ordinal LSTM\": {\n",
    "#             \"model\": ordinal_lstm,  # Use the renamed variable\n",
    "#             \"parameters\": ordinal_lstm.count_params()\n",
    "#         },\n",
    "#         \"Hierarchical LSTM\": {\n",
    "#             \"model\": hierarchical_lstm,  # Use the renamed variable\n",
    "#             \"parameters\": hierarchical_lstm.count_params()\n",
    "#         },\n",
    "#         \"Hybrid LSTM\": {\n",
    "#             \"model\": hybrid_lstm,  # Use the renamed variable\n",
    "#             \"parameters\": hybrid_lstm.count_params()\n",
    "#         },\n",
    "#         \"Multioutput LSTM\": {\n",
    "#             \"model\": multioutput_lstm,  # Use the renamed variable\n",
    "#             \"parameters\": multioutput_lstm.count_params()\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "#     return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCua7L8cT8fH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create Model Dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-prXETVUrl_u",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_models_simple(input_shape, binary, cnn_window_size=100):\n",
    "    \"\"\"\n",
    "    Creates and compiles all the models, returning them in a dictionary.\n",
    "\n",
    "    Args:\n",
    "        input_shape: Tuple specifying the input shape for the models.\n",
    "        binary: Boolean indicating if the problem is binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary where keys are model names and values are dictionaries\n",
    "        containing the model and an empty 'parameters' subkey.\n",
    "    \"\"\"\n",
    "    lstm_model = create_lstm_baseline(input_shape, binary)\n",
    "    bilstm_model = create_bidirectional_lstm_balanced(input_shape, binary)\n",
    "    tcn_model = create_tcn_balanced(input_shape, binary)\n",
    "    conv_lstm = create_convLSTM_model(input_shape, binary)\n",
    "    cnn_model = create_cnn_balanced((cnn_window_size, input_shape[1]), binary)\n",
    "    cnn_timestep_model = create_cnn_per_timestep(input_shape, binary)\n",
    "    gru_model = create_gru_balanced(input_shape, binary)\n",
    "    rnn_model = create_rnn_balanced(input_shape, binary)\n",
    "    fnn_model = create_ffn_balanced(input_shape, binary)\n",
    "    models = {\n",
    "        # \"Threshold Hilbert\": {\n",
    "        #     \"model\": detect_bursts_hilbert,\n",
    "        #     \"parameters\": 0\n",
    "        # },\n",
    "        # \"Threshold NeuroDSP\": {\n",
    "        #     \"model\": detect_bursts_neurodsp,\n",
    "        #     \"parameters\": 0\n",
    "        # },\n",
    "        # \"CNN\": {\n",
    "        #     \"model\": cnn_model,\n",
    "        #     \"parameters\": cnn_model.count_params()\n",
    "        # },\n",
    "        # \"CNN Timestep\": {\n",
    "        #     \"model\": cnn_timestep_model,\n",
    "        #     \"parameters\": cnn_timestep_model.count_params()\n",
    "        # },\n",
    "        \"LSTM\": {\n",
    "            \"model\": lstm_model,\n",
    "            \"parameters\": lstm_model.count_params()\n",
    "        },\n",
    "        \"BiLSTM\": {\n",
    "            \"model\": bilstm_model,\n",
    "            \"parameters\": bilstm_model.count_params()\n",
    "        },\n",
    "        \"RNN\": {\n",
    "            \"model\": rnn_model,\n",
    "            \"parameters\": rnn_model.count_params()\n",
    "        },\n",
    "        \"GRU\": {\n",
    "            \"model\": gru_model,\n",
    "            \"parameters\": gru_model.count_params()\n",
    "        },\n",
    "        \"TCN\": {\n",
    "            \"model\": tcn_model,\n",
    "            \"parameters\": tcn_model.count_params()\n",
    "        },\n",
    "\n",
    "        \"MLP\": {\n",
    "            \"model\": fnn_model,\n",
    "            \"parameters\": fnn_model.count_params()\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LrjefpHIl6H1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def model_funcs_simple():\n",
    "    \"\"\"\n",
    "    Creates a dictionary of model creation functions.\n",
    "\n",
    "    Args:\n",
    "        input_shape: Tuple specifying the input shape for the models.\n",
    "        binary: Boolean indicating if the problem is binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary where keys are model names and values are the\n",
    "        corresponding model creation functions.\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        # \"Threshold NeuroDSP\": detect_bursts_neurodsp,\n",
    "        # \"Threshold Hilbert\": detect_bursts_hilbert,\n",
    "        # \"CNN\": create_cnn_balanced,\n",
    "        # \"CNN Timestep\": create_cnn_per_timestep,\n",
    "        \"LSTM\": create_lstm_baseline,\n",
    "        \"BiLSTM\": create_bidirectional_lstm_balanced,\n",
    "        \"RNN\": create_rnn_balanced,\n",
    "        \"GRU\": create_gru_balanced,\n",
    "        \"TCN\": create_tcn_balanced,  # Uncomment to include TCN\n",
    "        \"MLP\": create_ffn_balanced\n",
    "    }\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "models_siganl_binary = create_models_simple((500, 1), True)\n",
    "models_singal_multi = create_models_simple((500, 1), False)\n",
    "\n",
    "models_hilbert_binary = create_models_simple((500, 2), True)\n",
    "models_hilbert_multi = create_models_simple((500, 5), False)\n",
    "\n",
    "models_all_features_binary = create_models_simple((500, 7), True)\n",
    "models_all_features_multi = create_models_simple((500, 25), False)"
   ],
   "metadata": {
    "id": "2g_Ku0JupuRe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np  # Make sure NumPy is imported\n",
    "\n",
    "def combine_and_summarize_models(model_dicts):\n",
    "  \"\"\"Combines multiple model dictionaries and summarizes parameters.\n",
    "\n",
    "  Args:\n",
    "    model_dicts: A list of dictionaries, where each dictionary represents\n",
    "      a set of models with their parameters.\n",
    "\n",
    "  Returns:\n",
    "    A new dictionary containing all the models and their summarized parameters.\n",
    "  \"\"\"\n",
    "  combined_models = {}\n",
    "  for model_dict in model_dicts:\n",
    "    for model_name, model_info in model_dict.items():\n",
    "      if model_name not in combined_models:\n",
    "        combined_models[model_name] = {\"parameters\": []}\n",
    "      combined_models[model_name][\"parameters\"].append(model_info[\"parameters\"])\n",
    "\n",
    "  for model_name, model_info in combined_models.items():\n",
    "    if model_info[\"parameters\"]:\n",
    "      combined_models[model_name][\"parameters_sum\"] = np.mean(\n",
    "          model_info[\"parameters\"]\n",
    "      )\n",
    "      combined_models[model_name][\"parameters_std\"] = np.std(\n",
    "          model_info[\"parameters\"]\n",
    "      )\n",
    "      del combined_models[model_name][\"parameters\"]\n",
    "  return combined_models\n",
    "\n",
    "all_model_dicts = [models_siganl_binary,\n",
    "                   models_singal_multi,\n",
    "                   models_hilbert_binary,\n",
    "                   models_hilbert_multi,\n",
    "                   models_all_features_binary,\n",
    "                   models_all_features_multi]\n",
    "\n",
    "# Get the summarized parameters\n",
    "combined_models = combine_and_summarize_models(all_model_dicts)\n",
    "\n",
    "# Print the results\n",
    "for model_name, model_info in combined_models.items():\n",
    "  print(f\"Model: {model_name}\")\n",
    "  print(f\"  Average Parameters: {model_info['parameters_sum']}\")\n",
    "  print(f\"  Standard Deviation of Parameters: {model_info['parameters_std']}\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rp76QN394sNY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1744796451437,
     "user_tz": -120,
     "elapsed": 21,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     }
    },
    "outputId": "a94a83a1-c020-4590-dc48-ecfa7ced5758",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: LSTM\n",
      "  Average Parameters: 5197.666666666667\n",
      "  Standard Deviation of Parameters: 1106.1510847177353\n",
      "\n",
      "Model: BiLSTM\n",
      "  Average Parameters: 5385.666666666667\n",
      "  Standard Deviation of Parameters: 1520.6093807710408\n",
      "\n",
      "Model: RNN\n",
      "  Average Parameters: 5217.833333333333\n",
      "  Standard Deviation of Parameters: 632.5552457207899\n",
      "\n",
      "Model: GRU\n",
      "  Average Parameters: 5201.5\n",
      "  Standard Deviation of Parameters: 968.1029129178364\n",
      "\n",
      "Model: TCN\n",
      "  Average Parameters: 5318.0\n",
      "  Standard Deviation of Parameters: 519.0028901653632\n",
      "\n",
      "Model: MLP\n",
      "  Average Parameters: 5080.333333333333\n",
      "  Standard Deviation of Parameters: 565.1261412778173\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(models_siganl_binary)\n",
    "print(models_singal_multi)\n",
    "print(models_hilbert_binary)\n",
    "print(models_hilbert_multi)\n",
    "print(models_all_features_binary)\n",
    "print(models_all_features_multi)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UZf6uxpmp3Rl",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1744796456306,
     "user_tz": -120,
     "elapsed": 29,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     }
    },
    "outputId": "e86d9fa9-7445-4215-f026-9ae13fe1d41c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'LSTM': {'model': <Sequential name=sequential_186, built=True>, 'parameters': 4385}, 'BiLSTM': {'model': <Sequential name=sequential_187, built=True>, 'parameters': 4269}, 'RNN': {'model': <Sequential name=sequential_193, built=True>, 'parameters': 4691}, 'GRU': {'model': <Sequential name=sequential_192, built=True>, 'parameters': 4478}, 'TCN': {'model': <Sequential name=sequential_188, built=True>, 'parameters': 4936}, 'MLP': {'model': <Sequential name=sequential_194, built=True>, 'parameters': 4649}}\n",
      "{'LSTM': {'model': <Sequential name=sequential_195, built=True>, 'parameters': 4517}, 'BiLSTM': {'model': <Sequential name=sequential_196, built=True>, 'parameters': 4449}, 'RNN': {'model': <Sequential name=sequential_202, built=True>, 'parameters': 4963}, 'GRU': {'model': <Sequential name=sequential_201, built=True>, 'parameters': 4630}, 'TCN': {'model': <Sequential name=sequential_197, built=True>, 'parameters': 5000}, 'MLP': {'model': <Sequential name=sequential_203, built=True>, 'parameters': 4765}}\n",
      "{'LSTM': {'model': <Sequential name=sequential_204, built=True>, 'parameters': 4513}, 'BiLSTM': {'model': <Sequential name=sequential_205, built=True>, 'parameters': 4445}, 'RNN': {'model': <Sequential name=sequential_211, built=True>, 'parameters': 4758}, 'GRU': {'model': <Sequential name=sequential_210, built=True>, 'parameters': 4589}, 'TCN': {'model': <Sequential name=sequential_206, built=True>, 'parameters': 4996}, 'MLP': {'model': <Sequential name=sequential_212, built=True>, 'parameters': 4713}}\n",
      "{'LSTM': {'model': <Sequential name=sequential_213, built=True>, 'parameters': 5029}, 'BiLSTM': {'model': <Sequential name=sequential_214, built=True>, 'parameters': 5153}, 'RNN': {'model': <Sequential name=sequential_220, built=True>, 'parameters': 5231}, 'GRU': {'model': <Sequential name=sequential_219, built=True>, 'parameters': 5074}, 'TCN': {'model': <Sequential name=sequential_215, built=True>, 'parameters': 5240}, 'MLP': {'model': <Sequential name=sequential_221, built=True>, 'parameters': 5021}}\n",
      "{'LSTM': {'model': <Sequential name=sequential_222, built=True>, 'parameters': 5153}, 'BiLSTM': {'model': <Sequential name=sequential_223, built=True>, 'parameters': 5325}, 'RNN': {'model': <Sequential name=sequential_229, built=True>, 'parameters': 5093}, 'GRU': {'model': <Sequential name=sequential_228, built=True>, 'parameters': 5144}, 'TCN': {'model': <Sequential name=sequential_224, built=True>, 'parameters': 5296}, 'MLP': {'model': <Sequential name=sequential_230, built=True>, 'parameters': 5033}}\n",
      "{'LSTM': {'model': <Sequential name=sequential_231, built=True>, 'parameters': 7589}, 'BiLSTM': {'model': <Sequential name=sequential_232, built=True>, 'parameters': 8673}, 'RNN': {'model': <Sequential name=sequential_238, built=True>, 'parameters': 6571}, 'GRU': {'model': <Sequential name=sequential_237, built=True>, 'parameters': 7294}, 'TCN': {'model': <Sequential name=sequential_233, built=True>, 'parameters': 6440}, 'MLP': {'model': <Sequential name=sequential_239, built=True>, 'parameters': 6301}}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBNCJqQLuSth",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24086,
     "status": "ok",
     "timestamp": 1744796482751,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     },
     "user_tz": -120
    },
    "id": "bulzztRauP-J",
    "outputId": "8a898f42-b145-4c8d-9962-a1f4e3664295",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DATASET INFO:\n",
      "Shape: (10, 20, 5, 7500, 25)\n",
      "\n",
      "No of Samples: 10\n",
      "\n",
      "No of Frequencies: 20\n",
      "Freqency values: [np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(11), np.int64(13), np.int64(16), np.int64(18), np.int64(22), np.int64(26), np.int64(31), np.int64(36), np.int64(43), np.int64(51), np.int64(60), np.int64(71), np.int64(84), np.int64(100)]\n",
      "\n",
      "No of noise ratios: 5\n",
      "Signal to Noise ratios (in db) [np.int64(-10), np.int64(-8), np.int64(-6), np.int64(-4), np.int64(-2), np.int64(0), np.int64(2), np.int64(4), np.int64(6), np.int64(8)]\n",
      "\n",
      "No of Datapoints: 7500\n",
      "\n",
      "No of Features per Datapoint: 25 (signal, hilbert amp, 20 wavelets for each freq)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/content/drive/MyDrive/Colab Notebooks/Bachelor Thesis/Data/Including Features/5_class_mid_noise_30s_features_vec.npy\"\n",
    "label_path = \"/content/drive/MyDrive/Colab Notebooks/Bachelor Thesis/Data/Including Features/5_class_mid_noise_30s_numeric_label_vec.npy\"\n",
    "\n",
    "data_vec, label_vec = du.load_data(data_path, label_path)\n",
    "\n",
    "du.data_info(data_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1744796482787,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     },
     "user_tz": -120
    },
    "id": "yi75Jy_NvlCV",
    "outputId": "3670c54a-70b0-426d-aefa-60e6b2f75bef",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10, 20, 5, 7500, 25)\n",
      "(10, 20, 5, 7500)\n"
     ]
    }
   ],
   "source": [
    "data_vec_trim = data_vec[:, :, :]\n",
    "label_vec_trim = label_vec[:, :, :]\n",
    "\n",
    "print(data_vec_trim.shape)\n",
    "print(label_vec_trim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kg4x5Pbl23A8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_sequences_keep_data(X, y, new_seq_len):\n",
    "    \"\"\"\n",
    "    Splits input sequences and their per-timestep labels into smaller sequences of length `new_seq_len`.\n",
    "\n",
    "    Args:\n",
    "        X (numpy array): Input data of shape (samples, seq_len, features).\n",
    "        y (numpy array): Labels of shape (samples, seq_len) or (samples, seq_len, ...).\n",
    "        new_seq_len (int): Desired sequence length.\n",
    "\n",
    "    Returns:\n",
    "        X_new: New input data with shape (new_samples, new_seq_len, features).\n",
    "        y_new: New labels with shape (new_samples, new_seq_len, ...).\n",
    "    \"\"\"\n",
    "    num_samples, original_seq_len, num_features = X.shape\n",
    "    if original_seq_len % new_seq_len != 0:\n",
    "        print(f\"Warning: Original seq_len ({original_seq_len}) is not a multiple of new_seq_len ({new_seq_len}).\")\n",
    "\n",
    "    # Number of new samples per original sequence\n",
    "    num_segments = original_seq_len // new_seq_len\n",
    "\n",
    "    # Create new datasets by reshaping\n",
    "    X_new = np.reshape(X[:, :num_segments * new_seq_len, :],\n",
    "                       (-1, new_seq_len, num_features))  # Shape: (samples * num_segments, new_seq_len, features)\n",
    "    y_new = np.reshape(y[:, :num_segments * new_seq_len, ...],\n",
    "                       (-1, new_seq_len, *y.shape[2:]))  # Adjust labels to match input shape\n",
    "\n",
    "    return X_new, y_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1744796499478,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     },
     "user_tz": -120
    },
    "id": "wc43pWiwvpsH",
    "outputId": "3331e821-02d1-4c8e-f6d6-13f3a0ae0468",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1000, 7500, 25)\n",
      "(1000, 7500, 1)\n"
     ]
    }
   ],
   "source": [
    "data_vec_shaped, label_vec_shaped = du.preprocess_data(data_vector=data_vec_trim, label_vector=label_vec_trim)\n",
    "\n",
    "print(data_vec_shaped.shape)\n",
    "print(label_vec_shaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "new_seq_len = 500 # 7500 is origianl length\n",
    "\n",
    "sample_increase_factor = int(data_vec_shaped.shape[1] / new_seq_len)\n",
    "\n",
    "data_vec_reshaped, label_vec_reshaped = split_sequences_keep_data(data_vec_shaped, label_vec_shaped, new_seq_len=new_seq_len)\n",
    "\n",
    "# Extract noise levels\n",
    "noise_levels = np.arange(data_vec_trim.shape[2])  # Assuming noise levels are 0, 1, 2, 3, 4\n",
    "noise_levels = np.repeat(noise_levels, data_vec_trim.shape[0] * data_vec_trim.shape[1] * sample_increase_factor)"
   ],
   "metadata": {
    "id": "6SSeyn958A4k",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1744796501774,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     },
     "user_tz": -120
    },
    "id": "RYWhCZB8298N",
    "outputId": "b6dc3bd2-572e-4259-ffd8-23ac3d4e0435",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(15000, 500, 25)\n",
      "(15000, 500, 1)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(data_vec_reshaped.shape)\n",
    "print(label_vec_reshaped.shape)\n",
    "print(noise_levels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJw1XMp2uUVw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Splits\n",
    "\n",
    "Be careful about choosing binary or not in the TT Splits"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Multi Models:\n",
    "wavelet_remove_index = [1,2,3,4]\n",
    "all_indices = np.arange(data_vec_reshaped.shape[-1])\n",
    "indices_to_keep = np.delete(all_indices, wavelet_remove_index)\n",
    "\n",
    "hilbert_data_vec_multi = data_vec_reshaped[:,:,:5]\n",
    "signal_data_vec_multi = data_vec_reshaped[:,:, :1]\n",
    "wavelet_data_vec_multi = data_vec_reshaped[:,:, indices_to_keep]\n",
    "all_data_vec_multi = data_vec_reshaped\n",
    "\n",
    "label_multi = label_vec_reshaped\n",
    "\n",
    "print(hilbert_data_vec_multi.shape)\n",
    "print(signal_data_vec_multi.shape)\n",
    "print(wavelet_data_vec_multi.shape)\n",
    "print(all_data_vec_multi.shape)\n",
    "print(label_multi.shape)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7DKGGk9a5sss",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1744796504331,
     "user_tz": -120,
     "elapsed": 1478,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     }
    },
    "outputId": "d3cec6bf-b461-4de0-d8eb-d88fd7189c4c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(15000, 500, 5)\n",
      "(15000, 500, 1)\n",
      "(15000, 500, 21)\n",
      "(15000, 500, 25)\n",
      "(15000, 500, 1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Binary Models:\n",
    "\n",
    "data_vec_beta_trim = data_vec[:, 10:15, :]\n",
    "label_vec_beta_trim = label_vec[:, 10:15, :]\n",
    "\n",
    "data_vec_shaped, label_vec_shaped = du.preprocess_data(data_vector=data_vec_beta_trim, label_vector=label_vec_beta_trim)\n",
    "\n",
    "print(data_vec_shaped.shape)\n",
    "print(label_vec_shaped.shape)\n",
    "\n",
    "new_seq_len = 500 # 7500 is origianl length\n",
    "\n",
    "sample_increase_factor = int(data_vec_shaped.shape[1] / new_seq_len)\n",
    "\n",
    "data_vec_reshaped, label_vec_reshaped = split_sequences_keep_data(data_vec_shaped, label_vec_shaped, new_seq_len=new_seq_len)\n",
    "\n",
    "print(data_vec_reshaped.shape)\n",
    "print(label_vec_reshaped.shape)\n",
    "\n",
    "beta_hilbert_incl_index = [0,3]\n",
    "beta_hilbert_only_index = [3]\n",
    "beta_wavelet_incl_index = [0,12,13,14,15,16]\n",
    "beta_wavelet_only_index = [12,13,14,15,16]\n",
    "beta_allF_index         = beta_hilbert_incl_index + beta_wavelet_only_index\n",
    "\n",
    "hilbert_data_vec_binary = data_vec_reshaped[:,:,beta_hilbert_incl_index]\n",
    "signal_data_vec_binary = data_vec_reshaped[:,:, :1]\n",
    "wavelet_data_vec_binary = data_vec_reshaped[:,:, beta_wavelet_incl_index]\n",
    "all_data_vec_binary = data_vec_reshaped[:,:,beta_allF_index]\n",
    "\n",
    "label_binary = label_vec_reshaped.copy()\n",
    "label_binary[label_binary >= 1] = 1  # Convert to binary labels\n",
    "\n",
    "print(hilbert_data_vec_binary.shape)\n",
    "print(signal_data_vec_binary.shape)\n",
    "print(wavelet_data_vec_binary.shape)\n",
    "print(all_data_vec_binary.shape)\n",
    "print(label_binary.shape)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uz81P9Pj6MPu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1744796504664,
     "user_tz": -120,
     "elapsed": 332,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     }
    },
    "outputId": "f5129b58-0bec-4663-f6a9-96cfb6d498ae",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(250, 7500, 25)\n",
      "(250, 7500, 1)\n",
      "(3750, 500, 25)\n",
      "(3750, 500, 1)\n",
      "(3750, 500, 2)\n",
      "(3750, 500, 1)\n",
      "(3750, 500, 6)\n",
      "(3750, 500, 7)\n",
      "(3750, 500, 1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zs3IQP22uoB4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXWqvPEzupkc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_val, y_val, binary):\n",
    "    \"\"\"\n",
    "    Trains and evaluates the model, returning the metrics and evaluation data.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=16, verbose=1, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Measure training time\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_val).argmax(axis=-1) if not binary else (model.predict(X_val) > 0.5).astype(int)\n",
    "    inference_time = time.time() - start_time\n",
    "\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_val = y_val.flatten()\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred, average=\"binary\" if binary else \"macro\")\n",
    "    f1 = f1_score(y_val, y_pred, average=\"binary\" if binary else \"macro\")\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    mcc = matthews_corrcoef(y_val, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"MCC: {mcc}\")\n",
    "\n",
    "    return model , {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"mcc\": mcc,\n",
    "        \"mae\": mae,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"training_time\": training_time,\n",
    "        \"inference_time\": inference_time\n",
    "\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuvtDw_v3PN6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(models, X_train, y_train, X_val, y_val, binary):\n",
    "    \"\"\"\n",
    "    Trains and evaluates all models in the dictionary, storing performance metrics.\n",
    "\n",
    "    Args:\n",
    "        models: Dictionary containing models with subkeys \"model\" and \"parameters\".\n",
    "        X_train: Training data.\n",
    "        y_train: Training labels.\n",
    "        X_val: Validation data.\n",
    "        y_val: Validation labels.\n",
    "\n",
    "    Returns:\n",
    "        The updated models dictionary with a new \"performances\" subkey for each model.\n",
    "    \"\"\"\n",
    "\n",
    "    for model_name, model_data in models.items():#\n",
    "        print(f\"Training and evaluating {model_name}...\")  # Optional: Print progress\n",
    "        model = model_data[\"model\"]  # Get the model object\n",
    "\n",
    "        trained_model, performance_metrics = evaluate_model(model, X_train, y_train, X_val, y_val, binary)\n",
    "\n",
    "        # Save the trained model in Dict\n",
    "        model_data[\"model\"] = trained_model\n",
    "\n",
    "        # Store the performance metrics in the \"performances\" subkey\n",
    "        model_data[\"performances\"] = performance_metrics\n",
    "\n",
    "    return models  # Return the updated models dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1062,
     "status": "error",
     "timestamp": 1738770275244,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     },
     "user_tz": -60
    },
    "id": "GHqO2yXZhCuV",
    "outputId": "be6f9d7f-20f0-40eb-9094-79f277e0607e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-16-47ffb7f3a48a>\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_train\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3VeSFTOS4Ruk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Using Only the signal as an input feature\n",
    "\n",
    "signal_only_models = train_and_evaluate_models(models, X_train, y_train, X_test, y_test, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1738447926852,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     },
     "user_tz": -60
    },
    "id": "6gR_O7s5PRCl",
    "outputId": "3d34201e-f39c-4487-f858-c63521073865",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LSTM': {'model': <keras.engine.sequential.Sequential at 0x78eb28a7b850>,\n",
       "  'parameters': 4385,\n",
       "  'performances': {'accuracy': 0.8542,\n",
       "   'mcc': 0.70743184074071,\n",
       "   'mae': 0.1458,\n",
       "   'recall': 0.8183711048158641,\n",
       "   'f1': 0.8408574921411107,\n",
       "   'confusion_matrix': array([[70353,  9047],\n",
       "          [12823, 57777]]),\n",
       "   'training_time': 144.01327061653137,\n",
       "   'inference_time': 0.8876395225524902}},\n",
       " 'BiLSTM': {'model': <keras.engine.sequential.Sequential at 0x78eb2929d150>,\n",
       "  'parameters': 5041,\n",
       "  'performances': {'accuracy': 0.8995066666666667,\n",
       "   'mcc': 0.7982790522855711,\n",
       "   'mae': 0.10049333333333334,\n",
       "   'recall': 0.8911756373937677,\n",
       "   'f1': 0.8930223975927556,\n",
       "   'confusion_matrix': array([[72009,  7391],\n",
       "          [ 7683, 62917]]),\n",
       "   'training_time': 153.8624861240387,\n",
       "   'inference_time': 1.3268213272094727}},\n",
       " 'RNN': {'model': <keras.engine.sequential.Sequential at 0x78eb2b4e1090>,\n",
       "  'parameters': 4289,\n",
       "  'performances': {'accuracy': 0.83588,\n",
       "   'mcc': 0.6710292799915758,\n",
       "   'mae': 0.16412,\n",
       "   'recall': 0.7867705382436261,\n",
       "   'f1': 0.8185984820573281,\n",
       "   'confusion_matrix': array([[69836,  9564],\n",
       "          [15054, 55546]]),\n",
       "   'training_time': 61.187647342681885,\n",
       "   'inference_time': 0.49288153648376465}},\n",
       " 'GRU': {'model': <keras.engine.sequential.Sequential at 0x78eb2b308190>,\n",
       "  'parameters': 3393,\n",
       "  'performances': {'accuracy': 0.83762,\n",
       "   'mcc': 0.6738597065538349,\n",
       "   'mae': 0.16238,\n",
       "   'recall': 0.8157223796033994,\n",
       "   'f1': 0.8254441474304306,\n",
       "   'confusion_matrix': array([[68053, 11347],\n",
       "          [13010, 57590]]),\n",
       "   'training_time': 143.50585746765137,\n",
       "   'inference_time': 1.0248956680297852}},\n",
       " 'TCN': {'model': <keras.engine.sequential.Sequential at 0x78eb29250e90>,\n",
       "  'parameters': 5601,\n",
       "  'performances': {'accuracy': 0.8420866666666667,\n",
       "   'mcc': 0.6829179889773844,\n",
       "   'mae': 0.15791333333333332,\n",
       "   'recall': 0.8263597733711048,\n",
       "   'f1': 0.8312519145965277,\n",
       "   'confusion_matrix': array([[67972, 11428],\n",
       "          [12259, 58341]]),\n",
       "   'training_time': 43.51044297218323,\n",
       "   'inference_time': 0.5817756652832031}},\n",
       " 'FNN': {'model': <keras.engine.sequential.Sequential at 0x78eb2b3b0890>,\n",
       "  'parameters': 2241,\n",
       "  'performances': {'accuracy': 0.6877533333333333,\n",
       "   'mcc': 0.374887498919398,\n",
       "   'mae': 0.3122466666666667,\n",
       "   'recall': 0.5487393767705382,\n",
       "   'f1': 0.6232514740305183,\n",
       "   'confusion_matrix': array([[64422, 14978],\n",
       "          [31859, 38741]]),\n",
       "   'training_time': 11.091627836227417,\n",
       "   'inference_time': 0.1857895851135254}}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkLoQWoxNSg7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "def display_models_with_performances(models):\n",
    "    \"\"\"\n",
    "    Displays models with existing 'performances' in an HTML table.\n",
    "\n",
    "    Args:\n",
    "        models: A dictionary where keys are model names and values are dictionaries\n",
    "               containing model information, including 'performances' if available.\n",
    "    \"\"\"\n",
    "\n",
    "    html = \"\"\"\n",
    "    <style>\n",
    "    table {\n",
    "        border-collapse: collapse;\n",
    "        width: 100%;\n",
    "    }\n",
    "    th, td {\n",
    "        text-align: center;\n",
    "        padding: 8px;\n",
    "        border: 1px solid #ddd;\n",
    "    }\n",
    "    th {\n",
    "        background-color: #4f50b3;\n",
    "    }\n",
    "    </style>\n",
    "    <table><thead><tr><th>Model</th><th>Parameters</th><th>Accuracy</th><th>MCC</th><th>Recall</th><th>F1</th><th>Training Time</th><th>Inference Time</th></tr></thead><tbody>\"\"\"\n",
    "\n",
    "    for model_name, model_data in models.items():\n",
    "        if \"performances\" in model_data:\n",
    "            performances = model_data[\"performances\"]\n",
    "            html += f\"<tr><td>{model_name}</td>\"\n",
    "            html += f\"<td>{model_data['parameters']}</td>\"\n",
    "            html += f\"<td>{performances['accuracy']:.3f}</td>\"\n",
    "            html += f\"<td>{performances['mcc']:.3f}</td>\"\n",
    "            html += f\"<td>{performances['recall']:.3f}</td>\"\n",
    "            html += f\"<td>{performances['f1']:.3f}</td>\"\n",
    "            html += f\"<td>{performances['training_time']:.1f}</td>\"\n",
    "            html += f\"<td>{performances['inference_time']:.3f}</td></tr>\"\n",
    "\n",
    "    html += \"</tbody></table>\"\n",
    "    display(HTML(html))\n",
    "\n",
    "display_models_with_performances(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwhQ88ipzjmj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## K-Fold Analysis\n",
    "\n",
    "- Stratified k-fold\n",
    "- Make function that takes in only the model_dict and returns result dict\n",
    "- Create Heatlike result visualizations\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFTGPyDbvBsj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "class MCCCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data, is_binary=True):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data  # Tuple (x_val, y_val)\n",
    "        self.is_binary = is_binary\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        x_val, y_val = self.validation_data\n",
    "        y_pred = self.model.predict(x_val, verbose=0)\n",
    "\n",
    "        # Ensure y_val is flattened (shape: (N,))\n",
    "        y_true = y_val.flatten()\n",
    "\n",
    "        if self.is_binary:\n",
    "            # Binary classification: round predictions\n",
    "            y_pred = np.round(y_pred).flatten()\n",
    "        else:\n",
    "            # Multiclass classification: use argmax (since predictions are (N, 5) softmax outputs)\n",
    "            y_pred = np.argmax(y_pred, axis=-1).flatten()\n",
    "\n",
    "        # Compute MCC\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "        # Log MCC\n",
    "        logs[\"mcc\"] = mcc\n",
    "        print(f\"\\nEpoch {epoch + 1} - MCC: {mcc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wmd2kVu4k15R",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def stratified_kfold_split(X, y, num_folds=5):\n",
    "    \"\"\"\n",
    "    Performs Stratified K-Fold cross-validation on sequence data.\n",
    "\n",
    "    Args:\n",
    "        X: ndarray of shape (samples, timesteps, features) -> (7500, 500, ?)\n",
    "        y: ndarray of shape (samples, timesteps, 1) -> (7500, 500, 1)\n",
    "        num_folds: Number of folds for cross-validation.\n",
    "\n",
    "    Returns:\n",
    "        List of (train_idx, val_idx) tuples.\n",
    "    \"\"\"\n",
    "    # Convert y from (7500, 500, 1) → (7500, 500)\n",
    "    y_flat = y[:, :, 0]  # Remove last dimension\n",
    "\n",
    "    # Get **max class per sequence**\n",
    "    y_max = np.max(y_flat, axis=1)  # Shape → (7500,)\n",
    "\n",
    "    # Stratified K-Fold splitting\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    folds = list(skf.split(X, y_max))  # Get (train_idx, val_idx) splits\n",
    "\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXahq6ze2yQw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Train and Evaluate Function\n",
    "def train_and_evaluate(models, X, y, k_folds=5, batch_size=16, epochs=10, basePath=\"/content/drive/MyDrive/Colab Notebooks/Bachelor Thesis/Data/Model Comparisons/\", dir_name=\"hilbert_binary\"):\n",
    "\n",
    "    skf_folds = stratified_kfold_split(X,y,num_folds=k_folds)\n",
    "\n",
    "    # Determines whether we work with binary data or multi data\n",
    "    binary = len(np.unique(y)) == 2  # Check if only 2 unique values in y\n",
    "    print(f\"Binary: {binary}\")\n",
    "\n",
    "\n",
    "    model_results = {model_name: {} for model_name in models.keys()}\n",
    "    trained_models = {model_name: [] for model_name in models.keys()}\n",
    "\n",
    "    for model_name, model_fn in models.items():\n",
    "        acc_scores, mcc_scores, train_times, infer_times = [], [], [], []\n",
    "\n",
    "        # *** Initialize a list to store history for each fold ***\n",
    "        val_mcc = []\n",
    "        val_accuracy = []\n",
    "        val_losses = []\n",
    "        training_losses = []\n",
    "        training_accuracy = []\n",
    "        num_params = None\n",
    "\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf_folds):\n",
    "\n",
    "            print(f\"Training Model: {model_name}, Fold: {fold+1}\")\n",
    "\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "\n",
    "\n",
    "            val_mccs = None # Initialize to None for Threshold case\n",
    "\n",
    "            mcc_callback = MCCCallback(validation_data=(X_val, y_val), is_binary=binary)\n",
    "\n",
    "            if model_name == \"CNN\":\n",
    "                model = model_fn(input_shape=(100, X_train.shape[-1]), binary=binary)\n",
    "\n",
    "                 # Create a small subset of data for estimation (e.g., 10%)\n",
    "                subset_size = int(0.5 * len(X))\n",
    "\n",
    "                train_gen_100 = SlidingWindowGenerator(X_train[:subset_size], y_train[:subset_size], window_size=100, batch_size=batch_size*32, shuffle=False)\n",
    "                val_gen_100 = SlidingWindowGenerator(X_val[:subset_size], y_val[:subset_size], window_size=100, batch_size=batch_size*32, shuffle=False)\n",
    "\n",
    "                start_train = time.time()\n",
    "                history = model.fit(train_gen_100, epochs=epochs, batch_size=batch_size*32, validation_data=val_gen_100,\n",
    "                                    verbose=1)\n",
    "                train_time = time.time() - start_train\n",
    "\n",
    "                start_time = time.time()\n",
    "                y_true = []\n",
    "                y_pred = []\n",
    "                for i in range(len(val_gen_100)):\n",
    "                    X_batch, y_batch = val_gen_100[i]  # Get a batch of data\n",
    "                    y_true.extend(y_batch)\n",
    "                    y_pred_batch = model.predict(X_batch, verbose=0).argmax(axis=-1) if not binary else (model.predict(X_batch) > 0.5).astype(int)\n",
    "                    y_pred.extend(y_pred_batch)\n",
    "                infer_time = time.time() - start_time\n",
    "\n",
    "                 # Convert y_true_flat and y_pred_flat to NumPy arrays\n",
    "                y_true_flat = np.array(y_true).flatten()\n",
    "                y_pred_flat = np.array(y_pred).flatten()\n",
    "\n",
    "                training_accs = history.history['accuracy']\n",
    "                val_accs = history.history['val_accuracy']\n",
    "                val_losses = history.history['val_loss']\n",
    "                training_loss = history.history['loss']\n",
    "\n",
    "                print(np.unique(y_true_flat))\n",
    "                print(np.unique(y_pred_flat))\n",
    "                print(len(y_true_flat))\n",
    "                print(len(y_pred_flat))\n",
    "                print(y_true_flat.shape)\n",
    "                print(y_pred_flat.shape)\n",
    "\n",
    "            elif model_name in [\"Threshold NeuroDSP\", \"Threshold Hilbert\"]:\n",
    "                # Apply neurodsp burst detection\n",
    "                start_infer = time.time()\n",
    "                y_true = y_val\n",
    "                y_pred = model_fn(X_val, is_binary=binary)\n",
    "                train_time = 0.0\n",
    "                num_params = \"N/A\"\n",
    "                infer_time = (time.time() - start_infer) / len(X_val)\n",
    "                y_true_flat = y_true.flatten()\n",
    "                y_pred_flat = y_pred.flatten()\n",
    "\n",
    "\n",
    "\n",
    "            else:\n",
    "                model = model_fn(input_shape=X_train.shape[1:], binary=binary)\n",
    "                start_train = time.time()\n",
    "                history = model.fit(X_train, y_train, epochs=epochs,\n",
    "                                    batch_size=batch_size, validation_data=(X_val, y_val),\n",
    "                                    verbose=1, callbacks=[mcc_callback])\n",
    "                train_time = time.time() - start_train\n",
    "\n",
    "                start_infer = time.time()\n",
    "                y_true = y_val\n",
    "                y_pred = model.predict(X_val).argmax(axis=-1) if not binary else (model.predict(X_val) > 0.5).astype(int)\n",
    "                infer_time = (time.time() - start_infer) / len(X_val)\n",
    "\n",
    "                val_mccs = history.history['mcc']  # Get the validation MCC values\n",
    "\n",
    "                y_true_flat = y_true.flatten()\n",
    "                y_pred_flat = y_pred.flatten()\n",
    "                training_accs = history.history['accuracy']\n",
    "                val_accs = history.history['val_accuracy']\n",
    "                val_losses = history.history['val_loss']\n",
    "                training_loss = history.history['loss']\n",
    "\n",
    "            acc_scores.append(accuracy_score(y_true_flat, y_pred_flat))\n",
    "            mcc_scores.append(matthews_corrcoef(y_true_flat, y_pred_flat))\n",
    "\n",
    "            infer_times.append(infer_time)\n",
    "            train_times.append(train_time)\n",
    "\n",
    "            if model_name not in [\"Threshold NeuroDSP\", \"Threshold Hilbert\"]:\n",
    "\n",
    "                if val_mccs:\n",
    "                  val_mcc.append(val_mccs)\n",
    "                val_accuracy.append(val_accs)\n",
    "                training_accuracy.append(training_accs)\n",
    "                training_losses.append(training_loss)\n",
    "\n",
    "                num_params = model.count_params()\n",
    "\n",
    "                model_save_path = f\"{basePath}/{dir_name}/{model_name}/{model_name}_fold_{fold+1}.h5\"\n",
    "                model.save(model_save_path)\n",
    "                trained_models[model_name].append(model_save_path)\n",
    "\n",
    "\n",
    "\n",
    "        model_results[model_name] = {\n",
    "            \"Accuracy\": {\"mean\": np.mean(acc_scores), \"std\": np.std(acc_scores), \"min\": np.min(acc_scores), \"max\": np.max(acc_scores)},\n",
    "            \"MCC\": {\"mean\": np.mean(mcc_scores), \"std\": np.std(mcc_scores), \"min\": np.min(mcc_scores), \"max\": np.max(mcc_scores)},\n",
    "            \"Train Time (s)\": {\"mean\": np.mean(train_times), \"std\": np.std(train_times), \"min\": np.min(train_times), \"max\": np.max(train_times)} if train_times else None,\n",
    "            \"Inference Time (s/sample)\": {\"mean\": np.mean(infer_times), \"std\": np.std(infer_times), \"min\": np.min(infer_times), \"max\": np.max(infer_times)},\n",
    "            \"Training Accuracy\": training_accuracy,\n",
    "            \"Training Loss\": training_losses,\n",
    "            \"Validation MCC\": val_mcc,\n",
    "            \"Validation Accuracy\": val_accuracy,\n",
    "            \"Validation Loss\": val_losses,\n",
    "            \"Parameters\": num_params\n",
    "        }\n",
    "\n",
    "        pprint(model_results[model_name], width=1)\n",
    "\n",
    "        if model_name not in [\"Threshold NeuroDSP\", \"Threshold Hilbert\"]:\n",
    "            final_model_save_path = f\"{basePath}/{dir_name}/{model_name}/{model_name}_final.h5\"\n",
    "            model.save(final_model_save_path)\n",
    "\n",
    "    return model_results, trained_models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "simple_models_dict = model_funcs_simple()"
   ],
   "metadata": {
    "id": "YqnNRP24ESDG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(simple_models_dict.keys())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYro8KTK7Xqz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1744796634293,
     "user_tz": -120,
     "elapsed": 4,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     }
    },
    "outputId": "42f67602-fcc2-441c-dd30-c869db075966",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['LSTM', 'BiLSTM', 'RNN', 'GRU', 'TCN', 'MLP'])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "basePath= \"/content/drive/MyDrive/Colab Notebooks/Bachelor Thesis/Data/Model Comparisons/Cross-Model Comparison/\""
   ],
   "metadata": {
    "id": "dcZelUQj3A7s",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "signal_data_vec_binary.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4UStBFg79Ik",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1744796588241,
     "user_tz": -120,
     "elapsed": 12,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     }
    },
    "outputId": "9ac8ef04-2104-42fd-f76e-69ef483a94ae",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3750, 500, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Binary Models\n"
   ],
   "metadata": {
    "id": "uSxHbG1i3V_W",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Signal Binary\n",
    "\n",
    "model_results, trained_models = train_and_evaluate(simple_models_dict, X=signal_data_vec_binary, y=label_binary,\n",
    "                                                   epochs=20, batch_size=32,\n",
    "                                                   basePath=basePath, dir_name='signal_binary')\n",
    "\n",
    "filePath = f\"{basePath}/Signal_Binary_Model_Results.json\"\n",
    "\n",
    "with open(filePath, 'w') as f:\n",
    "        json.dump(model_results, f, indent=4)  # indent=4 for pretty formatting"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SE5hUARxGa8q",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1744798554395,
     "user_tz": -120,
     "elapsed": 1737187,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     }
    },
    "outputId": "0c45c615-2f5e-410c-f977-b6feabe94fb2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Binary: True\n",
      "Training Model: LSTM, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.6222 - loss: 0.6540\n",
      "Epoch 1 - MCC: 0.6589\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.6230 - loss: 0.6532 - val_accuracy: 0.8299 - val_loss: 0.3922 - mcc: 0.6589\n",
      "Epoch 2/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8403 - loss: 0.3722\n",
      "Epoch 2 - MCC: 0.7232\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8405 - loss: 0.3717 - val_accuracy: 0.8620 - val_loss: 0.3272 - mcc: 0.7232\n",
      "Epoch 3/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8659 - loss: 0.3194\n",
      "Epoch 3 - MCC: 0.7517\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8659 - loss: 0.3193 - val_accuracy: 0.8760 - val_loss: 0.2986 - mcc: 0.7517\n",
      "Epoch 4/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8792 - loss: 0.2906\n",
      "Epoch 4 - MCC: 0.7648\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8792 - loss: 0.2906 - val_accuracy: 0.8827 - val_loss: 0.2829 - mcc: 0.7648\n",
      "Epoch 5/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8860 - loss: 0.2760\n",
      "Epoch 5 - MCC: 0.7744\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8858 - loss: 0.2762 - val_accuracy: 0.8874 - val_loss: 0.2748 - mcc: 0.7744\n",
      "Epoch 6/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.8854 - loss: 0.2765\n",
      "Epoch 6 - MCC: 0.7765\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - accuracy: 0.8854 - loss: 0.2764 - val_accuracy: 0.8884 - val_loss: 0.2710 - mcc: 0.7765\n",
      "Epoch 7/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8884 - loss: 0.2695\n",
      "Epoch 7 - MCC: 0.7792\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8884 - loss: 0.2695 - val_accuracy: 0.8899 - val_loss: 0.2662 - mcc: 0.7792\n",
      "Epoch 8/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8885 - loss: 0.2696\n",
      "Epoch 8 - MCC: 0.7833\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8885 - loss: 0.2696 - val_accuracy: 0.8919 - val_loss: 0.2627 - mcc: 0.7833\n",
      "Epoch 9/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8927 - loss: 0.2607\n",
      "Epoch 9 - MCC: 0.7845\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8926 - loss: 0.2609 - val_accuracy: 0.8923 - val_loss: 0.2613 - mcc: 0.7845\n",
      "Epoch 10/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8903 - loss: 0.2641\n",
      "Epoch 10 - MCC: 0.7871\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8904 - loss: 0.2640 - val_accuracy: 0.8938 - val_loss: 0.2575 - mcc: 0.7871\n",
      "Epoch 11/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.8907 - loss: 0.2638\n",
      "Epoch 11 - MCC: 0.7905\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 30ms/step - accuracy: 0.8908 - loss: 0.2636 - val_accuracy: 0.8955 - val_loss: 0.2542 - mcc: 0.7905\n",
      "Epoch 12/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8928 - loss: 0.2587\n",
      "Epoch 12 - MCC: 0.7922\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 25ms/step - accuracy: 0.8928 - loss: 0.2587 - val_accuracy: 0.8963 - val_loss: 0.2539 - mcc: 0.7922\n",
      "Epoch 13/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8956 - loss: 0.2532\n",
      "Epoch 13 - MCC: 0.7914\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8955 - loss: 0.2532 - val_accuracy: 0.8960 - val_loss: 0.2526 - mcc: 0.7914\n",
      "Epoch 14/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8967 - loss: 0.2497\n",
      "Epoch 14 - MCC: 0.7919\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8967 - loss: 0.2498 - val_accuracy: 0.8962 - val_loss: 0.2516 - mcc: 0.7919\n",
      "Epoch 15/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8953 - loss: 0.2522\n",
      "Epoch 15 - MCC: 0.7964\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8953 - loss: 0.2522 - val_accuracy: 0.8984 - val_loss: 0.2489 - mcc: 0.7964\n",
      "Epoch 16/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8930 - loss: 0.2572\n",
      "Epoch 16 - MCC: 0.7965\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 26ms/step - accuracy: 0.8930 - loss: 0.2572 - val_accuracy: 0.8984 - val_loss: 0.2498 - mcc: 0.7965\n",
      "Epoch 17/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8960 - loss: 0.2513\n",
      "Epoch 17 - MCC: 0.7962\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 26ms/step - accuracy: 0.8960 - loss: 0.2513 - val_accuracy: 0.8982 - val_loss: 0.2477 - mcc: 0.7962\n",
      "Epoch 18/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8946 - loss: 0.2540\n",
      "Epoch 18 - MCC: 0.7944\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - accuracy: 0.8946 - loss: 0.2539 - val_accuracy: 0.8973 - val_loss: 0.2480 - mcc: 0.7944\n",
      "Epoch 19/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8982 - loss: 0.2462\n",
      "Epoch 19 - MCC: 0.7990\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8982 - loss: 0.2462 - val_accuracy: 0.8997 - val_loss: 0.2464 - mcc: 0.7990\n",
      "Epoch 20/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8975 - loss: 0.2477\n",
      "Epoch 20 - MCC: 0.8002\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8975 - loss: 0.2477 - val_accuracy: 0.9002 - val_loss: 0.2439 - mcc: 0.8002\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.6246 - loss: 0.6448\n",
      "Epoch 1 - MCC: 0.6283\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 46ms/step - accuracy: 0.6254 - loss: 0.6440 - val_accuracy: 0.8142 - val_loss: 0.4345 - mcc: 0.6283\n",
      "Epoch 2/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8213 - loss: 0.4084\n",
      "Epoch 2 - MCC: 0.6917\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - accuracy: 0.8214 - loss: 0.4082 - val_accuracy: 0.8464 - val_loss: 0.3566 - mcc: 0.6917\n",
      "Epoch 3/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8491 - loss: 0.3490\n",
      "Epoch 3 - MCC: 0.7296\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8492 - loss: 0.3487 - val_accuracy: 0.8650 - val_loss: 0.3193 - mcc: 0.7296\n",
      "Epoch 4/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8664 - loss: 0.3163\n",
      "Epoch 4 - MCC: 0.7566\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8665 - loss: 0.3161 - val_accuracy: 0.8787 - val_loss: 0.2920 - mcc: 0.7566\n",
      "Epoch 5/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8781 - loss: 0.2923\n",
      "Epoch 5 - MCC: 0.7614\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8781 - loss: 0.2923 - val_accuracy: 0.8811 - val_loss: 0.2866 - mcc: 0.7614\n",
      "Epoch 6/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8808 - loss: 0.2858\n",
      "Epoch 6 - MCC: 0.7715\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 26ms/step - accuracy: 0.8809 - loss: 0.2857 - val_accuracy: 0.8860 - val_loss: 0.2762 - mcc: 0.7715\n",
      "Epoch 7/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8878 - loss: 0.2712\n",
      "Epoch 7 - MCC: 0.7745\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - accuracy: 0.8878 - loss: 0.2713 - val_accuracy: 0.8874 - val_loss: 0.2712 - mcc: 0.7745\n",
      "Epoch 8/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8873 - loss: 0.2724\n",
      "Epoch 8 - MCC: 0.7771\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8873 - loss: 0.2724 - val_accuracy: 0.8888 - val_loss: 0.2679 - mcc: 0.7771\n",
      "Epoch 9/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8908 - loss: 0.2646\n",
      "Epoch 9 - MCC: 0.7814\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 21ms/step - accuracy: 0.8908 - loss: 0.2648 - val_accuracy: 0.8910 - val_loss: 0.2630 - mcc: 0.7814\n",
      "Epoch 10/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8880 - loss: 0.2699\n",
      "Epoch 10 - MCC: 0.7823\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8880 - loss: 0.2698 - val_accuracy: 0.8915 - val_loss: 0.2618 - mcc: 0.7823\n",
      "Epoch 11/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8944 - loss: 0.2572\n",
      "Epoch 11 - MCC: 0.7820\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 25ms/step - accuracy: 0.8943 - loss: 0.2573 - val_accuracy: 0.8913 - val_loss: 0.2619 - mcc: 0.7820\n",
      "Epoch 12/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8896 - loss: 0.2656\n",
      "Epoch 12 - MCC: 0.7847\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 29ms/step - accuracy: 0.8897 - loss: 0.2655 - val_accuracy: 0.8927 - val_loss: 0.2585 - mcc: 0.7847\n",
      "Epoch 13/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8914 - loss: 0.2625\n",
      "Epoch 13 - MCC: 0.7881\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - accuracy: 0.8914 - loss: 0.2625 - val_accuracy: 0.8944 - val_loss: 0.2556 - mcc: 0.7881\n",
      "Epoch 14/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8913 - loss: 0.2616\n",
      "Epoch 14 - MCC: 0.7855\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8913 - loss: 0.2616 - val_accuracy: 0.8931 - val_loss: 0.2579 - mcc: 0.7855\n",
      "Epoch 15/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8950 - loss: 0.2546\n",
      "Epoch 15 - MCC: 0.7887\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - accuracy: 0.8950 - loss: 0.2546 - val_accuracy: 0.8946 - val_loss: 0.2549 - mcc: 0.7887\n",
      "Epoch 16/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8920 - loss: 0.2585\n",
      "Epoch 16 - MCC: 0.7897\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - accuracy: 0.8921 - loss: 0.2584 - val_accuracy: 0.8951 - val_loss: 0.2525 - mcc: 0.7897\n",
      "Epoch 17/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8931 - loss: 0.2572\n",
      "Epoch 17 - MCC: 0.7870\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 29ms/step - accuracy: 0.8931 - loss: 0.2571 - val_accuracy: 0.8938 - val_loss: 0.2557 - mcc: 0.7870\n",
      "Epoch 18/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8928 - loss: 0.2568\n",
      "Epoch 18 - MCC: 0.7911\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.8929 - loss: 0.2567 - val_accuracy: 0.8958 - val_loss: 0.2506 - mcc: 0.7911\n",
      "Epoch 19/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8957 - loss: 0.2522\n",
      "Epoch 19 - MCC: 0.7921\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8957 - loss: 0.2522 - val_accuracy: 0.8964 - val_loss: 0.2494 - mcc: 0.7921\n",
      "Epoch 20/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8974 - loss: 0.2474\n",
      "Epoch 20 - MCC: 0.7938\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8973 - loss: 0.2475 - val_accuracy: 0.8972 - val_loss: 0.2469 - mcc: 0.7938\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.6156 - loss: 0.6548\n",
      "Epoch 1 - MCC: 0.6227\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 29ms/step - accuracy: 0.6164 - loss: 0.6540 - val_accuracy: 0.8121 - val_loss: 0.4403 - mcc: 0.6227\n",
      "Epoch 2/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8242 - loss: 0.4069\n",
      "Epoch 2 - MCC: 0.6912\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8245 - loss: 0.4062 - val_accuracy: 0.8462 - val_loss: 0.3558 - mcc: 0.6912\n",
      "Epoch 3/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8573 - loss: 0.3365\n",
      "Epoch 3 - MCC: 0.7418\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 21ms/step - accuracy: 0.8574 - loss: 0.3364 - val_accuracy: 0.8714 - val_loss: 0.3104 - mcc: 0.7418\n",
      "Epoch 4/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8791 - loss: 0.2946\n",
      "Epoch 4 - MCC: 0.7542\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 19ms/step - accuracy: 0.8791 - loss: 0.2946 - val_accuracy: 0.8775 - val_loss: 0.2941 - mcc: 0.7542\n",
      "Epoch 5/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8800 - loss: 0.2895\n",
      "Epoch 5 - MCC: 0.7588\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8801 - loss: 0.2893 - val_accuracy: 0.8797 - val_loss: 0.2893 - mcc: 0.7588\n",
      "Epoch 6/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8872 - loss: 0.2744\n",
      "Epoch 6 - MCC: 0.7660\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - accuracy: 0.8871 - loss: 0.2745 - val_accuracy: 0.8832 - val_loss: 0.2813 - mcc: 0.7660\n",
      "Epoch 7/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8869 - loss: 0.2736\n",
      "Epoch 7 - MCC: 0.7686\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 22ms/step - accuracy: 0.8869 - loss: 0.2736 - val_accuracy: 0.8848 - val_loss: 0.2776 - mcc: 0.7686\n",
      "Epoch 8/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8889 - loss: 0.2704\n",
      "Epoch 8 - MCC: 0.7670\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8889 - loss: 0.2704 - val_accuracy: 0.8838 - val_loss: 0.2806 - mcc: 0.7670\n",
      "Epoch 9/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8906 - loss: 0.2658\n",
      "Epoch 9 - MCC: 0.7739\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8906 - loss: 0.2658 - val_accuracy: 0.8873 - val_loss: 0.2713 - mcc: 0.7739\n",
      "Epoch 10/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8904 - loss: 0.2646\n",
      "Epoch 10 - MCC: 0.7728\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - accuracy: 0.8904 - loss: 0.2647 - val_accuracy: 0.8868 - val_loss: 0.2743 - mcc: 0.7728\n",
      "Epoch 11/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8916 - loss: 0.2632\n",
      "Epoch 11 - MCC: 0.7768\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8916 - loss: 0.2632 - val_accuracy: 0.8888 - val_loss: 0.2685 - mcc: 0.7768\n",
      "Epoch 12/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8938 - loss: 0.2572\n",
      "Epoch 12 - MCC: 0.7721\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8937 - loss: 0.2573 - val_accuracy: 0.8863 - val_loss: 0.2737 - mcc: 0.7721\n",
      "Epoch 13/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8927 - loss: 0.2594\n",
      "Epoch 13 - MCC: 0.7771\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8927 - loss: 0.2595 - val_accuracy: 0.8889 - val_loss: 0.2669 - mcc: 0.7771\n",
      "Epoch 14/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8926 - loss: 0.2592\n",
      "Epoch 14 - MCC: 0.7803\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - accuracy: 0.8926 - loss: 0.2592 - val_accuracy: 0.8905 - val_loss: 0.2646 - mcc: 0.7803\n",
      "Epoch 15/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8945 - loss: 0.2565\n",
      "Epoch 15 - MCC: 0.7796\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 26ms/step - accuracy: 0.8945 - loss: 0.2565 - val_accuracy: 0.8902 - val_loss: 0.2640 - mcc: 0.7796\n",
      "Epoch 16/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8944 - loss: 0.2559\n",
      "Epoch 16 - MCC: 0.7799\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 27ms/step - accuracy: 0.8944 - loss: 0.2558 - val_accuracy: 0.8903 - val_loss: 0.2629 - mcc: 0.7799\n",
      "Epoch 17/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8948 - loss: 0.2537\n",
      "Epoch 17 - MCC: 0.7795\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 22ms/step - accuracy: 0.8948 - loss: 0.2537 - val_accuracy: 0.8902 - val_loss: 0.2633 - mcc: 0.7795\n",
      "Epoch 18/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8944 - loss: 0.2551\n",
      "Epoch 18 - MCC: 0.7802\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8944 - loss: 0.2550 - val_accuracy: 0.8903 - val_loss: 0.2637 - mcc: 0.7802\n",
      "Epoch 19/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8967 - loss: 0.2504\n",
      "Epoch 19 - MCC: 0.7792\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8967 - loss: 0.2505 - val_accuracy: 0.8899 - val_loss: 0.2642 - mcc: 0.7792\n",
      "Epoch 20/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.8967 - loss: 0.2500\n",
      "Epoch 20 - MCC: 0.7815\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 29ms/step - accuracy: 0.8967 - loss: 0.2500 - val_accuracy: 0.8912 - val_loss: 0.2602 - mcc: 0.7815\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6364 - loss: 0.6426\n",
      "Epoch 1 - MCC: 0.6355\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 28ms/step - accuracy: 0.6380 - loss: 0.6410 - val_accuracy: 0.8184 - val_loss: 0.4178 - mcc: 0.6355\n",
      "Epoch 2/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8259 - loss: 0.3992\n",
      "Epoch 2 - MCC: 0.7051\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8262 - loss: 0.3986 - val_accuracy: 0.8530 - val_loss: 0.3542 - mcc: 0.7051\n",
      "Epoch 3/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8562 - loss: 0.3395\n",
      "Epoch 3 - MCC: 0.7282\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 19ms/step - accuracy: 0.8562 - loss: 0.3394 - val_accuracy: 0.8642 - val_loss: 0.3232 - mcc: 0.7282\n",
      "Epoch 4/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8684 - loss: 0.3137\n",
      "Epoch 4 - MCC: 0.7508\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 25ms/step - accuracy: 0.8684 - loss: 0.3137 - val_accuracy: 0.8757 - val_loss: 0.2975 - mcc: 0.7508\n",
      "Epoch 5/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8781 - loss: 0.2932\n",
      "Epoch 5 - MCC: 0.7676\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 25ms/step - accuracy: 0.8781 - loss: 0.2932 - val_accuracy: 0.8841 - val_loss: 0.2820 - mcc: 0.7676\n",
      "Epoch 6/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8828 - loss: 0.2824\n",
      "Epoch 6 - MCC: 0.7733\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - accuracy: 0.8828 - loss: 0.2823 - val_accuracy: 0.8868 - val_loss: 0.2759 - mcc: 0.7733\n",
      "Epoch 7/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8860 - loss: 0.2753\n",
      "Epoch 7 - MCC: 0.7722\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 21ms/step - accuracy: 0.8860 - loss: 0.2753 - val_accuracy: 0.8864 - val_loss: 0.2740 - mcc: 0.7722\n",
      "Epoch 8/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8878 - loss: 0.2707\n",
      "Epoch 8 - MCC: 0.7813\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 21ms/step - accuracy: 0.8878 - loss: 0.2707 - val_accuracy: 0.8909 - val_loss: 0.2663 - mcc: 0.7813\n",
      "Epoch 9/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8889 - loss: 0.2685\n",
      "Epoch 9 - MCC: 0.7800\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8889 - loss: 0.2685 - val_accuracy: 0.8903 - val_loss: 0.2652 - mcc: 0.7800\n",
      "Epoch 10/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8905 - loss: 0.2648\n",
      "Epoch 10 - MCC: 0.7792\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - accuracy: 0.8905 - loss: 0.2648 - val_accuracy: 0.8899 - val_loss: 0.2661 - mcc: 0.7792\n",
      "Epoch 11/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8943 - loss: 0.2573\n",
      "Epoch 11 - MCC: 0.7853\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8942 - loss: 0.2575 - val_accuracy: 0.8930 - val_loss: 0.2600 - mcc: 0.7853\n",
      "Epoch 12/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8920 - loss: 0.2618\n",
      "Epoch 12 - MCC: 0.7867\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8920 - loss: 0.2618 - val_accuracy: 0.8936 - val_loss: 0.2581 - mcc: 0.7867\n",
      "Epoch 13/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8929 - loss: 0.2591\n",
      "Epoch 13 - MCC: 0.7875\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - accuracy: 0.8929 - loss: 0.2591 - val_accuracy: 0.8941 - val_loss: 0.2559 - mcc: 0.7875\n",
      "Epoch 14/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8943 - loss: 0.2541\n",
      "Epoch 14 - MCC: 0.7895\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8943 - loss: 0.2542 - val_accuracy: 0.8948 - val_loss: 0.2555 - mcc: 0.7895\n",
      "Epoch 15/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8971 - loss: 0.2510\n",
      "Epoch 15 - MCC: 0.7895\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 24ms/step - accuracy: 0.8970 - loss: 0.2511 - val_accuracy: 0.8951 - val_loss: 0.2543 - mcc: 0.7895\n",
      "Epoch 16/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8956 - loss: 0.2519\n",
      "Epoch 16 - MCC: 0.7910\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 26ms/step - accuracy: 0.8956 - loss: 0.2519 - val_accuracy: 0.8958 - val_loss: 0.2519 - mcc: 0.7910\n",
      "Epoch 17/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8946 - loss: 0.2536\n",
      "Epoch 17 - MCC: 0.7922\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8946 - loss: 0.2535 - val_accuracy: 0.8964 - val_loss: 0.2501 - mcc: 0.7922\n",
      "Epoch 18/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8964 - loss: 0.2496\n",
      "Epoch 18 - MCC: 0.7934\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8964 - loss: 0.2497 - val_accuracy: 0.8969 - val_loss: 0.2494 - mcc: 0.7934\n",
      "Epoch 19/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8959 - loss: 0.2511\n",
      "Epoch 19 - MCC: 0.7934\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8959 - loss: 0.2510 - val_accuracy: 0.8970 - val_loss: 0.2497 - mcc: 0.7934\n",
      "Epoch 20/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8960 - loss: 0.2496\n",
      "Epoch 20 - MCC: 0.7947\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8960 - loss: 0.2496 - val_accuracy: 0.8977 - val_loss: 0.2473 - mcc: 0.7947\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.6307 - loss: 0.6469\n",
      "Epoch 1 - MCC: 0.6585\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 29ms/step - accuracy: 0.6333 - loss: 0.6443 - val_accuracy: 0.8300 - val_loss: 0.3993 - mcc: 0.6585\n",
      "Epoch 2/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8375 - loss: 0.3775\n",
      "Epoch 2 - MCC: 0.7115\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - accuracy: 0.8376 - loss: 0.3774 - val_accuracy: 0.8563 - val_loss: 0.3369 - mcc: 0.7115\n",
      "Epoch 3/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8645 - loss: 0.3221\n",
      "Epoch 3 - MCC: 0.7448\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 21ms/step - accuracy: 0.8646 - loss: 0.3218 - val_accuracy: 0.8729 - val_loss: 0.3027 - mcc: 0.7448\n",
      "Epoch 4/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8772 - loss: 0.2948\n",
      "Epoch 4 - MCC: 0.7569\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8772 - loss: 0.2948 - val_accuracy: 0.8787 - val_loss: 0.2877 - mcc: 0.7569\n",
      "Epoch 5/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8820 - loss: 0.2840\n",
      "Epoch 5 - MCC: 0.7695\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 25ms/step - accuracy: 0.8820 - loss: 0.2840 - val_accuracy: 0.8852 - val_loss: 0.2763 - mcc: 0.7695\n",
      "Epoch 6/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8840 - loss: 0.2788\n",
      "Epoch 6 - MCC: 0.7707\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 25ms/step - accuracy: 0.8840 - loss: 0.2787 - val_accuracy: 0.8857 - val_loss: 0.2741 - mcc: 0.7707\n",
      "Epoch 7/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8891 - loss: 0.2688\n",
      "Epoch 7 - MCC: 0.7733\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8891 - loss: 0.2689 - val_accuracy: 0.8868 - val_loss: 0.2711 - mcc: 0.7733\n",
      "Epoch 8/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8906 - loss: 0.2640\n",
      "Epoch 8 - MCC: 0.7764\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8906 - loss: 0.2641 - val_accuracy: 0.8886 - val_loss: 0.2685 - mcc: 0.7764\n",
      "Epoch 9/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8904 - loss: 0.2639\n",
      "Epoch 9 - MCC: 0.7793\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 19ms/step - accuracy: 0.8904 - loss: 0.2639 - val_accuracy: 0.8900 - val_loss: 0.2648 - mcc: 0.7793\n",
      "Epoch 10/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8936 - loss: 0.2591\n",
      "Epoch 10 - MCC: 0.7808\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 21ms/step - accuracy: 0.8935 - loss: 0.2592 - val_accuracy: 0.8908 - val_loss: 0.2631 - mcc: 0.7808\n",
      "Epoch 11/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8905 - loss: 0.2643\n",
      "Epoch 11 - MCC: 0.7821\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 29ms/step - accuracy: 0.8905 - loss: 0.2642 - val_accuracy: 0.8914 - val_loss: 0.2611 - mcc: 0.7821\n",
      "Epoch 12/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8921 - loss: 0.2605\n",
      "Epoch 12 - MCC: 0.7819\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 19ms/step - accuracy: 0.8921 - loss: 0.2604 - val_accuracy: 0.8913 - val_loss: 0.2613 - mcc: 0.7819\n",
      "Epoch 13/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8941 - loss: 0.2559\n",
      "Epoch 13 - MCC: 0.7867\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 21ms/step - accuracy: 0.8941 - loss: 0.2559 - val_accuracy: 0.8937 - val_loss: 0.2564 - mcc: 0.7867\n",
      "Epoch 14/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8945 - loss: 0.2555\n",
      "Epoch 14 - MCC: 0.7863\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 21ms/step - accuracy: 0.8945 - loss: 0.2555 - val_accuracy: 0.8935 - val_loss: 0.2560 - mcc: 0.7863\n",
      "Epoch 15/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8964 - loss: 0.2507\n",
      "Epoch 15 - MCC: 0.7886\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - accuracy: 0.8963 - loss: 0.2507 - val_accuracy: 0.8947 - val_loss: 0.2527 - mcc: 0.7886\n",
      "Epoch 16/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8973 - loss: 0.2502\n",
      "Epoch 16 - MCC: 0.7908\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - accuracy: 0.8973 - loss: 0.2502 - val_accuracy: 0.8956 - val_loss: 0.2503 - mcc: 0.7908\n",
      "Epoch 17/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8965 - loss: 0.2504\n",
      "Epoch 17 - MCC: 0.7905\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 23ms/step - accuracy: 0.8965 - loss: 0.2503 - val_accuracy: 0.8956 - val_loss: 0.2507 - mcc: 0.7905\n",
      "Epoch 18/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8976 - loss: 0.2483\n",
      "Epoch 18 - MCC: 0.7896\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8976 - loss: 0.2482 - val_accuracy: 0.8952 - val_loss: 0.2507 - mcc: 0.7896\n",
      "Epoch 19/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8965 - loss: 0.2503\n",
      "Epoch 19 - MCC: 0.7932\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8966 - loss: 0.2502 - val_accuracy: 0.8969 - val_loss: 0.2479 - mcc: 0.7932\n",
      "Epoch 20/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8977 - loss: 0.2482\n",
      "Epoch 20 - MCC: 0.7912\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - accuracy: 0.8977 - loss: 0.2480 - val_accuracy: 0.8960 - val_loss: 0.2482 - mcc: 0.7912\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.9002453333333333),\n",
      "              'mean': np.float64(0.8964538666666666),\n",
      "              'min': np.float64(0.89116),\n",
      "              'std': np.float64(0.0029911030860054377)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.0004672295252482096),\n",
      "                               'mean': np.float64(0.00039638462066650393),\n",
      "                               'min': np.float64(0.00031096649169921875),\n",
      "                               'std': np.float64(6.83968018553403e-05)},\n",
      " 'MCC': {'max': np.float64(0.8002171546363468),\n",
      "         'mean': np.float64(0.7922902353796175),\n",
      "         'min': np.float64(0.7815136006935063),\n",
      "         'std': np.float64(0.006141154997829237)},\n",
      " 'Parameters': 4385,\n",
      " 'Train Time (s)': {'max': np.float64(55.9499614238739),\n",
      "                    'mean': np.float64(53.26328263282776),\n",
      "                    'min': np.float64(49.41970419883728),\n",
      "                    'std': np.float64(2.420584402593524)},\n",
      " 'Training Accuracy': [[0.7002634406089783,\n",
      "                        0.8477667570114136,\n",
      "                        0.8695380091667175,\n",
      "                        0.8786988258361816,\n",
      "                        0.8832440376281738,\n",
      "                        0.8860484957695007,\n",
      "                        0.887993335723877,\n",
      "                        0.8890339136123657,\n",
      "                        0.8902028799057007,\n",
      "                        0.8917739987373352,\n",
      "                        0.8922203779220581,\n",
      "                        0.893707275390625,\n",
      "                        0.8939508199691772,\n",
      "                        0.8951080441474915,\n",
      "                        0.8958488702774048,\n",
      "                        0.8962749242782593,\n",
      "                        0.8967131972312927,\n",
      "                        0.8976999521255493,\n",
      "                        0.8980114459991455,\n",
      "                        0.898019552230835],\n",
      "                       [0.7003594040870667,\n",
      "                        0.8303762078285217,\n",
      "                        0.854052722454071,\n",
      "                        0.8704773783683777,\n",
      "                        0.8784905076026917,\n",
      "                        0.8825759291648865,\n",
      "                        0.8853499889373779,\n",
      "                        0.8866772651672363,\n",
      "                        0.8885219693183899,\n",
      "                        0.8894088268280029,\n",
      "                        0.8905172348022461,\n",
      "                        0.8910313248634338,\n",
      "                        0.8918633460998535,\n",
      "                        0.892599880695343,\n",
      "                        0.8928959369659424,\n",
      "                        0.8939483761787415,\n",
      "                        0.8940963745117188,\n",
      "                        0.8946700692176819,\n",
      "                        0.8949620127677917,\n",
      "                        0.8956432938575745],\n",
      "                       [0.6892299652099609,\n",
      "                        0.8335686922073364,\n",
      "                        0.8636006712913513,\n",
      "                        0.8785539269447327,\n",
      "                        0.8832286596298218,\n",
      "                        0.886287271976471,\n",
      "                        0.8877365589141846,\n",
      "                        0.8897380232810974,\n",
      "                        0.8900244832038879,\n",
      "                        0.8900699019432068,\n",
      "                        0.8920454978942871,\n",
      "                        0.8920325636863708,\n",
      "                        0.8925079107284546,\n",
      "                        0.8933840990066528,\n",
      "                        0.8941666483879089,\n",
      "                        0.8950820565223694,\n",
      "                        0.894707202911377,\n",
      "                        0.8955419659614563,\n",
      "                        0.8957501649856567,\n",
      "                        0.8961839079856873],\n",
      "                       [0.711286723613739,\n",
      "                        0.8354973793029785,\n",
      "                        0.8579928278923035,\n",
      "                        0.8723053336143494,\n",
      "                        0.8784145712852478,\n",
      "                        0.884232759475708,\n",
      "                        0.8864051699638367,\n",
      "                        0.8878584504127502,\n",
      "                        0.8890864849090576,\n",
      "                        0.890525221824646,\n",
      "                        0.8913084864616394,\n",
      "                        0.8922960758209229,\n",
      "                        0.8930577635765076,\n",
      "                        0.8934299945831299,\n",
      "                        0.8940693140029907,\n",
      "                        0.8947388529777527,\n",
      "                        0.8950313329696655,\n",
      "                        0.8958078622817993,\n",
      "                        0.8962278366088867,\n",
      "                        0.896488606929779],\n",
      "                       [0.7124260067939758,\n",
      "                        0.8452118039131165,\n",
      "                        0.8670340776443481,\n",
      "                        0.8777807354927063,\n",
      "                        0.8835992217063904,\n",
      "                        0.8865004777908325,\n",
      "                        0.8881343007087708,\n",
      "                        0.889460027217865,\n",
      "                        0.8906593322753906,\n",
      "                        0.8916100859642029,\n",
      "                        0.892614483833313,\n",
      "                        0.892922043800354,\n",
      "                        0.8944854140281677,\n",
      "                        0.8949134349822998,\n",
      "                        0.8958876132965088,\n",
      "                        0.8968481421470642,\n",
      "                        0.8968780636787415,\n",
      "                        0.8977559208869934,\n",
      "                        0.8984237313270569,\n",
      "                        0.8992167711257935]],\n",
      " 'Training Loss': [[0.5764443874359131,\n",
      "                    0.35547390580177307,\n",
      "                    0.31185755133628845,\n",
      "                    0.29117152094841003,\n",
      "                    0.28113770484924316,\n",
      "                    0.27488845586776733,\n",
      "                    0.27034512162208557,\n",
      "                    0.2677615284919739,\n",
      "                    0.2652420997619629,\n",
      "                    0.26149091124534607,\n",
      "                    0.2597576081752777,\n",
      "                    0.25692084431648254,\n",
      "                    0.25582370162010193,\n",
      "                    0.253570556640625,\n",
      "                    0.2514089047908783,\n",
      "                    0.2505922317504883,\n",
      "                    0.24948762357234955,\n",
      "                    0.24776336550712585,\n",
      "                    0.24643518030643463,\n",
      "                    0.24598559737205505],\n",
      "                   [0.5738010406494141,\n",
      "                    0.39027661085128784,\n",
      "                    0.33995145559310913,\n",
      "                    0.3079552948474884,\n",
      "                    0.29090189933776855,\n",
      "                    0.2821390926837921,\n",
      "                    0.2764807641506195,\n",
      "                    0.2731121778488159,\n",
      "                    0.26883089542388916,\n",
      "                    0.26671209931373596,\n",
      "                    0.26421302556991577,\n",
      "                    0.2629809081554413,\n",
      "                    0.26084190607070923,\n",
      "                    0.2596279978752136,\n",
      "                    0.25867703557014465,\n",
      "                    0.25576046109199524,\n",
      "                    0.2550782561302185,\n",
      "                    0.25338485836982727,\n",
      "                    0.25236958265304565,\n",
      "                    0.2507660388946533],\n",
      "                   [0.5858787894248962,\n",
      "                    0.3853529393672943,\n",
      "                    0.324765682220459,\n",
      "                    0.2938605844974518,\n",
      "                    0.2826422452926636,\n",
      "                    0.2756182849407196,\n",
      "                    0.2723481357097626,\n",
      "                    0.2679339349269867,\n",
      "                    0.26671674847602844,\n",
      "                    0.265983909368515,\n",
      "                    0.2622320353984833,\n",
      "                    0.26159030199050903,\n",
      "                    0.2599991261959076,\n",
      "                    0.2585429847240448,\n",
      "                    0.25666698813438416,\n",
      "                    0.2544211745262146,\n",
      "                    0.2547239661216736,\n",
      "                    0.25301221013069153,\n",
      "                    0.2525500953197479,\n",
      "                    0.2513003945350647],\n",
      "                   [0.5654569268226624,\n",
      "                    0.3805592954158783,\n",
      "                    0.3348170816898346,\n",
      "                    0.30519336462020874,\n",
      "                    0.29203832149505615,\n",
      "                    0.27928921580314636,\n",
      "                    0.274483323097229,\n",
      "                    0.27080437541007996,\n",
      "                    0.26775816082954407,\n",
      "                    0.2645830512046814,\n",
      "                    0.26247575879096985,\n",
      "                    0.2607012391090393,\n",
      "                    0.2581948935985565,\n",
      "                    0.25683116912841797,\n",
      "                    0.255489319562912,\n",
      "                    0.2535029947757721,\n",
      "                    0.2525540292263031,\n",
      "                    0.2513538897037506,\n",
      "                    0.2495858520269394,\n",
      "                    0.24859029054641724],\n",
      "                   [0.5634174942970276,\n",
      "                    0.3600037097930908,\n",
      "                    0.31580260396003723,\n",
      "                    0.2936002314090729,\n",
      "                    0.2808917760848999,\n",
      "                    0.27421659231185913,\n",
      "                    0.2701597511768341,\n",
      "                    0.2665911614894867,\n",
      "                    0.26436176896095276,\n",
      "                    0.2621161639690399,\n",
      "                    0.2598663866519928,\n",
      "                    0.25853514671325684,\n",
      "                    0.25585344433784485,\n",
      "                    0.25482118129730225,\n",
      "                    0.25228622555732727,\n",
      "                    0.2505849301815033,\n",
      "                    0.24963101744651794,\n",
      "                    0.24747762084007263,\n",
      "                    0.24619369208812714,\n",
      "                    0.24438099563121796]],\n",
      " 'Validation Accuracy': [[0.8299333453178406,\n",
      "                          0.8619921207427979,\n",
      "                          0.875986635684967,\n",
      "                          0.8826826214790344,\n",
      "                          0.8874239921569824,\n",
      "                          0.8883891701698303,\n",
      "                          0.8899279236793518,\n",
      "                          0.8919038772583008,\n",
      "                          0.8923121094703674,\n",
      "                          0.89383465051651,\n",
      "                          0.8955174088478088,\n",
      "                          0.8962506651878357,\n",
      "                          0.8960052728652954,\n",
      "                          0.8961840271949768,\n",
      "                          0.8984426259994507,\n",
      "                          0.8983546495437622,\n",
      "                          0.8981786370277405,\n",
      "                          0.8973013758659363,\n",
      "                          0.8996719717979431,\n",
      "                          0.9002453684806824],\n",
      "                         [0.8142426609992981,\n",
      "                          0.8463573455810547,\n",
      "                          0.8649706840515137,\n",
      "                          0.8786773085594177,\n",
      "                          0.8810907602310181,\n",
      "                          0.8860426545143127,\n",
      "                          0.8873999118804932,\n",
      "                          0.8888266682624817,\n",
      "                          0.8909760117530823,\n",
      "                          0.8914797902107239,\n",
      "                          0.8913252949714661,\n",
      "                          0.8926907777786255,\n",
      "                          0.8943573236465454,\n",
      "                          0.8930826783180237,\n",
      "                          0.8946161270141602,\n",
      "                          0.8950880765914917,\n",
      "                          0.8937865495681763,\n",
      "                          0.8958425521850586,\n",
      "                          0.8963760733604431,\n",
      "                          0.8972318768501282],\n",
      "                         [0.8121092319488525,\n",
      "                          0.8462052941322327,\n",
      "                          0.8713811635971069,\n",
      "                          0.8775440454483032,\n",
      "                          0.8797121047973633,\n",
      "                          0.8832293152809143,\n",
      "                          0.8847573399543762,\n",
      "                          0.8837679028511047,\n",
      "                          0.8873466849327087,\n",
      "                          0.8868239521980286,\n",
      "                          0.8888106346130371,\n",
      "                          0.886266827583313,\n",
      "                          0.888856053352356,\n",
      "                          0.8905120491981506,\n",
      "                          0.8902267813682556,\n",
      "                          0.8903494477272034,\n",
      "                          0.8901678919792175,\n",
      "                          0.8902612924575806,\n",
      "                          0.8899468779563904,\n",
      "                          0.8911598920822144],\n",
      "                         [0.8183600306510925,\n",
      "                          0.8530080318450928,\n",
      "                          0.8641626238822937,\n",
      "                          0.8756613731384277,\n",
      "                          0.8841359615325928,\n",
      "                          0.8867546319961548,\n",
      "                          0.8864267468452454,\n",
      "                          0.8909013867378235,\n",
      "                          0.8902933597564697,\n",
      "                          0.8899492025375366,\n",
      "                          0.8929519653320312,\n",
      "                          0.8936346769332886,\n",
      "                          0.8940934538841248,\n",
      "                          0.8948453664779663,\n",
      "                          0.8950880765914917,\n",
      "                          0.8958027958869934,\n",
      "                          0.8964399695396423,\n",
      "                          0.8969094157218933,\n",
      "                          0.896997332572937,\n",
      "                          0.8976719379425049],\n",
      "                         [0.8299518823623657,\n",
      "                          0.8563093543052673,\n",
      "                          0.8728612661361694,\n",
      "                          0.8787438869476318,\n",
      "                          0.885165274143219,\n",
      "                          0.885693371295929,\n",
      "                          0.8868054151535034,\n",
      "                          0.8886052966117859,\n",
      "                          0.8900134563446045,\n",
      "                          0.8907840847969055,\n",
      "                          0.8914480209350586,\n",
      "                          0.8912879228591919,\n",
      "                          0.8937119245529175,\n",
      "                          0.893519937992096,\n",
      "                          0.8946800231933594,\n",
      "                          0.8956372737884521,\n",
      "                          0.8955758213996887,\n",
      "                          0.8951999545097351,\n",
      "                          0.8969040513038635,\n",
      "                          0.8959599733352661]],\n",
      " 'Validation Loss': [0.3993135690689087,\n",
      "                     0.33686503767967224,\n",
      "                     0.3026803731918335,\n",
      "                     0.28768467903137207,\n",
      "                     0.2762894332408905,\n",
      "                     0.2740759253501892,\n",
      "                     0.2711191475391388,\n",
      "                     0.26851916313171387,\n",
      "                     0.26481547951698303,\n",
      "                     0.26305943727493286,\n",
      "                     0.2611291706562042,\n",
      "                     0.2613047957420349,\n",
      "                     0.2563856840133667,\n",
      "                     0.2560184597969055,\n",
      "                     0.2527008354663849,\n",
      "                     0.25027501583099365,\n",
      "                     0.25070008635520935,\n",
      "                     0.2507045865058899,\n",
      "                     0.24791912734508514,\n",
      "                     0.2482260763645172],\n",
      " 'Validation MCC': [[np.float64(0.6588783518393405),\n",
      "                     np.float64(0.7231599259469845),\n",
      "                     np.float64(0.751687328920615),\n",
      "                     np.float64(0.7648116195264925),\n",
      "                     np.float64(0.7743836854944632),\n",
      "                     np.float64(0.7765144598057308),\n",
      "                     np.float64(0.7792475161775659),\n",
      "                     np.float64(0.7832886927245781),\n",
      "                     np.float64(0.7845197632902836),\n",
      "                     np.float64(0.7870597602648003),\n",
      "                     np.float64(0.7904800147128165),\n",
      "                     np.float64(0.7921829670076426),\n",
      "                     np.float64(0.7914100422312002),\n",
      "                     np.float64(0.7919488255334524),\n",
      "                     np.float64(0.7963516526166227),\n",
      "                     np.float64(0.7965061631337108),\n",
      "                     np.float64(0.796151596884978),\n",
      "                     np.float64(0.7944499020326179),\n",
      "                     np.float64(0.7990307648296247),\n",
      "                     np.float64(0.8002171546363468)],\n",
      "                    [np.float64(0.6282820491079578),\n",
      "                     np.float64(0.691690882004171),\n",
      "                     np.float64(0.7296046639376386),\n",
      "                     np.float64(0.7566281955458908),\n",
      "                     np.float64(0.7614311957738462),\n",
      "                     np.float64(0.7715072266159826),\n",
      "                     np.float64(0.7744502644098015),\n",
      "                     np.float64(0.7770961734797716),\n",
      "                     np.float64(0.7813940136752024),\n",
      "                     np.float64(0.7823042092592426),\n",
      "                     np.float64(0.782027215738395),\n",
      "                     np.float64(0.7847228633864197),\n",
      "                     np.float64(0.788068567290051),\n",
      "                     np.float64(0.7854994946308768),\n",
      "                     np.float64(0.7886998796973854),\n",
      "                     np.float64(0.7896984706438716),\n",
      "                     np.float64(0.7869615107658102),\n",
      "                     np.float64(0.7911479492737057),\n",
      "                     np.float64(0.7921093537846985),\n",
      "                     np.float64(0.7938289079280185)],\n",
      "                    [np.float64(0.6226818335811238),\n",
      "                     np.float64(0.6911938444844747),\n",
      "                     np.float64(0.7417886983231873),\n",
      "                     np.float64(0.7541942756263268),\n",
      "                     np.float64(0.758806840897616),\n",
      "                     np.float64(0.7659589050029622),\n",
      "                     np.float64(0.7686372254545946),\n",
      "                     np.float64(0.7670312970594594),\n",
      "                     np.float64(0.7739106383167673),\n",
      "                     np.float64(0.7727989519430312),\n",
      "                     np.float64(0.7767691976889524),\n",
      "                     np.float64(0.7720759073333958),\n",
      "                     np.float64(0.777063337407624),\n",
      "                     np.float64(0.7803413441641069),\n",
      "                     np.float64(0.7796239690714177),\n",
      "                     np.float64(0.7798798479639633),\n",
      "                     np.float64(0.7795062989105382),\n",
      "                     np.float64(0.7802404214865833),\n",
      "                     np.float64(0.7791561530749196),\n",
      "                     np.float64(0.7815136006935063)],\n",
      "                    [np.float64(0.6354633058230226),\n",
      "                     np.float64(0.7050767070118621),\n",
      "                     np.float64(0.7281720680280811),\n",
      "                     np.float64(0.7507707972643263),\n",
      "                     np.float64(0.767624140533302),\n",
      "                     np.float64(0.7732976164443934),\n",
      "                     np.float64(0.7722097918465577),\n",
      "                     np.float64(0.7812964296346682),\n",
      "                     np.float64(0.7799568935129653),\n",
      "                     np.float64(0.7792334276557967),\n",
      "                     np.float64(0.7852509504806114),\n",
      "                     np.float64(0.7867066790707476),\n",
      "                     np.float64(0.7875444611888287),\n",
      "                     np.float64(0.7894547010785852),\n",
      "                     np.float64(0.7895365356741538),\n",
      "                     np.float64(0.7910028797791122),\n",
      "                     np.float64(0.7922499518960981),\n",
      "                     np.float64(0.7933906075210024),\n",
      "                     np.float64(0.7934338269221355),\n",
      "                     np.float64(0.7947304261938472)],\n",
      "                    [np.float64(0.6585131412196135),\n",
      "                     np.float64(0.7115052744748532),\n",
      "                     np.float64(0.7447855849291738),\n",
      "                     np.float64(0.7568673400096368),\n",
      "                     np.float64(0.7694947849866745),\n",
      "                     np.float64(0.7706833399672988),\n",
      "                     np.float64(0.7732568309393846),\n",
      "                     np.float64(0.7764337256259578),\n",
      "                     np.float64(0.7792605430899759),\n",
      "                     np.float64(0.7807685571254295),\n",
      "                     np.float64(0.782092636100779),\n",
      "                     np.float64(0.781920149531232),\n",
      "                     np.float64(0.7866621371800906),\n",
      "                     np.float64(0.7862784193594118),\n",
      "                     np.float64(0.7885926429446849),\n",
      "                     np.float64(0.7907985307298908),\n",
      "                     np.float64(0.7905123290645113),\n",
      "                     np.float64(0.789629084413048),\n",
      "                     np.float64(0.7932466815968309),\n",
      "                     np.float64(0.7911610874463686)]]}\n",
      "Training Model: BiLSTM, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.6477 - loss: 0.6455\n",
      "Epoch 1 - MCC: 0.7059\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 49ms/step - accuracy: 0.6485 - loss: 0.6447 - val_accuracy: 0.8531 - val_loss: 0.3617 - mcc: 0.7059\n",
      "Epoch 2/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.8719 - loss: 0.3208\n",
      "Epoch 2 - MCC: 0.8035\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 44ms/step - accuracy: 0.8722 - loss: 0.3201 - val_accuracy: 0.9020 - val_loss: 0.2452 - mcc: 0.8035\n",
      "Epoch 3/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9031 - loss: 0.2387\n",
      "Epoch 3 - MCC: 0.8259\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - accuracy: 0.9031 - loss: 0.2387 - val_accuracy: 0.9132 - val_loss: 0.2160 - mcc: 0.8259\n",
      "Epoch 4/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9119 - loss: 0.2164\n",
      "Epoch 4 - MCC: 0.8364\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - accuracy: 0.9119 - loss: 0.2163 - val_accuracy: 0.9184 - val_loss: 0.2004 - mcc: 0.8364\n",
      "Epoch 5/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.9175 - loss: 0.2016\n",
      "Epoch 5 - MCC: 0.8441\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 45ms/step - accuracy: 0.9175 - loss: 0.2016 - val_accuracy: 0.9222 - val_loss: 0.1909 - mcc: 0.8441\n",
      "Epoch 6/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9195 - loss: 0.1957\n",
      "Epoch 6 - MCC: 0.8502\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 33ms/step - accuracy: 0.9195 - loss: 0.1956 - val_accuracy: 0.9253 - val_loss: 0.1815 - mcc: 0.8502\n",
      "Epoch 7/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9252 - loss: 0.1819\n",
      "Epoch 7 - MCC: 0.8577\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 35ms/step - accuracy: 0.9252 - loss: 0.1819 - val_accuracy: 0.9290 - val_loss: 0.1739 - mcc: 0.8577\n",
      "Epoch 8/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9257 - loss: 0.1804\n",
      "Epoch 8 - MCC: 0.8626\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.9257 - loss: 0.1803 - val_accuracy: 0.9314 - val_loss: 0.1671 - mcc: 0.8626\n",
      "Epoch 9/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9322 - loss: 0.1649\n",
      "Epoch 9 - MCC: 0.8685\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.9322 - loss: 0.1649 - val_accuracy: 0.9344 - val_loss: 0.1611 - mcc: 0.8685\n",
      "Epoch 10/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9327 - loss: 0.1647\n",
      "Epoch 10 - MCC: 0.8708\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - accuracy: 0.9327 - loss: 0.1647 - val_accuracy: 0.9355 - val_loss: 0.1577 - mcc: 0.8708\n",
      "Epoch 11/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.9327 - loss: 0.1635\n",
      "Epoch 11 - MCC: 0.8713\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 43ms/step - accuracy: 0.9327 - loss: 0.1634 - val_accuracy: 0.9358 - val_loss: 0.1568 - mcc: 0.8713\n",
      "Epoch 12/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9327 - loss: 0.1623\n",
      "Epoch 12 - MCC: 0.8723\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - accuracy: 0.9328 - loss: 0.1622 - val_accuracy: 0.9363 - val_loss: 0.1554 - mcc: 0.8723\n",
      "Epoch 13/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9346 - loss: 0.1580\n",
      "Epoch 13 - MCC: 0.8757\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 35ms/step - accuracy: 0.9346 - loss: 0.1579 - val_accuracy: 0.9380 - val_loss: 0.1521 - mcc: 0.8757\n",
      "Epoch 14/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.9380 - loss: 0.1511\n",
      "Epoch 14 - MCC: 0.8765\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 46ms/step - accuracy: 0.9379 - loss: 0.1512 - val_accuracy: 0.9384 - val_loss: 0.1506 - mcc: 0.8765\n",
      "Epoch 15/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9353 - loss: 0.1557\n",
      "Epoch 15 - MCC: 0.8790\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 33ms/step - accuracy: 0.9354 - loss: 0.1556 - val_accuracy: 0.9397 - val_loss: 0.1478 - mcc: 0.8790\n",
      "Epoch 16/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9355 - loss: 0.1552\n",
      "Epoch 16 - MCC: 0.8764\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - accuracy: 0.9355 - loss: 0.1551 - val_accuracy: 0.9383 - val_loss: 0.1499 - mcc: 0.8764\n",
      "Epoch 17/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9390 - loss: 0.1480\n",
      "Epoch 17 - MCC: 0.8793\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 39ms/step - accuracy: 0.9390 - loss: 0.1480 - val_accuracy: 0.9398 - val_loss: 0.1471 - mcc: 0.8793\n",
      "Epoch 18/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9369 - loss: 0.1521\n",
      "Epoch 18 - MCC: 0.8799\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 39ms/step - accuracy: 0.9369 - loss: 0.1520 - val_accuracy: 0.9401 - val_loss: 0.1462 - mcc: 0.8799\n",
      "Epoch 19/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9380 - loss: 0.1504\n",
      "Epoch 19 - MCC: 0.8817\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.9380 - loss: 0.1504 - val_accuracy: 0.9409 - val_loss: 0.1451 - mcc: 0.8817\n",
      "Epoch 20/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9393 - loss: 0.1480\n",
      "Epoch 20 - MCC: 0.8828\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 37ms/step - accuracy: 0.9393 - loss: 0.1480 - val_accuracy: 0.9415 - val_loss: 0.1438 - mcc: 0.8828\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.6375 - loss: 0.6519\n",
      "Epoch 1 - MCC: 0.7090\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 48ms/step - accuracy: 0.6390 - loss: 0.6502 - val_accuracy: 0.8531 - val_loss: 0.3609 - mcc: 0.7090\n",
      "Epoch 2/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8814 - loss: 0.3070\n",
      "Epoch 2 - MCC: 0.8166\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 33ms/step - accuracy: 0.8815 - loss: 0.3067 - val_accuracy: 0.9084 - val_loss: 0.2305 - mcc: 0.8166\n",
      "Epoch 3/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9099 - loss: 0.2258\n",
      "Epoch 3 - MCC: 0.8372\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 43ms/step - accuracy: 0.9100 - loss: 0.2256 - val_accuracy: 0.9187 - val_loss: 0.1997 - mcc: 0.8372\n",
      "Epoch 4/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9177 - loss: 0.2013\n",
      "Epoch 4 - MCC: 0.8448\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 35ms/step - accuracy: 0.9177 - loss: 0.2013 - val_accuracy: 0.9226 - val_loss: 0.1864 - mcc: 0.8448\n",
      "Epoch 5/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9214 - loss: 0.1902\n",
      "Epoch 5 - MCC: 0.8529\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 33ms/step - accuracy: 0.9214 - loss: 0.1902 - val_accuracy: 0.9266 - val_loss: 0.1768 - mcc: 0.8529\n",
      "Epoch 6/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9256 - loss: 0.1792\n",
      "Epoch 6 - MCC: 0.8560\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 40ms/step - accuracy: 0.9256 - loss: 0.1792 - val_accuracy: 0.9282 - val_loss: 0.1712 - mcc: 0.8560\n",
      "Epoch 7/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9276 - loss: 0.1747\n",
      "Epoch 7 - MCC: 0.8621\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.9276 - loss: 0.1747 - val_accuracy: 0.9312 - val_loss: 0.1648 - mcc: 0.8621\n",
      "Epoch 8/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9304 - loss: 0.1676\n",
      "Epoch 8 - MCC: 0.8669\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.9304 - loss: 0.1676 - val_accuracy: 0.9336 - val_loss: 0.1598 - mcc: 0.8669\n",
      "Epoch 9/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.9331 - loss: 0.1610\n",
      "Epoch 9 - MCC: 0.8691\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 40ms/step - accuracy: 0.9331 - loss: 0.1610 - val_accuracy: 0.9347 - val_loss: 0.1575 - mcc: 0.8691\n",
      "Epoch 10/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9323 - loss: 0.1636\n",
      "Epoch 10 - MCC: 0.8705\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 34ms/step - accuracy: 0.9323 - loss: 0.1635 - val_accuracy: 0.9354 - val_loss: 0.1559 - mcc: 0.8705\n",
      "Epoch 11/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9352 - loss: 0.1566\n",
      "Epoch 11 - MCC: 0.8729\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - accuracy: 0.9352 - loss: 0.1566 - val_accuracy: 0.9366 - val_loss: 0.1527 - mcc: 0.8729\n",
      "Epoch 12/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9339 - loss: 0.1598\n",
      "Epoch 12 - MCC: 0.8751\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.9339 - loss: 0.1598 - val_accuracy: 0.9377 - val_loss: 0.1511 - mcc: 0.8751\n",
      "Epoch 13/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9366 - loss: 0.1545\n",
      "Epoch 13 - MCC: 0.8776\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.9366 - loss: 0.1545 - val_accuracy: 0.9389 - val_loss: 0.1480 - mcc: 0.8776\n",
      "Epoch 14/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9386 - loss: 0.1488\n",
      "Epoch 14 - MCC: 0.8766\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 41ms/step - accuracy: 0.9385 - loss: 0.1489 - val_accuracy: 0.9385 - val_loss: 0.1478 - mcc: 0.8766\n",
      "Epoch 15/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9356 - loss: 0.1551\n",
      "Epoch 15 - MCC: 0.8774\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 33ms/step - accuracy: 0.9357 - loss: 0.1550 - val_accuracy: 0.9389 - val_loss: 0.1468 - mcc: 0.8774\n",
      "Epoch 16/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9393 - loss: 0.1476\n",
      "Epoch 16 - MCC: 0.8778\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.9393 - loss: 0.1476 - val_accuracy: 0.9388 - val_loss: 0.1482 - mcc: 0.8778\n",
      "Epoch 17/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9383 - loss: 0.1501\n",
      "Epoch 17 - MCC: 0.8776\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 41ms/step - accuracy: 0.9383 - loss: 0.1501 - val_accuracy: 0.9390 - val_loss: 0.1475 - mcc: 0.8776\n",
      "Epoch 18/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9408 - loss: 0.1464\n",
      "Epoch 18 - MCC: 0.8809\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 36ms/step - accuracy: 0.9408 - loss: 0.1464 - val_accuracy: 0.9406 - val_loss: 0.1434 - mcc: 0.8809\n",
      "Epoch 19/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9398 - loss: 0.1471\n",
      "Epoch 19 - MCC: 0.8816\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.9398 - loss: 0.1471 - val_accuracy: 0.9409 - val_loss: 0.1448 - mcc: 0.8816\n",
      "Epoch 20/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.9395 - loss: 0.1480\n",
      "Epoch 20 - MCC: 0.8822\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 44ms/step - accuracy: 0.9396 - loss: 0.1479 - val_accuracy: 0.9412 - val_loss: 0.1432 - mcc: 0.8822\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.6408 - loss: 0.6478\n",
      "Epoch 1 - MCC: 0.7015\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 41ms/step - accuracy: 0.6416 - loss: 0.6468 - val_accuracy: 0.8510 - val_loss: 0.3537 - mcc: 0.7015\n",
      "Epoch 2/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.8792 - loss: 0.3036\n",
      "Epoch 2 - MCC: 0.8062\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 40ms/step - accuracy: 0.8794 - loss: 0.3033 - val_accuracy: 0.9031 - val_loss: 0.2433 - mcc: 0.8062\n",
      "Epoch 3/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9078 - loss: 0.2292\n",
      "Epoch 3 - MCC: 0.8251\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.9079 - loss: 0.2290 - val_accuracy: 0.9125 - val_loss: 0.2140 - mcc: 0.8251\n",
      "Epoch 4/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9177 - loss: 0.2014\n",
      "Epoch 4 - MCC: 0.8365\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - accuracy: 0.9178 - loss: 0.2014 - val_accuracy: 0.9184 - val_loss: 0.1967 - mcc: 0.8365\n",
      "Epoch 5/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9222 - loss: 0.1873\n",
      "Epoch 5 - MCC: 0.8437\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 42ms/step - accuracy: 0.9223 - loss: 0.1873 - val_accuracy: 0.9220 - val_loss: 0.1870 - mcc: 0.8437\n",
      "Epoch 6/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9261 - loss: 0.1780\n",
      "Epoch 6 - MCC: 0.8457\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 33ms/step - accuracy: 0.9261 - loss: 0.1780 - val_accuracy: 0.9222 - val_loss: 0.1879 - mcc: 0.8457\n",
      "Epoch 7/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9281 - loss: 0.1729\n",
      "Epoch 7 - MCC: 0.8561\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - accuracy: 0.9281 - loss: 0.1729 - val_accuracy: 0.9283 - val_loss: 0.1737 - mcc: 0.8561\n",
      "Epoch 8/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9310 - loss: 0.1663\n",
      "Epoch 8 - MCC: 0.8578\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 44ms/step - accuracy: 0.9310 - loss: 0.1663 - val_accuracy: 0.9291 - val_loss: 0.1711 - mcc: 0.8578\n",
      "Epoch 9/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9339 - loss: 0.1603\n",
      "Epoch 9 - MCC: 0.8636\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 34ms/step - accuracy: 0.9339 - loss: 0.1603 - val_accuracy: 0.9320 - val_loss: 0.1657 - mcc: 0.8636\n",
      "Epoch 10/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9348 - loss: 0.1589\n",
      "Epoch 10 - MCC: 0.8655\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 35ms/step - accuracy: 0.9348 - loss: 0.1589 - val_accuracy: 0.9330 - val_loss: 0.1626 - mcc: 0.8655\n",
      "Epoch 11/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9342 - loss: 0.1595\n",
      "Epoch 11 - MCC: 0.8644\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 40ms/step - accuracy: 0.9342 - loss: 0.1595 - val_accuracy: 0.9324 - val_loss: 0.1637 - mcc: 0.8644\n",
      "Epoch 12/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9336 - loss: 0.1595\n",
      "Epoch 12 - MCC: 0.8681\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.9336 - loss: 0.1594 - val_accuracy: 0.9343 - val_loss: 0.1598 - mcc: 0.8681\n",
      "Epoch 13/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9371 - loss: 0.1529\n",
      "Epoch 13 - MCC: 0.8686\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - accuracy: 0.9371 - loss: 0.1529 - val_accuracy: 0.9345 - val_loss: 0.1610 - mcc: 0.8686\n",
      "Epoch 14/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9373 - loss: 0.1530\n",
      "Epoch 14 - MCC: 0.8693\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 36ms/step - accuracy: 0.9374 - loss: 0.1530 - val_accuracy: 0.9349 - val_loss: 0.1573 - mcc: 0.8693\n",
      "Epoch 15/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9401 - loss: 0.1464\n",
      "Epoch 15 - MCC: 0.8700\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 33ms/step - accuracy: 0.9401 - loss: 0.1464 - val_accuracy: 0.9352 - val_loss: 0.1576 - mcc: 0.8700\n",
      "Epoch 16/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9386 - loss: 0.1491\n",
      "Epoch 16 - MCC: 0.8707\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - accuracy: 0.9386 - loss: 0.1491 - val_accuracy: 0.9356 - val_loss: 0.1562 - mcc: 0.8707\n",
      "Epoch 17/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.9395 - loss: 0.1472\n",
      "Epoch 17 - MCC: 0.8719\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 47ms/step - accuracy: 0.9395 - loss: 0.1472 - val_accuracy: 0.9362 - val_loss: 0.1552 - mcc: 0.8719\n",
      "Epoch 18/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9399 - loss: 0.1469\n",
      "Epoch 18 - MCC: 0.8683\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 33ms/step - accuracy: 0.9399 - loss: 0.1469 - val_accuracy: 0.9343 - val_loss: 0.1587 - mcc: 0.8683\n",
      "Epoch 19/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9394 - loss: 0.1474\n",
      "Epoch 19 - MCC: 0.8725\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.9394 - loss: 0.1474 - val_accuracy: 0.9365 - val_loss: 0.1533 - mcc: 0.8725\n",
      "Epoch 20/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.9397 - loss: 0.1475\n",
      "Epoch 20 - MCC: 0.8754\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 44ms/step - accuracy: 0.9397 - loss: 0.1474 - val_accuracy: 0.9379 - val_loss: 0.1511 - mcc: 0.8754\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.6484 - loss: 0.6525\n",
      "Epoch 1 - MCC: 0.7061\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 41ms/step - accuracy: 0.6491 - loss: 0.6518 - val_accuracy: 0.8532 - val_loss: 0.3672 - mcc: 0.7061\n",
      "Epoch 2/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8697 - loss: 0.3209\n",
      "Epoch 2 - MCC: 0.8034\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 40ms/step - accuracy: 0.8700 - loss: 0.3201 - val_accuracy: 0.9017 - val_loss: 0.2399 - mcc: 0.8034\n",
      "Epoch 3/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9039 - loss: 0.2346\n",
      "Epoch 3 - MCC: 0.8321\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.9041 - loss: 0.2343 - val_accuracy: 0.9162 - val_loss: 0.2052 - mcc: 0.8321\n",
      "Epoch 4/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9164 - loss: 0.2012\n",
      "Epoch 4 - MCC: 0.8398\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.9164 - loss: 0.2012 - val_accuracy: 0.9200 - val_loss: 0.1938 - mcc: 0.8398\n",
      "Epoch 5/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9194 - loss: 0.1942\n",
      "Epoch 5 - MCC: 0.8471\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 45ms/step - accuracy: 0.9194 - loss: 0.1941 - val_accuracy: 0.9236 - val_loss: 0.1833 - mcc: 0.8471\n",
      "Epoch 6/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9232 - loss: 0.1842\n",
      "Epoch 6 - MCC: 0.8490\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 33ms/step - accuracy: 0.9232 - loss: 0.1841 - val_accuracy: 0.9246 - val_loss: 0.1800 - mcc: 0.8490\n",
      "Epoch 7/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9259 - loss: 0.1772\n",
      "Epoch 7 - MCC: 0.8616\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.9259 - loss: 0.1771 - val_accuracy: 0.9310 - val_loss: 0.1656 - mcc: 0.8616\n",
      "Epoch 8/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.9305 - loss: 0.1675\n",
      "Epoch 8 - MCC: 0.8671\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 42ms/step - accuracy: 0.9305 - loss: 0.1675 - val_accuracy: 0.9337 - val_loss: 0.1602 - mcc: 0.8671\n",
      "Epoch 9/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9322 - loss: 0.1633\n",
      "Epoch 9 - MCC: 0.8699\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 33ms/step - accuracy: 0.9323 - loss: 0.1632 - val_accuracy: 0.9351 - val_loss: 0.1572 - mcc: 0.8699\n",
      "Epoch 10/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9325 - loss: 0.1623\n",
      "Epoch 10 - MCC: 0.8721\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 33ms/step - accuracy: 0.9326 - loss: 0.1623 - val_accuracy: 0.9362 - val_loss: 0.1543 - mcc: 0.8721\n",
      "Epoch 11/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9335 - loss: 0.1599\n",
      "Epoch 11 - MCC: 0.8722\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 39ms/step - accuracy: 0.9335 - loss: 0.1598 - val_accuracy: 0.9363 - val_loss: 0.1546 - mcc: 0.8722\n",
      "Epoch 12/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9370 - loss: 0.1538\n",
      "Epoch 12 - MCC: 0.8752\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.9369 - loss: 0.1538 - val_accuracy: 0.9378 - val_loss: 0.1504 - mcc: 0.8752\n",
      "Epoch 13/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9377 - loss: 0.1518\n",
      "Epoch 13 - MCC: 0.8761\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - accuracy: 0.9377 - loss: 0.1518 - val_accuracy: 0.9382 - val_loss: 0.1497 - mcc: 0.8761\n",
      "Epoch 14/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9388 - loss: 0.1480\n",
      "Epoch 14 - MCC: 0.8762\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.9388 - loss: 0.1480 - val_accuracy: 0.9382 - val_loss: 0.1490 - mcc: 0.8762\n",
      "Epoch 15/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9376 - loss: 0.1507\n",
      "Epoch 15 - MCC: 0.8774\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 37ms/step - accuracy: 0.9376 - loss: 0.1507 - val_accuracy: 0.9389 - val_loss: 0.1486 - mcc: 0.8774\n",
      "Epoch 16/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9383 - loss: 0.1496\n",
      "Epoch 16 - MCC: 0.8786\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.9383 - loss: 0.1496 - val_accuracy: 0.9395 - val_loss: 0.1470 - mcc: 0.8786\n",
      "Epoch 17/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9390 - loss: 0.1480\n",
      "Epoch 17 - MCC: 0.8797\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 42ms/step - accuracy: 0.9390 - loss: 0.1480 - val_accuracy: 0.9399 - val_loss: 0.1457 - mcc: 0.8797\n",
      "Epoch 18/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9385 - loss: 0.1480\n",
      "Epoch 18 - MCC: 0.8800\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 34ms/step - accuracy: 0.9386 - loss: 0.1480 - val_accuracy: 0.9402 - val_loss: 0.1450 - mcc: 0.8800\n",
      "Epoch 19/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9391 - loss: 0.1485\n",
      "Epoch 19 - MCC: 0.8807\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 35ms/step - accuracy: 0.9391 - loss: 0.1485 - val_accuracy: 0.9405 - val_loss: 0.1442 - mcc: 0.8807\n",
      "Epoch 20/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.9386 - loss: 0.1487\n",
      "Epoch 20 - MCC: 0.8805\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 46ms/step - accuracy: 0.9386 - loss: 0.1487 - val_accuracy: 0.9403 - val_loss: 0.1453 - mcc: 0.8805\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.6766 - loss: 0.6317\n",
      "Epoch 1 - MCC: 0.7386\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 42ms/step - accuracy: 0.6781 - loss: 0.6297 - val_accuracy: 0.8693 - val_loss: 0.3259 - mcc: 0.7386\n",
      "Epoch 2/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8858 - loss: 0.2874\n",
      "Epoch 2 - MCC: 0.8140\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 46ms/step - accuracy: 0.8860 - loss: 0.2869 - val_accuracy: 0.9073 - val_loss: 0.2282 - mcc: 0.8140\n",
      "Epoch 3/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9126 - loss: 0.2170\n",
      "Epoch 3 - MCC: 0.8290\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 35ms/step - accuracy: 0.9127 - loss: 0.2169 - val_accuracy: 0.9146 - val_loss: 0.2043 - mcc: 0.8290\n",
      "Epoch 4/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9207 - loss: 0.1923\n",
      "Epoch 4 - MCC: 0.8431\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 35ms/step - accuracy: 0.9207 - loss: 0.1923 - val_accuracy: 0.9218 - val_loss: 0.1880 - mcc: 0.8431\n",
      "Epoch 5/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.9262 - loss: 0.1783\n",
      "Epoch 5 - MCC: 0.8523\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 46ms/step - accuracy: 0.9262 - loss: 0.1783 - val_accuracy: 0.9264 - val_loss: 0.1773 - mcc: 0.8523\n",
      "Epoch 6/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9286 - loss: 0.1719\n",
      "Epoch 6 - MCC: 0.8577\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 39ms/step - accuracy: 0.9286 - loss: 0.1719 - val_accuracy: 0.9291 - val_loss: 0.1704 - mcc: 0.8577\n",
      "Epoch 7/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9281 - loss: 0.1721\n",
      "Epoch 7 - MCC: 0.8586\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.9281 - loss: 0.1720 - val_accuracy: 0.9296 - val_loss: 0.1677 - mcc: 0.8586\n",
      "Epoch 8/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.9333 - loss: 0.1615\n",
      "Epoch 8 - MCC: 0.8623\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 46ms/step - accuracy: 0.9332 - loss: 0.1615 - val_accuracy: 0.9313 - val_loss: 0.1645 - mcc: 0.8623\n",
      "Epoch 9/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9359 - loss: 0.1553\n",
      "Epoch 9 - MCC: 0.8671\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - accuracy: 0.9358 - loss: 0.1554 - val_accuracy: 0.9338 - val_loss: 0.1589 - mcc: 0.8671\n",
      "Epoch 10/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9331 - loss: 0.1604\n",
      "Epoch 10 - MCC: 0.8668\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 36ms/step - accuracy: 0.9332 - loss: 0.1603 - val_accuracy: 0.9336 - val_loss: 0.1584 - mcc: 0.8668\n",
      "Epoch 11/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.9346 - loss: 0.1568\n",
      "Epoch 11 - MCC: 0.8702\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 48ms/step - accuracy: 0.9347 - loss: 0.1568 - val_accuracy: 0.9353 - val_loss: 0.1547 - mcc: 0.8702\n",
      "Epoch 12/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9378 - loss: 0.1489\n",
      "Epoch 12 - MCC: 0.8707\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 35ms/step - accuracy: 0.9378 - loss: 0.1490 - val_accuracy: 0.9356 - val_loss: 0.1550 - mcc: 0.8707\n",
      "Epoch 13/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9378 - loss: 0.1500\n",
      "Epoch 13 - MCC: 0.8735\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 35ms/step - accuracy: 0.9378 - loss: 0.1500 - val_accuracy: 0.9369 - val_loss: 0.1524 - mcc: 0.8735\n",
      "Epoch 14/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9398 - loss: 0.1456\n",
      "Epoch 14 - MCC: 0.8718\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.9398 - loss: 0.1456 - val_accuracy: 0.9361 - val_loss: 0.1530 - mcc: 0.8718\n",
      "Epoch 15/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9387 - loss: 0.1489\n",
      "Epoch 15 - MCC: 0.8739\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.9387 - loss: 0.1488 - val_accuracy: 0.9372 - val_loss: 0.1509 - mcc: 0.8739\n",
      "Epoch 16/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9390 - loss: 0.1480\n",
      "Epoch 16 - MCC: 0.8740\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.9390 - loss: 0.1480 - val_accuracy: 0.9372 - val_loss: 0.1517 - mcc: 0.8740\n",
      "Epoch 17/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.9403 - loss: 0.1443\n",
      "Epoch 17 - MCC: 0.8754\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 43ms/step - accuracy: 0.9403 - loss: 0.1443 - val_accuracy: 0.9379 - val_loss: 0.1495 - mcc: 0.8754\n",
      "Epoch 18/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9392 - loss: 0.1468\n",
      "Epoch 18 - MCC: 0.8770\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - accuracy: 0.9392 - loss: 0.1467 - val_accuracy: 0.9387 - val_loss: 0.1484 - mcc: 0.8770\n",
      "Epoch 19/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9399 - loss: 0.1448\n",
      "Epoch 19 - MCC: 0.8772\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 35ms/step - accuracy: 0.9399 - loss: 0.1448 - val_accuracy: 0.9388 - val_loss: 0.1487 - mcc: 0.8772\n",
      "Epoch 20/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9412 - loss: 0.1434\n",
      "Epoch 20 - MCC: 0.8768\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 37ms/step - accuracy: 0.9412 - loss: 0.1434 - val_accuracy: 0.9386 - val_loss: 0.1487 - mcc: 0.8768\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.9415226666666666),\n",
      "              'mean': np.float64(0.9399146666666667),\n",
      "              'min': np.float64(0.937896),\n",
      "              'std': np.float64(0.0014356556690237354)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.000904101053873698),\n",
      "                               'mean': np.float64(0.000813666852315267),\n",
      "                               'min': np.float64(0.00047376346588134764),\n",
      "                               'std': np.float64(0.00016997854025523523)},\n",
      " 'MCC': {'max': np.float64(0.8828147456793188),\n",
      "         'mean': np.float64(0.8795170836875498),\n",
      "         'min': np.float64(0.8753576834044836),\n",
      "         'std': np.float64(0.0029523066020785828)},\n",
      " 'Parameters': 4269,\n",
      " 'Train Time (s)': {'max': np.float64(104.72200059890747),\n",
      "                    'mean': np.float64(91.87452726364135),\n",
      "                    'min': np.float64(85.53996181488037),\n",
      "                    'std': np.float64(6.759190043579263)},\n",
      " 'Training Accuracy': [[0.7229685187339783,\n",
      "                        0.883668065071106,\n",
      "                        0.905796468257904,\n",
      "                        0.9138525128364563,\n",
      "                        0.9181240797042847,\n",
      "                        0.9218288660049438,\n",
      "                        0.9250959753990173,\n",
      "                        0.9287784695625305,\n",
      "                        0.9312806725502014,\n",
      "                        0.9330588579177856,\n",
      "                        0.9343274831771851,\n",
      "                        0.9351329207420349,\n",
      "                        0.9356600642204285,\n",
      "                        0.9364407658576965,\n",
      "                        0.9372658729553223,\n",
      "                        0.9374610185623169,\n",
      "                        0.9383847117424011,\n",
      "                        0.9386369585990906,\n",
      "                        0.9388206601142883,\n",
      "                        0.939604640007019],\n",
      "                       [0.7125193476676941,\n",
      "                        0.8912632465362549,\n",
      "                        0.9121018052101135,\n",
      "                        0.9187211990356445,\n",
      "                        0.922122061252594,\n",
      "                        0.9257100224494934,\n",
      "                        0.9289366006851196,\n",
      "                        0.9304072260856628,\n",
      "                        0.9322826862335205,\n",
      "                        0.9336857795715332,\n",
      "                        0.9345337152481079,\n",
      "                        0.935912013053894,\n",
      "                        0.9368593692779541,\n",
      "                        0.9376538991928101,\n",
      "                        0.9377439022064209,\n",
      "                        0.938665509223938,\n",
      "                        0.9387433528900146,\n",
      "                        0.9398273825645447,\n",
      "                        0.9398193359375,\n",
      "                        0.9403637647628784],\n",
      "                       [0.7239773869514465,\n",
      "                        0.889965832233429,\n",
      "                        0.912122905254364,\n",
      "                        0.9190593957901001,\n",
      "                        0.9234577417373657,\n",
      "                        0.9264000654220581,\n",
      "                        0.9292067885398865,\n",
      "                        0.9315659403800964,\n",
      "                        0.93280428647995,\n",
      "                        0.9345704913139343,\n",
      "                        0.935627281665802,\n",
      "                        0.9362404942512512,\n",
      "                        0.9374133348464966,\n",
      "                        0.9378209114074707,\n",
      "                        0.938633382320404,\n",
      "                        0.9390361905097961,\n",
      "                        0.9396165609359741,\n",
      "                        0.9396999478340149,\n",
      "                        0.9402900338172913,\n",
      "                        0.9409545063972473],\n",
      "                       [0.715142011642456,\n",
      "                        0.8843626379966736,\n",
      "                        0.9084019660949707,\n",
      "                        0.9164090752601624,\n",
      "                        0.9205747246742249,\n",
      "                        0.9237514734268188,\n",
      "                        0.9273639917373657,\n",
      "                        0.93094801902771,\n",
      "                        0.9323267340660095,\n",
      "                        0.9342648386955261,\n",
      "                        0.9352813959121704,\n",
      "                        0.9361953735351562,\n",
      "                        0.9372247457504272,\n",
      "                        0.9371378421783447,\n",
      "                        0.9380546808242798,\n",
      "                        0.9384378790855408,\n",
      "                        0.938930094242096,\n",
      "                        0.9391399621963501,\n",
      "                        0.9398473501205444,\n",
      "                        0.9400684237480164],\n",
      "                       [0.7516158819198608,\n",
      "                        0.8949981331825256,\n",
      "                        0.9139519929885864,\n",
      "                        0.9217227101325989,\n",
      "                        0.9256848096847534,\n",
      "                        0.9288013577461243,\n",
      "                        0.9308874607086182,\n",
      "                        0.9326751828193665,\n",
      "                        0.9343999028205872,\n",
      "                        0.9350860118865967,\n",
      "                        0.9363244771957397,\n",
      "                        0.9370452761650085,\n",
      "                        0.9374380111694336,\n",
      "                        0.9382885694503784,\n",
      "                        0.9387707710266113,\n",
      "                        0.9395879507064819,\n",
      "                        0.9397001266479492,\n",
      "                        0.9399592876434326,\n",
      "                        0.9402914047241211,\n",
      "                        0.9411745667457581]],\n",
      " 'Training Loss': [[0.5685209631919861,\n",
      "                    0.2908664047718048,\n",
      "                    0.23252294957637787,\n",
      "                    0.21118298172950745,\n",
      "                    0.1991545557975769,\n",
      "                    0.1904086321592331,\n",
      "                    0.18151649832725525,\n",
      "                    0.17295385897159576,\n",
      "                    0.16706007719039917,\n",
      "                    0.16329233348369598,\n",
      "                    0.1600545346736908,\n",
      "                    0.15746507048606873,\n",
      "                    0.15597140789031982,\n",
      "                    0.15437616407871246,\n",
      "                    0.1526467502117157,\n",
      "                    0.15135864913463593,\n",
      "                    0.14960213005542755,\n",
      "                    0.14885754883289337,\n",
      "                    0.14847323298454285,\n",
      "                    0.14683227241039276],\n",
      "                   [0.5723451375961304,\n",
      "                    0.2775804102420807,\n",
      "                    0.21765759587287903,\n",
      "                    0.19823428988456726,\n",
      "                    0.18765103816986084,\n",
      "                    0.17827822268009186,\n",
      "                    0.171574205160141,\n",
      "                    0.1675305813550949,\n",
      "                    0.16330313682556152,\n",
      "                    0.1601557731628418,\n",
      "                    0.1585237979888916,\n",
      "                    0.1558312326669693,\n",
      "                    0.1536710113286972,\n",
      "                    0.1517624855041504,\n",
      "                    0.15143537521362305,\n",
      "                    0.1497572362422943,\n",
      "                    0.14957699179649353,\n",
      "                    0.14742547273635864,\n",
      "                    0.14684510231018066,\n",
      "                    0.1459878385066986],\n",
      "                   [0.5593996047973633,\n",
      "                    0.2779044806957245,\n",
      "                    0.21882151067256927,\n",
      "                    0.19682267308235168,\n",
      "                    0.18465450406074524,\n",
      "                    0.17709574103355408,\n",
      "                    0.1710616499185562,\n",
      "                    0.16526852548122406,\n",
      "                    0.1625492423772812,\n",
      "                    0.15874634683132172,\n",
      "                    0.1564110368490219,\n",
      "                    0.15497800707817078,\n",
      "                    0.15255221724510193,\n",
      "                    0.1513928472995758,\n",
      "                    0.14960718154907227,\n",
      "                    0.14907096326351166,\n",
      "                    0.14734086394309998,\n",
      "                    0.14674220979213715,\n",
      "                    0.14577114582061768,\n",
      "                    0.14458467066287994],\n",
      "                   [0.579973042011261,\n",
      "                    0.28674933314323425,\n",
      "                    0.22338247299194336,\n",
      "                    0.20108066499233246,\n",
      "                    0.19091375172138214,\n",
      "                    0.18240877985954285,\n",
      "                    0.1742284893989563,\n",
      "                    0.1662835329771042,\n",
      "                    0.16253383457660675,\n",
      "                    0.15881606936454773,\n",
      "                    0.15643323957920074,\n",
      "                    0.15448227524757385,\n",
      "                    0.1519545018672943,\n",
      "                    0.1518089771270752,\n",
      "                    0.15025770664215088,\n",
      "                    0.1494436413049698,\n",
      "                    0.14840994775295258,\n",
      "                    0.14731429517269135,\n",
      "                    0.1462298482656479,\n",
      "                    0.1457979679107666],\n",
      "                   [0.5372312068939209,\n",
      "                    0.2639124393463135,\n",
      "                    0.2113683670759201,\n",
      "                    0.18971870839595795,\n",
      "                    0.17875277996063232,\n",
      "                    0.17131277918815613,\n",
      "                    0.16641023755073547,\n",
      "                    0.16153590381145477,\n",
      "                    0.1581718921661377,\n",
      "                    0.15593008697032928,\n",
      "                    0.15332964062690735,\n",
      "                    0.15150032937526703,\n",
      "                    0.150765523314476,\n",
      "                    0.14877387881278992,\n",
      "                    0.14778563380241394,\n",
      "                    0.14649967849254608,\n",
      "                    0.14590242505073547,\n",
      "                    0.1450379192829132,\n",
      "                    0.14482830464839935,\n",
      "                    0.14293672144412994]],\n",
      " 'Validation Accuracy': [[0.8530932664871216,\n",
      "                          0.9020399451255798,\n",
      "                          0.913170576095581,\n",
      "                          0.9184186458587646,\n",
      "                          0.9222372770309448,\n",
      "                          0.9252772331237793,\n",
      "                          0.9289920926094055,\n",
      "                          0.9314054250717163,\n",
      "                          0.9344292879104614,\n",
      "                          0.9355493783950806,\n",
      "                          0.9358161091804504,\n",
      "                          0.9363013505935669,\n",
      "                          0.9379627108573914,\n",
      "                          0.9384158253669739,\n",
      "                          0.9396772980690002,\n",
      "                          0.9383333325386047,\n",
      "                          0.9397920966148376,\n",
      "                          0.9401066303253174,\n",
      "                          0.9408959150314331,\n",
      "                          0.9415227174758911],\n",
      "                         [0.853056013584137,\n",
      "                          0.9084452986717224,\n",
      "                          0.918735921382904,\n",
      "                          0.9226292967796326,\n",
      "                          0.9266080856323242,\n",
      "                          0.9281651973724365,\n",
      "                          0.9312080144882202,\n",
      "                          0.9336373805999756,\n",
      "                          0.9347413778305054,\n",
      "                          0.9353922009468079,\n",
      "                          0.9366292953491211,\n",
      "                          0.9376826286315918,\n",
      "                          0.9389494061470032,\n",
      "                          0.9384558200836182,\n",
      "                          0.9388587474822998,\n",
      "                          0.9388214349746704,\n",
      "                          0.9389786124229431,\n",
      "                          0.9406294226646423,\n",
      "                          0.9409413933753967,\n",
      "                          0.9412398934364319],\n",
      "                         [0.8510027527809143,\n",
      "                          0.9030559062957764,\n",
      "                          0.9124747514724731,\n",
      "                          0.9183812737464905,\n",
      "                          0.9219573736190796,\n",
      "                          0.922210693359375,\n",
      "                          0.9282720685005188,\n",
      "                          0.9291253089904785,\n",
      "                          0.9320453405380249,\n",
      "                          0.9330105781555176,\n",
      "                          0.9324293732643127,\n",
      "                          0.9342719912528992,\n",
      "                          0.934482753276825,\n",
      "                          0.9348611831665039,\n",
      "                          0.935242772102356,\n",
      "                          0.9355972409248352,\n",
      "                          0.9361708164215088,\n",
      "                          0.9343386292457581,\n",
      "                          0.9364612698554993,\n",
      "                          0.9378960728645325],\n",
      "                         [0.8532400727272034,\n",
      "                          0.901725172996521,\n",
      "                          0.9162266254425049,\n",
      "                          0.9199973344802856,\n",
      "                          0.9235706329345703,\n",
      "                          0.9245786070823669,\n",
      "                          0.93096524477005,\n",
      "                          0.93369060754776,\n",
      "                          0.9351120591163635,\n",
      "                          0.9361679553985596,\n",
      "                          0.9362507462501526,\n",
      "                          0.9377733469009399,\n",
      "                          0.9382001757621765,\n",
      "                          0.9382186532020569,\n",
      "                          0.9388586282730103,\n",
      "                          0.9394533634185791,\n",
      "                          0.939936101436615,\n",
      "                          0.9401946067810059,\n",
      "                          0.9404773116111755,\n",
      "                          0.9403145909309387],\n",
      "                         [0.8693253397941589,\n",
      "                          0.907333254814148,\n",
      "                          0.9146374464035034,\n",
      "                          0.9218133091926575,\n",
      "                          0.9263653755187988,\n",
      "                          0.929085373878479,\n",
      "                          0.929570734500885,\n",
      "                          0.9312719106674194,\n",
      "                          0.9337706565856934,\n",
      "                          0.9335599541664124,\n",
      "                          0.9353280663490295,\n",
      "                          0.9355520009994507,\n",
      "                          0.9369386434555054,\n",
      "                          0.9360853433609009,\n",
      "                          0.9371652603149414,\n",
      "                          0.9371706247329712,\n",
      "                          0.937925398349762,\n",
      "                          0.9386881589889526,\n",
      "                          0.9387999773025513,\n",
      "                          0.9386000037193298]],\n",
      " 'Validation Loss': [0.3259434998035431,\n",
      "                     0.22817347943782806,\n",
      "                     0.20432566106319427,\n",
      "                     0.18796421587467194,\n",
      "                     0.177336186170578,\n",
      "                     0.17039699852466583,\n",
      "                     0.1677480787038803,\n",
      "                     0.16446295380592346,\n",
      "                     0.15893472731113434,\n",
      "                     0.15842173993587494,\n",
      "                     0.15472936630249023,\n",
      "                     0.1549692451953888,\n",
      "                     0.15242771804332733,\n",
      "                     0.15302884578704834,\n",
      "                     0.15091857314109802,\n",
      "                     0.1516527235507965,\n",
      "                     0.14947332441806793,\n",
      "                     0.1484232246875763,\n",
      "                     0.14865753054618835,\n",
      "                     0.14872463047504425],\n",
      " 'Validation MCC': [[np.float64(0.7059173641124468),\n",
      "                     np.float64(0.8035157114810512),\n",
      "                     np.float64(0.8258571287746523),\n",
      "                     np.float64(0.8363775951352539),\n",
      "                     np.float64(0.8440631884941604),\n",
      "                     np.float64(0.8501624744553833),\n",
      "                     np.float64(0.857658888252071),\n",
      "                     np.float64(0.8626027111980795),\n",
      "                     np.float64(0.8685063941691693),\n",
      "                     np.float64(0.8708316389321338),\n",
      "                     np.float64(0.8712781695614479),\n",
      "                     np.float64(0.8723464159059765),\n",
      "                     np.float64(0.8757332346109272),\n",
      "                     np.float64(0.8765021862313623),\n",
      "                     np.float64(0.8790244152084082),\n",
      "                     np.float64(0.8763702244155923),\n",
      "                     np.float64(0.8793065710998554),\n",
      "                     np.float64(0.87993913232993),\n",
      "                     np.float64(0.8816956929711102),\n",
      "                     np.float64(0.8828147456793188)],\n",
      "                    [np.float64(0.7089650854986274),\n",
      "                     np.float64(0.8165852495239754),\n",
      "                     np.float64(0.8372061220639425),\n",
      "                     np.float64(0.8448276066791858),\n",
      "                     np.float64(0.8528961530323951),\n",
      "                     np.float64(0.8560169947264942),\n",
      "                     np.float64(0.8620946063467407),\n",
      "                     np.float64(0.8669225149671833),\n",
      "                     np.float64(0.8690992594060545),\n",
      "                     np.float64(0.8704696210282188),\n",
      "                     np.float64(0.8729291982450643),\n",
      "                     np.float64(0.8750721819361543),\n",
      "                     np.float64(0.877617499252769),\n",
      "                     np.float64(0.876568754887316),\n",
      "                     np.float64(0.8773638936314788),\n",
      "                     np.float64(0.8777557019953537),\n",
      "                     np.float64(0.8776357424579692),\n",
      "                     np.float64(0.8809188875033382),\n",
      "                     np.float64(0.8815896497262148),\n",
      "                     np.float64(0.8821535821810015)],\n",
      "                    [np.float64(0.7014811296334484),\n",
      "                     np.float64(0.8061783186906155),\n",
      "                     np.float64(0.8250827154098979),\n",
      "                     np.float64(0.8365491423391879),\n",
      "                     np.float64(0.8437157526363542),\n",
      "                     np.float64(0.8457054747004874),\n",
      "                     np.float64(0.8561401604182136),\n",
      "                     np.float64(0.8577817546784167),\n",
      "                     np.float64(0.8636112764153139),\n",
      "                     np.float64(0.8655378418311249),\n",
      "                     np.float64(0.8643716211415714),\n",
      "                     np.float64(0.8680693915478284),\n",
      "                     np.float64(0.8686279022992358),\n",
      "                     np.float64(0.8693161046799286),\n",
      "                     np.float64(0.8700326098805156),\n",
      "                     np.float64(0.8707366570957815),\n",
      "                     np.float64(0.8719265000408868),\n",
      "                     np.float64(0.8682888671153265),\n",
      "                     np.float64(0.8724983286129847),\n",
      "                     np.float64(0.8753576834044836)],\n",
      "                    [np.float64(0.7061207561674773),\n",
      "                     np.float64(0.8034213113141164),\n",
      "                     np.float64(0.8320713473444427),\n",
      "                     np.float64(0.8397843110571943),\n",
      "                     np.float64(0.8470785107536529),\n",
      "                     np.float64(0.8489990291303318),\n",
      "                     np.float64(0.861581234420885),\n",
      "                     np.float64(0.8671098341151136),\n",
      "                     np.float64(0.8699155950400183),\n",
      "                     np.float64(0.8720663656762175),\n",
      "                     np.float64(0.8721836579554322),\n",
      "                     np.float64(0.8751943677629679),\n",
      "                     np.float64(0.8760508743325202),\n",
      "                     np.float64(0.8762330290766881),\n",
      "                     np.float64(0.8773677285741772),\n",
      "                     np.float64(0.8785687774930362),\n",
      "                     np.float64(0.879660138438054),\n",
      "                     np.float64(0.8800457177073399),\n",
      "                     np.float64(0.8806629254233853),\n",
      "                     np.float64(0.8804843430181548)],\n",
      "                    [np.float64(0.7386316719157953),\n",
      "                     np.float64(0.8140056040709657),\n",
      "                     np.float64(0.8289594637453637),\n",
      "                     np.float64(0.8431080799270477),\n",
      "                     np.float64(0.852259741404774),\n",
      "                     np.float64(0.8576986151561133),\n",
      "                     np.float64(0.8586462174827195),\n",
      "                     np.float64(0.8623174917353666),\n",
      "                     np.float64(0.8671170771134752),\n",
      "                     np.float64(0.8667652409645832),\n",
      "                     np.float64(0.8702055146215092),\n",
      "                     np.float64(0.8706910964003323),\n",
      "                     np.float64(0.8734528246925614),\n",
      "                     np.float64(0.8718294411471427),\n",
      "                     np.float64(0.8738956364203259),\n",
      "                     np.float64(0.8740282107751617),\n",
      "                     np.float64(0.8754245793595953),\n",
      "                     np.float64(0.8769509920088617),\n",
      "                     np.float64(0.8772028430939002),\n",
      "                     np.float64(0.8767750641547895)]]}\n",
      "Training Model: RNN, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.6442 - loss: 0.5856\n",
      "Epoch 1 - MCC: 0.6921\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 73ms/step - accuracy: 0.6453 - loss: 0.5846 - val_accuracy: 0.8462 - val_loss: 0.3639 - mcc: 0.6921\n",
      "Epoch 2/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8493 - loss: 0.3582\n",
      "Epoch 2 - MCC: 0.7104\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8493 - loss: 0.3581 - val_accuracy: 0.8555 - val_loss: 0.3404 - mcc: 0.7104\n",
      "Epoch 3/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8533 - loss: 0.3454\n",
      "Epoch 3 - MCC: 0.7024\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8533 - loss: 0.3454 - val_accuracy: 0.8507 - val_loss: 0.3600 - mcc: 0.7024\n",
      "Epoch 4/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8555 - loss: 0.3437\n",
      "Epoch 4 - MCC: 0.7281\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 39ms/step - accuracy: 0.8555 - loss: 0.3434 - val_accuracy: 0.8635 - val_loss: 0.3280 - mcc: 0.7281\n",
      "Epoch 5/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8623 - loss: 0.3259\n",
      "Epoch 5 - MCC: 0.7455\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8624 - loss: 0.3257 - val_accuracy: 0.8729 - val_loss: 0.3027 - mcc: 0.7455\n",
      "Epoch 6/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8671 - loss: 0.3171\n",
      "Epoch 6 - MCC: 0.7419\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8671 - loss: 0.3172 - val_accuracy: 0.8713 - val_loss: 0.3022 - mcc: 0.7419\n",
      "Epoch 7/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8719 - loss: 0.3051\n",
      "Epoch 7 - MCC: 0.7552\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 39ms/step - accuracy: 0.8720 - loss: 0.3051 - val_accuracy: 0.8774 - val_loss: 0.2929 - mcc: 0.7552\n",
      "Epoch 8/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8722 - loss: 0.3039\n",
      "Epoch 8 - MCC: 0.7640\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8722 - loss: 0.3038 - val_accuracy: 0.8823 - val_loss: 0.2818 - mcc: 0.7640\n",
      "Epoch 9/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8774 - loss: 0.2938\n",
      "Epoch 9 - MCC: 0.7623\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8774 - loss: 0.2939 - val_accuracy: 0.8812 - val_loss: 0.2849 - mcc: 0.7623\n",
      "Epoch 10/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8789 - loss: 0.2915\n",
      "Epoch 10 - MCC: 0.7480\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 39ms/step - accuracy: 0.8788 - loss: 0.2916 - val_accuracy: 0.8730 - val_loss: 0.2986 - mcc: 0.7480\n",
      "Epoch 11/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8798 - loss: 0.2886\n",
      "Epoch 11 - MCC: 0.7641\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8798 - loss: 0.2886 - val_accuracy: 0.8806 - val_loss: 0.2888 - mcc: 0.7641\n",
      "Epoch 12/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8793 - loss: 0.2907\n",
      "Epoch 12 - MCC: 0.7653\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 37ms/step - accuracy: 0.8793 - loss: 0.2907 - val_accuracy: 0.8824 - val_loss: 0.2823 - mcc: 0.7653\n",
      "Epoch 13/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8837 - loss: 0.2809\n",
      "Epoch 13 - MCC: 0.7600\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 39ms/step - accuracy: 0.8837 - loss: 0.2810 - val_accuracy: 0.8802 - val_loss: 0.2874 - mcc: 0.7600\n",
      "Epoch 14/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8702 - loss: 0.3105\n",
      "Epoch 14 - MCC: 0.7395\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8702 - loss: 0.3106 - val_accuracy: 0.8701 - val_loss: 0.3098 - mcc: 0.7395\n",
      "Epoch 15/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8728 - loss: 0.3059\n",
      "Epoch 15 - MCC: 0.7687\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8729 - loss: 0.3057 - val_accuracy: 0.8841 - val_loss: 0.2772 - mcc: 0.7687\n",
      "Epoch 16/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8867 - loss: 0.2733\n",
      "Epoch 16 - MCC: 0.7680\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 42ms/step - accuracy: 0.8867 - loss: 0.2734 - val_accuracy: 0.8837 - val_loss: 0.2759 - mcc: 0.7680\n",
      "Epoch 17/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8845 - loss: 0.2802\n",
      "Epoch 17 - MCC: 0.7608\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8845 - loss: 0.2802 - val_accuracy: 0.8807 - val_loss: 0.2839 - mcc: 0.7608\n",
      "Epoch 18/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8812 - loss: 0.2850\n",
      "Epoch 18 - MCC: 0.7638\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 37ms/step - accuracy: 0.8811 - loss: 0.2851 - val_accuracy: 0.8820 - val_loss: 0.2839 - mcc: 0.7638\n",
      "Epoch 19/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8762 - loss: 0.2976\n",
      "Epoch 19 - MCC: 0.7459\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 39ms/step - accuracy: 0.8761 - loss: 0.2978 - val_accuracy: 0.8731 - val_loss: 0.3047 - mcc: 0.7459\n",
      "Epoch 20/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8731 - loss: 0.3062\n",
      "Epoch 20 - MCC: 0.7492\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 37ms/step - accuracy: 0.8731 - loss: 0.3063 - val_accuracy: 0.8750 - val_loss: 0.3012 - mcc: 0.7492\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.6569 - loss: 0.5817\n",
      "Epoch 1 - MCC: 0.6876\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 76ms/step - accuracy: 0.6579 - loss: 0.5807 - val_accuracy: 0.8443 - val_loss: 0.3691 - mcc: 0.6876\n",
      "Epoch 2/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8434 - loss: 0.3686\n",
      "Epoch 2 - MCC: 0.7128\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8435 - loss: 0.3684 - val_accuracy: 0.8567 - val_loss: 0.3416 - mcc: 0.7128\n",
      "Epoch 3/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8552 - loss: 0.3439\n",
      "Epoch 3 - MCC: 0.7257\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 37ms/step - accuracy: 0.8552 - loss: 0.3438 - val_accuracy: 0.8624 - val_loss: 0.3306 - mcc: 0.7257\n",
      "Epoch 4/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8623 - loss: 0.3295\n",
      "Epoch 4 - MCC: 0.7481\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8623 - loss: 0.3294 - val_accuracy: 0.8743 - val_loss: 0.3019 - mcc: 0.7481\n",
      "Epoch 5/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8654 - loss: 0.3205\n",
      "Epoch 5 - MCC: 0.7362\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 37ms/step - accuracy: 0.8655 - loss: 0.3204 - val_accuracy: 0.8669 - val_loss: 0.3202 - mcc: 0.7362\n",
      "Epoch 6/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8665 - loss: 0.3189\n",
      "Epoch 6 - MCC: 0.7587\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8666 - loss: 0.3187 - val_accuracy: 0.8794 - val_loss: 0.2927 - mcc: 0.7587\n",
      "Epoch 7/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8669 - loss: 0.3179\n",
      "Epoch 7 - MCC: 0.7611\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 37ms/step - accuracy: 0.8670 - loss: 0.3177 - val_accuracy: 0.8809 - val_loss: 0.2898 - mcc: 0.7611\n",
      "Epoch 8/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8764 - loss: 0.2979\n",
      "Epoch 8 - MCC: 0.7651\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 37ms/step - accuracy: 0.8763 - loss: 0.2979 - val_accuracy: 0.8827 - val_loss: 0.2836 - mcc: 0.7651\n",
      "Epoch 9/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8783 - loss: 0.2923\n",
      "Epoch 9 - MCC: 0.7654\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 39ms/step - accuracy: 0.8783 - loss: 0.2923 - val_accuracy: 0.8828 - val_loss: 0.2835 - mcc: 0.7654\n",
      "Epoch 10/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8802 - loss: 0.2898\n",
      "Epoch 10 - MCC: 0.7697\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 37ms/step - accuracy: 0.8801 - loss: 0.2900 - val_accuracy: 0.8852 - val_loss: 0.2788 - mcc: 0.7697\n",
      "Epoch 11/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8811 - loss: 0.2881\n",
      "Epoch 11 - MCC: 0.7197\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 37ms/step - accuracy: 0.8811 - loss: 0.2883 - val_accuracy: 0.8598 - val_loss: 0.3365 - mcc: 0.7197\n",
      "Epoch 12/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8580 - loss: 0.3341\n",
      "Epoch 12 - MCC: 0.7426\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8581 - loss: 0.3340 - val_accuracy: 0.8715 - val_loss: 0.3095 - mcc: 0.7426\n",
      "Epoch 13/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8683 - loss: 0.3150\n",
      "Epoch 13 - MCC: 0.7489\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 37ms/step - accuracy: 0.8683 - loss: 0.3149 - val_accuracy: 0.8742 - val_loss: 0.3052 - mcc: 0.7489\n",
      "Epoch 14/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8716 - loss: 0.3105\n",
      "Epoch 14 - MCC: 0.7510\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 37ms/step - accuracy: 0.8716 - loss: 0.3105 - val_accuracy: 0.8753 - val_loss: 0.3041 - mcc: 0.7510\n",
      "Epoch 15/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8738 - loss: 0.3058\n",
      "Epoch 15 - MCC: 0.7527\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 42ms/step - accuracy: 0.8738 - loss: 0.3058 - val_accuracy: 0.8759 - val_loss: 0.3022 - mcc: 0.7527\n",
      "Epoch 16/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8750 - loss: 0.3038\n",
      "Epoch 16 - MCC: 0.7566\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 37ms/step - accuracy: 0.8750 - loss: 0.3039 - val_accuracy: 0.8781 - val_loss: 0.2988 - mcc: 0.7566\n",
      "Epoch 17/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8731 - loss: 0.3068\n",
      "Epoch 17 - MCC: 0.7575\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 37ms/step - accuracy: 0.8731 - loss: 0.3068 - val_accuracy: 0.8785 - val_loss: 0.2970 - mcc: 0.7575\n",
      "Epoch 18/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8765 - loss: 0.2997\n",
      "Epoch 18 - MCC: 0.7585\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8765 - loss: 0.2998 - val_accuracy: 0.8796 - val_loss: 0.2938 - mcc: 0.7585\n",
      "Epoch 19/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8731 - loss: 0.3059\n",
      "Epoch 19 - MCC: 0.7608\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 37ms/step - accuracy: 0.8731 - loss: 0.3058 - val_accuracy: 0.8800 - val_loss: 0.2933 - mcc: 0.7608\n",
      "Epoch 20/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8764 - loss: 0.2988\n",
      "Epoch 20 - MCC: 0.7709\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 37ms/step - accuracy: 0.8764 - loss: 0.2987 - val_accuracy: 0.8848 - val_loss: 0.2788 - mcc: 0.7709\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.6362 - loss: 0.5968\n",
      "Epoch 1 - MCC: 0.6732\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 63ms/step - accuracy: 0.6372 - loss: 0.5959 - val_accuracy: 0.8369 - val_loss: 0.3851 - mcc: 0.6732\n",
      "Epoch 2/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8459 - loss: 0.3640\n",
      "Epoch 2 - MCC: 0.7008\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 37ms/step - accuracy: 0.8460 - loss: 0.3638 - val_accuracy: 0.8509 - val_loss: 0.3519 - mcc: 0.7008\n",
      "Epoch 3/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8553 - loss: 0.3426\n",
      "Epoch 3 - MCC: 0.7158\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8554 - loss: 0.3425 - val_accuracy: 0.8579 - val_loss: 0.3375 - mcc: 0.7158\n",
      "Epoch 4/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8654 - loss: 0.3224\n",
      "Epoch 4 - MCC: 0.7223\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 37ms/step - accuracy: 0.8654 - loss: 0.3224 - val_accuracy: 0.8617 - val_loss: 0.3288 - mcc: 0.7223\n",
      "Epoch 5/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8685 - loss: 0.3155\n",
      "Epoch 5 - MCC: 0.7227\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8685 - loss: 0.3156 - val_accuracy: 0.8613 - val_loss: 0.3315 - mcc: 0.7227\n",
      "Epoch 6/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8682 - loss: 0.3157\n",
      "Epoch 6 - MCC: 0.7166\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8682 - loss: 0.3157 - val_accuracy: 0.8588 - val_loss: 0.3355 - mcc: 0.7166\n",
      "Epoch 7/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8684 - loss: 0.3170\n",
      "Epoch 7 - MCC: 0.7286\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 37ms/step - accuracy: 0.8684 - loss: 0.3169 - val_accuracy: 0.8630 - val_loss: 0.3269 - mcc: 0.7286\n",
      "Epoch 8/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8750 - loss: 0.3026\n",
      "Epoch 8 - MCC: 0.7388\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 37ms/step - accuracy: 0.8750 - loss: 0.3026 - val_accuracy: 0.8699 - val_loss: 0.3130 - mcc: 0.7388\n",
      "Epoch 9/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8748 - loss: 0.3018\n",
      "Epoch 9 - MCC: 0.7437\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 39ms/step - accuracy: 0.8749 - loss: 0.3017 - val_accuracy: 0.8716 - val_loss: 0.3103 - mcc: 0.7437\n",
      "Epoch 10/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8763 - loss: 0.2977\n",
      "Epoch 10 - MCC: 0.7525\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8763 - loss: 0.2977 - val_accuracy: 0.8767 - val_loss: 0.2951 - mcc: 0.7525\n",
      "Epoch 11/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8847 - loss: 0.2780\n",
      "Epoch 11 - MCC: 0.7494\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 37ms/step - accuracy: 0.8847 - loss: 0.2781 - val_accuracy: 0.8747 - val_loss: 0.3016 - mcc: 0.7494\n",
      "Epoch 12/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8818 - loss: 0.2841\n",
      "Epoch 12 - MCC: 0.7580\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8819 - loss: 0.2840 - val_accuracy: 0.8792 - val_loss: 0.2904 - mcc: 0.7580\n",
      "Epoch 13/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8820 - loss: 0.2875\n",
      "Epoch 13 - MCC: 0.7613\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8820 - loss: 0.2874 - val_accuracy: 0.8811 - val_loss: 0.2863 - mcc: 0.7613\n",
      "Epoch 14/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8854 - loss: 0.2766\n",
      "Epoch 14 - MCC: 0.7658\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 37ms/step - accuracy: 0.8854 - loss: 0.2766 - val_accuracy: 0.8829 - val_loss: 0.2809 - mcc: 0.7658\n",
      "Epoch 15/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8869 - loss: 0.2731\n",
      "Epoch 15 - MCC: 0.7435\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 39ms/step - accuracy: 0.8869 - loss: 0.2731 - val_accuracy: 0.8716 - val_loss: 0.3109 - mcc: 0.7435\n",
      "Epoch 16/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8816 - loss: 0.2867\n",
      "Epoch 16 - MCC: 0.7716\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8817 - loss: 0.2865 - val_accuracy: 0.8855 - val_loss: 0.2762 - mcc: 0.7716\n",
      "Epoch 17/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8887 - loss: 0.2707\n",
      "Epoch 17 - MCC: 0.7676\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8887 - loss: 0.2707 - val_accuracy: 0.8841 - val_loss: 0.2785 - mcc: 0.7676\n",
      "Epoch 18/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8887 - loss: 0.2694\n",
      "Epoch 18 - MCC: 0.7627\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8887 - loss: 0.2694 - val_accuracy: 0.8818 - val_loss: 0.2860 - mcc: 0.7627\n",
      "Epoch 19/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8927 - loss: 0.2616\n",
      "Epoch 19 - MCC: 0.7722\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8926 - loss: 0.2617 - val_accuracy: 0.8861 - val_loss: 0.2787 - mcc: 0.7722\n",
      "Epoch 20/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8868 - loss: 0.2726\n",
      "Epoch 20 - MCC: 0.7517\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8868 - loss: 0.2725 - val_accuracy: 0.8746 - val_loss: 0.2948 - mcc: 0.7517\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.6315 - loss: 0.5962\n",
      "Epoch 1 - MCC: 0.6881\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 64ms/step - accuracy: 0.6326 - loss: 0.5952 - val_accuracy: 0.8443 - val_loss: 0.3745 - mcc: 0.6881\n",
      "Epoch 2/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8463 - loss: 0.3665\n",
      "Epoch 2 - MCC: 0.7125\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 41ms/step - accuracy: 0.8463 - loss: 0.3663 - val_accuracy: 0.8566 - val_loss: 0.3418 - mcc: 0.7125\n",
      "Epoch 3/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8566 - loss: 0.3402\n",
      "Epoch 3 - MCC: 0.7215\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8566 - loss: 0.3402 - val_accuracy: 0.8608 - val_loss: 0.3319 - mcc: 0.7215\n",
      "Epoch 4/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8601 - loss: 0.3325\n",
      "Epoch 4 - MCC: 0.7329\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 37ms/step - accuracy: 0.8602 - loss: 0.3324 - val_accuracy: 0.8658 - val_loss: 0.3268 - mcc: 0.7329\n",
      "Epoch 5/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8663 - loss: 0.3206\n",
      "Epoch 5 - MCC: 0.7436\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 39ms/step - accuracy: 0.8663 - loss: 0.3207 - val_accuracy: 0.8720 - val_loss: 0.3108 - mcc: 0.7436\n",
      "Epoch 6/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8696 - loss: 0.3154\n",
      "Epoch 6 - MCC: 0.7408\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 37ms/step - accuracy: 0.8695 - loss: 0.3154 - val_accuracy: 0.8708 - val_loss: 0.3143 - mcc: 0.7408\n",
      "Epoch 7/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8711 - loss: 0.3126\n",
      "Epoch 7 - MCC: 0.7648\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 37ms/step - accuracy: 0.8711 - loss: 0.3126 - val_accuracy: 0.8823 - val_loss: 0.2854 - mcc: 0.7648\n",
      "Epoch 8/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8739 - loss: 0.3031\n",
      "Epoch 8 - MCC: 0.7243\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8739 - loss: 0.3031 - val_accuracy: 0.8615 - val_loss: 0.3389 - mcc: 0.7243\n",
      "Epoch 9/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8614 - loss: 0.3324\n",
      "Epoch 9 - MCC: 0.7492\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8615 - loss: 0.3321 - val_accuracy: 0.8750 - val_loss: 0.3002 - mcc: 0.7492\n",
      "Epoch 10/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8761 - loss: 0.2989\n",
      "Epoch 10 - MCC: 0.7671\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8761 - loss: 0.2989 - val_accuracy: 0.8839 - val_loss: 0.2799 - mcc: 0.7671\n",
      "Epoch 11/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8795 - loss: 0.2900\n",
      "Epoch 11 - MCC: 0.7767\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8795 - loss: 0.2900 - val_accuracy: 0.8887 - val_loss: 0.2708 - mcc: 0.7767\n",
      "Epoch 12/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8793 - loss: 0.2920\n",
      "Epoch 12 - MCC: 0.7243\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8792 - loss: 0.2923 - val_accuracy: 0.8625 - val_loss: 0.3255 - mcc: 0.7243\n",
      "Epoch 13/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8657 - loss: 0.3183\n",
      "Epoch 13 - MCC: 0.7447\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 39ms/step - accuracy: 0.8657 - loss: 0.3183 - val_accuracy: 0.8724 - val_loss: 0.3081 - mcc: 0.7447\n",
      "Epoch 14/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8689 - loss: 0.3138\n",
      "Epoch 14 - MCC: 0.7498\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 37ms/step - accuracy: 0.8690 - loss: 0.3137 - val_accuracy: 0.8744 - val_loss: 0.3052 - mcc: 0.7498\n",
      "Epoch 15/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8728 - loss: 0.3075\n",
      "Epoch 15 - MCC: 0.7472\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 37ms/step - accuracy: 0.8728 - loss: 0.3075 - val_accuracy: 0.8740 - val_loss: 0.3049 - mcc: 0.7472\n",
      "Epoch 16/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8754 - loss: 0.3016\n",
      "Epoch 16 - MCC: 0.7524\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 42ms/step - accuracy: 0.8753 - loss: 0.3017 - val_accuracy: 0.8766 - val_loss: 0.2973 - mcc: 0.7524\n",
      "Epoch 17/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8762 - loss: 0.2991\n",
      "Epoch 17 - MCC: 0.7405\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 37ms/step - accuracy: 0.8762 - loss: 0.2992 - val_accuracy: 0.8705 - val_loss: 0.3161 - mcc: 0.7405\n",
      "Epoch 18/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8712 - loss: 0.3113\n",
      "Epoch 18 - MCC: 0.7393\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8713 - loss: 0.3111 - val_accuracy: 0.8700 - val_loss: 0.3131 - mcc: 0.7393\n",
      "Epoch 19/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8708 - loss: 0.3098\n",
      "Epoch 19 - MCC: 0.7475\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 39ms/step - accuracy: 0.8708 - loss: 0.3097 - val_accuracy: 0.8739 - val_loss: 0.3031 - mcc: 0.7475\n",
      "Epoch 20/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8741 - loss: 0.3037\n",
      "Epoch 20 - MCC: 0.7546\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 37ms/step - accuracy: 0.8741 - loss: 0.3038 - val_accuracy: 0.8774 - val_loss: 0.2988 - mcc: 0.7546\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.6401 - loss: 0.5949\n",
      "Epoch 1 - MCC: 0.6705\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 66ms/step - accuracy: 0.6411 - loss: 0.5940 - val_accuracy: 0.8359 - val_loss: 0.3858 - mcc: 0.6705\n",
      "Epoch 2/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8419 - loss: 0.3720\n",
      "Epoch 2 - MCC: 0.7006\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 39ms/step - accuracy: 0.8420 - loss: 0.3718 - val_accuracy: 0.8507 - val_loss: 0.3505 - mcc: 0.7006\n",
      "Epoch 3/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8558 - loss: 0.3432\n",
      "Epoch 3 - MCC: 0.7165\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 39ms/step - accuracy: 0.8558 - loss: 0.3431 - val_accuracy: 0.8584 - val_loss: 0.3367 - mcc: 0.7165\n",
      "Epoch 4/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8607 - loss: 0.3325\n",
      "Epoch 4 - MCC: 0.7200\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8608 - loss: 0.3324 - val_accuracy: 0.8604 - val_loss: 0.3301 - mcc: 0.7200\n",
      "Epoch 5/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8663 - loss: 0.3211\n",
      "Epoch 5 - MCC: 0.7288\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8663 - loss: 0.3211 - val_accuracy: 0.8644 - val_loss: 0.3248 - mcc: 0.7288\n",
      "Epoch 6/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8719 - loss: 0.3104\n",
      "Epoch 6 - MCC: 0.6925\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 39ms/step - accuracy: 0.8719 - loss: 0.3105 - val_accuracy: 0.8449 - val_loss: 0.3619 - mcc: 0.6925\n",
      "Epoch 7/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8631 - loss: 0.3282\n",
      "Epoch 7 - MCC: 0.7397\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8632 - loss: 0.3280 - val_accuracy: 0.8702 - val_loss: 0.3104 - mcc: 0.7397\n",
      "Epoch 8/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8667 - loss: 0.3198\n",
      "Epoch 8 - MCC: 0.7176\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 37ms/step - accuracy: 0.8668 - loss: 0.3196 - val_accuracy: 0.8575 - val_loss: 0.3590 - mcc: 0.7176\n",
      "Epoch 9/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8711 - loss: 0.3094\n",
      "Epoch 9 - MCC: 0.7243\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 39ms/step - accuracy: 0.8712 - loss: 0.3093 - val_accuracy: 0.8624 - val_loss: 0.3261 - mcc: 0.7243\n",
      "Epoch 10/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8716 - loss: 0.3062\n",
      "Epoch 10 - MCC: 0.5641\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 37ms/step - accuracy: 0.8715 - loss: 0.3064 - val_accuracy: 0.7752 - val_loss: 0.4818 - mcc: 0.5641\n",
      "Epoch 11/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8407 - loss: 0.3690\n",
      "Epoch 11 - MCC: 0.7284\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8410 - loss: 0.3683 - val_accuracy: 0.8642 - val_loss: 0.3220 - mcc: 0.7284\n",
      "Epoch 12/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8653 - loss: 0.3206\n",
      "Epoch 12 - MCC: 0.7357\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8654 - loss: 0.3205 - val_accuracy: 0.8682 - val_loss: 0.3142 - mcc: 0.7357\n",
      "Epoch 13/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8700 - loss: 0.3119\n",
      "Epoch 13 - MCC: 0.7385\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8700 - loss: 0.3118 - val_accuracy: 0.8689 - val_loss: 0.3143 - mcc: 0.7385\n",
      "Epoch 14/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8692 - loss: 0.3130\n",
      "Epoch 14 - MCC: 0.7431\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8693 - loss: 0.3129 - val_accuracy: 0.8714 - val_loss: 0.3096 - mcc: 0.7431\n",
      "Epoch 15/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8753 - loss: 0.3030\n",
      "Epoch 15 - MCC: 0.7442\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 37ms/step - accuracy: 0.8753 - loss: 0.3031 - val_accuracy: 0.8723 - val_loss: 0.3071 - mcc: 0.7442\n",
      "Epoch 16/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8715 - loss: 0.3085\n",
      "Epoch 16 - MCC: 0.7464\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 38ms/step - accuracy: 0.8716 - loss: 0.3084 - val_accuracy: 0.8735 - val_loss: 0.3050 - mcc: 0.7464\n",
      "Epoch 17/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8756 - loss: 0.3012\n",
      "Epoch 17 - MCC: 0.7460\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 39ms/step - accuracy: 0.8756 - loss: 0.3012 - val_accuracy: 0.8731 - val_loss: 0.3046 - mcc: 0.7460\n",
      "Epoch 18/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8747 - loss: 0.3027\n",
      "Epoch 18 - MCC: 0.7483\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8747 - loss: 0.3027 - val_accuracy: 0.8745 - val_loss: 0.3030 - mcc: 0.7483\n",
      "Epoch 19/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8777 - loss: 0.2970\n",
      "Epoch 19 - MCC: 0.7483\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 38ms/step - accuracy: 0.8777 - loss: 0.2971 - val_accuracy: 0.8743 - val_loss: 0.3027 - mcc: 0.7483\n",
      "Epoch 20/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8784 - loss: 0.2958\n",
      "Epoch 20 - MCC: 0.7492\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 39ms/step - accuracy: 0.8784 - loss: 0.2959 - val_accuracy: 0.8743 - val_loss: 0.3031 - mcc: 0.7492\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.884784),\n",
      "              'mean': np.float64(0.8772144),\n",
      "              'min': np.float64(0.8742986666666667),\n",
      "              'std': np.float64(0.00393845943034133)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.00047535069783528644),\n",
      "                               'mean': np.float64(0.00046102085113525394),\n",
      "                               'min': np.float64(0.00044028854370117186),\n",
      "                               'std': np.float64(1.4467905762223714e-05)},\n",
      " 'MCC': {'max': np.float64(0.7708663586830065),\n",
      "         'mean': np.float64(0.7551200596817166),\n",
      "         'min': np.float64(0.749205611173082),\n",
      "         'std': np.float64(0.008122547121255095)},\n",
      " 'Parameters': 4691,\n",
      " 'Train Time (s)': {'max': np.float64(99.52117395401001),\n",
      "                    'mean': np.float64(93.67852005958557),\n",
      "                    'min': np.float64(88.84263348579407),\n",
      "                    'std': np.float64(4.010157653377745)},\n",
      " 'Training Accuracy': [[0.7469132542610168,\n",
      "                        0.8516077995300293,\n",
      "                        0.855607271194458,\n",
      "                        0.8598520755767822,\n",
      "                        0.8671892881393433,\n",
      "                        0.8665949702262878,\n",
      "                        0.8725940585136414,\n",
      "                        0.8738006353378296,\n",
      "                        0.876583993434906,\n",
      "                        0.8765195608139038,\n",
      "                        0.8798311948776245,\n",
      "                        0.8778076171875,\n",
      "                        0.8819153904914856,\n",
      "                        0.8672187328338623,\n",
      "                        0.8760313391685486,\n",
      "                        0.8839327692985535,\n",
      "                        0.8835693597793579,\n",
      "                        0.8778846263885498,\n",
      "                        0.8719114065170288,\n",
      "                        0.8728552460670471],\n",
      "                       [0.7527133822441101,\n",
      "                        0.8479665517807007,\n",
      "                        0.8566393256187439,\n",
      "                        0.8640487194061279,\n",
      "                        0.8689919710159302,\n",
      "                        0.8707854151725769,\n",
      "                        0.8716174960136414,\n",
      "                        0.8753297328948975,\n",
      "                        0.8773995041847229,\n",
      "                        0.8770292401313782,\n",
      "                        0.8781865835189819,\n",
      "                        0.8626760244369507,\n",
      "                        0.869125485420227,\n",
      "                        0.8710814714431763,\n",
      "                        0.8720940947532654,\n",
      "                        0.8726566433906555,\n",
      "                        0.874338686466217,\n",
      "                        0.8748925924301147,\n",
      "                        0.8758742809295654,\n",
      "                        0.879555881023407],\n",
      "                       [0.7287514805793762,\n",
      "                        0.8499178886413574,\n",
      "                        0.8588207364082336,\n",
      "                        0.8643567562103271,\n",
      "                        0.8678646683692932,\n",
      "                        0.8688520789146423,\n",
      "                        0.8700945377349854,\n",
      "                        0.8735620975494385,\n",
      "                        0.8772422075271606,\n",
      "                        0.8773267269134521,\n",
      "                        0.8823400735855103,\n",
      "                        0.8837648630142212,\n",
      "                        0.8828721642494202,\n",
      "                        0.8859686851501465,\n",
      "                        0.8833678364753723,\n",
      "                        0.8851308822631836,\n",
      "                        0.8875527381896973,\n",
      "                        0.8884009718894958,\n",
      "                        0.889291524887085,\n",
      "                        0.8892726898193359],\n",
      "                       [0.7340586185455322,\n",
      "                        0.8482191562652588,\n",
      "                        0.8570768237113953,\n",
      "                        0.8618901968002319,\n",
      "                        0.8649352788925171,\n",
      "                        0.8686491847038269,\n",
      "                        0.8710622787475586,\n",
      "                        0.8758952617645264,\n",
      "                        0.8674619793891907,\n",
      "                        0.8760836720466614,\n",
      "                        0.8788866400718689,\n",
      "                        0.8726247549057007,\n",
      "                        0.8660053014755249,\n",
      "                        0.871065080165863,\n",
      "                        0.8736196160316467,\n",
      "                        0.8740559816360474,\n",
      "                        0.8744934797286987,\n",
      "                        0.8755801320075989,\n",
      "                        0.873308002948761,\n",
      "                        0.8734447360038757],\n",
      "                       [0.7350519895553589,\n",
      "                        0.8476558327674866,\n",
      "                        0.8572107553482056,\n",
      "                        0.8629593253135681,\n",
      "                        0.8664200305938721,\n",
      "                        0.8687454462051392,\n",
      "                        0.8688510060310364,\n",
      "                        0.8714949488639832,\n",
      "                        0.8738920092582703,\n",
      "                        0.8668985962867737,\n",
      "                        0.8566327095031738,\n",
      "                        0.8686399459838867,\n",
      "                        0.8710761070251465,\n",
      "                        0.8722634315490723,\n",
      "                        0.8732174634933472,\n",
      "                        0.8740860223770142,\n",
      "                        0.8743693828582764,\n",
      "                        0.8752933144569397,\n",
      "                        0.8760042190551758,\n",
      "                        0.8762261271476746]],\n",
      " 'Training Loss': [[0.48772895336151123,\n",
      "                    0.3527264893054962,\n",
      "                    0.3445497751235962,\n",
      "                    0.3331149220466614,\n",
      "                    0.3147781193256378,\n",
      "                    0.3189566433429718,\n",
      "                    0.3053894340991974,\n",
      "                    0.3012906014919281,\n",
      "                    0.2953801453113556,\n",
      "                    0.29608798027038574,\n",
      "                    0.2885853350162506,\n",
      "                    0.29321351647377014,\n",
      "                    0.2843732237815857,\n",
      "                    0.31850576400756836,\n",
      "                    0.29752448201179504,\n",
      "                    0.2788310647010803,\n",
      "                    0.2809506952762604,\n",
      "                    0.2924852967262268,\n",
      "                    0.3072969913482666,\n",
      "                    0.30658578872680664],\n",
      "                   [0.4898490905761719,\n",
      "                    0.35890787839889526,\n",
      "                    0.34118151664733887,\n",
      "                    0.32535848021507263,\n",
      "                    0.3121801018714905,\n",
      "                    0.3100031018257141,\n",
      "                    0.30832329392433167,\n",
      "                    0.2993083894252777,\n",
      "                    0.2950752079486847,\n",
      "                    0.29553458094596863,\n",
      "                    0.29455479979515076,\n",
      "                    0.3252897560596466,\n",
      "                    0.3142393231391907,\n",
      "                    0.31108516454696655,\n",
      "                    0.30881282687187195,\n",
      "                    0.30791813135147095,\n",
      "                    0.30428197979927063,\n",
      "                    0.3029194176197052,\n",
      "                    0.30100443959236145,\n",
      "                    0.2921893000602722],\n",
      "                   [0.5108912587165833,\n",
      "                    0.35479235649108887,\n",
      "                    0.3352241516113281,\n",
      "                    0.32389578223228455,\n",
      "                    0.317692369222641,\n",
      "                    0.31531500816345215,\n",
      "                    0.31274086236953735,\n",
      "                    0.30532950162887573,\n",
      "                    0.2966121733188629,\n",
      "                    0.2955936789512634,\n",
      "                    0.28335368633270264,\n",
      "                    0.28023460507392883,\n",
      "                    0.2833799421787262,\n",
      "                    0.2751849293708801,\n",
      "                    0.2803453207015991,\n",
      "                    0.27836233377456665,\n",
      "                    0.272744745016098,\n",
      "                    0.2702752649784088,\n",
      "                    0.26699692010879517,\n",
      "                    0.2670600712299347],\n",
      "                   [0.5063991546630859,\n",
      "                    0.35927054286003113,\n",
      "                    0.3393554389476776,\n",
      "                    0.3297138214111328,\n",
      "                    0.32361647486686707,\n",
      "                    0.3167216181755066,\n",
      "                    0.3106037676334381,\n",
      "                    0.2992091178894043,\n",
      "                    0.3187263309955597,\n",
      "                    0.2985266149044037,\n",
      "                    0.2911994755268097,\n",
      "                    0.3060411512851715,\n",
      "                    0.3182149827480316,\n",
      "                    0.3098599314689636,\n",
      "                    0.30516892671585083,\n",
      "                    0.3043345510959625,\n",
      "                    0.3023586869239807,\n",
      "                    0.30063512921333313,\n",
      "                    0.3048487603664398,\n",
      "                    0.30497440695762634],\n",
      "                   [0.5108135342597961,\n",
      "                    0.3608940541744232,\n",
      "                    0.3391192555427551,\n",
      "                    0.3284664452075958,\n",
      "                    0.320652574300766,\n",
      "                    0.3158254325389862,\n",
      "                    0.31554433703422546,\n",
      "                    0.30912020802497864,\n",
      "                    0.303246408700943,\n",
      "                    0.31663960218429565,\n",
      "                    0.3379804193973541,\n",
      "                    0.31443801522254944,\n",
      "                    0.3099566102027893,\n",
      "                    0.3078516125679016,\n",
      "                    0.30617526173591614,\n",
      "                    0.30402734875679016,\n",
      "                    0.3034604787826538,\n",
      "                    0.3014170825481415,\n",
      "                    0.29973679780960083,\n",
      "                    0.29884132742881775]],\n",
      " 'Validation Accuracy': [[0.846216082572937,\n",
      "                          0.8554986715316772,\n",
      "                          0.8507226705551147,\n",
      "                          0.8634960055351257,\n",
      "                          0.8729333281517029,\n",
      "                          0.8712959885597229,\n",
      "                          0.8774028420448303,\n",
      "                          0.882256031036377,\n",
      "                          0.8811866641044617,\n",
      "                          0.8729814291000366,\n",
      "                          0.8806347846984863,\n",
      "                          0.882429301738739,\n",
      "                          0.8801813721656799,\n",
      "                          0.8700987696647644,\n",
      "                          0.8841227293014526,\n",
      "                          0.8837013244628906,\n",
      "                          0.8806853890419006,\n",
      "                          0.8819867372512817,\n",
      "                          0.873141348361969,\n",
      "                          0.8749840259552002],\n",
      "                         [0.8443253040313721,\n",
      "                          0.8567094206809998,\n",
      "                          0.8623759746551514,\n",
      "                          0.8743493556976318,\n",
      "                          0.8669360280036926,\n",
      "                          0.8794079422950745,\n",
      "                          0.880938708782196,\n",
      "                          0.8826960325241089,\n",
      "                          0.8827999830245972,\n",
      "                          0.8851520419120789,\n",
      "                          0.8597572445869446,\n",
      "                          0.8715279698371887,\n",
      "                          0.874154806137085,\n",
      "                          0.8753359913825989,\n",
      "                          0.8759413361549377,\n",
      "                          0.8780747056007385,\n",
      "                          0.8785440921783447,\n",
      "                          0.8796052932739258,\n",
      "                          0.8799627423286438,\n",
      "                          0.8847840428352356],\n",
      "                         [0.8369147181510925,\n",
      "                          0.8508639931678772,\n",
      "                          0.8579466938972473,\n",
      "                          0.8616934418678284,\n",
      "                          0.8613013625144958,\n",
      "                          0.8588399887084961,\n",
      "                          0.8630028367042542,\n",
      "                          0.8698987364768982,\n",
      "                          0.8715653419494629,\n",
      "                          0.8767359852790833,\n",
      "                          0.8747333884239197,\n",
      "                          0.8791681528091431,\n",
      "                          0.8810612559318542,\n",
      "                          0.8828693628311157,\n",
      "                          0.8716107606887817,\n",
      "                          0.8854799866676331,\n",
      "                          0.8841332793235779,\n",
      "                          0.8817573189735413,\n",
      "                          0.8860933184623718,\n",
      "                          0.8746161460876465],\n",
      "                         [0.8443067073822021,\n",
      "                          0.8565521836280823,\n",
      "                          0.8608133792877197,\n",
      "                          0.8657734394073486,\n",
      "                          0.8719547390937805,\n",
      "                          0.8707627058029175,\n",
      "                          0.8823468685150146,\n",
      "                          0.8615227341651917,\n",
      "                          0.8749573826789856,\n",
      "                          0.8839173316955566,\n",
      "                          0.8887119889259338,\n",
      "                          0.8624773621559143,\n",
      "                          0.8723761439323425,\n",
      "                          0.8744428157806396,\n",
      "                          0.8739947080612183,\n",
      "                          0.8765546679496765,\n",
      "                          0.8705441355705261,\n",
      "                          0.8700373768806458,\n",
      "                          0.8738908171653748,\n",
      "                          0.8773894309997559],\n",
      "                         [0.8359227180480957,\n",
      "                          0.8506801128387451,\n",
      "                          0.8584452867507935,\n",
      "                          0.8604347109794617,\n",
      "                          0.8644159436225891,\n",
      "                          0.8449040651321411,\n",
      "                          0.8702160120010376,\n",
      "                          0.8574800491333008,\n",
      "                          0.8623601794242859,\n",
      "                          0.7751920819282532,\n",
      "                          0.8642321228981018,\n",
      "                          0.8681786060333252,\n",
      "                          0.8688668012619019,\n",
      "                          0.8713813424110413,\n",
      "                          0.8723093271255493,\n",
      "                          0.8734585642814636,\n",
      "                          0.8731439709663391,\n",
      "                          0.8744774460792542,\n",
      "                          0.8743038773536682,\n",
      "                          0.8742986917495728]],\n",
      " 'Validation Loss': [0.38576188683509827,\n",
      "                     0.3505331575870514,\n",
      "                     0.3367317318916321,\n",
      "                     0.33012068271636963,\n",
      "                     0.3247597813606262,\n",
      "                     0.36185070872306824,\n",
      "                     0.3103661835193634,\n",
      "                     0.3590405285358429,\n",
      "                     0.32607948780059814,\n",
      "                     0.48177585005760193,\n",
      "                     0.32203409075737,\n",
      "                     0.3142017126083374,\n",
      "                     0.3143325746059418,\n",
      "                     0.30962637066841125,\n",
      "                     0.3070835471153259,\n",
      "                     0.30498960614204407,\n",
      "                     0.3046132028102875,\n",
      "                     0.3030175566673279,\n",
      "                     0.3026926815509796,\n",
      "                     0.3030650317668915],\n",
      " 'Validation MCC': [[np.float64(0.6921211262437243),\n",
      "                     np.float64(0.7103669480185626),\n",
      "                     np.float64(0.7023885303633833),\n",
      "                     np.float64(0.7280675881894239),\n",
      "                     np.float64(0.7454685449408958),\n",
      "                     np.float64(0.7419498578323501),\n",
      "                     np.float64(0.7552311659301012),\n",
      "                     np.float64(0.7639918274516305),\n",
      "                     np.float64(0.762315108587589),\n",
      "                     np.float64(0.7480023087474929),\n",
      "                     np.float64(0.7640609555610305),\n",
      "                     np.float64(0.7652783360279766),\n",
      "                     np.float64(0.7599847968851146),\n",
      "                     np.float64(0.7395423215629612),\n",
      "                     np.float64(0.7686837781919619),\n",
      "                     np.float64(0.767994564684064),\n",
      "                     np.float64(0.7607862489004191),\n",
      "                     np.float64(0.7638485378570531),\n",
      "                     np.float64(0.7458893167633446),\n",
      "                     np.float64(0.749219265281544)],\n",
      "                    [np.float64(0.6876390783346671),\n",
      "                     np.float64(0.7127733099184685),\n",
      "                     np.float64(0.7256798666817592),\n",
      "                     np.float64(0.7480847130789352),\n",
      "                     np.float64(0.7361767521459597),\n",
      "                     np.float64(0.7586609947204279),\n",
      "                     np.float64(0.7611274543911384),\n",
      "                     np.float64(0.7651443296901117),\n",
      "                     np.float64(0.7654330971581537),\n",
      "                     np.float64(0.769651843233726),\n",
      "                     np.float64(0.7197352722273366),\n",
      "                     np.float64(0.7426097245035392),\n",
      "                     np.float64(0.7489051915251911),\n",
      "                     np.float64(0.7509924125549242),\n",
      "                     np.float64(0.7526600397726079),\n",
      "                     np.float64(0.7565591020901796),\n",
      "                     np.float64(0.7574721808013001),\n",
      "                     np.float64(0.7585395007959329),\n",
      "                     np.float64(0.7608086963297459),\n",
      "                     np.float64(0.7708663586830065)],\n",
      "                    [np.float64(0.67321673634934),\n",
      "                     np.float64(0.7007964714424723),\n",
      "                     np.float64(0.7158420978101608),\n",
      "                     np.float64(0.7222950071618417),\n",
      "                     np.float64(0.7226975116713191),\n",
      "                     np.float64(0.71664447501543),\n",
      "                     np.float64(0.7286477322898938),\n",
      "                     np.float64(0.738817745453182),\n",
      "                     np.float64(0.7436667096957557),\n",
      "                     np.float64(0.752526573855153),\n",
      "                     np.float64(0.7493905234286012),\n",
      "                     np.float64(0.7580075720431058),\n",
      "                     np.float64(0.7612645140295872),\n",
      "                     np.float64(0.7658198204420659),\n",
      "                     np.float64(0.743499750765297),\n",
      "                     np.float64(0.7716342944968136),\n",
      "                     np.float64(0.7675706306510175),\n",
      "                     np.float64(0.7626981402272508),\n",
      "                     np.float64(0.7722295264749213),\n",
      "                     np.float64(0.7516702389198183)],\n",
      "                    [np.float64(0.6881365036888594),\n",
      "                     np.float64(0.7125042817776224),\n",
      "                     np.float64(0.7215177904983042),\n",
      "                     np.float64(0.7329008557495611),\n",
      "                     np.float64(0.7436098133849637),\n",
      "                     np.float64(0.7408448847381408),\n",
      "                     np.float64(0.7648140610172897),\n",
      "                     np.float64(0.7242606531193055),\n",
      "                     np.float64(0.7491820205227216),\n",
      "                     np.float64(0.7671324369356383),\n",
      "                     np.float64(0.7767430431314756),\n",
      "                     np.float64(0.7243164990147369),\n",
      "                     np.float64(0.7447248305357346),\n",
      "                     np.float64(0.7498280473052545),\n",
      "                     np.float64(0.7471969676844662),\n",
      "                     np.float64(0.7523537708597259),\n",
      "                     np.float64(0.7405044510782256),\n",
      "                     np.float64(0.7392568330685427),\n",
      "                     np.float64(0.7474968472256107),\n",
      "                     np.float64(0.7546388243511316)],\n",
      "                    [np.float64(0.6705431231387234),\n",
      "                     np.float64(0.700616630039098),\n",
      "                     np.float64(0.7164856153301815),\n",
      "                     np.float64(0.7199895995649827),\n",
      "                     np.float64(0.7288430634584504),\n",
      "                     np.float64(0.6925301787167248),\n",
      "                     np.float64(0.7397054031801947),\n",
      "                     np.float64(0.7175682508283916),\n",
      "                     np.float64(0.7242987423028951),\n",
      "                     np.float64(0.5640907966262765),\n",
      "                     np.float64(0.7284318635901175),\n",
      "                     np.float64(0.7357336661246758),\n",
      "                     np.float64(0.7385278133479083),\n",
      "                     np.float64(0.743100841360146),\n",
      "                     np.float64(0.7441898479535588),\n",
      "                     np.float64(0.7463575895108389),\n",
      "                     np.float64(0.7459925854328302),\n",
      "                     np.float64(0.7482600958871942),\n",
      "                     np.float64(0.7483079953534146),\n",
      "                     np.float64(0.749205611173082)]]}\n",
      "Training Model: GRU, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6242 - loss: 0.6494\n",
      "Epoch 1 - MCC: 0.6799\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 28ms/step - accuracy: 0.6277 - loss: 0.6458 - val_accuracy: 0.8404 - val_loss: 0.3747 - mcc: 0.6799\n",
      "Epoch 2/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8479 - loss: 0.3588\n",
      "Epoch 2 - MCC: 0.7166\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 25ms/step - accuracy: 0.8480 - loss: 0.3586 - val_accuracy: 0.8586 - val_loss: 0.3333 - mcc: 0.7166\n",
      "Epoch 3/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8614 - loss: 0.3302\n",
      "Epoch 3 - MCC: 0.7265\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 26ms/step - accuracy: 0.8614 - loss: 0.3303 - val_accuracy: 0.8634 - val_loss: 0.3228 - mcc: 0.7265\n",
      "Epoch 4/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8654 - loss: 0.3222\n",
      "Epoch 4 - MCC: 0.7341\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8654 - loss: 0.3222 - val_accuracy: 0.8671 - val_loss: 0.3155 - mcc: 0.7341\n",
      "Epoch 5/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8652 - loss: 0.3205\n",
      "Epoch 5 - MCC: 0.7376\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8652 - loss: 0.3205 - val_accuracy: 0.8692 - val_loss: 0.3106 - mcc: 0.7376\n",
      "Epoch 6/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8709 - loss: 0.3096\n",
      "Epoch 6 - MCC: 0.7440\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8709 - loss: 0.3096 - val_accuracy: 0.8723 - val_loss: 0.3045 - mcc: 0.7440\n",
      "Epoch 7/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8702 - loss: 0.3097\n",
      "Epoch 7 - MCC: 0.7526\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8703 - loss: 0.3095 - val_accuracy: 0.8765 - val_loss: 0.2927 - mcc: 0.7526\n",
      "Epoch 8/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8774 - loss: 0.2914\n",
      "Epoch 8 - MCC: 0.7761\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - accuracy: 0.8774 - loss: 0.2913 - val_accuracy: 0.8884 - val_loss: 0.2680 - mcc: 0.7761\n",
      "Epoch 9/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8894 - loss: 0.2659\n",
      "Epoch 9 - MCC: 0.7850\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 25ms/step - accuracy: 0.8893 - loss: 0.2659 - val_accuracy: 0.8927 - val_loss: 0.2622 - mcc: 0.7850\n",
      "Epoch 10/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8921 - loss: 0.2610\n",
      "Epoch 10 - MCC: 0.7853\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8920 - loss: 0.2611 - val_accuracy: 0.8926 - val_loss: 0.2603 - mcc: 0.7853\n",
      "Epoch 11/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8904 - loss: 0.2634\n",
      "Epoch 11 - MCC: 0.7883\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 21ms/step - accuracy: 0.8904 - loss: 0.2633 - val_accuracy: 0.8937 - val_loss: 0.2604 - mcc: 0.7883\n",
      "Epoch 12/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8918 - loss: 0.2601\n",
      "Epoch 12 - MCC: 0.7923\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8918 - loss: 0.2600 - val_accuracy: 0.8963 - val_loss: 0.2537 - mcc: 0.7923\n",
      "Epoch 13/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8953 - loss: 0.2540\n",
      "Epoch 13 - MCC: 0.7929\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 24ms/step - accuracy: 0.8953 - loss: 0.2540 - val_accuracy: 0.8964 - val_loss: 0.2527 - mcc: 0.7929\n",
      "Epoch 14/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8935 - loss: 0.2568\n",
      "Epoch 14 - MCC: 0.7932\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 29ms/step - accuracy: 0.8935 - loss: 0.2568 - val_accuracy: 0.8967 - val_loss: 0.2512 - mcc: 0.7932\n",
      "Epoch 15/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8933 - loss: 0.2566\n",
      "Epoch 15 - MCC: 0.7944\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.8933 - loss: 0.2565 - val_accuracy: 0.8973 - val_loss: 0.2505 - mcc: 0.7944\n",
      "Epoch 16/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8953 - loss: 0.2538\n",
      "Epoch 16 - MCC: 0.7939\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8953 - loss: 0.2537 - val_accuracy: 0.8972 - val_loss: 0.2501 - mcc: 0.7939\n",
      "Epoch 17/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8973 - loss: 0.2479\n",
      "Epoch 17 - MCC: 0.7934\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8973 - loss: 0.2480 - val_accuracy: 0.8970 - val_loss: 0.2505 - mcc: 0.7934\n",
      "Epoch 18/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.8970 - loss: 0.2485\n",
      "Epoch 18 - MCC: 0.7962\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - accuracy: 0.8969 - loss: 0.2486 - val_accuracy: 0.8981 - val_loss: 0.2488 - mcc: 0.7962\n",
      "Epoch 19/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8924 - loss: 0.2580\n",
      "Epoch 19 - MCC: 0.7925\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 24ms/step - accuracy: 0.8926 - loss: 0.2577 - val_accuracy: 0.8965 - val_loss: 0.2492 - mcc: 0.7925\n",
      "Epoch 20/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8967 - loss: 0.2490\n",
      "Epoch 20 - MCC: 0.7967\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8967 - loss: 0.2491 - val_accuracy: 0.8985 - val_loss: 0.2467 - mcc: 0.7967\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.6135 - loss: 0.6641\n",
      "Epoch 1 - MCC: 0.6796\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 32ms/step - accuracy: 0.6144 - loss: 0.6633 - val_accuracy: 0.8400 - val_loss: 0.3841 - mcc: 0.6796\n",
      "Epoch 2/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8453 - loss: 0.3661\n",
      "Epoch 2 - MCC: 0.7208\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.8453 - loss: 0.3659 - val_accuracy: 0.8606 - val_loss: 0.3319 - mcc: 0.7208\n",
      "Epoch 3/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8591 - loss: 0.3334\n",
      "Epoch 3 - MCC: 0.7315\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8591 - loss: 0.3334 - val_accuracy: 0.8660 - val_loss: 0.3200 - mcc: 0.7315\n",
      "Epoch 4/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8641 - loss: 0.3237\n",
      "Epoch 4 - MCC: 0.7398\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - accuracy: 0.8641 - loss: 0.3237 - val_accuracy: 0.8703 - val_loss: 0.3126 - mcc: 0.7398\n",
      "Epoch 5/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8672 - loss: 0.3162\n",
      "Epoch 5 - MCC: 0.7447\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8673 - loss: 0.3162 - val_accuracy: 0.8727 - val_loss: 0.3070 - mcc: 0.7447\n",
      "Epoch 6/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8712 - loss: 0.3093\n",
      "Epoch 6 - MCC: 0.7516\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 29ms/step - accuracy: 0.8712 - loss: 0.3093 - val_accuracy: 0.8761 - val_loss: 0.3009 - mcc: 0.7516\n",
      "Epoch 7/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8756 - loss: 0.3003\n",
      "Epoch 7 - MCC: 0.7555\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8755 - loss: 0.3005 - val_accuracy: 0.8779 - val_loss: 0.2969 - mcc: 0.7555\n",
      "Epoch 8/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8756 - loss: 0.3002\n",
      "Epoch 8 - MCC: 0.7572\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - accuracy: 0.8756 - loss: 0.3003 - val_accuracy: 0.8788 - val_loss: 0.2942 - mcc: 0.7572\n",
      "Epoch 9/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8750 - loss: 0.3015\n",
      "Epoch 9 - MCC: 0.7606\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8751 - loss: 0.3014 - val_accuracy: 0.8806 - val_loss: 0.2901 - mcc: 0.7606\n",
      "Epoch 10/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8783 - loss: 0.2941\n",
      "Epoch 10 - MCC: 0.7698\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8783 - loss: 0.2940 - val_accuracy: 0.8852 - val_loss: 0.2746 - mcc: 0.7698\n",
      "Epoch 11/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8866 - loss: 0.2718\n",
      "Epoch 11 - MCC: 0.7884\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8866 - loss: 0.2717 - val_accuracy: 0.8945 - val_loss: 0.2570 - mcc: 0.7884\n",
      "Epoch 12/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8902 - loss: 0.2639\n",
      "Epoch 12 - MCC: 0.7866\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - accuracy: 0.8902 - loss: 0.2638 - val_accuracy: 0.8936 - val_loss: 0.2575 - mcc: 0.7866\n",
      "Epoch 13/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8906 - loss: 0.2648\n",
      "Epoch 13 - MCC: 0.7906\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8907 - loss: 0.2646 - val_accuracy: 0.8952 - val_loss: 0.2540 - mcc: 0.7906\n",
      "Epoch 14/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8915 - loss: 0.2615\n",
      "Epoch 14 - MCC: 0.7929\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8915 - loss: 0.2613 - val_accuracy: 0.8967 - val_loss: 0.2506 - mcc: 0.7929\n",
      "Epoch 15/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8936 - loss: 0.2571\n",
      "Epoch 15 - MCC: 0.7889\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8936 - loss: 0.2571 - val_accuracy: 0.8948 - val_loss: 0.2526 - mcc: 0.7889\n",
      "Epoch 16/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8963 - loss: 0.2516\n",
      "Epoch 16 - MCC: 0.7923\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8963 - loss: 0.2518 - val_accuracy: 0.8965 - val_loss: 0.2512 - mcc: 0.7923\n",
      "Epoch 17/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8977 - loss: 0.2486\n",
      "Epoch 17 - MCC: 0.7943\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8976 - loss: 0.2488 - val_accuracy: 0.8974 - val_loss: 0.2474 - mcc: 0.7943\n",
      "Epoch 18/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.8954 - loss: 0.2523\n",
      "Epoch 18 - MCC: 0.7942\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 27ms/step - accuracy: 0.8954 - loss: 0.2522 - val_accuracy: 0.8973 - val_loss: 0.2471 - mcc: 0.7942\n",
      "Epoch 19/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8965 - loss: 0.2494\n",
      "Epoch 19 - MCC: 0.7967\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8965 - loss: 0.2494 - val_accuracy: 0.8986 - val_loss: 0.2453 - mcc: 0.7967\n",
      "Epoch 20/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8949 - loss: 0.2531\n",
      "Epoch 20 - MCC: 0.7937\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - accuracy: 0.8949 - loss: 0.2531 - val_accuracy: 0.8970 - val_loss: 0.2471 - mcc: 0.7937\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.6071 - loss: 0.6569\n",
      "Epoch 1 - MCC: 0.6783\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 26ms/step - accuracy: 0.6111 - loss: 0.6532 - val_accuracy: 0.8393 - val_loss: 0.3783 - mcc: 0.6783\n",
      "Epoch 2/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8499 - loss: 0.3564\n",
      "Epoch 2 - MCC: 0.7059\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 26ms/step - accuracy: 0.8500 - loss: 0.3562 - val_accuracy: 0.8533 - val_loss: 0.3459 - mcc: 0.7059\n",
      "Epoch 3/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8590 - loss: 0.3345\n",
      "Epoch 3 - MCC: 0.7146\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 27ms/step - accuracy: 0.8591 - loss: 0.3343 - val_accuracy: 0.8578 - val_loss: 0.3356 - mcc: 0.7146\n",
      "Epoch 4/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8647 - loss: 0.3217\n",
      "Epoch 4 - MCC: 0.7246\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8648 - loss: 0.3216 - val_accuracy: 0.8623 - val_loss: 0.3277 - mcc: 0.7246\n",
      "Epoch 5/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8696 - loss: 0.3129\n",
      "Epoch 5 - MCC: 0.7301\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - accuracy: 0.8696 - loss: 0.3128 - val_accuracy: 0.8647 - val_loss: 0.3240 - mcc: 0.7301\n",
      "Epoch 6/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8676 - loss: 0.3156\n",
      "Epoch 6 - MCC: 0.7366\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8677 - loss: 0.3155 - val_accuracy: 0.8683 - val_loss: 0.3165 - mcc: 0.7366\n",
      "Epoch 7/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8733 - loss: 0.3042\n",
      "Epoch 7 - MCC: 0.7454\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8734 - loss: 0.3040 - val_accuracy: 0.8726 - val_loss: 0.3062 - mcc: 0.7454\n",
      "Epoch 8/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8813 - loss: 0.2835\n",
      "Epoch 8 - MCC: 0.7677\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 29ms/step - accuracy: 0.8813 - loss: 0.2834 - val_accuracy: 0.8843 - val_loss: 0.2760 - mcc: 0.7677\n",
      "Epoch 9/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8893 - loss: 0.2662\n",
      "Epoch 9 - MCC: 0.7724\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8894 - loss: 0.2661 - val_accuracy: 0.8865 - val_loss: 0.2711 - mcc: 0.7724\n",
      "Epoch 10/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8900 - loss: 0.2635\n",
      "Epoch 10 - MCC: 0.7732\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8900 - loss: 0.2635 - val_accuracy: 0.8870 - val_loss: 0.2709 - mcc: 0.7732\n",
      "Epoch 11/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8903 - loss: 0.2632\n",
      "Epoch 11 - MCC: 0.7781\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8904 - loss: 0.2630 - val_accuracy: 0.8894 - val_loss: 0.2652 - mcc: 0.7781\n",
      "Epoch 12/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8951 - loss: 0.2537\n",
      "Epoch 12 - MCC: 0.7777\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8951 - loss: 0.2537 - val_accuracy: 0.8892 - val_loss: 0.2665 - mcc: 0.7777\n",
      "Epoch 13/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8931 - loss: 0.2570\n",
      "Epoch 13 - MCC: 0.7785\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - accuracy: 0.8931 - loss: 0.2570 - val_accuracy: 0.8892 - val_loss: 0.2659 - mcc: 0.7785\n",
      "Epoch 14/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8978 - loss: 0.2484\n",
      "Epoch 14 - MCC: 0.7798\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 27ms/step - accuracy: 0.8977 - loss: 0.2485 - val_accuracy: 0.8903 - val_loss: 0.2630 - mcc: 0.7798\n",
      "Epoch 15/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8932 - loss: 0.2567\n",
      "Epoch 15 - MCC: 0.7802\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8932 - loss: 0.2566 - val_accuracy: 0.8904 - val_loss: 0.2626 - mcc: 0.7802\n",
      "Epoch 16/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8960 - loss: 0.2519\n",
      "Epoch 16 - MCC: 0.7786\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8959 - loss: 0.2519 - val_accuracy: 0.8897 - val_loss: 0.2630 - mcc: 0.7786\n",
      "Epoch 17/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8961 - loss: 0.2508\n",
      "Epoch 17 - MCC: 0.7832\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8961 - loss: 0.2508 - val_accuracy: 0.8918 - val_loss: 0.2607 - mcc: 0.7832\n",
      "Epoch 18/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8986 - loss: 0.2450\n",
      "Epoch 18 - MCC: 0.7845\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8986 - loss: 0.2451 - val_accuracy: 0.8925 - val_loss: 0.2591 - mcc: 0.7845\n",
      "Epoch 19/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.8958 - loss: 0.2508\n",
      "Epoch 19 - MCC: 0.7812\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 31ms/step - accuracy: 0.8958 - loss: 0.2508 - val_accuracy: 0.8910 - val_loss: 0.2610 - mcc: 0.7812\n",
      "Epoch 20/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8962 - loss: 0.2508\n",
      "Epoch 20 - MCC: 0.7850\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.8963 - loss: 0.2507 - val_accuracy: 0.8928 - val_loss: 0.2577 - mcc: 0.7850\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6474 - loss: 0.6481\n",
      "Epoch 1 - MCC: 0.6934\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 29ms/step - accuracy: 0.6497 - loss: 0.6453 - val_accuracy: 0.8472 - val_loss: 0.3637 - mcc: 0.6934\n",
      "Epoch 2/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8508 - loss: 0.3528\n",
      "Epoch 2 - MCC: 0.7211\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 23ms/step - accuracy: 0.8509 - loss: 0.3525 - val_accuracy: 0.8607 - val_loss: 0.3313 - mcc: 0.7211\n",
      "Epoch 3/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8597 - loss: 0.3320\n",
      "Epoch 3 - MCC: 0.7299\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8597 - loss: 0.3320 - val_accuracy: 0.8651 - val_loss: 0.3207 - mcc: 0.7299\n",
      "Epoch 4/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8616 - loss: 0.3261\n",
      "Epoch 4 - MCC: 0.7383\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8617 - loss: 0.3260 - val_accuracy: 0.8693 - val_loss: 0.3117 - mcc: 0.7383\n",
      "Epoch 5/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8673 - loss: 0.3130\n",
      "Epoch 5 - MCC: 0.7471\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8673 - loss: 0.3130 - val_accuracy: 0.8739 - val_loss: 0.2999 - mcc: 0.7471\n",
      "Epoch 6/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8724 - loss: 0.3006\n",
      "Epoch 6 - MCC: 0.7636\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 25ms/step - accuracy: 0.8724 - loss: 0.3005 - val_accuracy: 0.8816 - val_loss: 0.2827 - mcc: 0.7636\n",
      "Epoch 7/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8825 - loss: 0.2808\n",
      "Epoch 7 - MCC: 0.7784\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - accuracy: 0.8826 - loss: 0.2808 - val_accuracy: 0.8894 - val_loss: 0.2660 - mcc: 0.7784\n",
      "Epoch 8/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8893 - loss: 0.2673\n",
      "Epoch 8 - MCC: 0.7814\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8893 - loss: 0.2673 - val_accuracy: 0.8910 - val_loss: 0.2627 - mcc: 0.7814\n",
      "Epoch 9/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8885 - loss: 0.2676\n",
      "Epoch 9 - MCC: 0.7834\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8885 - loss: 0.2675 - val_accuracy: 0.8917 - val_loss: 0.2609 - mcc: 0.7834\n",
      "Epoch 10/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8921 - loss: 0.2610\n",
      "Epoch 10 - MCC: 0.7853\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 21ms/step - accuracy: 0.8921 - loss: 0.2610 - val_accuracy: 0.8929 - val_loss: 0.2580 - mcc: 0.7853\n",
      "Epoch 11/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8939 - loss: 0.2566\n",
      "Epoch 11 - MCC: 0.7860\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8939 - loss: 0.2566 - val_accuracy: 0.8932 - val_loss: 0.2571 - mcc: 0.7860\n",
      "Epoch 12/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.8912 - loss: 0.2611\n",
      "Epoch 12 - MCC: 0.7858\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - accuracy: 0.8913 - loss: 0.2610 - val_accuracy: 0.8932 - val_loss: 0.2563 - mcc: 0.7858\n",
      "Epoch 13/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8924 - loss: 0.2583\n",
      "Epoch 13 - MCC: 0.7863\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8924 - loss: 0.2583 - val_accuracy: 0.8934 - val_loss: 0.2563 - mcc: 0.7863\n",
      "Epoch 14/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8939 - loss: 0.2550\n",
      "Epoch 14 - MCC: 0.7894\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8940 - loss: 0.2550 - val_accuracy: 0.8950 - val_loss: 0.2537 - mcc: 0.7894\n",
      "Epoch 15/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8956 - loss: 0.2515\n",
      "Epoch 15 - MCC: 0.7911\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8956 - loss: 0.2515 - val_accuracy: 0.8957 - val_loss: 0.2523 - mcc: 0.7911\n",
      "Epoch 16/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8950 - loss: 0.2531\n",
      "Epoch 16 - MCC: 0.7866\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8950 - loss: 0.2531 - val_accuracy: 0.8936 - val_loss: 0.2557 - mcc: 0.7866\n",
      "Epoch 17/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8937 - loss: 0.2558\n",
      "Epoch 17 - MCC: 0.7912\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - accuracy: 0.8937 - loss: 0.2558 - val_accuracy: 0.8959 - val_loss: 0.2512 - mcc: 0.7912\n",
      "Epoch 18/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8959 - loss: 0.2509\n",
      "Epoch 18 - MCC: 0.7904\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8959 - loss: 0.2509 - val_accuracy: 0.8955 - val_loss: 0.2512 - mcc: 0.7904\n",
      "Epoch 19/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8969 - loss: 0.2489\n",
      "Epoch 19 - MCC: 0.7926\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8969 - loss: 0.2489 - val_accuracy: 0.8966 - val_loss: 0.2496 - mcc: 0.7926\n",
      "Epoch 20/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8969 - loss: 0.2498\n",
      "Epoch 20 - MCC: 0.7949\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8969 - loss: 0.2498 - val_accuracy: 0.8977 - val_loss: 0.2473 - mcc: 0.7949\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.5975 - loss: 0.6678\n",
      "Epoch 1 - MCC: 0.6608\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 24ms/step - accuracy: 0.5983 - loss: 0.6671 - val_accuracy: 0.8310 - val_loss: 0.3945 - mcc: 0.6608\n",
      "Epoch 2/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8452 - loss: 0.3644\n",
      "Epoch 2 - MCC: 0.7119\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 29ms/step - accuracy: 0.8452 - loss: 0.3642 - val_accuracy: 0.8564 - val_loss: 0.3381 - mcc: 0.7119\n",
      "Epoch 3/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8600 - loss: 0.3320\n",
      "Epoch 3 - MCC: 0.7232\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8601 - loss: 0.3320 - val_accuracy: 0.8620 - val_loss: 0.3270 - mcc: 0.7232\n",
      "Epoch 4/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8647 - loss: 0.3223\n",
      "Epoch 4 - MCC: 0.7315\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8647 - loss: 0.3223 - val_accuracy: 0.8657 - val_loss: 0.3201 - mcc: 0.7315\n",
      "Epoch 5/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8681 - loss: 0.3157\n",
      "Epoch 5 - MCC: 0.7365\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8682 - loss: 0.3156 - val_accuracy: 0.8685 - val_loss: 0.3128 - mcc: 0.7365\n",
      "Epoch 6/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8707 - loss: 0.3097\n",
      "Epoch 6 - MCC: 0.7451\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.8708 - loss: 0.3096 - val_accuracy: 0.8727 - val_loss: 0.3022 - mcc: 0.7451\n",
      "Epoch 7/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8767 - loss: 0.2939\n",
      "Epoch 7 - MCC: 0.7693\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 26ms/step - accuracy: 0.8767 - loss: 0.2938 - val_accuracy: 0.8848 - val_loss: 0.2770 - mcc: 0.7693\n",
      "Epoch 8/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8875 - loss: 0.2701\n",
      "Epoch 8 - MCC: 0.7764\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 27ms/step - accuracy: 0.8875 - loss: 0.2701 - val_accuracy: 0.8884 - val_loss: 0.2681 - mcc: 0.7764\n",
      "Epoch 9/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8880 - loss: 0.2690\n",
      "Epoch 9 - MCC: 0.7796\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8881 - loss: 0.2687 - val_accuracy: 0.8901 - val_loss: 0.2632 - mcc: 0.7796\n",
      "Epoch 10/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8911 - loss: 0.2613\n",
      "Epoch 10 - MCC: 0.7819\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8911 - loss: 0.2613 - val_accuracy: 0.8913 - val_loss: 0.2612 - mcc: 0.7819\n",
      "Epoch 11/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8953 - loss: 0.2544\n",
      "Epoch 11 - MCC: 0.7823\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8952 - loss: 0.2545 - val_accuracy: 0.8915 - val_loss: 0.2596 - mcc: 0.7823\n",
      "Epoch 12/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8939 - loss: 0.2557\n",
      "Epoch 12 - MCC: 0.7842\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - accuracy: 0.8939 - loss: 0.2557 - val_accuracy: 0.8925 - val_loss: 0.2564 - mcc: 0.7842\n",
      "Epoch 13/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8963 - loss: 0.2515\n",
      "Epoch 13 - MCC: 0.7860\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - accuracy: 0.8963 - loss: 0.2516 - val_accuracy: 0.8934 - val_loss: 0.2558 - mcc: 0.7860\n",
      "Epoch 14/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8945 - loss: 0.2548\n",
      "Epoch 14 - MCC: 0.7872\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8945 - loss: 0.2547 - val_accuracy: 0.8940 - val_loss: 0.2546 - mcc: 0.7872\n",
      "Epoch 15/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8960 - loss: 0.2510\n",
      "Epoch 15 - MCC: 0.7888\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8960 - loss: 0.2511 - val_accuracy: 0.8947 - val_loss: 0.2527 - mcc: 0.7888\n",
      "Epoch 16/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8969 - loss: 0.2500\n",
      "Epoch 16 - MCC: 0.7881\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - accuracy: 0.8969 - loss: 0.2500 - val_accuracy: 0.8940 - val_loss: 0.2542 - mcc: 0.7881\n",
      "Epoch 17/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8976 - loss: 0.2488\n",
      "Epoch 17 - MCC: 0.7864\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8975 - loss: 0.2489 - val_accuracy: 0.8936 - val_loss: 0.2553 - mcc: 0.7864\n",
      "Epoch 18/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8948 - loss: 0.2536\n",
      "Epoch 18 - MCC: 0.7904\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - accuracy: 0.8949 - loss: 0.2534 - val_accuracy: 0.8955 - val_loss: 0.2502 - mcc: 0.7904\n",
      "Epoch 19/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8963 - loss: 0.2506\n",
      "Epoch 19 - MCC: 0.7879\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - accuracy: 0.8963 - loss: 0.2505 - val_accuracy: 0.8943 - val_loss: 0.2519 - mcc: 0.7879\n",
      "Epoch 20/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8969 - loss: 0.2482\n",
      "Epoch 20 - MCC: 0.7895\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - accuracy: 0.8969 - loss: 0.2482 - val_accuracy: 0.8950 - val_loss: 0.2506 - mcc: 0.7895\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.898488),\n",
      "              'mean': np.float64(0.896208),\n",
      "              'min': np.float64(0.8928053333333333),\n",
      "              'std': np.float64(0.0020554108970119653)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.0004736172358194987),\n",
      "                               'mean': np.float64(0.00047150548299153646),\n",
      "                               'min': np.float64(0.0004691308339436849),\n",
      "                               'std': np.float64(1.7049474118550771e-06)},\n",
      " 'MCC': {'max': np.float64(0.7966634041460389),\n",
      "         'mean': np.float64(0.7919302357904143),\n",
      "         'min': np.float64(0.7849747097535731),\n",
      "         'std': np.float64(0.004210556862029541)},\n",
      " 'Parameters': 4478,\n",
      " 'Train Time (s)': {'max': np.float64(57.67559003829956),\n",
      "                    'mean': np.float64(52.32693338394165),\n",
      "                    'min': np.float64(48.99950051307678),\n",
      "                    'std': np.float64(2.9293237722242718)},\n",
      " 'Training Accuracy': [[0.7086653113365173,\n",
      "                        0.8516492247581482,\n",
      "                        0.8601113557815552,\n",
      "                        0.8642382025718689,\n",
      "                        0.8677179217338562,\n",
      "                        0.8700132369995117,\n",
      "                        0.8732792139053345,\n",
      "                        0.880269467830658,\n",
      "                        0.8888803720474243,\n",
      "                        0.8904728293418884,\n",
      "                        0.8916196227073669,\n",
      "                        0.892646074295044,\n",
      "                        0.8936495184898376,\n",
      "                        0.8942359089851379,\n",
      "                        0.894498884677887,\n",
      "                        0.8953866362571716,\n",
      "                        0.8954140543937683,\n",
      "                        0.895440936088562,\n",
      "                        0.8958021402359009,\n",
      "                        0.8962901830673218],\n",
      "                       [0.6936487555503845,\n",
      "                        0.8504607677459717,\n",
      "                        0.8587679266929626,\n",
      "                        0.8638173937797546,\n",
      "                        0.8675205111503601,\n",
      "                        0.870028555393219,\n",
      "                        0.8722245097160339,\n",
      "                        0.8738240599632263,\n",
      "                        0.8755680918693542,\n",
      "                        0.8790601491928101,\n",
      "                        0.8886128067970276,\n",
      "                        0.8912453055381775,\n",
      "                        0.893069326877594,\n",
      "                        0.8937464952468872,\n",
      "                        0.8948480486869812,\n",
      "                        0.8947068452835083,\n",
      "                        0.8952614068984985,\n",
      "                        0.8957394361495972,\n",
      "                        0.8957878947257996,\n",
      "                        0.8966351747512817],\n",
      "                       [0.703079342842102,\n",
      "                        0.8534427285194397,\n",
      "                        0.861890435218811,\n",
      "                        0.8661059737205505,\n",
      "                        0.8696552515029907,\n",
      "                        0.8722332119941711,\n",
      "                        0.876146674156189,\n",
      "                        0.8854495286941528,\n",
      "                        0.8904547691345215,\n",
      "                        0.8917354345321655,\n",
      "                        0.892840564250946,\n",
      "                        0.8947579860687256,\n",
      "                        0.8946884870529175,\n",
      "                        0.8954053521156311,\n",
      "                        0.8954964280128479,\n",
      "                        0.8956106901168823,\n",
      "                        0.8964340090751648,\n",
      "                        0.8963345289230347,\n",
      "                        0.8961667418479919,\n",
      "                        0.897227942943573],\n",
      "                       [0.7214032411575317,\n",
      "                        0.8543266654014587,\n",
      "                        0.8610226511955261,\n",
      "                        0.8653600811958313,\n",
      "                        0.8691098690032959,\n",
      "                        0.8750771284103394,\n",
      "                        0.8841673135757446,\n",
      "                        0.8885371685028076,\n",
      "                        0.8903440833091736,\n",
      "                        0.8915358781814575,\n",
      "                        0.8919259309768677,\n",
      "                        0.8933501243591309,\n",
      "                        0.8938160538673401,\n",
      "                        0.8941074013710022,\n",
      "                        0.8948208093643188,\n",
      "                        0.8951507806777954,\n",
      "                        0.895500659942627,\n",
      "                        0.8959453701972961,\n",
      "                        0.8961631655693054,\n",
      "                        0.8965467214584351],\n",
      "                       [0.6766778826713562,\n",
      "                        0.8516573309898376,\n",
      "                        0.8611171841621399,\n",
      "                        0.865654706954956,\n",
      "                        0.8691646456718445,\n",
      "                        0.8723227381706238,\n",
      "                        0.8795353770256042,\n",
      "                        0.8880133628845215,\n",
      "                        0.8904592990875244,\n",
      "                        0.892167329788208,\n",
      "                        0.8933138251304626,\n",
      "                        0.8937667012214661,\n",
      "                        0.8942962288856506,\n",
      "                        0.8950799703598022,\n",
      "                        0.8951734304428101,\n",
      "                        0.8960182070732117,\n",
      "                        0.896173357963562,\n",
      "                        0.8966471552848816,\n",
      "                        0.8967465162277222,\n",
      "                        0.8968386054039001]],\n",
      " 'Training Loss': [[0.5619003772735596,\n",
      "                    0.3495858907699585,\n",
      "                    0.33134615421295166,\n",
      "                    0.3226805329322815,\n",
      "                    0.316000372171402,\n",
      "                    0.3107794523239136,\n",
      "                    0.3026401102542877,\n",
      "                    0.2840050756931305,\n",
      "                    0.26681941747665405,\n",
      "                    0.2631232738494873,\n",
      "                    0.26064473390579224,\n",
      "                    0.2581222653388977,\n",
      "                    0.25676706433296204,\n",
      "                    0.2549450397491455,\n",
      "                    0.25436586141586304,\n",
      "                    0.25272974371910095,\n",
      "                    0.25197380781173706,\n",
      "                    0.25182652473449707,\n",
      "                    0.2509033977985382,\n",
      "                    0.25002321600914],\n",
      "                   [0.587523877620697,\n",
      "                    0.35343098640441895,\n",
      "                    0.3335532546043396,\n",
      "                    0.3234957158565521,\n",
      "                    0.31623575091362,\n",
      "                    0.3112611174583435,\n",
      "                    0.30688637495040894,\n",
      "                    0.3035285174846649,\n",
      "                    0.29959577322006226,\n",
      "                    0.29120203852653503,\n",
      "                    0.268463671207428,\n",
      "                    0.2626520097255707,\n",
      "                    0.25883185863494873,\n",
      "                    0.25664281845092773,\n",
      "                    0.254660427570343,\n",
      "                    0.25459548830986023,\n",
      "                    0.2531835734844208,\n",
      "                    0.25175416469573975,\n",
      "                    0.25130969285964966,\n",
      "                    0.24971045553684235],\n",
      "                   [0.5684975385665894,\n",
      "                    0.3476657569408417,\n",
      "                    0.3280949592590332,\n",
      "                    0.3192044198513031,\n",
      "                    0.3122296631336212,\n",
      "                    0.3069235682487488,\n",
      "                    0.2986665666103363,\n",
      "                    0.2739693224430084,\n",
      "                    0.263824999332428,\n",
      "                    0.2604517936706543,\n",
      "                    0.2581183612346649,\n",
      "                    0.25478971004486084,\n",
      "                    0.25450599193573,\n",
      "                    0.25305724143981934,\n",
      "                    0.25242096185684204,\n",
      "                    0.2521499693393707,\n",
      "                    0.25046613812446594,\n",
      "                    0.24970664083957672,\n",
      "                    0.25004497170448303,\n",
      "                    0.24830275774002075],\n",
      "                   [0.558778703212738,\n",
      "                    0.3445650339126587,\n",
      "                    0.32878878712654114,\n",
      "                    0.3196760416030884,\n",
      "                    0.30972760915756226,\n",
      "                    0.2952243387699127,\n",
      "                    0.27724337577819824,\n",
      "                    0.2688165307044983,\n",
      "                    0.2646993100643158,\n",
      "                    0.26164019107818604,\n",
      "                    0.26080387830734253,\n",
      "                    0.2572694718837738,\n",
      "                    0.25617384910583496,\n",
      "                    0.25563421845436096,\n",
      "                    0.25364771485328674,\n",
      "                    0.25256913900375366,\n",
      "                    0.25189486145973206,\n",
      "                    0.2507885694503784,\n",
      "                    0.2503569722175598,\n",
      "                    0.24955038726329803],\n",
      "                   [0.5950791239738464,\n",
      "                    0.35061031579971313,\n",
      "                    0.3296847641468048,\n",
      "                    0.32061728835105896,\n",
      "                    0.31347209215164185,\n",
      "                    0.30586832761764526,\n",
      "                    0.28731054067611694,\n",
      "                    0.26890867948532104,\n",
      "                    0.26396021246910095,\n",
      "                    0.2598801255226135,\n",
      "                    0.25753235816955566,\n",
      "                    0.25601840019226074,\n",
      "                    0.25471213459968567,\n",
      "                    0.25335633754730225,\n",
      "                    0.25295454263687134,\n",
      "                    0.25150033831596375,\n",
      "                    0.2506958544254303,\n",
      "                    0.24961383640766144,\n",
      "                    0.2490585893392563,\n",
      "                    0.24926689267158508]],\n",
      " 'Validation Accuracy': [[0.8403867483139038,\n",
      "                          0.8586399555206299,\n",
      "                          0.8633679747581482,\n",
      "                          0.8671038150787354,\n",
      "                          0.8691521883010864,\n",
      "                          0.872322678565979,\n",
      "                          0.8765227198600769,\n",
      "                          0.8883599638938904,\n",
      "                          0.8927385807037354,\n",
      "                          0.8926318883895874,\n",
      "                          0.8936854004859924,\n",
      "                          0.8962852954864502,\n",
      "                          0.8964480757713318,\n",
      "                          0.8967093229293823,\n",
      "                          0.8973493576049805,\n",
      "                          0.897199809551239,\n",
      "                          0.8969839811325073,\n",
      "                          0.8980692625045776,\n",
      "                          0.8965440392494202,\n",
      "                          0.8984878659248352],\n",
      "                         [0.8400079607963562,\n",
      "                          0.8605919480323792,\n",
      "                          0.8659653067588806,\n",
      "                          0.8702933192253113,\n",
      "                          0.8726559281349182,\n",
      "                          0.8761013746261597,\n",
      "                          0.8778746724128723,\n",
      "                          0.8787946105003357,\n",
      "                          0.8805760741233826,\n",
      "                          0.8851945996284485,\n",
      "                          0.8944665789604187,\n",
      "                          0.8935546875,\n",
      "                          0.8951999545097351,\n",
      "                          0.8967040181159973,\n",
      "                          0.8947626352310181,\n",
      "                          0.8964504599571228,\n",
      "                          0.8973573446273804,\n",
      "                          0.8973466753959656,\n",
      "                          0.8986132144927979,\n",
      "                          0.8970346450805664],\n",
      "                         [0.8392507433891296,\n",
      "                          0.8532853722572327,\n",
      "                          0.8578453063964844,\n",
      "                          0.8623279333114624,\n",
      "                          0.8646665811538696,\n",
      "                          0.8683146834373474,\n",
      "                          0.8726106882095337,\n",
      "                          0.8842934370040894,\n",
      "                          0.8864986896514893,\n",
      "                          0.88700270652771,\n",
      "                          0.8894266486167908,\n",
      "                          0.8892291784286499,\n",
      "                          0.889218807220459,\n",
      "                          0.8903067111968994,\n",
      "                          0.8903919458389282,\n",
      "                          0.8897252678871155,\n",
      "                          0.891759991645813,\n",
      "                          0.8925145864486694,\n",
      "                          0.8910213112831116,\n",
      "                          0.8928053379058838],\n",
      "                         [0.8471946716308594,\n",
      "                          0.8606559038162231,\n",
      "                          0.8650932908058167,\n",
      "                          0.8693201541900635,\n",
      "                          0.8739014267921448,\n",
      "                          0.8815839886665344,\n",
      "                          0.8894479274749756,\n",
      "                          0.890951931476593,\n",
      "                          0.8917174339294434,\n",
      "                          0.8929254412651062,\n",
      "                          0.8931705951690674,\n",
      "                          0.8931945562362671,\n",
      "                          0.8934452533721924,\n",
      "                          0.8950027823448181,\n",
      "                          0.895693302154541,\n",
      "                          0.8936346173286438,\n",
      "                          0.8958960175514221,\n",
      "                          0.8955093026161194,\n",
      "                          0.8966053128242493,\n",
      "                          0.8977014422416687],\n",
      "                         [0.8310052752494812,\n",
      "                          0.8564080595970154,\n",
      "                          0.8619521260261536,\n",
      "                          0.8657041192054749,\n",
      "                          0.8684906363487244,\n",
      "                          0.8727332949638367,\n",
      "                          0.884754478931427,\n",
      "                          0.8884079456329346,\n",
      "                          0.8901440501213074,\n",
      "                          0.8913065791130066,\n",
      "                          0.891520082950592,\n",
      "                          0.8924640417098999,\n",
      "                          0.8933947086334229,\n",
      "                          0.8939918875694275,\n",
      "                          0.894711971282959,\n",
      "                          0.8940346837043762,\n",
      "                          0.8935680985450745,\n",
      "                          0.895541250705719,\n",
      "                          0.8943253755569458,\n",
      "                          0.8950106501579285]],\n",
      " 'Validation Loss': [0.39449113607406616,\n",
      "                     0.33810916543006897,\n",
      "                     0.32702773809432983,\n",
      "                     0.3201338052749634,\n",
      "                     0.3127671182155609,\n",
      "                     0.30220702290534973,\n",
      "                     0.27697354555130005,\n",
      "                     0.26811450719833374,\n",
      "                     0.2631956934928894,\n",
      "                     0.26121941208839417,\n",
      "                     0.2595618963241577,\n",
      "                     0.25635725259780884,\n",
      "                     0.25583431124687195,\n",
      "                     0.254596471786499,\n",
      "                     0.25269976258277893,\n",
      "                     0.2541904151439667,\n",
      "                     0.2553495764732361,\n",
      "                     0.250249445438385,\n",
      "                     0.25188538432121277,\n",
      "                     0.2505614161491394],\n",
      " 'Validation MCC': [[np.float64(0.6798945905178426),\n",
      "                     np.float64(0.7165719207836141),\n",
      "                     np.float64(0.7265032122918216),\n",
      "                     np.float64(0.7341471518562763),\n",
      "                     np.float64(0.7375528785634871),\n",
      "                     np.float64(0.743950739183372),\n",
      "                     np.float64(0.7525917721685986),\n",
      "                     np.float64(0.776064263152349),\n",
      "                     np.float64(0.7849618092663649),\n",
      "                     np.float64(0.7852969096570847),\n",
      "                     np.float64(0.7883032589675878),\n",
      "                     np.float64(0.7922718230783744),\n",
      "                     np.float64(0.7928561542873577),\n",
      "                     np.float64(0.7931544171976554),\n",
      "                     np.float64(0.7943848568715658),\n",
      "                     np.float64(0.7939246468941359),\n",
      "                     np.float64(0.7933769471528714),\n",
      "                     np.float64(0.7961962788081012),\n",
      "                     np.float64(0.7925089772426575),\n",
      "                     np.float64(0.7966634041460389)],\n",
      "                    [np.float64(0.6796228423994335),\n",
      "                     np.float64(0.7208011433211398),\n",
      "                     np.float64(0.7314613027676667),\n",
      "                     np.float64(0.7397806815529606),\n",
      "                     np.float64(0.7446725709123441),\n",
      "                     np.float64(0.7515702766807987),\n",
      "                     np.float64(0.7554861596719392),\n",
      "                     np.float64(0.7571560420476573),\n",
      "                     np.float64(0.7606453576689357),\n",
      "                     np.float64(0.7698209387157252),\n",
      "                     np.float64(0.7883523851423705),\n",
      "                     np.float64(0.7865937486575283),\n",
      "                     np.float64(0.7906149456648225),\n",
      "                     np.float64(0.7928685054488736),\n",
      "                     np.float64(0.7888913503635329),\n",
      "                     np.float64(0.7922738292200692),\n",
      "                     np.float64(0.7942864972985824),\n",
      "                     np.float64(0.7941987668289836),\n",
      "                     np.float64(0.7966767134089623),\n",
      "                     np.float64(0.7936563397233924)],\n",
      "                    [np.float64(0.6783124865279159),\n",
      "                     np.float64(0.7059382847732222),\n",
      "                     np.float64(0.7145803865814924),\n",
      "                     np.float64(0.7246260031610255),\n",
      "                     np.float64(0.7301487856327352),\n",
      "                     np.float64(0.7366115074224834),\n",
      "                     np.float64(0.7454075303776087),\n",
      "                     np.float64(0.7676972445989495),\n",
      "                     np.float64(0.7723812707161573),\n",
      "                     np.float64(0.7732331417213949),\n",
      "                     np.float64(0.7780583171819784),\n",
      "                     np.float64(0.777738591913978),\n",
      "                     np.float64(0.7784992138754165),\n",
      "                     np.float64(0.7798316465327993),\n",
      "                     np.float64(0.7801996215009129),\n",
      "                     np.float64(0.7786182414749309),\n",
      "                     np.float64(0.7831857232440097),\n",
      "                     np.float64(0.7845159243876096),\n",
      "                     np.float64(0.7812424960848303),\n",
      "                     np.float64(0.7849747097535731)],\n",
      "                    [np.float64(0.693396836378023),\n",
      "                     np.float64(0.7211484974802858),\n",
      "                     np.float64(0.7299112585080271),\n",
      "                     np.float64(0.7383164835444831),\n",
      "                     np.float64(0.7471469651492435),\n",
      "                     np.float64(0.7635825256719131),\n",
      "                     np.float64(0.7784228650367011),\n",
      "                     np.float64(0.7813832941421545),\n",
      "                     np.float64(0.7833772632528101),\n",
      "                     np.float64(0.7852570226960194),\n",
      "                     np.float64(0.786044778668448),\n",
      "                     np.float64(0.7858205725343592),\n",
      "                     np.float64(0.7862770931562095),\n",
      "                     np.float64(0.7894059979569377),\n",
      "                     np.float64(0.791063813512605),\n",
      "                     np.float64(0.7866213034203214),\n",
      "                     np.float64(0.7912434606140635),\n",
      "                     np.float64(0.790419291682002),\n",
      "                     np.float64(0.7925820823879441),\n",
      "                     np.float64(0.7948949001326441)],\n",
      "                    [np.float64(0.6607538738748457),\n",
      "                     np.float64(0.7118893812050755),\n",
      "                     np.float64(0.7232043375303286),\n",
      "                     np.float64(0.731495982198765),\n",
      "                     np.float64(0.7364620411897608),\n",
      "                     np.float64(0.7451136609171285),\n",
      "                     np.float64(0.7692896097289725),\n",
      "                     np.float64(0.7764394545685543),\n",
      "                     np.float64(0.7796242945063527),\n",
      "                     np.float64(0.7819235584090217),\n",
      "                     np.float64(0.7822672645248078),\n",
      "                     np.float64(0.7841879534982803),\n",
      "                     np.float64(0.7860118851840858),\n",
      "                     np.float64(0.7872111706062745),\n",
      "                     np.float64(0.7888210864122653),\n",
      "                     np.float64(0.7881039605007643),\n",
      "                     np.float64(0.7864453460197111),\n",
      "                     np.float64(0.7904179363497882),\n",
      "                     np.float64(0.7878792899306426),\n",
      "                     np.float64(0.7894618251964233)]]}\n",
      "Training Model: TCN, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.5481 - loss: 1.8403\n",
      "Epoch 1 - MCC: 0.4970\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 86ms/step - accuracy: 0.5488 - loss: 1.8315 - val_accuracy: 0.7478 - val_loss: 0.5137 - mcc: 0.4970\n",
      "Epoch 2/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7747 - loss: 0.4770\n",
      "Epoch 2 - MCC: 0.6586\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 8ms/step - accuracy: 0.7761 - loss: 0.4748 - val_accuracy: 0.8298 - val_loss: 0.3854 - mcc: 0.6586\n",
      "Epoch 3/20\n",
      "\u001B[1m83/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8339 - loss: 0.3782\n",
      "Epoch 3 - MCC: 0.6914\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8343 - loss: 0.3772 - val_accuracy: 0.8462 - val_loss: 0.3507 - mcc: 0.6914\n",
      "Epoch 4/20\n",
      "\u001B[1m86/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8510 - loss: 0.3429\n",
      "Epoch 4 - MCC: 0.7095\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8509 - loss: 0.3430 - val_accuracy: 0.8551 - val_loss: 0.3330 - mcc: 0.7095\n",
      "Epoch 5/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8592 - loss: 0.3276\n",
      "Epoch 5 - MCC: 0.7273\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8592 - loss: 0.3277 - val_accuracy: 0.8638 - val_loss: 0.3196 - mcc: 0.7273\n",
      "Epoch 6/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8634 - loss: 0.3202\n",
      "Epoch 6 - MCC: 0.7348\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8634 - loss: 0.3202 - val_accuracy: 0.8677 - val_loss: 0.3104 - mcc: 0.7348\n",
      "Epoch 7/20\n",
      "\u001B[1m85/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8650 - loss: 0.3157\n",
      "Epoch 7 - MCC: 0.7407\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8652 - loss: 0.3153 - val_accuracy: 0.8704 - val_loss: 0.3053 - mcc: 0.7407\n",
      "Epoch 8/20\n",
      "\u001B[1m86/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8693 - loss: 0.3067\n",
      "Epoch 8 - MCC: 0.7386\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8693 - loss: 0.3067 - val_accuracy: 0.8696 - val_loss: 0.3033 - mcc: 0.7386\n",
      "Epoch 9/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8716 - loss: 0.3017\n",
      "Epoch 9 - MCC: 0.7448\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8716 - loss: 0.3017 - val_accuracy: 0.8728 - val_loss: 0.2979 - mcc: 0.7448\n",
      "Epoch 10/20\n",
      "\u001B[1m86/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8737 - loss: 0.2975\n",
      "Epoch 10 - MCC: 0.7461\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8736 - loss: 0.2977 - val_accuracy: 0.8734 - val_loss: 0.2963 - mcc: 0.7461\n",
      "Epoch 11/20\n",
      "\u001B[1m84/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8721 - loss: 0.3008\n",
      "Epoch 11 - MCC: 0.7489\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8723 - loss: 0.3002 - val_accuracy: 0.8748 - val_loss: 0.2930 - mcc: 0.7489\n",
      "Epoch 12/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8761 - loss: 0.2925\n",
      "Epoch 12 - MCC: 0.7542\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8761 - loss: 0.2925 - val_accuracy: 0.8767 - val_loss: 0.2901 - mcc: 0.7542\n",
      "Epoch 13/20\n",
      "\u001B[1m87/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8763 - loss: 0.2916\n",
      "Epoch 13 - MCC: 0.7543\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8763 - loss: 0.2916 - val_accuracy: 0.8775 - val_loss: 0.2873 - mcc: 0.7543\n",
      "Epoch 14/20\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8770 - loss: 0.2909\n",
      "Epoch 14 - MCC: 0.7557\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8770 - loss: 0.2908 - val_accuracy: 0.8781 - val_loss: 0.2858 - mcc: 0.7557\n",
      "Epoch 15/20\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8762 - loss: 0.2909\n",
      "Epoch 15 - MCC: 0.7589\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8764 - loss: 0.2907 - val_accuracy: 0.8796 - val_loss: 0.2835 - mcc: 0.7589\n",
      "Epoch 16/20\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8754 - loss: 0.2909\n",
      "Epoch 16 - MCC: 0.7606\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8757 - loss: 0.2905 - val_accuracy: 0.8802 - val_loss: 0.2821 - mcc: 0.7606\n",
      "Epoch 17/20\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8778 - loss: 0.2876\n",
      "Epoch 17 - MCC: 0.7597\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8779 - loss: 0.2874 - val_accuracy: 0.8802 - val_loss: 0.2814 - mcc: 0.7597\n",
      "Epoch 18/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8792 - loss: 0.2850\n",
      "Epoch 18 - MCC: 0.7626\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8792 - loss: 0.2849 - val_accuracy: 0.8809 - val_loss: 0.2804 - mcc: 0.7626\n",
      "Epoch 19/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8812 - loss: 0.2805\n",
      "Epoch 19 - MCC: 0.7631\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8812 - loss: 0.2806 - val_accuracy: 0.8817 - val_loss: 0.2778 - mcc: 0.7631\n",
      "Epoch 20/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8795 - loss: 0.2838\n",
      "Epoch 20 - MCC: 0.7630\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8795 - loss: 0.2838 - val_accuracy: 0.8815 - val_loss: 0.2780 - mcc: 0.7630\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: TCN, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.5921 - loss: 1.1696\n",
      "Epoch 1 - MCC: 0.5982\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 74ms/step - accuracy: 0.5929 - loss: 1.1653 - val_accuracy: 0.7990 - val_loss: 0.4479 - mcc: 0.5982\n",
      "Epoch 2/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8159 - loss: 0.4201\n",
      "Epoch 2 - MCC: 0.6978\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8167 - loss: 0.4185 - val_accuracy: 0.8494 - val_loss: 0.3528 - mcc: 0.6978\n",
      "Epoch 3/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8485 - loss: 0.3521\n",
      "Epoch 3 - MCC: 0.7240\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8486 - loss: 0.3518 - val_accuracy: 0.8621 - val_loss: 0.3255 - mcc: 0.7240\n",
      "Epoch 4/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8591 - loss: 0.3301\n",
      "Epoch 4 - MCC: 0.7338\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8592 - loss: 0.3300 - val_accuracy: 0.8673 - val_loss: 0.3135 - mcc: 0.7338\n",
      "Epoch 5/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8646 - loss: 0.3174\n",
      "Epoch 5 - MCC: 0.7442\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8646 - loss: 0.3174 - val_accuracy: 0.8722 - val_loss: 0.3046 - mcc: 0.7442\n",
      "Epoch 6/20\n",
      "\u001B[1m84/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8697 - loss: 0.3074\n",
      "Epoch 6 - MCC: 0.7499\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8696 - loss: 0.3075 - val_accuracy: 0.8750 - val_loss: 0.2983 - mcc: 0.7499\n",
      "Epoch 7/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8689 - loss: 0.3077\n",
      "Epoch 7 - MCC: 0.7498\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8690 - loss: 0.3075 - val_accuracy: 0.8752 - val_loss: 0.2956 - mcc: 0.7498\n",
      "Epoch 8/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8708 - loss: 0.3031\n",
      "Epoch 8 - MCC: 0.7554\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8709 - loss: 0.3029 - val_accuracy: 0.8781 - val_loss: 0.2898 - mcc: 0.7554\n",
      "Epoch 9/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8754 - loss: 0.2941\n",
      "Epoch 9 - MCC: 0.7611\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8754 - loss: 0.2940 - val_accuracy: 0.8809 - val_loss: 0.2851 - mcc: 0.7611\n",
      "Epoch 10/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8759 - loss: 0.2928\n",
      "Epoch 10 - MCC: 0.7640\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8759 - loss: 0.2927 - val_accuracy: 0.8821 - val_loss: 0.2818 - mcc: 0.7640\n",
      "Epoch 11/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8774 - loss: 0.2895\n",
      "Epoch 11 - MCC: 0.7646\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8774 - loss: 0.2895 - val_accuracy: 0.8825 - val_loss: 0.2800 - mcc: 0.7646\n",
      "Epoch 12/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8794 - loss: 0.2837\n",
      "Epoch 12 - MCC: 0.7607\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8793 - loss: 0.2839 - val_accuracy: 0.8806 - val_loss: 0.2826 - mcc: 0.7607\n",
      "Epoch 13/20\n",
      "\u001B[1m85/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8790 - loss: 0.2848\n",
      "Epoch 13 - MCC: 0.7658\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8791 - loss: 0.2848 - val_accuracy: 0.8832 - val_loss: 0.2775 - mcc: 0.7658\n",
      "Epoch 14/20\n",
      "\u001B[1m87/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8782 - loss: 0.2855\n",
      "Epoch 14 - MCC: 0.7693\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8783 - loss: 0.2854 - val_accuracy: 0.8849 - val_loss: 0.2748 - mcc: 0.7693\n",
      "Epoch 15/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8789 - loss: 0.2852\n",
      "Epoch 15 - MCC: 0.7696\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8790 - loss: 0.2850 - val_accuracy: 0.8848 - val_loss: 0.2742 - mcc: 0.7696\n",
      "Epoch 16/20\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8813 - loss: 0.2803\n",
      "Epoch 16 - MCC: 0.7705\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8813 - loss: 0.2804 - val_accuracy: 0.8855 - val_loss: 0.2729 - mcc: 0.7705\n",
      "Epoch 17/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8806 - loss: 0.2809\n",
      "Epoch 17 - MCC: 0.7716\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8806 - loss: 0.2809 - val_accuracy: 0.8859 - val_loss: 0.2716 - mcc: 0.7716\n",
      "Epoch 18/20\n",
      "\u001B[1m83/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8828 - loss: 0.2765\n",
      "Epoch 18 - MCC: 0.7721\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8827 - loss: 0.2768 - val_accuracy: 0.8860 - val_loss: 0.2713 - mcc: 0.7721\n",
      "Epoch 19/20\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8799 - loss: 0.2825\n",
      "Epoch 19 - MCC: 0.7715\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8800 - loss: 0.2821 - val_accuracy: 0.8860 - val_loss: 0.2704 - mcc: 0.7715\n",
      "Epoch 20/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8834 - loss: 0.2755\n",
      "Epoch 20 - MCC: 0.7725\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8834 - loss: 0.2756 - val_accuracy: 0.8865 - val_loss: 0.2691 - mcc: 0.7725\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: TCN, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.5898 - loss: 0.9862\n",
      "Epoch 1 - MCC: 0.6382\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 80ms/step - accuracy: 0.5910 - loss: 0.9828 - val_accuracy: 0.8199 - val_loss: 0.4143 - mcc: 0.6382\n",
      "Epoch 2/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8338 - loss: 0.3871\n",
      "Epoch 2 - MCC: 0.6829\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8340 - loss: 0.3866 - val_accuracy: 0.8421 - val_loss: 0.3644 - mcc: 0.6829\n",
      "Epoch 3/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8503 - loss: 0.3472\n",
      "Epoch 3 - MCC: 0.6977\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8503 - loss: 0.3471 - val_accuracy: 0.8492 - val_loss: 0.3477 - mcc: 0.6977\n",
      "Epoch 4/20\n",
      "\u001B[1m86/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8532 - loss: 0.3392\n",
      "Epoch 4 - MCC: 0.7059\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8536 - loss: 0.3385 - val_accuracy: 0.8534 - val_loss: 0.3370 - mcc: 0.7059\n",
      "Epoch 5/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8598 - loss: 0.3246\n",
      "Epoch 5 - MCC: 0.7168\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8600 - loss: 0.3244 - val_accuracy: 0.8583 - val_loss: 0.3275 - mcc: 0.7168\n",
      "Epoch 6/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8619 - loss: 0.3200\n",
      "Epoch 6 - MCC: 0.7222\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8622 - loss: 0.3195 - val_accuracy: 0.8609 - val_loss: 0.3206 - mcc: 0.7222\n",
      "Epoch 7/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8717 - loss: 0.2996\n",
      "Epoch 7 - MCC: 0.7269\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8716 - loss: 0.2999 - val_accuracy: 0.8639 - val_loss: 0.3144 - mcc: 0.7269\n",
      "Epoch 8/20\n",
      "\u001B[1m86/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8690 - loss: 0.3046\n",
      "Epoch 8 - MCC: 0.7291\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8692 - loss: 0.3043 - val_accuracy: 0.8651 - val_loss: 0.3108 - mcc: 0.7291\n",
      "Epoch 9/20\n",
      "\u001B[1m87/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8717 - loss: 0.2998\n",
      "Epoch 9 - MCC: 0.7342\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8718 - loss: 0.2995 - val_accuracy: 0.8659 - val_loss: 0.3111 - mcc: 0.7342\n",
      "Epoch 10/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8728 - loss: 0.2972\n",
      "Epoch 10 - MCC: 0.7407\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8728 - loss: 0.2971 - val_accuracy: 0.8705 - val_loss: 0.3015 - mcc: 0.7407\n",
      "Epoch 11/20\n",
      "\u001B[1m82/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8763 - loss: 0.2910\n",
      "Epoch 11 - MCC: 0.7408\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8764 - loss: 0.2906 - val_accuracy: 0.8709 - val_loss: 0.2998 - mcc: 0.7408\n",
      "Epoch 12/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8809 - loss: 0.2811\n",
      "Epoch 12 - MCC: 0.7434\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8807 - loss: 0.2814 - val_accuracy: 0.8722 - val_loss: 0.2973 - mcc: 0.7434\n",
      "Epoch 13/20\n",
      "\u001B[1m85/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8851 - loss: 0.2721\n",
      "Epoch 13 - MCC: 0.7402\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8846 - loss: 0.2733 - val_accuracy: 0.8705 - val_loss: 0.3013 - mcc: 0.7402\n",
      "Epoch 14/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8788 - loss: 0.2845\n",
      "Epoch 14 - MCC: 0.7489\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8789 - loss: 0.2844 - val_accuracy: 0.8738 - val_loss: 0.2959 - mcc: 0.7489\n",
      "Epoch 15/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8803 - loss: 0.2814\n",
      "Epoch 15 - MCC: 0.7500\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8804 - loss: 0.2813 - val_accuracy: 0.8754 - val_loss: 0.2912 - mcc: 0.7500\n",
      "Epoch 16/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8800 - loss: 0.2819\n",
      "Epoch 16 - MCC: 0.7526\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8800 - loss: 0.2818 - val_accuracy: 0.8765 - val_loss: 0.2891 - mcc: 0.7526\n",
      "Epoch 17/20\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8819 - loss: 0.2774\n",
      "Epoch 17 - MCC: 0.7530\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8820 - loss: 0.2774 - val_accuracy: 0.8769 - val_loss: 0.2880 - mcc: 0.7530\n",
      "Epoch 18/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8846 - loss: 0.2732\n",
      "Epoch 18 - MCC: 0.7554\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8845 - loss: 0.2733 - val_accuracy: 0.8776 - val_loss: 0.2870 - mcc: 0.7554\n",
      "Epoch 19/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8823 - loss: 0.2775\n",
      "Epoch 19 - MCC: 0.7556\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8824 - loss: 0.2775 - val_accuracy: 0.8781 - val_loss: 0.2855 - mcc: 0.7556\n",
      "Epoch 20/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8846 - loss: 0.2721\n",
      "Epoch 20 - MCC: 0.7546\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8846 - loss: 0.2722 - val_accuracy: 0.8777 - val_loss: 0.2855 - mcc: 0.7546\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: TCN, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.6144 - loss: 0.8359\n",
      "Epoch 1 - MCC: 0.6131\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 71ms/step - accuracy: 0.6152 - loss: 0.8337 - val_accuracy: 0.8072 - val_loss: 0.4387 - mcc: 0.6131\n",
      "Epoch 2/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8235 - loss: 0.4066\n",
      "Epoch 2 - MCC: 0.6936\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8236 - loss: 0.4064 - val_accuracy: 0.8472 - val_loss: 0.3546 - mcc: 0.6936\n",
      "Epoch 3/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8449 - loss: 0.3568\n",
      "Epoch 3 - MCC: 0.7114\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8451 - loss: 0.3564 - val_accuracy: 0.8561 - val_loss: 0.3351 - mcc: 0.7114\n",
      "Epoch 4/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8533 - loss: 0.3399\n",
      "Epoch 4 - MCC: 0.7221\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8535 - loss: 0.3396 - val_accuracy: 0.8602 - val_loss: 0.3261 - mcc: 0.7221\n",
      "Epoch 5/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8599 - loss: 0.3256\n",
      "Epoch 5 - MCC: 0.7275\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8600 - loss: 0.3255 - val_accuracy: 0.8642 - val_loss: 0.3176 - mcc: 0.7275\n",
      "Epoch 6/20\n",
      "\u001B[1m85/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8651 - loss: 0.3153\n",
      "Epoch 6 - MCC: 0.7345\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8650 - loss: 0.3156 - val_accuracy: 0.8675 - val_loss: 0.3101 - mcc: 0.7345\n",
      "Epoch 7/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8651 - loss: 0.3147\n",
      "Epoch 7 - MCC: 0.7362\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8652 - loss: 0.3146 - val_accuracy: 0.8685 - val_loss: 0.3070 - mcc: 0.7362\n",
      "Epoch 8/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8696 - loss: 0.3047\n",
      "Epoch 8 - MCC: 0.7436\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8696 - loss: 0.3048 - val_accuracy: 0.8721 - val_loss: 0.2994 - mcc: 0.7436\n",
      "Epoch 9/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8686 - loss: 0.3071\n",
      "Epoch 9 - MCC: 0.7493\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8686 - loss: 0.3069 - val_accuracy: 0.8746 - val_loss: 0.2946 - mcc: 0.7493\n",
      "Epoch 10/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8715 - loss: 0.3008\n",
      "Epoch 10 - MCC: 0.7492\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8715 - loss: 0.3007 - val_accuracy: 0.8750 - val_loss: 0.2934 - mcc: 0.7492\n",
      "Epoch 11/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8732 - loss: 0.2968\n",
      "Epoch 11 - MCC: 0.7558\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8732 - loss: 0.2968 - val_accuracy: 0.8777 - val_loss: 0.2880 - mcc: 0.7558\n",
      "Epoch 12/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8742 - loss: 0.2953\n",
      "Epoch 12 - MCC: 0.7583\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8742 - loss: 0.2952 - val_accuracy: 0.8792 - val_loss: 0.2855 - mcc: 0.7583\n",
      "Epoch 13/20\n",
      "\u001B[1m83/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8784 - loss: 0.2870\n",
      "Epoch 13 - MCC: 0.7594\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8782 - loss: 0.2873 - val_accuracy: 0.8798 - val_loss: 0.2834 - mcc: 0.7594\n",
      "Epoch 14/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8771 - loss: 0.2892\n",
      "Epoch 14 - MCC: 0.7597\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8771 - loss: 0.2891 - val_accuracy: 0.8802 - val_loss: 0.2820 - mcc: 0.7597\n",
      "Epoch 15/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8823 - loss: 0.2793\n",
      "Epoch 15 - MCC: 0.7607\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8822 - loss: 0.2795 - val_accuracy: 0.8807 - val_loss: 0.2818 - mcc: 0.7607\n",
      "Epoch 16/20\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8773 - loss: 0.2891\n",
      "Epoch 16 - MCC: 0.7606\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8774 - loss: 0.2887 - val_accuracy: 0.8807 - val_loss: 0.2821 - mcc: 0.7606\n",
      "Epoch 17/20\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8814 - loss: 0.2811\n",
      "Epoch 17 - MCC: 0.7617\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8814 - loss: 0.2812 - val_accuracy: 0.8812 - val_loss: 0.2803 - mcc: 0.7617\n",
      "Epoch 18/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8802 - loss: 0.2832\n",
      "Epoch 18 - MCC: 0.7606\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8803 - loss: 0.2832 - val_accuracy: 0.8806 - val_loss: 0.2814 - mcc: 0.7606\n",
      "Epoch 19/20\n",
      "\u001B[1m86/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8852 - loss: 0.2732\n",
      "Epoch 19 - MCC: 0.7665\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8848 - loss: 0.2739 - val_accuracy: 0.8833 - val_loss: 0.2764 - mcc: 0.7665\n",
      "Epoch 20/20\n",
      "\u001B[1m83/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8798 - loss: 0.2826\n",
      "Epoch 20 - MCC: 0.7674\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8801 - loss: 0.2821 - val_accuracy: 0.8836 - val_loss: 0.2758 - mcc: 0.7674\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: TCN, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.5414 - loss: 1.1968\n",
      "Epoch 1 - MCC: 0.5821\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 75ms/step - accuracy: 0.5424 - loss: 1.1924 - val_accuracy: 0.7916 - val_loss: 0.4617 - mcc: 0.5821\n",
      "Epoch 2/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8166 - loss: 0.4192\n",
      "Epoch 2 - MCC: 0.6831\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8167 - loss: 0.4190 - val_accuracy: 0.8414 - val_loss: 0.3649 - mcc: 0.6831\n",
      "Epoch 3/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8439 - loss: 0.3602\n",
      "Epoch 3 - MCC: 0.7031\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8442 - loss: 0.3597 - val_accuracy: 0.8516 - val_loss: 0.3421 - mcc: 0.7031\n",
      "Epoch 4/20\n",
      "\u001B[1m86/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8578 - loss: 0.3318\n",
      "Epoch 4 - MCC: 0.7153\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8578 - loss: 0.3316 - val_accuracy: 0.8580 - val_loss: 0.3276 - mcc: 0.7153\n",
      "Epoch 5/20\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8603 - loss: 0.3249\n",
      "Epoch 5 - MCC: 0.7216\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8605 - loss: 0.3244 - val_accuracy: 0.8612 - val_loss: 0.3207 - mcc: 0.7216\n",
      "Epoch 6/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8682 - loss: 0.3105\n",
      "Epoch 6 - MCC: 0.7269\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8682 - loss: 0.3106 - val_accuracy: 0.8640 - val_loss: 0.3145 - mcc: 0.7269\n",
      "Epoch 7/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8665 - loss: 0.3122\n",
      "Epoch 7 - MCC: 0.7339\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8665 - loss: 0.3121 - val_accuracy: 0.8672 - val_loss: 0.3088 - mcc: 0.7339\n",
      "Epoch 8/20\n",
      "\u001B[1m81/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8649 - loss: 0.3145\n",
      "Epoch 8 - MCC: 0.7312\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8659 - loss: 0.3127 - val_accuracy: 0.8661 - val_loss: 0.3092 - mcc: 0.7312\n",
      "Epoch 9/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8732 - loss: 0.2983\n",
      "Epoch 9 - MCC: 0.7406\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8731 - loss: 0.2983 - val_accuracy: 0.8705 - val_loss: 0.3024 - mcc: 0.7406\n",
      "Epoch 10/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8744 - loss: 0.2960\n",
      "Epoch 10 - MCC: 0.7452\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8744 - loss: 0.2960 - val_accuracy: 0.8724 - val_loss: 0.3001 - mcc: 0.7452\n",
      "Epoch 11/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8740 - loss: 0.2961\n",
      "Epoch 11 - MCC: 0.7462\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8741 - loss: 0.2959 - val_accuracy: 0.8735 - val_loss: 0.2951 - mcc: 0.7462\n",
      "Epoch 12/20\n",
      "\u001B[1m85/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8755 - loss: 0.2925\n",
      "Epoch 12 - MCC: 0.7472\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8756 - loss: 0.2923 - val_accuracy: 0.8741 - val_loss: 0.2946 - mcc: 0.7472\n",
      "Epoch 13/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8788 - loss: 0.2864\n",
      "Epoch 13 - MCC: 0.7516\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8788 - loss: 0.2865 - val_accuracy: 0.8757 - val_loss: 0.2918 - mcc: 0.7516\n",
      "Epoch 14/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8768 - loss: 0.2899\n",
      "Epoch 14 - MCC: 0.7521\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8769 - loss: 0.2897 - val_accuracy: 0.8763 - val_loss: 0.2893 - mcc: 0.7521\n",
      "Epoch 15/20\n",
      "\u001B[1m86/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8795 - loss: 0.2845\n",
      "Epoch 15 - MCC: 0.7524\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8795 - loss: 0.2846 - val_accuracy: 0.8766 - val_loss: 0.2892 - mcc: 0.7524\n",
      "Epoch 16/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8796 - loss: 0.2841\n",
      "Epoch 16 - MCC: 0.7533\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8796 - loss: 0.2841 - val_accuracy: 0.8771 - val_loss: 0.2872 - mcc: 0.7533\n",
      "Epoch 17/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8779 - loss: 0.2866\n",
      "Epoch 17 - MCC: 0.7519\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8780 - loss: 0.2864 - val_accuracy: 0.8764 - val_loss: 0.2887 - mcc: 0.7519\n",
      "Epoch 18/20\n",
      "\u001B[1m81/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8798 - loss: 0.2827\n",
      "Epoch 18 - MCC: 0.7552\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8799 - loss: 0.2824 - val_accuracy: 0.8779 - val_loss: 0.2861 - mcc: 0.7552\n",
      "Epoch 19/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8837 - loss: 0.2747\n",
      "Epoch 19 - MCC: 0.7573\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8836 - loss: 0.2748 - val_accuracy: 0.8787 - val_loss: 0.2835 - mcc: 0.7573\n",
      "Epoch 20/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8844 - loss: 0.2734\n",
      "Epoch 20 - MCC: 0.7582\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8843 - loss: 0.2736 - val_accuracy: 0.8792 - val_loss: 0.2831 - mcc: 0.7582\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.886504),\n",
      "              'mean': np.float64(0.8816970666666666),\n",
      "              'min': np.float64(0.877704),\n",
      "              'std': np.float64(0.00313203994865964)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.00025868479410807294),\n",
      "                               'mean': np.float64(0.00020440343221028644),\n",
      "                               'min': np.float64(0.0001615610122680664),\n",
      "                               'std': np.float64(4.344449989326129e-05)},\n",
      " 'MCC': {'max': np.float64(0.7725199600963473),\n",
      "         'mean': np.float64(0.7631445464217429),\n",
      "         'min': np.float64(0.754620329861892),\n",
      "         'std': np.float64(0.00638088922869058)},\n",
      " 'Parameters': 4936,\n",
      " 'Train Time (s)': {'max': np.float64(41.15656757354736),\n",
      "                    'mean': np.float64(33.51361050605774),\n",
      "                    'min': np.float64(30.438552618026733),\n",
      "                    'std': np.float64(3.968161437519785)},\n",
      " 'Training Accuracy': [[0.6140013337135315,\n",
      "                        0.7985773086547852,\n",
      "                        0.8368527293205261,\n",
      "                        0.850185215473175,\n",
      "                        0.8580945730209351,\n",
      "                        0.8637301325798035,\n",
      "                        0.866757869720459,\n",
      "                        0.86942458152771,\n",
      "                        0.8716906905174255,\n",
      "                        0.8727580308914185,\n",
      "                        0.8744415044784546,\n",
      "                        0.8746488690376282,\n",
      "                        0.8766393065452576,\n",
      "                        0.8771440982818604,\n",
      "                        0.8781008124351501,\n",
      "                        0.8787320852279663,\n",
      "                        0.879296064376831,\n",
      "                        0.8797887563705444,\n",
      "                        0.8804466724395752,\n",
      "                        0.8806140422821045],\n",
      "                       [0.6693153977394104,\n",
      "                        0.8293033838272095,\n",
      "                        0.8528371453285217,\n",
      "                        0.8607441186904907,\n",
      "                        0.8654245734214783,\n",
      "                        0.8688214421272278,\n",
      "                        0.8705099821090698,\n",
      "                        0.8736079931259155,\n",
      "                        0.8757261037826538,\n",
      "                        0.8768160939216614,\n",
      "                        0.8772954940795898,\n",
      "                        0.8783573508262634,\n",
      "                        0.8791479468345642,\n",
      "                        0.8792321085929871,\n",
      "                        0.880220890045166,\n",
      "                        0.8804018497467041,\n",
      "                        0.8811215758323669,\n",
      "                        0.8816262483596802,\n",
      "                        0.8819506168365479,\n",
      "                        0.8820220828056335],\n",
      "                       [0.7010453939437866,\n",
      "                        0.8400379419326782,\n",
      "                        0.8512873649597168,\n",
      "                        0.857124924659729,\n",
      "                        0.8616753816604614,\n",
      "                        0.8658695220947266,\n",
      "                        0.8682084679603577,\n",
      "                        0.8707394003868103,\n",
      "                        0.873132586479187,\n",
      "                        0.8748881816864014,\n",
      "                        0.8766437768936157,\n",
      "                        0.8779761791229248,\n",
      "                        0.8793975710868835,\n",
      "                        0.8799955248832703,\n",
      "                        0.8811292052268982,\n",
      "                        0.8813899755477905,\n",
      "                        0.8828374743461609,\n",
      "                        0.8829563856124878,\n",
      "                        0.8837065696716309,\n",
      "                        0.8837898969650269],\n",
      "                       [0.6983126401901245,\n",
      "                        0.8333587050437927,\n",
      "                        0.8511373400688171,\n",
      "                        0.8569620847702026,\n",
      "                        0.8608255982398987,\n",
      "                        0.8639076352119446,\n",
      "                        0.8662294149398804,\n",
      "                        0.8685714602470398,\n",
      "                        0.8710422515869141,\n",
      "                        0.87349933385849,\n",
      "                        0.8746612668037415,\n",
      "                        0.8765414357185364,\n",
      "                        0.8773658275604248,\n",
      "                        0.8778940439224243,\n",
      "                        0.8795021772384644,\n",
      "                        0.8797752261161804,\n",
      "                        0.8804973363876343,\n",
      "                        0.8810270428657532,\n",
      "                        0.8811008334159851,\n",
      "                        0.881908118724823],\n",
      "                       [0.6427961587905884,\n",
      "                        0.8279908299446106,\n",
      "                        0.8500420451164246,\n",
      "                        0.8583391904830933,\n",
      "                        0.8633652329444885,\n",
      "                        0.8667412996292114,\n",
      "                        0.8688092231750488,\n",
      "                        0.8707800507545471,\n",
      "                        0.8721879720687866,\n",
      "                        0.8743066191673279,\n",
      "                        0.875235915184021,\n",
      "                        0.8762714862823486,\n",
      "                        0.877615213394165,\n",
      "                        0.8784186244010925,\n",
      "                        0.8790373802185059,\n",
      "                        0.8793972730636597,\n",
      "                        0.8804447650909424,\n",
      "                        0.8808748126029968,\n",
      "                        0.8812546133995056,\n",
      "                        0.8818677663803101]],\n",
      " 'Training Loss': [[0.9975993633270264,\n",
      "                    0.4407580494880676,\n",
      "                    0.37062472105026245,\n",
      "                    0.3442506790161133,\n",
      "                    0.3293403089046478,\n",
      "                    0.3188236355781555,\n",
      "                    0.3127060830593109,\n",
      "                    0.3068362772464752,\n",
      "                    0.30195724964141846,\n",
      "                    0.2993275821208954,\n",
      "                    0.2957170307636261,\n",
      "                    0.2950560450553894,\n",
      "                    0.2911194860935211,\n",
      "                    0.28971463441848755,\n",
      "                    0.28765079379081726,\n",
      "                    0.285889595746994,\n",
      "                    0.28488701581954956,\n",
      "                    0.28384652733802795,\n",
      "                    0.2821407616138458,\n",
      "                    0.2817629873752594],\n",
      "                   [0.7625608444213867,\n",
      "                    0.3940872251987457,\n",
      "                    0.34321126341819763,\n",
      "                    0.3260210454463959,\n",
      "                    0.3156227469444275,\n",
      "                    0.3085680305957794,\n",
      "                    0.3049391210079193,\n",
      "                    0.2981870174407959,\n",
      "                    0.29342198371887207,\n",
      "                    0.2905038893222809,\n",
      "                    0.28942495584487915,\n",
      "                    0.28659459948539734,\n",
      "                    0.28480610251426697,\n",
      "                    0.2840598225593567,\n",
      "                    0.2820996046066284,\n",
      "                    0.2813251316547394,\n",
      "                    0.28002047538757324,\n",
      "                    0.2790009379386902,\n",
      "                    0.27765804529190063,\n",
      "                    0.2774195969104767],\n",
      "                   [0.6646576523780823,\n",
      "                    0.3719460964202881,\n",
      "                    0.34453344345092773,\n",
      "                    0.3318667709827423,\n",
      "                    0.32125675678253174,\n",
      "                    0.3122674822807312,\n",
      "                    0.3063592314720154,\n",
      "                    0.3012661635875702,\n",
      "                    0.2964634895324707,\n",
      "                    0.2930285632610321,\n",
      "                    0.2889876663684845,\n",
      "                    0.28650060296058655,\n",
      "                    0.28372469544410706,\n",
      "                    0.28252580761909485,\n",
      "                    0.28012967109680176,\n",
      "                    0.27892568707466125,\n",
      "                    0.2761675715446472,\n",
      "                    0.27597859501838684,\n",
      "                    0.27413469552993774,\n",
      "                    0.27365225553512573],\n",
      "                   [0.6274364590644836,\n",
      "                    0.3848002552986145,\n",
      "                    0.34580692648887634,\n",
      "                    0.33303749561309814,\n",
      "                    0.3241581320762634,\n",
      "                    0.3175320327281952,\n",
      "                    0.31216615438461304,\n",
      "                    0.3069342374801636,\n",
      "                    0.3016496002674103,\n",
      "                    0.29659706354141235,\n",
      "                    0.2942107617855072,\n",
      "                    0.29058921337127686,\n",
      "                    0.2890750467777252,\n",
      "                    0.28741443157196045,\n",
      "                    0.2848207652568817,\n",
      "                    0.2839936912059784,\n",
      "                    0.28256791830062866,\n",
      "                    0.28139662742614746,\n",
      "                    0.281057745218277,\n",
      "                    0.2793189585208893],\n",
      "                   [0.7802368998527527,\n",
      "                    0.3956148624420166,\n",
      "                    0.3475741744041443,\n",
      "                    0.3298434019088745,\n",
      "                    0.31901654601097107,\n",
      "                    0.31238770484924316,\n",
      "                    0.30720579624176025,\n",
      "                    0.3029654026031494,\n",
      "                    0.3001309335231781,\n",
      "                    0.29553908109664917,\n",
      "                    0.2933691143989563,\n",
      "                    0.29116207361221313,\n",
      "                    0.28814154863357544,\n",
      "                    0.28681886196136475,\n",
      "                    0.2851049602031708,\n",
      "                    0.28420355916023254,\n",
      "                    0.2817367613315582,\n",
      "                    0.280719518661499,\n",
      "                    0.279864102602005,\n",
      "                    0.2785431742668152]],\n",
      " 'Validation Accuracy': [[0.7477707266807556,\n",
      "                          0.8298346400260925,\n",
      "                          0.8461573123931885,\n",
      "                          0.8551467061042786,\n",
      "                          0.8637708425521851,\n",
      "                          0.8677493333816528,\n",
      "                          0.8703681826591492,\n",
      "                          0.8696027994155884,\n",
      "                          0.8727759718894958,\n",
      "                          0.8733974695205688,\n",
      "                          0.8748267292976379,\n",
      "                          0.8767173886299133,\n",
      "                          0.877501368522644,\n",
      "                          0.8781441450119019,\n",
      "                          0.8796400427818298,\n",
      "                          0.8801920413970947,\n",
      "                          0.8801892995834351,\n",
      "                          0.8809201121330261,\n",
      "                          0.8817173838615417,\n",
      "                          0.8815227746963501],\n",
      "                         [0.7989867329597473,\n",
      "                          0.8493840098381042,\n",
      "                          0.8620614409446716,\n",
      "                          0.8673093318939209,\n",
      "                          0.8722186088562012,\n",
      "                          0.8749654293060303,\n",
      "                          0.8752399682998657,\n",
      "                          0.8780773878097534,\n",
      "                          0.8808560371398926,\n",
      "                          0.8820693492889404,\n",
      "                          0.8825334310531616,\n",
      "                          0.8806453347206116,\n",
      "                          0.88319993019104,\n",
      "                          0.8848587274551392,\n",
      "                          0.8847974538803101,\n",
      "                          0.8854880332946777,\n",
      "                          0.8859360218048096,\n",
      "                          0.8860346674919128,\n",
      "                          0.8859546780586243,\n",
      "                          0.886504054069519],\n",
      "                         [0.8198854327201843,\n",
      "                          0.8420640230178833,\n",
      "                          0.8491679430007935,\n",
      "                          0.8534135818481445,\n",
      "                          0.8582667708396912,\n",
      "                          0.8608906865119934,\n",
      "                          0.8638774156570435,\n",
      "                          0.8650668263435364,\n",
      "                          0.8659200072288513,\n",
      "                          0.8705254197120667,\n",
      "                          0.870901346206665,\n",
      "                          0.8722000122070312,\n",
      "                          0.8705226182937622,\n",
      "                          0.8737815022468567,\n",
      "                          0.8754026889801025,\n",
      "                          0.876501202583313,\n",
      "                          0.8768985867500305,\n",
      "                          0.877608060836792,\n",
      "                          0.8780561685562134,\n",
      "                          0.8777040243148804],\n",
      "                         [0.807242751121521,\n",
      "                          0.8472133874893188,\n",
      "                          0.8561388254165649,\n",
      "                          0.8602427840232849,\n",
      "                          0.8641706705093384,\n",
      "                          0.8674880266189575,\n",
      "                          0.8685120344161987,\n",
      "                          0.8720827102661133,\n",
      "                          0.8746054768562317,\n",
      "                          0.8749681115150452,\n",
      "                          0.8777439594268799,\n",
      "                          0.8792053461074829,\n",
      "                          0.8798266649246216,\n",
      "                          0.8801786303520203,\n",
      "                          0.8806987404823303,\n",
      "                          0.8806747198104858,\n",
      "                          0.8811947703361511,\n",
      "                          0.8806214928627014,\n",
      "                          0.8833146691322327,\n",
      "                          0.8835866451263428],\n",
      "                         [0.7915707230567932,\n",
      "                          0.8413894176483154,\n",
      "                          0.8515946269035339,\n",
      "                          0.8580240607261658,\n",
      "                          0.8611547946929932,\n",
      "                          0.8639814257621765,\n",
      "                          0.8672052621841431,\n",
      "                          0.8660826683044434,\n",
      "                          0.8704720735549927,\n",
      "                          0.8724159598350525,\n",
      "                          0.8734986782073975,\n",
      "                          0.8740533590316772,\n",
      "                          0.8757414817810059,\n",
      "                          0.8763147592544556,\n",
      "                          0.876589298248291,\n",
      "                          0.8770774602890015,\n",
      "                          0.8764213919639587,\n",
      "                          0.8778799772262573,\n",
      "                          0.878690779209137,\n",
      "                          0.8791680335998535]],\n",
      " 'Validation Loss': [0.46166566014289856,\n",
      "                     0.36486926674842834,\n",
      "                     0.34208235144615173,\n",
      "                     0.3276238739490509,\n",
      "                     0.32070523500442505,\n",
      "                     0.314488023519516,\n",
      "                     0.30875977873802185,\n",
      "                     0.3092307448387146,\n",
      "                     0.302367627620697,\n",
      "                     0.3000572621822357,\n",
      "                     0.2951318621635437,\n",
      "                     0.29463616013526917,\n",
      "                     0.2917684018611908,\n",
      "                     0.2892974317073822,\n",
      "                     0.28921493887901306,\n",
      "                     0.28718432784080505,\n",
      "                     0.2887013554573059,\n",
      "                     0.2860789895057678,\n",
      "                     0.28347456455230713,\n",
      "                     0.2831369638442993],\n",
      " 'Validation MCC': [[np.float64(0.4970456851749035),\n",
      "                     np.float64(0.6585740300322903),\n",
      "                     np.float64(0.6913891263167152),\n",
      "                     np.float64(0.7094729463120321),\n",
      "                     np.float64(0.7272627127788582),\n",
      "                     np.float64(0.7348354333752467),\n",
      "                     np.float64(0.7406565195218228),\n",
      "                     np.float64(0.7385980219292999),\n",
      "                     np.float64(0.7447900954140046),\n",
      "                     np.float64(0.7460959895685809),\n",
      "                     np.float64(0.7489292352513529),\n",
      "                     np.float64(0.7541770138577025),\n",
      "                     np.float64(0.7543054235546564),\n",
      "                     np.float64(0.7556712774684273),\n",
      "                     np.float64(0.7589477535956164),\n",
      "                     np.float64(0.760552302132351),\n",
      "                     np.float64(0.7596710706174882),\n",
      "                     np.float64(0.7626293816251918),\n",
      "                     np.float64(0.7630686549007633),\n",
      "                     np.float64(0.7630269902122947)],\n",
      "                    [np.float64(0.598169544796316),\n",
      "                     np.float64(0.6977649519031096),\n",
      "                     np.float64(0.7239901556366263),\n",
      "                     np.float64(0.7337832519045085),\n",
      "                     np.float64(0.7442464074677038),\n",
      "                     np.float64(0.7498589885212604),\n",
      "                     np.float64(0.7498189124477684),\n",
      "                     np.float64(0.7553962249308562),\n",
      "                     np.float64(0.7611468018368881),\n",
      "                     np.float64(0.7639562666073243),\n",
      "                     np.float64(0.764607731170237),\n",
      "                     np.float64(0.7606533856016056),\n",
      "                     np.float64(0.7658241687365869),\n",
      "                     np.float64(0.7692645297528741),\n",
      "                     np.float64(0.769561742869844),\n",
      "                     np.float64(0.770483082620998),\n",
      "                     np.float64(0.7715896172653117),\n",
      "                     np.float64(0.7721163786164893),\n",
      "                     np.float64(0.7714957489070765),\n",
      "                     np.float64(0.7725199600963473)],\n",
      "                    [np.float64(0.6382256484124885),\n",
      "                     np.float64(0.6829143776632977),\n",
      "                     np.float64(0.6977380436903532),\n",
      "                     np.float64(0.7058614605348378),\n",
      "                     np.float64(0.7168027746460452),\n",
      "                     np.float64(0.7221972095295044),\n",
      "                     np.float64(0.7268713619573802),\n",
      "                     np.float64(0.7291146235504147),\n",
      "                     np.float64(0.7342036500319555),\n",
      "                     np.float64(0.7406854716395188),\n",
      "                     np.float64(0.7407961509760713),\n",
      "                     np.float64(0.74341624513998),\n",
      "                     np.float64(0.7402305859918321),\n",
      "                     np.float64(0.748939297818674),\n",
      "                     np.float64(0.7499645142977729),\n",
      "                     np.float64(0.7526273021336207),\n",
      "                     np.float64(0.7529907334548357),\n",
      "                     np.float64(0.7554032760641685),\n",
      "                     np.float64(0.7555848576257471),\n",
      "                     np.float64(0.754620329861892)],\n",
      "                    [np.float64(0.6131419599469434),\n",
      "                     np.float64(0.6936371506824073),\n",
      "                     np.float64(0.7113845967013365),\n",
      "                     np.float64(0.7220836734737813),\n",
      "                     np.float64(0.7275431787193081),\n",
      "                     np.float64(0.7344552318630833),\n",
      "                     np.float64(0.7361965223323006),\n",
      "                     np.float64(0.7435885091612476),\n",
      "                     np.float64(0.749262749550671),\n",
      "                     np.float64(0.7491771963240619),\n",
      "                     np.float64(0.7557719763498143),\n",
      "                     np.float64(0.7582664735863184),\n",
      "                     np.float64(0.7593752754413355),\n",
      "                     np.float64(0.759706634345033),\n",
      "                     np.float64(0.7606745501974859),\n",
      "                     np.float64(0.760632589974921),\n",
      "                     np.float64(0.7616507496854512),\n",
      "                     np.float64(0.7606369059828406),\n",
      "                     np.float64(0.7664708130150125),\n",
      "                     np.float64(0.7674002335820398)],\n",
      "                    [np.float64(0.582062428184249),\n",
      "                     np.float64(0.6831142851157652),\n",
      "                     np.float64(0.7030827005671909),\n",
      "                     np.float64(0.715260381442472),\n",
      "                     np.float64(0.7215598192301784),\n",
      "                     np.float64(0.7269494938411678),\n",
      "                     np.float64(0.7338945967490276),\n",
      "                     np.float64(0.7312395206331697),\n",
      "                     np.float64(0.7406387937161072),\n",
      "                     np.float64(0.7452112963056716),\n",
      "                     np.float64(0.7461854458907677),\n",
      "                     np.float64(0.7471645559719302),\n",
      "                     np.float64(0.7515868680214794),\n",
      "                     np.float64(0.7520736818326057),\n",
      "                     np.float64(0.7524018309584853),\n",
      "                     np.float64(0.7532629044981317),\n",
      "                     np.float64(0.7519145557687582),\n",
      "                     np.float64(0.7552134524927692),\n",
      "                     np.float64(0.7572852317031601),\n",
      "                     np.float64(0.7581552183561406)]]}\n",
      "Training Model: MLP, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.6092 - loss: 0.6550\n",
      "Epoch 1 - MCC: 0.3472\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 43ms/step - accuracy: 0.6096 - loss: 0.6548 - val_accuracy: 0.6731 - val_loss: 0.6110 - mcc: 0.3472\n",
      "Epoch 2/20\n",
      "\u001B[1m75/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6674 - loss: 0.6154\n",
      "Epoch 2 - MCC: 0.3454\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 6ms/step - accuracy: 0.6681 - loss: 0.6147 - val_accuracy: 0.6726 - val_loss: 0.6112 - mcc: 0.3454\n",
      "Epoch 3/20\n",
      "\u001B[1m76/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6701 - loss: 0.6126\n",
      "Epoch 3 - MCC: 0.3439\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6700 - loss: 0.6127 - val_accuracy: 0.6727 - val_loss: 0.6113 - mcc: 0.3439\n",
      "Epoch 4/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6733 - loss: 0.6094\n",
      "Epoch 4 - MCC: 0.3466\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6733 - loss: 0.6094 - val_accuracy: 0.6738 - val_loss: 0.6107 - mcc: 0.3466\n",
      "Epoch 5/20\n",
      "\u001B[1m80/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6722 - loss: 0.6114\n",
      "Epoch 5 - MCC: 0.3473\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6719 - loss: 0.6115 - val_accuracy: 0.6729 - val_loss: 0.6110 - mcc: 0.3473\n",
      "Epoch 6/20\n",
      "\u001B[1m78/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6681 - loss: 0.6143\n",
      "Epoch 6 - MCC: 0.3469\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.6687 - loss: 0.6138 - val_accuracy: 0.6731 - val_loss: 0.6110 - mcc: 0.3469\n",
      "Epoch 7/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6650 - loss: 0.6170\n",
      "Epoch 7 - MCC: 0.3417\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.6651 - loss: 0.6169 - val_accuracy: 0.6723 - val_loss: 0.6120 - mcc: 0.3417\n",
      "Epoch 8/20\n",
      "\u001B[1m81/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6711 - loss: 0.6119\n",
      "Epoch 8 - MCC: 0.3471\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.6709 - loss: 0.6121 - val_accuracy: 0.6739 - val_loss: 0.6106 - mcc: 0.3471\n",
      "Epoch 9/20\n",
      "\u001B[1m85/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6677 - loss: 0.6144\n",
      "Epoch 9 - MCC: 0.3470\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.6679 - loss: 0.6142 - val_accuracy: 0.6735 - val_loss: 0.6107 - mcc: 0.3470\n",
      "Epoch 10/20\n",
      "\u001B[1m75/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6685 - loss: 0.6139\n",
      "Epoch 10 - MCC: 0.3473\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6689 - loss: 0.6136 - val_accuracy: 0.6727 - val_loss: 0.6111 - mcc: 0.3473\n",
      "Epoch 11/20\n",
      "\u001B[1m79/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6671 - loss: 0.6146\n",
      "Epoch 11 - MCC: 0.3459\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6676 - loss: 0.6142 - val_accuracy: 0.6722 - val_loss: 0.6117 - mcc: 0.3459\n",
      "Epoch 12/20\n",
      "\u001B[1m75/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6714 - loss: 0.6113\n",
      "Epoch 12 - MCC: 0.3432\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.6712 - loss: 0.6115 - val_accuracy: 0.6720 - val_loss: 0.6116 - mcc: 0.3432\n",
      "Epoch 13/20\n",
      "\u001B[1m77/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6673 - loss: 0.6147\n",
      "Epoch 13 - MCC: 0.3473\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.6678 - loss: 0.6143 - val_accuracy: 0.6740 - val_loss: 0.6106 - mcc: 0.3473\n",
      "Epoch 14/20\n",
      "\u001B[1m77/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6707 - loss: 0.6114\n",
      "Epoch 14 - MCC: 0.3454\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6705 - loss: 0.6117 - val_accuracy: 0.6735 - val_loss: 0.6108 - mcc: 0.3454\n",
      "Epoch 15/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6718 - loss: 0.6106\n",
      "Epoch 15 - MCC: 0.3452\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6718 - loss: 0.6106 - val_accuracy: 0.6731 - val_loss: 0.6107 - mcc: 0.3452\n",
      "Epoch 16/20\n",
      "\u001B[1m77/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6697 - loss: 0.6123\n",
      "Epoch 16 - MCC: 0.3462\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6700 - loss: 0.6121 - val_accuracy: 0.6737 - val_loss: 0.6108 - mcc: 0.3462\n",
      "Epoch 17/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6709 - loss: 0.6116\n",
      "Epoch 17 - MCC: 0.3428\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6709 - loss: 0.6116 - val_accuracy: 0.6727 - val_loss: 0.6116 - mcc: 0.3428\n",
      "Epoch 18/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6658 - loss: 0.6165\n",
      "Epoch 18 - MCC: 0.3469\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6659 - loss: 0.6165 - val_accuracy: 0.6734 - val_loss: 0.6107 - mcc: 0.3469\n",
      "Epoch 19/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6694 - loss: 0.6124\n",
      "Epoch 19 - MCC: 0.3468\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6694 - loss: 0.6124 - val_accuracy: 0.6720 - val_loss: 0.6117 - mcc: 0.3468\n",
      "Epoch 20/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6696 - loss: 0.6132\n",
      "Epoch 20 - MCC: 0.3451\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6696 - loss: 0.6132 - val_accuracy: 0.6730 - val_loss: 0.6108 - mcc: 0.3451\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: MLP, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.6243 - loss: 0.6575\n",
      "Epoch 1 - MCC: 0.3442\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 30ms/step - accuracy: 0.6246 - loss: 0.6573 - val_accuracy: 0.6732 - val_loss: 0.6103 - mcc: 0.3442\n",
      "Epoch 2/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6702 - loss: 0.6119\n",
      "Epoch 2 - MCC: 0.3474\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.6702 - loss: 0.6120 - val_accuracy: 0.6731 - val_loss: 0.6105 - mcc: 0.3474\n",
      "Epoch 3/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6744 - loss: 0.6090\n",
      "Epoch 3 - MCC: 0.3459\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6743 - loss: 0.6091 - val_accuracy: 0.6730 - val_loss: 0.6104 - mcc: 0.3459\n",
      "Epoch 4/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6731 - loss: 0.6103\n",
      "Epoch 4 - MCC: 0.3470\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6729 - loss: 0.6104 - val_accuracy: 0.6731 - val_loss: 0.6105 - mcc: 0.3470\n",
      "Epoch 5/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6704 - loss: 0.6123\n",
      "Epoch 5 - MCC: 0.3457\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6704 - loss: 0.6123 - val_accuracy: 0.6734 - val_loss: 0.6101 - mcc: 0.3457\n",
      "Epoch 6/20\n",
      "\u001B[1m79/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6690 - loss: 0.6134\n",
      "Epoch 6 - MCC: 0.3443\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.6692 - loss: 0.6132 - val_accuracy: 0.6732 - val_loss: 0.6106 - mcc: 0.3443\n",
      "Epoch 7/20\n",
      "\u001B[1m78/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6714 - loss: 0.6119\n",
      "Epoch 7 - MCC: 0.3459\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6712 - loss: 0.6120 - val_accuracy: 0.6734 - val_loss: 0.6100 - mcc: 0.3459\n",
      "Epoch 8/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6688 - loss: 0.6140\n",
      "Epoch 8 - MCC: 0.3436\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6688 - loss: 0.6139 - val_accuracy: 0.6730 - val_loss: 0.6106 - mcc: 0.3436\n",
      "Epoch 9/20\n",
      "\u001B[1m86/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6686 - loss: 0.6139\n",
      "Epoch 9 - MCC: 0.3466\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6688 - loss: 0.6138 - val_accuracy: 0.6720 - val_loss: 0.6113 - mcc: 0.3466\n",
      "Epoch 10/20\n",
      "\u001B[1m77/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6720 - loss: 0.6103\n",
      "Epoch 10 - MCC: 0.3472\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6717 - loss: 0.6106 - val_accuracy: 0.6734 - val_loss: 0.6103 - mcc: 0.3472\n",
      "Epoch 11/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6724 - loss: 0.6107\n",
      "Epoch 11 - MCC: 0.3430\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6723 - loss: 0.6108 - val_accuracy: 0.6730 - val_loss: 0.6111 - mcc: 0.3430\n",
      "Epoch 12/20\n",
      "\u001B[1m78/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6743 - loss: 0.6094\n",
      "Epoch 12 - MCC: 0.3465\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6737 - loss: 0.6099 - val_accuracy: 0.6732 - val_loss: 0.6102 - mcc: 0.3465\n",
      "Epoch 13/20\n",
      "\u001B[1m76/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6703 - loss: 0.6124\n",
      "Epoch 13 - MCC: 0.3447\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.6703 - loss: 0.6124 - val_accuracy: 0.6733 - val_loss: 0.6103 - mcc: 0.3447\n",
      "Epoch 14/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6683 - loss: 0.6135\n",
      "Epoch 14 - MCC: 0.3462\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6683 - loss: 0.6135 - val_accuracy: 0.6732 - val_loss: 0.6102 - mcc: 0.3462\n",
      "Epoch 15/20\n",
      "\u001B[1m87/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6729 - loss: 0.6103\n",
      "Epoch 15 - MCC: 0.3462\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6727 - loss: 0.6104 - val_accuracy: 0.6733 - val_loss: 0.6102 - mcc: 0.3462\n",
      "Epoch 16/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6713 - loss: 0.6119\n",
      "Epoch 16 - MCC: 0.3462\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6712 - loss: 0.6119 - val_accuracy: 0.6733 - val_loss: 0.6101 - mcc: 0.3462\n",
      "Epoch 17/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6704 - loss: 0.6115\n",
      "Epoch 17 - MCC: 0.3471\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6704 - loss: 0.6116 - val_accuracy: 0.6733 - val_loss: 0.6103 - mcc: 0.3471\n",
      "Epoch 18/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6621 - loss: 0.6202\n",
      "Epoch 18 - MCC: 0.3445\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6624 - loss: 0.6198 - val_accuracy: 0.6732 - val_loss: 0.6104 - mcc: 0.3445\n",
      "Epoch 19/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6678 - loss: 0.6149\n",
      "Epoch 19 - MCC: 0.3468\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.6680 - loss: 0.6148 - val_accuracy: 0.6731 - val_loss: 0.6104 - mcc: 0.3468\n",
      "Epoch 20/20\n",
      "\u001B[1m87/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6696 - loss: 0.6126\n",
      "Epoch 20 - MCC: 0.3450\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.6697 - loss: 0.6126 - val_accuracy: 0.6730 - val_loss: 0.6103 - mcc: 0.3450\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: MLP, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.6237 - loss: 0.6515\n",
      "Epoch 1 - MCC: 0.3314\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 27ms/step - accuracy: 0.6241 - loss: 0.6512 - val_accuracy: 0.6669 - val_loss: 0.6151 - mcc: 0.3314\n",
      "Epoch 2/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6679 - loss: 0.6141\n",
      "Epoch 2 - MCC: 0.3318\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.6680 - loss: 0.6140 - val_accuracy: 0.6668 - val_loss: 0.6155 - mcc: 0.3318\n",
      "Epoch 3/20\n",
      "\u001B[1m77/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6721 - loss: 0.6103\n",
      "Epoch 3 - MCC: 0.3276\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6720 - loss: 0.6105 - val_accuracy: 0.6659 - val_loss: 0.6157 - mcc: 0.3276\n",
      "Epoch 4/20\n",
      "\u001B[1m78/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6714 - loss: 0.6109\n",
      "Epoch 4 - MCC: 0.3329\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6715 - loss: 0.6109 - val_accuracy: 0.6665 - val_loss: 0.6157 - mcc: 0.3329\n",
      "Epoch 5/20\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6744 - loss: 0.6093\n",
      "Epoch 5 - MCC: 0.3306\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6743 - loss: 0.6094 - val_accuracy: 0.6667 - val_loss: 0.6153 - mcc: 0.3306\n",
      "Epoch 6/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6734 - loss: 0.6097\n",
      "Epoch 6 - MCC: 0.3306\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6734 - loss: 0.6097 - val_accuracy: 0.6670 - val_loss: 0.6154 - mcc: 0.3306\n",
      "Epoch 7/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6731 - loss: 0.6103\n",
      "Epoch 7 - MCC: 0.3292\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6731 - loss: 0.6103 - val_accuracy: 0.6666 - val_loss: 0.6160 - mcc: 0.3292\n",
      "Epoch 8/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6718 - loss: 0.6110\n",
      "Epoch 8 - MCC: 0.3281\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6718 - loss: 0.6110 - val_accuracy: 0.6655 - val_loss: 0.6163 - mcc: 0.3281\n",
      "Epoch 9/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6701 - loss: 0.6123\n",
      "Epoch 9 - MCC: 0.3292\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6702 - loss: 0.6122 - val_accuracy: 0.6663 - val_loss: 0.6153 - mcc: 0.3292\n",
      "Epoch 10/20\n",
      "\u001B[1m83/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6706 - loss: 0.6118\n",
      "Epoch 10 - MCC: 0.3305\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.6708 - loss: 0.6117 - val_accuracy: 0.6667 - val_loss: 0.6152 - mcc: 0.3305\n",
      "Epoch 11/20\n",
      "\u001B[1m84/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6792 - loss: 0.6043\n",
      "Epoch 11 - MCC: 0.3333\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.6784 - loss: 0.6050 - val_accuracy: 0.6666 - val_loss: 0.6159 - mcc: 0.3333\n",
      "Epoch 12/20\n",
      "\u001B[1m82/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6708 - loss: 0.6120\n",
      "Epoch 12 - MCC: 0.3328\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.6710 - loss: 0.6118 - val_accuracy: 0.6667 - val_loss: 0.6154 - mcc: 0.3328\n",
      "Epoch 13/20\n",
      "\u001B[1m77/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6758 - loss: 0.6077\n",
      "Epoch 13 - MCC: 0.3311\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6752 - loss: 0.6082 - val_accuracy: 0.6670 - val_loss: 0.6150 - mcc: 0.3311\n",
      "Epoch 14/20\n",
      "\u001B[1m83/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6722 - loss: 0.6111\n",
      "Epoch 14 - MCC: 0.3332\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6722 - loss: 0.6111 - val_accuracy: 0.6665 - val_loss: 0.6156 - mcc: 0.3332\n",
      "Epoch 15/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6704 - loss: 0.6122\n",
      "Epoch 15 - MCC: 0.3288\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6704 - loss: 0.6122 - val_accuracy: 0.6661 - val_loss: 0.6157 - mcc: 0.3288\n",
      "Epoch 16/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6709 - loss: 0.6119\n",
      "Epoch 16 - MCC: 0.3299\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6709 - loss: 0.6119 - val_accuracy: 0.6666 - val_loss: 0.6159 - mcc: 0.3299\n",
      "Epoch 17/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6727 - loss: 0.6095\n",
      "Epoch 17 - MCC: 0.3311\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6727 - loss: 0.6095 - val_accuracy: 0.6669 - val_loss: 0.6151 - mcc: 0.3311\n",
      "Epoch 18/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6716 - loss: 0.6116\n",
      "Epoch 18 - MCC: 0.3320\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6716 - loss: 0.6116 - val_accuracy: 0.6668 - val_loss: 0.6150 - mcc: 0.3320\n",
      "Epoch 19/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6744 - loss: 0.6091\n",
      "Epoch 19 - MCC: 0.3320\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6743 - loss: 0.6092 - val_accuracy: 0.6669 - val_loss: 0.6151 - mcc: 0.3320\n",
      "Epoch 20/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6720 - loss: 0.6110\n",
      "Epoch 20 - MCC: 0.3300\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6720 - loss: 0.6110 - val_accuracy: 0.6665 - val_loss: 0.6154 - mcc: 0.3300\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: MLP, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.6049 - loss: 0.6524\n",
      "Epoch 1 - MCC: 0.3391\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 25ms/step - accuracy: 0.6053 - loss: 0.6522 - val_accuracy: 0.6703 - val_loss: 0.6123 - mcc: 0.3391\n",
      "Epoch 2/20\n",
      "\u001B[1m77/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6739 - loss: 0.6094\n",
      "Epoch 2 - MCC: 0.3399\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6734 - loss: 0.6099 - val_accuracy: 0.6707 - val_loss: 0.6114 - mcc: 0.3399\n",
      "Epoch 3/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6730 - loss: 0.6093\n",
      "Epoch 3 - MCC: 0.3432\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.6730 - loss: 0.6093 - val_accuracy: 0.6687 - val_loss: 0.6140 - mcc: 0.3432\n",
      "Epoch 4/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6747 - loss: 0.6096\n",
      "Epoch 4 - MCC: 0.3395\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.6745 - loss: 0.6098 - val_accuracy: 0.6706 - val_loss: 0.6116 - mcc: 0.3395\n",
      "Epoch 5/20\n",
      "\u001B[1m85/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6706 - loss: 0.6117\n",
      "Epoch 5 - MCC: 0.3412\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.6706 - loss: 0.6117 - val_accuracy: 0.6710 - val_loss: 0.6114 - mcc: 0.3412\n",
      "Epoch 6/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6728 - loss: 0.6099\n",
      "Epoch 6 - MCC: 0.3390\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6727 - loss: 0.6100 - val_accuracy: 0.6705 - val_loss: 0.6115 - mcc: 0.3390\n",
      "Epoch 7/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6682 - loss: 0.6140\n",
      "Epoch 7 - MCC: 0.3381\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6683 - loss: 0.6139 - val_accuracy: 0.6694 - val_loss: 0.6131 - mcc: 0.3381\n",
      "Epoch 8/20\n",
      "\u001B[1m76/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6719 - loss: 0.6112\n",
      "Epoch 8 - MCC: 0.3422\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6719 - loss: 0.6112 - val_accuracy: 0.6706 - val_loss: 0.6117 - mcc: 0.3422\n",
      "Epoch 9/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6745 - loss: 0.6091\n",
      "Epoch 9 - MCC: 0.3409\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6745 - loss: 0.6091 - val_accuracy: 0.6708 - val_loss: 0.6114 - mcc: 0.3409\n",
      "Epoch 10/20\n",
      "\u001B[1m76/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6719 - loss: 0.6116\n",
      "Epoch 10 - MCC: 0.3396\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6717 - loss: 0.6116 - val_accuracy: 0.6706 - val_loss: 0.6115 - mcc: 0.3396\n",
      "Epoch 11/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6742 - loss: 0.6089\n",
      "Epoch 11 - MCC: 0.3387\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 16ms/step - accuracy: 0.6741 - loss: 0.6090 - val_accuracy: 0.6705 - val_loss: 0.6117 - mcc: 0.3387\n",
      "Epoch 12/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6713 - loss: 0.6115\n",
      "Epoch 12 - MCC: 0.3401\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6713 - loss: 0.6115 - val_accuracy: 0.6707 - val_loss: 0.6114 - mcc: 0.3401\n",
      "Epoch 13/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6710 - loss: 0.6117\n",
      "Epoch 13 - MCC: 0.3415\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6710 - loss: 0.6118 - val_accuracy: 0.6709 - val_loss: 0.6115 - mcc: 0.3415\n",
      "Epoch 14/20\n",
      "\u001B[1m93/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6696 - loss: 0.6127\n",
      "Epoch 14 - MCC: 0.3372\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6697 - loss: 0.6127 - val_accuracy: 0.6700 - val_loss: 0.6121 - mcc: 0.3372\n",
      "Epoch 15/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6722 - loss: 0.6115\n",
      "Epoch 15 - MCC: 0.3418\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6721 - loss: 0.6115 - val_accuracy: 0.6707 - val_loss: 0.6115 - mcc: 0.3418\n",
      "Epoch 16/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6701 - loss: 0.6129\n",
      "Epoch 16 - MCC: 0.3397\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6702 - loss: 0.6129 - val_accuracy: 0.6707 - val_loss: 0.6114 - mcc: 0.3397\n",
      "Epoch 17/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6721 - loss: 0.6104\n",
      "Epoch 17 - MCC: 0.3405\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6721 - loss: 0.6104 - val_accuracy: 0.6708 - val_loss: 0.6114 - mcc: 0.3405\n",
      "Epoch 18/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6685 - loss: 0.6144\n",
      "Epoch 18 - MCC: 0.3419\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6686 - loss: 0.6143 - val_accuracy: 0.6708 - val_loss: 0.6115 - mcc: 0.3419\n",
      "Epoch 19/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6702 - loss: 0.6124\n",
      "Epoch 19 - MCC: 0.3400\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6702 - loss: 0.6124 - val_accuracy: 0.6706 - val_loss: 0.6116 - mcc: 0.3400\n",
      "Epoch 20/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6673 - loss: 0.6152\n",
      "Epoch 20 - MCC: 0.3397\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6676 - loss: 0.6150 - val_accuracy: 0.6707 - val_loss: 0.6116 - mcc: 0.3397\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: MLP, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.5997 - loss: 0.6546\n",
      "Epoch 1 - MCC: 0.3429\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 27ms/step - accuracy: 0.6002 - loss: 0.6544 - val_accuracy: 0.6703 - val_loss: 0.6118 - mcc: 0.3429\n",
      "Epoch 2/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6709 - loss: 0.6122\n",
      "Epoch 2 - MCC: 0.3382\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.6709 - loss: 0.6122 - val_accuracy: 0.6709 - val_loss: 0.6113 - mcc: 0.3382\n",
      "Epoch 3/20\n",
      "\u001B[1m77/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6708 - loss: 0.6120\n",
      "Epoch 3 - MCC: 0.3407\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6710 - loss: 0.6120 - val_accuracy: 0.6711 - val_loss: 0.6108 - mcc: 0.3407\n",
      "Epoch 4/20\n",
      "\u001B[1m89/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6693 - loss: 0.6135\n",
      "Epoch 4 - MCC: 0.3395\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6694 - loss: 0.6134 - val_accuracy: 0.6713 - val_loss: 0.6109 - mcc: 0.3395\n",
      "Epoch 5/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6721 - loss: 0.6109\n",
      "Epoch 5 - MCC: 0.3422\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6721 - loss: 0.6110 - val_accuracy: 0.6711 - val_loss: 0.6111 - mcc: 0.3422\n",
      "Epoch 6/20\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6714 - loss: 0.6115\n",
      "Epoch 6 - MCC: 0.3393\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6713 - loss: 0.6115 - val_accuracy: 0.6710 - val_loss: 0.6108 - mcc: 0.3393\n",
      "Epoch 7/20\n",
      "\u001B[1m92/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6700 - loss: 0.6134\n",
      "Epoch 7 - MCC: 0.3390\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6700 - loss: 0.6134 - val_accuracy: 0.6711 - val_loss: 0.6109 - mcc: 0.3390\n",
      "Epoch 8/20\n",
      "\u001B[1m87/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6748 - loss: 0.6091\n",
      "Epoch 8 - MCC: 0.3390\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6745 - loss: 0.6094 - val_accuracy: 0.6710 - val_loss: 0.6113 - mcc: 0.3390\n",
      "Epoch 9/20\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6748 - loss: 0.6093\n",
      "Epoch 9 - MCC: 0.3400\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6745 - loss: 0.6095 - val_accuracy: 0.6713 - val_loss: 0.6108 - mcc: 0.3400\n",
      "Epoch 10/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6710 - loss: 0.6119\n",
      "Epoch 10 - MCC: 0.3415\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6710 - loss: 0.6119 - val_accuracy: 0.6712 - val_loss: 0.6111 - mcc: 0.3415\n",
      "Epoch 11/20\n",
      "\u001B[1m90/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6707 - loss: 0.6125\n",
      "Epoch 11 - MCC: 0.3407\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.6707 - loss: 0.6125 - val_accuracy: 0.6714 - val_loss: 0.6108 - mcc: 0.3407\n",
      "Epoch 12/20\n",
      "\u001B[1m91/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6697 - loss: 0.6131\n",
      "Epoch 12 - MCC: 0.3410\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.6698 - loss: 0.6130 - val_accuracy: 0.6714 - val_loss: 0.6109 - mcc: 0.3410\n",
      "Epoch 13/20\n",
      "\u001B[1m84/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6678 - loss: 0.6149\n",
      "Epoch 13 - MCC: 0.3416\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.6682 - loss: 0.6145 - val_accuracy: 0.6709 - val_loss: 0.6113 - mcc: 0.3416\n",
      "Epoch 14/20\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6686 - loss: 0.6143\n",
      "Epoch 14 - MCC: 0.3381\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6688 - loss: 0.6142 - val_accuracy: 0.6709 - val_loss: 0.6113 - mcc: 0.3381\n",
      "Epoch 15/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6689 - loss: 0.6140\n",
      "Epoch 15 - MCC: 0.3402\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6689 - loss: 0.6140 - val_accuracy: 0.6714 - val_loss: 0.6111 - mcc: 0.3402\n",
      "Epoch 16/20\n",
      "\u001B[1m87/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6706 - loss: 0.6131\n",
      "Epoch 16 - MCC: 0.3400\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6707 - loss: 0.6130 - val_accuracy: 0.6714 - val_loss: 0.6111 - mcc: 0.3400\n",
      "Epoch 17/20\n",
      "\u001B[1m77/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6730 - loss: 0.6100\n",
      "Epoch 17 - MCC: 0.3401\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6726 - loss: 0.6104 - val_accuracy: 0.6713 - val_loss: 0.6108 - mcc: 0.3401\n",
      "Epoch 18/20\n",
      "\u001B[1m88/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6697 - loss: 0.6129\n",
      "Epoch 18 - MCC: 0.3389\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6698 - loss: 0.6128 - val_accuracy: 0.6711 - val_loss: 0.6111 - mcc: 0.3389\n",
      "Epoch 19/20\n",
      "\u001B[1m77/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6735 - loss: 0.6097\n",
      "Epoch 19 - MCC: 0.3394\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6730 - loss: 0.6101 - val_accuracy: 0.6710 - val_loss: 0.6109 - mcc: 0.3394\n",
      "Epoch 20/20\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6679 - loss: 0.6146\n",
      "Epoch 20 - MCC: 0.3388\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6679 - loss: 0.6146 - val_accuracy: 0.6710 - val_loss: 0.6111 - mcc: 0.3388\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.673032),\n",
      "              'mean': np.float64(0.6708309333333333),\n",
      "              'min': np.float64(0.6664666666666667),\n",
      "              'std': np.float64(0.002396516345772658)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.0003018061319986979),\n",
      "                               'mean': np.float64(0.0002565639495849609),\n",
      "                               'min': np.float64(0.0001734301249186198),\n",
      "                               'std': np.float64(4.4827774278185976e-05)},\n",
      " 'MCC': {'max': np.float64(0.34508052552965757),\n",
      "         'mean': np.float64(0.3397109407932288),\n",
      "         'min': np.float64(0.32995444704069504),\n",
      "         'std': np.float64(0.005528070869962765)},\n",
      " 'Parameters': 4649,\n",
      " 'Train Time (s)': {'max': np.float64(24.03471541404724),\n",
      "                    'mean': np.float64(19.505299663543703),\n",
      "                    'min': np.float64(17.112409591674805),\n",
      "                    'std': np.float64(2.403096235557626)},\n",
      " 'Training Accuracy': [[0.645784854888916,\n",
      "                        0.6703073382377625,\n",
      "                        0.6704574227333069,\n",
      "                        0.6702806949615479,\n",
      "                        0.6703153848648071,\n",
      "                        0.67044597864151,\n",
      "                        0.6702640056610107,\n",
      "                        0.6701533794403076,\n",
      "                        0.6702880263328552,\n",
      "                        0.6705345511436462,\n",
      "                        0.670237123966217,\n",
      "                        0.670136570930481,\n",
      "                        0.6700220704078674,\n",
      "                        0.6703227162361145,\n",
      "                        0.6704066395759583,\n",
      "                        0.6704620122909546,\n",
      "                        0.6703382134437561,\n",
      "                        0.6705185770988464,\n",
      "                        0.6704601049423218,\n",
      "                        0.6703471541404724],\n",
      "                       [0.6554786562919617,\n",
      "                        0.6703619956970215,\n",
      "                        0.6702653169631958,\n",
      "                        0.6705067753791809,\n",
      "                        0.6703353524208069,\n",
      "                        0.6702134013175964,\n",
      "                        0.6702227592468262,\n",
      "                        0.6703487038612366,\n",
      "                        0.6703801155090332,\n",
      "                        0.6704606413841248,\n",
      "                        0.6703053712844849,\n",
      "                        0.6702040433883667,\n",
      "                        0.6702947020530701,\n",
      "                        0.6703839302062988,\n",
      "                        0.6704519391059875,\n",
      "                        0.670549213886261,\n",
      "                        0.6700199842453003,\n",
      "                        0.6705088019371033,\n",
      "                        0.6705082058906555,\n",
      "                        0.6702600717544556],\n",
      "                       [0.657637357711792,\n",
      "                        0.6713740825653076,\n",
      "                        0.6719967722892761,\n",
      "                        0.6718186140060425,\n",
      "                        0.6720212697982788,\n",
      "                        0.6718667149543762,\n",
      "                        0.672049343585968,\n",
      "                        0.6718359589576721,\n",
      "                        0.6719027757644653,\n",
      "                        0.6718226075172424,\n",
      "                        0.6720412373542786,\n",
      "                        0.6719574928283691,\n",
      "                        0.6716533899307251,\n",
      "                        0.6722093224525452,\n",
      "                        0.6718986630439758,\n",
      "                        0.6720061302185059,\n",
      "                        0.6719326972961426,\n",
      "                        0.671990156173706,\n",
      "                        0.6719847917556763,\n",
      "                        0.6721027493476868],\n",
      "                       [0.6463119387626648,\n",
      "                        0.6710786819458008,\n",
      "                        0.6708385944366455,\n",
      "                        0.6708580255508423,\n",
      "                        0.6709866523742676,\n",
      "                        0.6709094047546387,\n",
      "                        0.6709460616111755,\n",
      "                        0.6709325909614563,\n",
      "                        0.6710514426231384,\n",
      "                        0.671122133731842,\n",
      "                        0.6707580089569092,\n",
      "                        0.6709973812103271,\n",
      "                        0.670970618724823,\n",
      "                        0.6709232330322266,\n",
      "                        0.6711233854293823,\n",
      "                        0.6711327433586121,\n",
      "                        0.671038806438446,\n",
      "                        0.6709827184677124,\n",
      "                        0.6709739565849304,\n",
      "                        0.6709880232810974],\n",
      "                       [0.6435325741767883,\n",
      "                        0.6706300973892212,\n",
      "                        0.6711393594741821,\n",
      "                        0.6707679033279419,\n",
      "                        0.67071133852005,\n",
      "                        0.6708393692970276,\n",
      "                        0.6707087755203247,\n",
      "                        0.6708727478981018,\n",
      "                        0.6707133650779724,\n",
      "                        0.6704166531562805,\n",
      "                        0.6706565618515015,\n",
      "                        0.6708859205245972,\n",
      "                        0.670916736125946,\n",
      "                        0.6710054874420166,\n",
      "                        0.6709441542625427,\n",
      "                        0.6709241271018982,\n",
      "                        0.6710467338562012,\n",
      "                        0.6710273027420044,\n",
      "                        0.6710067391395569,\n",
      "                        0.6709167957305908]],\n",
      " 'Training Loss': [[0.63367760181427,\n",
      "                    0.6122702956199646,\n",
      "                    0.612131655216217,\n",
      "                    0.6121199727058411,\n",
      "                    0.6125478744506836,\n",
      "                    0.6121209263801575,\n",
      "                    0.6122327446937561,\n",
      "                    0.6123469471931458,\n",
      "                    0.6122604608535767,\n",
      "                    0.6121242046356201,\n",
      "                    0.6121535301208496,\n",
      "                    0.6121944785118103,\n",
      "                    0.6123811602592468,\n",
      "                    0.6121094822883606,\n",
      "                    0.6120828986167908,\n",
      "                    0.612025797367096,\n",
      "                    0.6120238304138184,\n",
      "                    0.6121953725814819,\n",
      "                    0.6119779348373413,\n",
      "                    0.612318754196167],\n",
      "                   [0.6337764859199524,\n",
      "                    0.6122653484344482,\n",
      "                    0.6122872829437256,\n",
      "                    0.6121577024459839,\n",
      "                    0.6122995615005493,\n",
      "                    0.612303614616394,\n",
      "                    0.6124557852745056,\n",
      "                    0.6123838424682617,\n",
      "                    0.6122241020202637,\n",
      "                    0.6122339367866516,\n",
      "                    0.6123056411743164,\n",
      "                    0.6125982999801636,\n",
      "                    0.6124486327171326,\n",
      "                    0.6122363209724426,\n",
      "                    0.6122891306877136,\n",
      "                    0.6120411157608032,\n",
      "                    0.6123962998390198,\n",
      "                    0.612135648727417,\n",
      "                    0.6121862530708313,\n",
      "                    0.6125113368034363],\n",
      "                   [0.6280854940414429,\n",
      "                    0.6114944219589233,\n",
      "                    0.6110796928405762,\n",
      "                    0.611137866973877,\n",
      "                    0.6111103296279907,\n",
      "                    0.6110755205154419,\n",
      "                    0.6110607385635376,\n",
      "                    0.6111780405044556,\n",
      "                    0.6111661791801453,\n",
      "                    0.6112555861473083,\n",
      "                    0.611020028591156,\n",
      "                    0.6110997200012207,\n",
      "                    0.6111027598381042,\n",
      "                    0.6110830307006836,\n",
      "                    0.6109815835952759,\n",
      "                    0.6110522747039795,\n",
      "                    0.6111541390419006,\n",
      "                    0.611211895942688,\n",
      "                    0.6110772490501404,\n",
      "                    0.6109151244163513],\n",
      "                   [0.6315994262695312,\n",
      "                    0.612051784992218,\n",
      "                    0.6120286583900452,\n",
      "                    0.612352192401886,\n",
      "                    0.6119706034660339,\n",
      "                    0.6120399236679077,\n",
      "                    0.6119596362113953,\n",
      "                    0.6118918657302856,\n",
      "                    0.6119699478149414,\n",
      "                    0.611944317817688,\n",
      "                    0.6123929023742676,\n",
      "                    0.6119675636291504,\n",
      "                    0.6121552586555481,\n",
      "                    0.6120675206184387,\n",
      "                    0.611888587474823,\n",
      "                    0.6118789315223694,\n",
      "                    0.6117666959762573,\n",
      "                    0.6119486689567566,\n",
      "                    0.6119529008865356,\n",
      "                    0.6118751764297485],\n",
      "                   [0.6350672841072083,\n",
      "                    0.6123889088630676,\n",
      "                    0.6120843291282654,\n",
      "                    0.6122580766677856,\n",
      "                    0.612395703792572,\n",
      "                    0.6122685670852661,\n",
      "                    0.6122579574584961,\n",
      "                    0.6122849583625793,\n",
      "                    0.6123183369636536,\n",
      "                    0.6123735308647156,\n",
      "                    0.6124483346939087,\n",
      "                    0.6120633482933044,\n",
      "                    0.6121711730957031,\n",
      "                    0.6122018694877625,\n",
      "                    0.6121529340744019,\n",
      "                    0.6122971773147583,\n",
      "                    0.6120259761810303,\n",
      "                    0.6120527386665344,\n",
      "                    0.6119661927223206,\n",
      "                    0.6119772791862488]],\n",
      " 'Validation Accuracy': [[0.6731093525886536,\n",
      "                          0.6725867390632629,\n",
      "                          0.6727120280265808,\n",
      "                          0.6738293766975403,\n",
      "                          0.6729227900505066,\n",
      "                          0.6731253862380981,\n",
      "                          0.672269344329834,\n",
      "                          0.6738693714141846,\n",
      "                          0.6734799742698669,\n",
      "                          0.6726987361907959,\n",
      "                          0.6721547245979309,\n",
      "                          0.6720134019851685,\n",
      "                          0.6739813685417175,\n",
      "                          0.673509418964386,\n",
      "                          0.6731173992156982,\n",
      "                          0.6736934185028076,\n",
      "                          0.6727040410041809,\n",
      "                          0.6733707189559937,\n",
      "                          0.6720399260520935,\n",
      "                          0.6730320453643799],\n",
      "                         [0.6732240319252014,\n",
      "                          0.6730853915214539,\n",
      "                          0.6730453968048096,\n",
      "                          0.6731386780738831,\n",
      "                          0.6733787059783936,\n",
      "                          0.6732373833656311,\n",
      "                          0.6734186410903931,\n",
      "                          0.6730480194091797,\n",
      "                          0.6719893217086792,\n",
      "                          0.6733733415603638,\n",
      "                          0.6729893684387207,\n",
      "                          0.6732133626937866,\n",
      "                          0.6732560396194458,\n",
      "                          0.6732373237609863,\n",
      "                          0.673298716545105,\n",
      "                          0.67331463098526,\n",
      "                          0.6732667088508606,\n",
      "                          0.6731893420219421,\n",
      "                          0.6731333136558533,\n",
      "                          0.673018753528595],\n",
      "                         [0.6669493317604065,\n",
      "                          0.6667574048042297,\n",
      "                          0.6658720374107361,\n",
      "                          0.66648268699646,\n",
      "                          0.6667466759681702,\n",
      "                          0.6670054197311401,\n",
      "                          0.6665626764297485,\n",
      "                          0.6655093431472778,\n",
      "                          0.6663280129432678,\n",
      "                          0.6666827201843262,\n",
      "                          0.6666133403778076,\n",
      "                          0.6667093634605408,\n",
      "                          0.6669707298278809,\n",
      "                          0.6665120720863342,\n",
      "                          0.6660853028297424,\n",
      "                          0.6666213274002075,\n",
      "                          0.666930615901947,\n",
      "                          0.6668426990509033,\n",
      "                          0.666861355304718,\n",
      "                          0.6664667129516602],\n",
      "                         [0.6703386306762695,\n",
      "                          0.6706666946411133,\n",
      "                          0.6686986684799194,\n",
      "                          0.6706347465515137,\n",
      "                          0.6710479259490967,\n",
      "                          0.670509397983551,\n",
      "                          0.6693947315216064,\n",
      "                          0.6706374287605286,\n",
      "                          0.6708213090896606,\n",
      "                          0.6706346869468689,\n",
      "                          0.6704640984535217,\n",
      "                          0.6707440614700317,\n",
      "                          0.67085862159729,\n",
      "                          0.6699759364128113,\n",
      "                          0.6707066893577576,\n",
      "                          0.6706666946411133,\n",
      "                          0.6707813739776611,\n",
      "                          0.6707813739776611,\n",
      "                          0.6705600619316101,\n",
      "                          0.6706801056861877],\n",
      "                         [0.6703413128852844,\n",
      "                          0.6708773374557495,\n",
      "                          0.6711174249649048,\n",
      "                          0.6712560057640076,\n",
      "                          0.6711307168006897,\n",
      "                          0.6709680557250977,\n",
      "                          0.6710960268974304,\n",
      "                          0.6710399985313416,\n",
      "                          0.6712880730628967,\n",
      "                          0.6711921095848083,\n",
      "                          0.6713759899139404,\n",
      "                          0.6714347004890442,\n",
      "                          0.670853316783905,\n",
      "                          0.6708506941795349,\n",
      "                          0.6713974475860596,\n",
      "                          0.6713786721229553,\n",
      "                          0.6712774038314819,\n",
      "                          0.671069324016571,\n",
      "                          0.6709520816802979,\n",
      "                          0.6709573864936829]],\n",
      " 'Validation Loss': [0.6118270754814148,\n",
      "                     0.6113247275352478,\n",
      "                     0.6108464598655701,\n",
      "                     0.6109439134597778,\n",
      "                     0.6110741496086121,\n",
      "                     0.6108073592185974,\n",
      "                     0.6108824014663696,\n",
      "                     0.6112585067749023,\n",
      "                     0.6107670664787292,\n",
      "                     0.6111329197883606,\n",
      "                     0.610804557800293,\n",
      "                     0.6108872890472412,\n",
      "                     0.611299455165863,\n",
      "                     0.6113207340240479,\n",
      "                     0.6111009120941162,\n",
      "                     0.6110770106315613,\n",
      "                     0.6107791662216187,\n",
      "                     0.6111039519309998,\n",
      "                     0.6109277606010437,\n",
      "                     0.6110934615135193],\n",
      " 'Validation MCC': [[np.float64(0.3471718333833592),\n",
      "                     np.float64(0.34537699396639643),\n",
      "                     np.float64(0.3438786060426734),\n",
      "                     np.float64(0.3466095093669172),\n",
      "                     np.float64(0.3473423877426409),\n",
      "                     np.float64(0.34690089005052094),\n",
      "                     np.float64(0.3416711630837538),\n",
      "                     np.float64(0.347079327482806),\n",
      "                     np.float64(0.3470032929485738),\n",
      "                     np.float64(0.3473295919272746),\n",
      "                     np.float64(0.34594404053407213),\n",
      "                     np.float64(0.3431876986717973),\n",
      "                     np.float64(0.34732300811151734),\n",
      "                     np.float64(0.34538337510295025),\n",
      "                     np.float64(0.34524238123557327),\n",
      "                     np.float64(0.34622790190327796),\n",
      "                     np.float64(0.3427709438243669),\n",
      "                     np.float64(0.3469260091820501),\n",
      "                     np.float64(0.34675538051243093),\n",
      "                     np.float64(0.34508052552965757)],\n",
      "                    [np.float64(0.3441713927709838),\n",
      "                     np.float64(0.34735751246839114),\n",
      "                     np.float64(0.3458501534750294),\n",
      "                     np.float64(0.3470253332124942),\n",
      "                     np.float64(0.34567605241236254),\n",
      "                     np.float64(0.34425728597687455),\n",
      "                     np.float64(0.3458836350677997),\n",
      "                     np.float64(0.34355249073091293),\n",
      "                     np.float64(0.34664351020421647),\n",
      "                     np.float64(0.3472050448784142),\n",
      "                     np.float64(0.34303687904163643),\n",
      "                     np.float64(0.34653598952956993),\n",
      "                     np.float64(0.3447297345755899),\n",
      "                     np.float64(0.3461808930584033),\n",
      "                     np.float64(0.3461500624554097),\n",
      "                     np.float64(0.3461717666937656),\n",
      "                     np.float64(0.3470531773854395),\n",
      "                     np.float64(0.34452345409192764),\n",
      "                     np.float64(0.34683473802371706),\n",
      "                     np.float64(0.3450052730818177)],\n",
      "                    [np.float64(0.33139599234679035),\n",
      "                     np.float64(0.3318496189274886),\n",
      "                     np.float64(0.32764701623061293),\n",
      "                     np.float64(0.33293281598403396),\n",
      "                     np.float64(0.3306424050112388),\n",
      "                     np.float64(0.330618522666568),\n",
      "                     np.float64(0.32922636341777717),\n",
      "                     np.float64(0.3280947444804758),\n",
      "                     np.float64(0.3291542467380247),\n",
      "                     np.float64(0.330498322051505),\n",
      "                     np.float64(0.33332971067711964),\n",
      "                     np.float64(0.3328127365177895),\n",
      "                     np.float64(0.33114391203077087),\n",
      "                     np.float64(0.33322971885288305),\n",
      "                     np.float64(0.32881429314253013),\n",
      "                     np.float64(0.3298900065703954),\n",
      "                     np.float64(0.33114829883136404),\n",
      "                     np.float64(0.3319786775057017),\n",
      "                     np.float64(0.33204377876483293),\n",
      "                     np.float64(0.32995444704069504)],\n",
      "                    [np.float64(0.33913755767260434),\n",
      "                     np.float64(0.33989280180391723),\n",
      "                     np.float64(0.34324560792079756),\n",
      "                     np.float64(0.3395496519941368),\n",
      "                     np.float64(0.34116271810986104),\n",
      "                     np.float64(0.3390109919696435),\n",
      "                     np.float64(0.3381027610773265),\n",
      "                     np.float64(0.342201712368011),\n",
      "                     np.float64(0.34091654058461807),\n",
      "                     np.float64(0.3395941914086071),\n",
      "                     np.float64(0.3386900837229161),\n",
      "                     np.float64(0.34009796274080906),\n",
      "                     np.float64(0.34147997431608157),\n",
      "                     np.float64(0.33721947162114935),\n",
      "                     np.float64(0.3418221782750233),\n",
      "                     np.float64(0.3397467519466468),\n",
      "                     np.float64(0.3404913619795647),\n",
      "                     np.float64(0.34186864412090706),\n",
      "                     np.float64(0.3400123184012911),\n",
      "                     np.float64(0.3396662305335234)],\n",
      "                    [np.float64(0.3428878258440904),\n",
      "                     np.float64(0.33821972889874896),\n",
      "                     np.float64(0.34072617942492234),\n",
      "                     np.float64(0.3395294664231003),\n",
      "                     np.float64(0.3422152009519769),\n",
      "                     np.float64(0.33932824720501553),\n",
      "                     np.float64(0.33904568506749927),\n",
      "                     np.float64(0.3390176293416431),\n",
      "                     np.float64(0.3400425958238209),\n",
      "                     np.float64(0.3414740604946094),\n",
      "                     np.float64(0.3406596123302455),\n",
      "                     np.float64(0.3409608785785994),\n",
      "                     np.float64(0.34161190080273096),\n",
      "                     np.float64(0.3380781393379619),\n",
      "                     np.float64(0.340215602989321),\n",
      "                     np.float64(0.34001470312707077),\n",
      "                     np.float64(0.3401367795510878),\n",
      "                     np.float64(0.3388947834954447),\n",
      "                     np.float64(0.3393800888195663),\n",
      "                     np.float64(0.3388482277804504)]]}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Hilbert Binary\n",
    "\n",
    "model_results, trained_models = train_and_evaluate(simple_models_dict, X=hilbert_data_vec_binary, y=label_binary, epochs=20, basePath=basePath, dir_name='hilbert_binary')\n",
    "\n",
    "filePath = f\"{basePath}/Hilbert_Binary_Model_Results.json\"\n",
    "\n",
    "with open(filePath, 'w') as f:\n",
    "        json.dump(model_results, f, indent=4)  # indent=4 for pretty formatting"
   ],
   "metadata": {
    "id": "LScLQag3OhCy",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1744801491206,
     "user_tz": -120,
     "elapsed": 2936808,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     }
    },
    "outputId": "e7d08dd7-7ca9-462d-efec-4e1e19a6fc1c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Binary: True\n",
      "Training Model: LSTM, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7250 - loss: 0.5030\n",
      "Epoch 1 - MCC: 0.7848\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 24ms/step - accuracy: 0.7261 - loss: 0.5017 - val_accuracy: 0.8924 - val_loss: 0.2573 - mcc: 0.7848\n",
      "Epoch 2/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9007 - loss: 0.2378\n",
      "Epoch 2 - MCC: 0.8128\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 22ms/step - accuracy: 0.9007 - loss: 0.2377 - val_accuracy: 0.9064 - val_loss: 0.2251 - mcc: 0.8128\n",
      "Epoch 3/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9062 - loss: 0.2196\n",
      "Epoch 3 - MCC: 0.8135\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9062 - loss: 0.2196 - val_accuracy: 0.9068 - val_loss: 0.2168 - mcc: 0.8135\n",
      "Epoch 4/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9101 - loss: 0.2104\n",
      "Epoch 4 - MCC: 0.8256\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9101 - loss: 0.2104 - val_accuracy: 0.9130 - val_loss: 0.2054 - mcc: 0.8256\n",
      "Epoch 5/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9125 - loss: 0.2055\n",
      "Epoch 5 - MCC: 0.8277\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9125 - loss: 0.2055 - val_accuracy: 0.9140 - val_loss: 0.2027 - mcc: 0.8277\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9119 - loss: 0.2052\n",
      "Epoch 6 - MCC: 0.8329\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9119 - loss: 0.2051 - val_accuracy: 0.9167 - val_loss: 0.1970 - mcc: 0.8329\n",
      "Epoch 7/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9169 - loss: 0.1951\n",
      "Epoch 7 - MCC: 0.8309\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9169 - loss: 0.1952 - val_accuracy: 0.9146 - val_loss: 0.2028 - mcc: 0.8309\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9169 - loss: 0.1945\n",
      "Epoch 8 - MCC: 0.8337\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9169 - loss: 0.1945 - val_accuracy: 0.9171 - val_loss: 0.1948 - mcc: 0.8337\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9163 - loss: 0.1948\n",
      "Epoch 9 - MCC: 0.8428\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9164 - loss: 0.1948 - val_accuracy: 0.9216 - val_loss: 0.1864 - mcc: 0.8428\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9187 - loss: 0.1893\n",
      "Epoch 10 - MCC: 0.8440\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9188 - loss: 0.1893 - val_accuracy: 0.9222 - val_loss: 0.1852 - mcc: 0.8440\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9212 - loss: 0.1866\n",
      "Epoch 11 - MCC: 0.8461\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9212 - loss: 0.1866 - val_accuracy: 0.9232 - val_loss: 0.1853 - mcc: 0.8461\n",
      "Epoch 12/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9210 - loss: 0.1846\n",
      "Epoch 12 - MCC: 0.8471\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9210 - loss: 0.1846 - val_accuracy: 0.9238 - val_loss: 0.1818 - mcc: 0.8471\n",
      "Epoch 13/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9241 - loss: 0.1797\n",
      "Epoch 13 - MCC: 0.8489\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9241 - loss: 0.1797 - val_accuracy: 0.9245 - val_loss: 0.1803 - mcc: 0.8489\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9229 - loss: 0.1818\n",
      "Epoch 14 - MCC: 0.8490\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.9229 - loss: 0.1818 - val_accuracy: 0.9245 - val_loss: 0.1805 - mcc: 0.8490\n",
      "Epoch 15/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9246 - loss: 0.1783\n",
      "Epoch 15 - MCC: 0.8405\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9246 - loss: 0.1783 - val_accuracy: 0.9195 - val_loss: 0.1904 - mcc: 0.8405\n",
      "Epoch 16/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9241 - loss: 0.1797\n",
      "Epoch 16 - MCC: 0.8474\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9241 - loss: 0.1797 - val_accuracy: 0.9239 - val_loss: 0.1813 - mcc: 0.8474\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9244 - loss: 0.1780\n",
      "Epoch 17 - MCC: 0.8516\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.9244 - loss: 0.1780 - val_accuracy: 0.9260 - val_loss: 0.1772 - mcc: 0.8516\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9283 - loss: 0.1690\n",
      "Epoch 18 - MCC: 0.8558\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9283 - loss: 0.1690 - val_accuracy: 0.9280 - val_loss: 0.1728 - mcc: 0.8558\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9260 - loss: 0.1746\n",
      "Epoch 19 - MCC: 0.8569\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 24ms/step - accuracy: 0.9260 - loss: 0.1746 - val_accuracy: 0.9285 - val_loss: 0.1723 - mcc: 0.8569\n",
      "Epoch 20/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9275 - loss: 0.1700\n",
      "Epoch 20 - MCC: 0.8550\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9275 - loss: 0.1700 - val_accuracy: 0.9273 - val_loss: 0.1740 - mcc: 0.8550\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7238 - loss: 0.5249\n",
      "Epoch 1 - MCC: 0.7779\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.7248 - loss: 0.5234 - val_accuracy: 0.8891 - val_loss: 0.2652 - mcc: 0.7779\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8928 - loss: 0.2544\n",
      "Epoch 2 - MCC: 0.7972\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.8928 - loss: 0.2542 - val_accuracy: 0.8988 - val_loss: 0.2352 - mcc: 0.7972\n",
      "Epoch 3/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9032 - loss: 0.2268\n",
      "Epoch 3 - MCC: 0.8063\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9032 - loss: 0.2268 - val_accuracy: 0.9033 - val_loss: 0.2227 - mcc: 0.8063\n",
      "Epoch 4/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9059 - loss: 0.2167\n",
      "Epoch 4 - MCC: 0.8222\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 25ms/step - accuracy: 0.9059 - loss: 0.2167 - val_accuracy: 0.9114 - val_loss: 0.2066 - mcc: 0.8222\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9102 - loss: 0.2089\n",
      "Epoch 5 - MCC: 0.8233\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9102 - loss: 0.2089 - val_accuracy: 0.9119 - val_loss: 0.2060 - mcc: 0.8233\n",
      "Epoch 6/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9146 - loss: 0.1984\n",
      "Epoch 6 - MCC: 0.8299\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9146 - loss: 0.1985 - val_accuracy: 0.9152 - val_loss: 0.1990 - mcc: 0.8299\n",
      "Epoch 7/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9142 - loss: 0.2012\n",
      "Epoch 7 - MCC: 0.8308\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9142 - loss: 0.2011 - val_accuracy: 0.9149 - val_loss: 0.2012 - mcc: 0.8308\n",
      "Epoch 8/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9192 - loss: 0.1905\n",
      "Epoch 8 - MCC: 0.8213\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9192 - loss: 0.1905 - val_accuracy: 0.9099 - val_loss: 0.2047 - mcc: 0.8213\n",
      "Epoch 9/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9176 - loss: 0.1911\n",
      "Epoch 9 - MCC: 0.8392\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9176 - loss: 0.1911 - val_accuracy: 0.9198 - val_loss: 0.1871 - mcc: 0.8392\n",
      "Epoch 10/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9176 - loss: 0.1918\n",
      "Epoch 10 - MCC: 0.8418\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.9176 - loss: 0.1918 - val_accuracy: 0.9209 - val_loss: 0.1877 - mcc: 0.8418\n",
      "Epoch 11/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9197 - loss: 0.1874\n",
      "Epoch 11 - MCC: 0.8460\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9197 - loss: 0.1874 - val_accuracy: 0.9230 - val_loss: 0.1812 - mcc: 0.8460\n",
      "Epoch 12/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9211 - loss: 0.1850\n",
      "Epoch 12 - MCC: 0.8459\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9211 - loss: 0.1850 - val_accuracy: 0.9232 - val_loss: 0.1818 - mcc: 0.8459\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9216 - loss: 0.1844\n",
      "Epoch 13 - MCC: 0.8430\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 24ms/step - accuracy: 0.9217 - loss: 0.1843 - val_accuracy: 0.9216 - val_loss: 0.1827 - mcc: 0.8430\n",
      "Epoch 14/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9245 - loss: 0.1791\n",
      "Epoch 14 - MCC: 0.8491\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9245 - loss: 0.1791 - val_accuracy: 0.9248 - val_loss: 0.1766 - mcc: 0.8491\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9242 - loss: 0.1782\n",
      "Epoch 15 - MCC: 0.8504\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9242 - loss: 0.1782 - val_accuracy: 0.9254 - val_loss: 0.1744 - mcc: 0.8504\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9261 - loss: 0.1749\n",
      "Epoch 16 - MCC: 0.8514\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 25ms/step - accuracy: 0.9261 - loss: 0.1749 - val_accuracy: 0.9259 - val_loss: 0.1737 - mcc: 0.8514\n",
      "Epoch 17/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9254 - loss: 0.1750\n",
      "Epoch 17 - MCC: 0.8510\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9253 - loss: 0.1751 - val_accuracy: 0.9257 - val_loss: 0.1735 - mcc: 0.8510\n",
      "Epoch 18/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9249 - loss: 0.1770\n",
      "Epoch 18 - MCC: 0.8495\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9249 - loss: 0.1770 - val_accuracy: 0.9249 - val_loss: 0.1732 - mcc: 0.8495\n",
      "Epoch 19/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9271 - loss: 0.1729\n",
      "Epoch 19 - MCC: 0.8539\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.9271 - loss: 0.1729 - val_accuracy: 0.9272 - val_loss: 0.1706 - mcc: 0.8539\n",
      "Epoch 20/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9272 - loss: 0.1731\n",
      "Epoch 20 - MCC: 0.8535\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9272 - loss: 0.1731 - val_accuracy: 0.9269 - val_loss: 0.1731 - mcc: 0.8535\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.7458 - loss: 0.4925\n",
      "Epoch 1 - MCC: 0.7905\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 26ms/step - accuracy: 0.7462 - loss: 0.4919 - val_accuracy: 0.8956 - val_loss: 0.2543 - mcc: 0.7905\n",
      "Epoch 2/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9017 - loss: 0.2351\n",
      "Epoch 2 - MCC: 0.8013\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9016 - loss: 0.2351 - val_accuracy: 0.9008 - val_loss: 0.2320 - mcc: 0.8013\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9032 - loss: 0.2279\n",
      "Epoch 3 - MCC: 0.8166\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9032 - loss: 0.2278 - val_accuracy: 0.9086 - val_loss: 0.2160 - mcc: 0.8166\n",
      "Epoch 4/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9088 - loss: 0.2148\n",
      "Epoch 4 - MCC: 0.8160\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 24ms/step - accuracy: 0.9088 - loss: 0.2148 - val_accuracy: 0.9082 - val_loss: 0.2149 - mcc: 0.8160\n",
      "Epoch 5/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9103 - loss: 0.2104\n",
      "Epoch 5 - MCC: 0.8172\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9103 - loss: 0.2104 - val_accuracy: 0.9089 - val_loss: 0.2167 - mcc: 0.8172\n",
      "Epoch 6/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9113 - loss: 0.2089\n",
      "Epoch 6 - MCC: 0.8278\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9114 - loss: 0.2088 - val_accuracy: 0.9142 - val_loss: 0.2037 - mcc: 0.8278\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9154 - loss: 0.1989\n",
      "Epoch 7 - MCC: 0.8282\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9154 - loss: 0.1989 - val_accuracy: 0.9141 - val_loss: 0.2034 - mcc: 0.8282\n",
      "Epoch 8/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9173 - loss: 0.1954\n",
      "Epoch 8 - MCC: 0.8304\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9173 - loss: 0.1954 - val_accuracy: 0.9155 - val_loss: 0.1996 - mcc: 0.8304\n",
      "Epoch 9/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9183 - loss: 0.1935\n",
      "Epoch 9 - MCC: 0.8322\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9183 - loss: 0.1935 - val_accuracy: 0.9164 - val_loss: 0.1970 - mcc: 0.8322\n",
      "Epoch 10/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9212 - loss: 0.1872\n",
      "Epoch 10 - MCC: 0.8352\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 22ms/step - accuracy: 0.9212 - loss: 0.1872 - val_accuracy: 0.9173 - val_loss: 0.1982 - mcc: 0.8352\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9207 - loss: 0.1865\n",
      "Epoch 11 - MCC: 0.8373\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9207 - loss: 0.1865 - val_accuracy: 0.9185 - val_loss: 0.1954 - mcc: 0.8373\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9228 - loss: 0.1827\n",
      "Epoch 12 - MCC: 0.8410\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9228 - loss: 0.1827 - val_accuracy: 0.9207 - val_loss: 0.1875 - mcc: 0.8410\n",
      "Epoch 13/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9241 - loss: 0.1801\n",
      "Epoch 13 - MCC: 0.8454\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.9241 - loss: 0.1801 - val_accuracy: 0.9230 - val_loss: 0.1828 - mcc: 0.8454\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9223 - loss: 0.1826\n",
      "Epoch 14 - MCC: 0.8456\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.9223 - loss: 0.1826 - val_accuracy: 0.9230 - val_loss: 0.1843 - mcc: 0.8456\n",
      "Epoch 15/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9232 - loss: 0.1802\n",
      "Epoch 15 - MCC: 0.8486\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9233 - loss: 0.1801 - val_accuracy: 0.9245 - val_loss: 0.1815 - mcc: 0.8486\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9277 - loss: 0.1723\n",
      "Epoch 16 - MCC: 0.8496\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9277 - loss: 0.1723 - val_accuracy: 0.9250 - val_loss: 0.1799 - mcc: 0.8496\n",
      "Epoch 17/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9246 - loss: 0.1774\n",
      "Epoch 17 - MCC: 0.8481\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9246 - loss: 0.1774 - val_accuracy: 0.9240 - val_loss: 0.1823 - mcc: 0.8481\n",
      "Epoch 18/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9249 - loss: 0.1756\n",
      "Epoch 18 - MCC: 0.8527\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9249 - loss: 0.1756 - val_accuracy: 0.9266 - val_loss: 0.1758 - mcc: 0.8527\n",
      "Epoch 19/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9253 - loss: 0.1753\n",
      "Epoch 19 - MCC: 0.8517\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9253 - loss: 0.1752 - val_accuracy: 0.9261 - val_loss: 0.1761 - mcc: 0.8517\n",
      "Epoch 20/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9279 - loss: 0.1711\n",
      "Epoch 20 - MCC: 0.8501\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9279 - loss: 0.1711 - val_accuracy: 0.9248 - val_loss: 0.1804 - mcc: 0.8501\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7189 - loss: 0.5063\n",
      "Epoch 1 - MCC: 0.7936\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.7210 - loss: 0.5035 - val_accuracy: 0.8971 - val_loss: 0.2454 - mcc: 0.7936\n",
      "Epoch 2/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8939 - loss: 0.2487\n",
      "Epoch 2 - MCC: 0.8034\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.8939 - loss: 0.2487 - val_accuracy: 0.9019 - val_loss: 0.2338 - mcc: 0.8034\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9009 - loss: 0.2308\n",
      "Epoch 3 - MCC: 0.8093\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 25ms/step - accuracy: 0.9009 - loss: 0.2308 - val_accuracy: 0.9048 - val_loss: 0.2242 - mcc: 0.8093\n",
      "Epoch 4/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9036 - loss: 0.2238\n",
      "Epoch 4 - MCC: 0.8130\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9036 - loss: 0.2238 - val_accuracy: 0.9062 - val_loss: 0.2204 - mcc: 0.8130\n",
      "Epoch 5/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9062 - loss: 0.2192\n",
      "Epoch 5 - MCC: 0.8200\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9062 - loss: 0.2192 - val_accuracy: 0.9102 - val_loss: 0.2095 - mcc: 0.8200\n",
      "Epoch 6/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9109 - loss: 0.2087\n",
      "Epoch 6 - MCC: 0.8239\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 22ms/step - accuracy: 0.9109 - loss: 0.2087 - val_accuracy: 0.9121 - val_loss: 0.2059 - mcc: 0.8239\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9119 - loss: 0.2058\n",
      "Epoch 7 - MCC: 0.8193\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9119 - loss: 0.2058 - val_accuracy: 0.9089 - val_loss: 0.2125 - mcc: 0.8193\n",
      "Epoch 8/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9143 - loss: 0.2022\n",
      "Epoch 8 - MCC: 0.8330\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9143 - loss: 0.2022 - val_accuracy: 0.9168 - val_loss: 0.1958 - mcc: 0.8330\n",
      "Epoch 9/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9146 - loss: 0.2021\n",
      "Epoch 9 - MCC: 0.8352\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9146 - loss: 0.2021 - val_accuracy: 0.9178 - val_loss: 0.1922 - mcc: 0.8352\n",
      "Epoch 10/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9185 - loss: 0.1932\n",
      "Epoch 10 - MCC: 0.8401\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9185 - loss: 0.1932 - val_accuracy: 0.9202 - val_loss: 0.1876 - mcc: 0.8401\n",
      "Epoch 11/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9182 - loss: 0.1916\n",
      "Epoch 11 - MCC: 0.8416\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.9182 - loss: 0.1916 - val_accuracy: 0.9208 - val_loss: 0.1858 - mcc: 0.8416\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9210 - loss: 0.1854\n",
      "Epoch 12 - MCC: 0.8466\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.9210 - loss: 0.1854 - val_accuracy: 0.9235 - val_loss: 0.1789 - mcc: 0.8466\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9207 - loss: 0.1870\n",
      "Epoch 13 - MCC: 0.8475\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9207 - loss: 0.1870 - val_accuracy: 0.9239 - val_loss: 0.1793 - mcc: 0.8475\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9224 - loss: 0.1833\n",
      "Epoch 14 - MCC: 0.8495\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9224 - loss: 0.1832 - val_accuracy: 0.9250 - val_loss: 0.1758 - mcc: 0.8495\n",
      "Epoch 15/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9219 - loss: 0.1844\n",
      "Epoch 15 - MCC: 0.8488\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.9220 - loss: 0.1844 - val_accuracy: 0.9246 - val_loss: 0.1757 - mcc: 0.8488\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9250 - loss: 0.1781\n",
      "Epoch 16 - MCC: 0.8540\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9250 - loss: 0.1781 - val_accuracy: 0.9271 - val_loss: 0.1718 - mcc: 0.8540\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9248 - loss: 0.1767\n",
      "Epoch 17 - MCC: 0.8529\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9248 - loss: 0.1767 - val_accuracy: 0.9264 - val_loss: 0.1725 - mcc: 0.8529\n",
      "Epoch 18/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9274 - loss: 0.1722\n",
      "Epoch 18 - MCC: 0.8539\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9274 - loss: 0.1723 - val_accuracy: 0.9270 - val_loss: 0.1711 - mcc: 0.8539\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9279 - loss: 0.1713\n",
      "Epoch 19 - MCC: 0.8566\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9279 - loss: 0.1713 - val_accuracy: 0.9284 - val_loss: 0.1685 - mcc: 0.8566\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9265 - loss: 0.1734\n",
      "Epoch 20 - MCC: 0.8536\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9265 - loss: 0.1734 - val_accuracy: 0.9270 - val_loss: 0.1703 - mcc: 0.8536\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7372 - loss: 0.5277\n",
      "Epoch 1 - MCC: 0.7842\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 22ms/step - accuracy: 0.7380 - loss: 0.5263 - val_accuracy: 0.8925 - val_loss: 0.2567 - mcc: 0.7842\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8963 - loss: 0.2471\n",
      "Epoch 2 - MCC: 0.8079\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8964 - loss: 0.2471 - val_accuracy: 0.9041 - val_loss: 0.2261 - mcc: 0.8079\n",
      "Epoch 3/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9008 - loss: 0.2323\n",
      "Epoch 3 - MCC: 0.8105\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9009 - loss: 0.2322 - val_accuracy: 0.9056 - val_loss: 0.2176 - mcc: 0.8105\n",
      "Epoch 4/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9080 - loss: 0.2163\n",
      "Epoch 4 - MCC: 0.8211\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9080 - loss: 0.2163 - val_accuracy: 0.9108 - val_loss: 0.2102 - mcc: 0.8211\n",
      "Epoch 5/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9095 - loss: 0.2126\n",
      "Epoch 5 - MCC: 0.8209\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9095 - loss: 0.2126 - val_accuracy: 0.9107 - val_loss: 0.2065 - mcc: 0.8209\n",
      "Epoch 6/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9135 - loss: 0.2035\n",
      "Epoch 6 - MCC: 0.8244\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9135 - loss: 0.2035 - val_accuracy: 0.9121 - val_loss: 0.2044 - mcc: 0.8244\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9180 - loss: 0.1939\n",
      "Epoch 7 - MCC: 0.8330\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9179 - loss: 0.1939 - val_accuracy: 0.9168 - val_loss: 0.1942 - mcc: 0.8330\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9163 - loss: 0.1980\n",
      "Epoch 8 - MCC: 0.8360\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9163 - loss: 0.1979 - val_accuracy: 0.9183 - val_loss: 0.1917 - mcc: 0.8360\n",
      "Epoch 9/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9216 - loss: 0.1866\n",
      "Epoch 9 - MCC: 0.8424\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.9216 - loss: 0.1866 - val_accuracy: 0.9213 - val_loss: 0.1856 - mcc: 0.8424\n",
      "Epoch 10/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9218 - loss: 0.1843\n",
      "Epoch 10 - MCC: 0.8258\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.9218 - loss: 0.1843 - val_accuracy: 0.9128 - val_loss: 0.2040 - mcc: 0.8258\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9221 - loss: 0.1853\n",
      "Epoch 11 - MCC: 0.8446\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9221 - loss: 0.1853 - val_accuracy: 0.9224 - val_loss: 0.1833 - mcc: 0.8446\n",
      "Epoch 12/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9223 - loss: 0.1850\n",
      "Epoch 12 - MCC: 0.8488\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9223 - loss: 0.1849 - val_accuracy: 0.9246 - val_loss: 0.1780 - mcc: 0.8488\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9260 - loss: 0.1756\n",
      "Epoch 13 - MCC: 0.8424\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9260 - loss: 0.1756 - val_accuracy: 0.9215 - val_loss: 0.1830 - mcc: 0.8424\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9229 - loss: 0.1812\n",
      "Epoch 14 - MCC: 0.8499\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.9230 - loss: 0.1812 - val_accuracy: 0.9252 - val_loss: 0.1780 - mcc: 0.8499\n",
      "Epoch 15/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9252 - loss: 0.1776\n",
      "Epoch 15 - MCC: 0.8493\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 24ms/step - accuracy: 0.9252 - loss: 0.1776 - val_accuracy: 0.9249 - val_loss: 0.1770 - mcc: 0.8493\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9256 - loss: 0.1764\n",
      "Epoch 16 - MCC: 0.8464\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9256 - loss: 0.1764 - val_accuracy: 0.9230 - val_loss: 0.1825 - mcc: 0.8464\n",
      "Epoch 17/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9275 - loss: 0.1731\n",
      "Epoch 17 - MCC: 0.8494\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9275 - loss: 0.1732 - val_accuracy: 0.9246 - val_loss: 0.1783 - mcc: 0.8494\n",
      "Epoch 18/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9265 - loss: 0.1740\n",
      "Epoch 18 - MCC: 0.8525\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 24ms/step - accuracy: 0.9265 - loss: 0.1740 - val_accuracy: 0.9265 - val_loss: 0.1735 - mcc: 0.8525\n",
      "Epoch 19/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9282 - loss: 0.1691\n",
      "Epoch 19 - MCC: 0.8546\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9282 - loss: 0.1691 - val_accuracy: 0.9274 - val_loss: 0.1709 - mcc: 0.8546\n",
      "Epoch 20/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9264 - loss: 0.1732\n",
      "Epoch 20 - MCC: 0.8560\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.9264 - loss: 0.1731 - val_accuracy: 0.9282 - val_loss: 0.1695 - mcc: 0.8560\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.928152),\n",
      "              'mean': np.float64(0.9268266666666666),\n",
      "              'min': np.float64(0.9247786666666666),\n",
      "              'std': np.float64(0.0011139621377966346)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.0009427150090535482),\n",
      "                               'mean': np.float64(0.0005466375350952149),\n",
      "                               'min': np.float64(0.0004172108968098958),\n",
      "                               'std': np.float64(0.00019927156400148643)},\n",
      " 'MCC': {'max': np.float64(0.8559901807150953),\n",
      "         'mean': np.float64(0.8536286650120847),\n",
      "         'min': np.float64(0.850140713952755),\n",
      "         'std': np.float64(0.0019802607156525365)},\n",
      " 'Parameters': 4513,\n",
      " 'Train Time (s)': {'max': np.float64(93.716481924057),\n",
      "                    'mean': np.float64(90.31224608421326),\n",
      "                    'min': np.float64(86.67320966720581),\n",
      "                    'std': np.float64(2.4687096404726967)},\n",
      " 'Training Accuracy': [[0.8245486617088318,\n",
      "                        0.9016160368919373,\n",
      "                        0.9067801237106323,\n",
      "                        0.9092617034912109,\n",
      "                        0.9121193289756775,\n",
      "                        0.9136688709259033,\n",
      "                        0.9153318405151367,\n",
      "                        0.9173172116279602,\n",
      "                        0.9184916019439697,\n",
      "                        0.9203462600708008,\n",
      "                        0.9206655025482178,\n",
      "                        0.9213526844978333,\n",
      "                        0.9226165413856506,\n",
      "                        0.9230600595474243,\n",
      "                        0.9240434765815735,\n",
      "                        0.9250486493110657,\n",
      "                        0.9255184531211853,\n",
      "                        0.9259533882141113,\n",
      "                        0.926215648651123,\n",
      "                        0.9264492392539978],\n",
      "                       [0.8208193182945251,\n",
      "                        0.8974325060844421,\n",
      "                        0.903921902179718,\n",
      "                        0.9079714417457581,\n",
      "                        0.9109849333763123,\n",
      "                        0.9130511283874512,\n",
      "                        0.9151453375816345,\n",
      "                        0.916854739189148,\n",
      "                        0.9175965785980225,\n",
      "                        0.919826328754425,\n",
      "                        0.9205374121665955,\n",
      "                        0.9214265942573547,\n",
      "                        0.9233414530754089,\n",
      "                        0.924247145652771,\n",
      "                        0.9243385195732117,\n",
      "                        0.925398588180542,\n",
      "                        0.9248149394989014,\n",
      "                        0.925374448299408,\n",
      "                        0.9268035292625427,\n",
      "                        0.926243245601654],\n",
      "                       [0.8307083249092102,\n",
      "                        0.9008767008781433,\n",
      "                        0.9057427644729614,\n",
      "                        0.909212589263916,\n",
      "                        0.9110538959503174,\n",
      "                        0.9124249815940857,\n",
      "                        0.9143605828285217,\n",
      "                        0.9164985418319702,\n",
      "                        0.9177088141441345,\n",
      "                        0.919734537601471,\n",
      "                        0.9204954504966736,\n",
      "                        0.9218553304672241,\n",
      "                        0.9230272769927979,\n",
      "                        0.9234837889671326,\n",
      "                        0.9238871335983276,\n",
      "                        0.9252633452415466,\n",
      "                        0.9259000420570374,\n",
      "                        0.9262357354164124,\n",
      "                        0.9267745018005371,\n",
      "                        0.9272333383560181],\n",
      "                       [0.8218090534210205,\n",
      "                        0.8959493637084961,\n",
      "                        0.9014492034912109,\n",
      "                        0.9039666056632996,\n",
      "                        0.906607985496521,\n",
      "                        0.9100486636161804,\n",
      "                        0.9118665456771851,\n",
      "                        0.9132859706878662,\n",
      "                        0.9148202538490295,\n",
      "                        0.9173000454902649,\n",
      "                        0.9184940457344055,\n",
      "                        0.9208688139915466,\n",
      "                        0.9218591451644897,\n",
      "                        0.9234212040901184,\n",
      "                        0.9240802526473999,\n",
      "                        0.9243201613426208,\n",
      "                        0.9246799349784851,\n",
      "                        0.9254682660102844,\n",
      "                        0.9263226985931396,\n",
      "                        0.9248816967010498],\n",
      "                       [0.8188855051994324,\n",
      "                        0.8975711464881897,\n",
      "                        0.903858482837677,\n",
      "                        0.9073050022125244,\n",
      "                        0.9104013442993164,\n",
      "                        0.9140834808349609,\n",
      "                        0.9158635139465332,\n",
      "                        0.9175341725349426,\n",
      "                        0.9204353094100952,\n",
      "                        0.9211674928665161,\n",
      "                        0.9226282835006714,\n",
      "                        0.9229480624198914,\n",
      "                        0.9245944619178772,\n",
      "                        0.924298107624054,\n",
      "                        0.9254530668258667,\n",
      "                        0.9260801672935486,\n",
      "                        0.9267426133155823,\n",
      "                        0.9275347590446472,\n",
      "                        0.9276435375213623,\n",
      "                        0.9280902743339539]],\n",
      " 'Training Loss': [[0.37218692898750305,\n",
      "                    0.23248904943466187,\n",
      "                    0.21786309778690338,\n",
      "                    0.21167276799678802,\n",
      "                    0.20553119480609894,\n",
      "                    0.20172569155693054,\n",
      "                    0.19847749173641205,\n",
      "                    0.19350840151309967,\n",
      "                    0.1905543953180313,\n",
      "                    0.18685992062091827,\n",
      "                    0.18632987141609192,\n",
      "                    0.18436363339424133,\n",
      "                    0.18233241140842438,\n",
      "                    0.18088649213314056,\n",
      "                    0.17882609367370605,\n",
      "                    0.17716896533966064,\n",
      "                    0.17547330260276794,\n",
      "                    0.17440861463546753,\n",
      "                    0.17389094829559326,\n",
      "                    0.172926127910614],\n",
      "                   [0.38855767250061035,\n",
      "                    0.24234417080879211,\n",
      "                    0.22451643645763397,\n",
      "                    0.2143310010433197,\n",
      "                    0.20674572885036469,\n",
      "                    0.20191548764705658,\n",
      "                    0.19730332493782043,\n",
      "                    0.19359855353832245,\n",
      "                    0.19174449145793915,\n",
      "                    0.1874372363090515,\n",
      "                    0.18576012551784515,\n",
      "                    0.18440084159374237,\n",
      "                    0.1808556467294693,\n",
      "                    0.17911534011363983,\n",
      "                    0.1785746067762375,\n",
      "                    0.17604434490203857,\n",
      "                    0.1769631952047348,\n",
      "                    0.1758449226617813,\n",
      "                    0.17324033379554749,\n",
      "                    0.17435120046138763],\n",
      "                   [0.36972326040267944,\n",
      "                    0.23537901043891907,\n",
      "                    0.222060889005661,\n",
      "                    0.21349500119686127,\n",
      "                    0.2090635746717453,\n",
      "                    0.205531045794487,\n",
      "                    0.20105373859405518,\n",
      "                    0.19597290456295013,\n",
      "                    0.19390347599983215,\n",
      "                    0.1891447901725769,\n",
      "                    0.1868315190076828,\n",
      "                    0.1844189614057541,\n",
      "                    0.18135479092597961,\n",
      "                    0.1804763525724411,\n",
      "                    0.17873115837574005,\n",
      "                    0.17582643032073975,\n",
      "                    0.17496873438358307,\n",
      "                    0.17352256178855896,\n",
      "                    0.1718180775642395,\n",
      "                    0.17111702263355255],\n",
      "                   [0.3738069534301758,\n",
      "                    0.2440348118543625,\n",
      "                    0.2289297729730606,\n",
      "                    0.22296181321144104,\n",
      "                    0.2175656110048294,\n",
      "                    0.21051844954490662,\n",
      "                    0.20631875097751617,\n",
      "                    0.20337706804275513,\n",
      "                    0.20011095702648163,\n",
      "                    0.1940310001373291,\n",
      "                    0.19117684662342072,\n",
      "                    0.18614153563976288,\n",
      "                    0.18473781645298004,\n",
      "                    0.1810082197189331,\n",
      "                    0.18026214838027954,\n",
      "                    0.17899316549301147,\n",
      "                    0.1782163679599762,\n",
      "                    0.1757836639881134,\n",
      "                    0.1739644706249237,\n",
      "                    0.17700724303722382],\n",
      "                   [0.3999005854129791,\n",
      "                    0.24265919625759125,\n",
      "                    0.226368248462677,\n",
      "                    0.21715566515922546,\n",
      "                    0.210317462682724,\n",
      "                    0.20212695002555847,\n",
      "                    0.19808408617973328,\n",
      "                    0.19436979293823242,\n",
      "                    0.18830043077468872,\n",
      "                    0.18618299067020416,\n",
      "                    0.18340325355529785,\n",
      "                    0.18245625495910645,\n",
      "                    0.1794198453426361,\n",
      "                    0.17868982255458832,\n",
      "                    0.17668268084526062,\n",
      "                    0.17532166838645935,\n",
      "                    0.1741517335176468,\n",
      "                    0.17213663458824158,\n",
      "                    0.17147815227508545,\n",
      "                    0.17027486860752106]],\n",
      " 'Validation Accuracy': [[0.8924319744110107,\n",
      "                          0.9063573479652405,\n",
      "                          0.9067680835723877,\n",
      "                          0.9130427241325378,\n",
      "                          0.9140000939369202,\n",
      "                          0.916703999042511,\n",
      "                          0.9146319031715393,\n",
      "                          0.9170639514923096,\n",
      "                          0.9216052293777466,\n",
      "                          0.9222106337547302,\n",
      "                          0.9231653809547424,\n",
      "                          0.9237707257270813,\n",
      "                          0.9244958758354187,\n",
      "                          0.9244879484176636,\n",
      "                          0.919498860836029,\n",
      "                          0.9238960146903992,\n",
      "                          0.9259786009788513,\n",
      "                          0.928010880947113,\n",
      "                          0.9284854531288147,\n",
      "                          0.9272932410240173],\n",
      "                         [0.8890719413757324,\n",
      "                          0.8987866044044495,\n",
      "                          0.9033201336860657,\n",
      "                          0.9113867282867432,\n",
      "                          0.911933422088623,\n",
      "                          0.915208101272583,\n",
      "                          0.9149145483970642,\n",
      "                          0.9098531603813171,\n",
      "                          0.9198238849639893,\n",
      "                          0.9209092855453491,\n",
      "                          0.922999918460846,\n",
      "                          0.9231733679771423,\n",
      "                          0.9216188192367554,\n",
      "                          0.9247547388076782,\n",
      "                          0.9253894090652466,\n",
      "                          0.925922691822052,\n",
      "                          0.9256905913352966,\n",
      "                          0.9249413013458252,\n",
      "                          0.9271572232246399,\n",
      "                          0.9269145727157593],\n",
      "                         [0.8956027626991272,\n",
      "                          0.9008080363273621,\n",
      "                          0.9086239337921143,\n",
      "                          0.9081574082374573,\n",
      "                          0.9088881015777588,\n",
      "                          0.9141627550125122,\n",
      "                          0.9140613079071045,\n",
      "                          0.9154799580574036,\n",
      "                          0.9163945317268372,\n",
      "                          0.917330801486969,\n",
      "                          0.918525218963623,\n",
      "                          0.9207199811935425,\n",
      "                          0.9229573607444763,\n",
      "                          0.9230266809463501,\n",
      "                          0.9245467185974121,\n",
      "                          0.9250240921974182,\n",
      "                          0.923957347869873,\n",
      "                          0.9265626072883606,\n",
      "                          0.926090657711029,\n",
      "                          0.9247786998748779],\n",
      "                         [0.8971198797225952,\n",
      "                          0.9018985033035278,\n",
      "                          0.9047626256942749,\n",
      "                          0.9062479138374329,\n",
      "                          0.9101679921150208,\n",
      "                          0.9121199250221252,\n",
      "                          0.9089118838310242,\n",
      "                          0.9167625904083252,\n",
      "                          0.9178320169448853,\n",
      "                          0.9202159643173218,\n",
      "                          0.9208346605300903,\n",
      "                          0.9235013723373413,\n",
      "                          0.9238693118095398,\n",
      "                          0.92495197057724,\n",
      "                          0.9245814085006714,\n",
      "                          0.9271198511123657,\n",
      "                          0.9264186024665833,\n",
      "                          0.9269545674324036,\n",
      "                          0.9284372329711914,\n",
      "                          0.926994800567627],\n",
      "                         [0.8924772143363953,\n",
      "                          0.9040800929069519,\n",
      "                          0.9055999517440796,\n",
      "                          0.9108051657676697,\n",
      "                          0.9107227325439453,\n",
      "                          0.9121361374855042,\n",
      "                          0.9167600274085999,\n",
      "                          0.9182718396186829,\n",
      "                          0.9212506413459778,\n",
      "                          0.9127520322799683,\n",
      "                          0.9224292635917664,\n",
      "                          0.924648106098175,\n",
      "                          0.9214800596237183,\n",
      "                          0.9251920580863953,\n",
      "                          0.9249250292778015,\n",
      "                          0.9230080842971802,\n",
      "                          0.924613356590271,\n",
      "                          0.9265197515487671,\n",
      "                          0.9273840188980103,\n",
      "                          0.9281520247459412]],\n",
      " 'Validation Loss': [0.25674524903297424,\n",
      "                     0.2260611206293106,\n",
      "                     0.2175878882408142,\n",
      "                     0.2102002203464508,\n",
      "                     0.20646360516548157,\n",
      "                     0.20442010462284088,\n",
      "                     0.194174662232399,\n",
      "                     0.19168128073215485,\n",
      "                     0.18558941781520844,\n",
      "                     0.20399145781993866,\n",
      "                     0.1832975596189499,\n",
      "                     0.17798185348510742,\n",
      "                     0.18303218483924866,\n",
      "                     0.177995964884758,\n",
      "                     0.17698873579502106,\n",
      "                     0.18249037861824036,\n",
      "                     0.17829501628875732,\n",
      "                     0.17352299392223358,\n",
      "                     0.17091859877109528,\n",
      "                     0.1694934368133545],\n",
      " 'Validation MCC': [[np.float64(0.7848430306747365),\n",
      "                     np.float64(0.8127917219393517),\n",
      "                     np.float64(0.813521159155927),\n",
      "                     np.float64(0.8255926513416306),\n",
      "                     np.float64(0.8276679797338129),\n",
      "                     np.float64(0.8329466538430568),\n",
      "                     np.float64(0.8309080848810532),\n",
      "                     np.float64(0.8337485618500935),\n",
      "                     np.float64(0.8427756282885711),\n",
      "                     np.float64(0.8440296859822684),\n",
      "                     np.float64(0.846052323144061),\n",
      "                     np.float64(0.8471189213587509),\n",
      "                     np.float64(0.8488954396347739),\n",
      "                     np.float64(0.84899228426005),\n",
      "                     np.float64(0.8404796418644523),\n",
      "                     np.float64(0.8474312528678377),\n",
      "                     np.float64(0.8516299811814787),\n",
      "                     np.float64(0.8557528487695577),\n",
      "                     np.float64(0.856935191613247),\n",
      "                     np.float64(0.8549827747861831)],\n",
      "                    [np.float64(0.7779266703017091),\n",
      "                     np.float64(0.7972448937093969),\n",
      "                     np.float64(0.806342608616694),\n",
      "                     np.float64(0.8222356586574042),\n",
      "                     np.float64(0.8233378555369273),\n",
      "                     np.float64(0.8299071681056444),\n",
      "                     np.float64(0.8307555392785824),\n",
      "                     np.float64(0.8212837222658751),\n",
      "                     np.float64(0.8391663314142974),\n",
      "                     np.float64(0.8417709043518505),\n",
      "                     np.float64(0.8459770903365718),\n",
      "                     np.float64(0.8458918067989799),\n",
      "                     np.float64(0.842956081595615),\n",
      "                     np.float64(0.8490632016935715),\n",
      "                     np.float64(0.8503755674234701),\n",
      "                     np.float64(0.8514098418406201),\n",
      "                     np.float64(0.8509987810701647),\n",
      "                     np.float64(0.8495390058637482),\n",
      "                     np.float64(0.8538999296089476),\n",
      "                     np.float64(0.8534644670974082)],\n",
      "                    [np.float64(0.7904837904285438),\n",
      "                     np.float64(0.8012972879927457),\n",
      "                     np.float64(0.8166057413650276),\n",
      "                     np.float64(0.816011124491124),\n",
      "                     np.float64(0.8171748300349407),\n",
      "                     np.float64(0.8278362676610791),\n",
      "                     np.float64(0.828245724679676),\n",
      "                     np.float64(0.8303846736066506),\n",
      "                     np.float64(0.8321767715049271),\n",
      "                     np.float64(0.8351573168888902),\n",
      "                     np.float64(0.8373314516296624),\n",
      "                     np.float64(0.840977835419985),\n",
      "                     np.float64(0.8453570865571892),\n",
      "                     np.float64(0.8456282336712931),\n",
      "                     np.float64(0.8486069093498739),\n",
      "                     np.float64(0.849612673729658),\n",
      "                     np.float64(0.8480826833379517),\n",
      "                     np.float64(0.852651881691453),\n",
      "                     np.float64(0.851656080866425),\n",
      "                     np.float64(0.850140713952755)],\n",
      "                    [np.float64(0.7936447914931586),\n",
      "                     np.float64(0.8033689806452875),\n",
      "                     np.float64(0.8092896343415711),\n",
      "                     np.float64(0.8129674787369655),\n",
      "                     np.float64(0.8199837224569788),\n",
      "                     np.float64(0.8238882432307368),\n",
      "                     np.float64(0.8192555428508909),\n",
      "                     np.float64(0.8330345492926686),\n",
      "                     np.float64(0.8351840200589814),\n",
      "                     np.float64(0.8401343547879245),\n",
      "                     np.float64(0.8416376195603703),\n",
      "                     np.float64(0.8465562776337371),\n",
      "                     np.float64(0.8475423278741567),\n",
      "                     np.float64(0.8494803670917243),\n",
      "                     np.float64(0.8487822136328083),\n",
      "                     np.float64(0.854025429425731),\n",
      "                     np.float64(0.8528912022427072),\n",
      "                     np.float64(0.8538742738704037),\n",
      "                     np.float64(0.8565788642669745),\n",
      "                     np.float64(0.853565188508982)],\n",
      "                    [np.float64(0.7841792542951946),\n",
      "                     np.float64(0.8079358843958783),\n",
      "                     np.float64(0.8105165362128874),\n",
      "                     np.float64(0.8210716935850233),\n",
      "                     np.float64(0.8208529264182306),\n",
      "                     np.float64(0.8243766462522113),\n",
      "                     np.float64(0.8329984237377389),\n",
      "                     np.float64(0.8359718420313214),\n",
      "                     np.float64(0.8423640017464449),\n",
      "                     np.float64(0.8258343286856634),\n",
      "                     np.float64(0.8445545478410926),\n",
      "                     np.float64(0.8487633978466655),\n",
      "                     np.float64(0.8424031890010297),\n",
      "                     np.float64(0.8499120169077956),\n",
      "                     np.float64(0.8493324592075034),\n",
      "                     np.float64(0.8463624006116586),\n",
      "                     np.float64(0.8494370740880087),\n",
      "                     np.float64(0.8525248559728618),\n",
      "                     np.float64(0.8545873875752438),\n",
      "                     np.float64(0.8559901807150953)]]}\n",
      "Training Model: BiLSTM, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.7293 - loss: 0.5240\n",
      "Epoch 1 - MCC: 0.7968\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 37ms/step - accuracy: 0.7298 - loss: 0.5232 - val_accuracy: 0.8986 - val_loss: 0.2453 - mcc: 0.7968\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.9013 - loss: 0.2342\n",
      "Epoch 2 - MCC: 0.8181\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.9013 - loss: 0.2341 - val_accuracy: 0.9092 - val_loss: 0.2140 - mcc: 0.8181\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9092 - loss: 0.2129\n",
      "Epoch 3 - MCC: 0.8313\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 39ms/step - accuracy: 0.9092 - loss: 0.2128 - val_accuracy: 0.9159 - val_loss: 0.1968 - mcc: 0.8313\n",
      "Epoch 4/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9151 - loss: 0.1998\n",
      "Epoch 4 - MCC: 0.8353\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 32ms/step - accuracy: 0.9151 - loss: 0.1998 - val_accuracy: 0.9179 - val_loss: 0.1937 - mcc: 0.8353\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9197 - loss: 0.1888\n",
      "Epoch 5 - MCC: 0.8442\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9197 - loss: 0.1888 - val_accuracy: 0.9222 - val_loss: 0.1812 - mcc: 0.8442\n",
      "Epoch 6/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9239 - loss: 0.1801\n",
      "Epoch 6 - MCC: 0.8441\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9239 - loss: 0.1801 - val_accuracy: 0.9221 - val_loss: 0.1806 - mcc: 0.8441\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9251 - loss: 0.1759\n",
      "Epoch 7 - MCC: 0.8556\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.9251 - loss: 0.1759 - val_accuracy: 0.9279 - val_loss: 0.1706 - mcc: 0.8556\n",
      "Epoch 8/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9269 - loss: 0.1729\n",
      "Epoch 8 - MCC: 0.8583\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 33ms/step - accuracy: 0.9269 - loss: 0.1729 - val_accuracy: 0.9293 - val_loss: 0.1659 - mcc: 0.8583\n",
      "Epoch 9/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9285 - loss: 0.1682\n",
      "Epoch 9 - MCC: 0.8580\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 38ms/step - accuracy: 0.9285 - loss: 0.1682 - val_accuracy: 0.9291 - val_loss: 0.1680 - mcc: 0.8580\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9325 - loss: 0.1601\n",
      "Epoch 10 - MCC: 0.8642\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9325 - loss: 0.1601 - val_accuracy: 0.9321 - val_loss: 0.1629 - mcc: 0.8642\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9332 - loss: 0.1588\n",
      "Epoch 11 - MCC: 0.8634\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 37ms/step - accuracy: 0.9332 - loss: 0.1588 - val_accuracy: 0.9319 - val_loss: 0.1602 - mcc: 0.8634\n",
      "Epoch 12/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9352 - loss: 0.1543\n",
      "Epoch 12 - MCC: 0.8681\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9352 - loss: 0.1543 - val_accuracy: 0.9340 - val_loss: 0.1595 - mcc: 0.8681\n",
      "Epoch 13/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9352 - loss: 0.1543\n",
      "Epoch 13 - MCC: 0.8748\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9352 - loss: 0.1543 - val_accuracy: 0.9374 - val_loss: 0.1513 - mcc: 0.8748\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9378 - loss: 0.1483\n",
      "Epoch 14 - MCC: 0.8770\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9378 - loss: 0.1483 - val_accuracy: 0.9386 - val_loss: 0.1475 - mcc: 0.8770\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9389 - loss: 0.1449\n",
      "Epoch 15 - MCC: 0.8790\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9389 - loss: 0.1449 - val_accuracy: 0.9397 - val_loss: 0.1460 - mcc: 0.8790\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9393 - loss: 0.1452\n",
      "Epoch 16 - MCC: 0.8817\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9393 - loss: 0.1452 - val_accuracy: 0.9410 - val_loss: 0.1432 - mcc: 0.8817\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9412 - loss: 0.1417\n",
      "Epoch 17 - MCC: 0.8808\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9412 - loss: 0.1417 - val_accuracy: 0.9404 - val_loss: 0.1452 - mcc: 0.8808\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9417 - loss: 0.1402\n",
      "Epoch 18 - MCC: 0.8843\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9417 - loss: 0.1402 - val_accuracy: 0.9422 - val_loss: 0.1416 - mcc: 0.8843\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9427 - loss: 0.1372\n",
      "Epoch 19 - MCC: 0.8863\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9427 - loss: 0.1372 - val_accuracy: 0.9432 - val_loss: 0.1387 - mcc: 0.8863\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9407 - loss: 0.1425\n",
      "Epoch 20 - MCC: 0.8878\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 39ms/step - accuracy: 0.9407 - loss: 0.1425 - val_accuracy: 0.9441 - val_loss: 0.1361 - mcc: 0.8878\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.7350 - loss: 0.4967\n",
      "Epoch 1 - MCC: 0.7871\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 45ms/step - accuracy: 0.7360 - loss: 0.4953 - val_accuracy: 0.8920 - val_loss: 0.2540 - mcc: 0.7871\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9007 - loss: 0.2366\n",
      "Epoch 2 - MCC: 0.8169\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9008 - loss: 0.2365 - val_accuracy: 0.9085 - val_loss: 0.2134 - mcc: 0.8169\n",
      "Epoch 3/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9092 - loss: 0.2128\n",
      "Epoch 3 - MCC: 0.8326\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9092 - loss: 0.2128 - val_accuracy: 0.9165 - val_loss: 0.1946 - mcc: 0.8326\n",
      "Epoch 4/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9161 - loss: 0.1974\n",
      "Epoch 4 - MCC: 0.8440\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 38ms/step - accuracy: 0.9161 - loss: 0.1973 - val_accuracy: 0.9222 - val_loss: 0.1823 - mcc: 0.8440\n",
      "Epoch 5/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9204 - loss: 0.1889\n",
      "Epoch 5 - MCC: 0.8506\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 32ms/step - accuracy: 0.9204 - loss: 0.1889 - val_accuracy: 0.9253 - val_loss: 0.1760 - mcc: 0.8506\n",
      "Epoch 6/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9260 - loss: 0.1771\n",
      "Epoch 6 - MCC: 0.8589\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9260 - loss: 0.1771 - val_accuracy: 0.9296 - val_loss: 0.1668 - mcc: 0.8589\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9301 - loss: 0.1666\n",
      "Epoch 7 - MCC: 0.8608\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9301 - loss: 0.1666 - val_accuracy: 0.9306 - val_loss: 0.1657 - mcc: 0.8608\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9305 - loss: 0.1662\n",
      "Epoch 8 - MCC: 0.8692\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9305 - loss: 0.1662 - val_accuracy: 0.9348 - val_loss: 0.1566 - mcc: 0.8692\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9343 - loss: 0.1573\n",
      "Epoch 9 - MCC: 0.8707\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9343 - loss: 0.1574 - val_accuracy: 0.9354 - val_loss: 0.1547 - mcc: 0.8707\n",
      "Epoch 10/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9337 - loss: 0.1574\n",
      "Epoch 10 - MCC: 0.8730\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 32ms/step - accuracy: 0.9337 - loss: 0.1574 - val_accuracy: 0.9365 - val_loss: 0.1525 - mcc: 0.8730\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9357 - loss: 0.1541\n",
      "Epoch 11 - MCC: 0.8760\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9357 - loss: 0.1541 - val_accuracy: 0.9382 - val_loss: 0.1476 - mcc: 0.8760\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9380 - loss: 0.1485\n",
      "Epoch 12 - MCC: 0.8789\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9380 - loss: 0.1485 - val_accuracy: 0.9396 - val_loss: 0.1459 - mcc: 0.8789\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9373 - loss: 0.1501\n",
      "Epoch 13 - MCC: 0.8816\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 37ms/step - accuracy: 0.9373 - loss: 0.1501 - val_accuracy: 0.9410 - val_loss: 0.1428 - mcc: 0.8816\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9394 - loss: 0.1457\n",
      "Epoch 14 - MCC: 0.8817\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 33ms/step - accuracy: 0.9394 - loss: 0.1457 - val_accuracy: 0.9409 - val_loss: 0.1420 - mcc: 0.8817\n",
      "Epoch 15/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9393 - loss: 0.1455\n",
      "Epoch 15 - MCC: 0.8821\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 38ms/step - accuracy: 0.9393 - loss: 0.1455 - val_accuracy: 0.9412 - val_loss: 0.1423 - mcc: 0.8821\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.9399 - loss: 0.1446\n",
      "Epoch 16 - MCC: 0.8836\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 39ms/step - accuracy: 0.9399 - loss: 0.1446 - val_accuracy: 0.9419 - val_loss: 0.1411 - mcc: 0.8836\n",
      "Epoch 17/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9393 - loss: 0.1463\n",
      "Epoch 17 - MCC: 0.8833\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 32ms/step - accuracy: 0.9393 - loss: 0.1462 - val_accuracy: 0.9417 - val_loss: 0.1413 - mcc: 0.8833\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9388 - loss: 0.1470\n",
      "Epoch 18 - MCC: 0.8854\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9389 - loss: 0.1470 - val_accuracy: 0.9428 - val_loss: 0.1388 - mcc: 0.8854\n",
      "Epoch 19/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9426 - loss: 0.1394\n",
      "Epoch 19 - MCC: 0.8876\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9426 - loss: 0.1394 - val_accuracy: 0.9440 - val_loss: 0.1359 - mcc: 0.8876\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9446 - loss: 0.1343\n",
      "Epoch 20 - MCC: 0.8895\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9446 - loss: 0.1343 - val_accuracy: 0.9449 - val_loss: 0.1344 - mcc: 0.8895\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7373 - loss: 0.5194\n",
      "Epoch 1 - MCC: 0.7909\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 40ms/step - accuracy: 0.7383 - loss: 0.5179 - val_accuracy: 0.8959 - val_loss: 0.2470 - mcc: 0.7909\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9029 - loss: 0.2306\n",
      "Epoch 2 - MCC: 0.8179\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 33ms/step - accuracy: 0.9029 - loss: 0.2305 - val_accuracy: 0.9093 - val_loss: 0.2148 - mcc: 0.8179\n",
      "Epoch 3/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9143 - loss: 0.2024\n",
      "Epoch 3 - MCC: 0.8361\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9143 - loss: 0.2024 - val_accuracy: 0.9183 - val_loss: 0.1949 - mcc: 0.8361\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9195 - loss: 0.1897\n",
      "Epoch 4 - MCC: 0.8441\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9195 - loss: 0.1897 - val_accuracy: 0.9223 - val_loss: 0.1836 - mcc: 0.8441\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9255 - loss: 0.1748\n",
      "Epoch 5 - MCC: 0.8403\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 39ms/step - accuracy: 0.9255 - loss: 0.1748 - val_accuracy: 0.9204 - val_loss: 0.1844 - mcc: 0.8403\n",
      "Epoch 6/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9296 - loss: 0.1668\n",
      "Epoch 6 - MCC: 0.8572\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 34ms/step - accuracy: 0.9296 - loss: 0.1668 - val_accuracy: 0.9288 - val_loss: 0.1696 - mcc: 0.8572\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9335 - loss: 0.1593\n",
      "Epoch 7 - MCC: 0.8631\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 38ms/step - accuracy: 0.9335 - loss: 0.1593 - val_accuracy: 0.9316 - val_loss: 0.1655 - mcc: 0.8631\n",
      "Epoch 8/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9344 - loss: 0.1563\n",
      "Epoch 8 - MCC: 0.8665\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9344 - loss: 0.1563 - val_accuracy: 0.9335 - val_loss: 0.1603 - mcc: 0.8665\n",
      "Epoch 9/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9352 - loss: 0.1543\n",
      "Epoch 9 - MCC: 0.8681\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9353 - loss: 0.1543 - val_accuracy: 0.9339 - val_loss: 0.1589 - mcc: 0.8681\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9353 - loss: 0.1546\n",
      "Epoch 10 - MCC: 0.8708\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 38ms/step - accuracy: 0.9353 - loss: 0.1546 - val_accuracy: 0.9356 - val_loss: 0.1559 - mcc: 0.8708\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9386 - loss: 0.1478\n",
      "Epoch 11 - MCC: 0.8732\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 34ms/step - accuracy: 0.9386 - loss: 0.1478 - val_accuracy: 0.9368 - val_loss: 0.1535 - mcc: 0.8732\n",
      "Epoch 12/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9404 - loss: 0.1441\n",
      "Epoch 12 - MCC: 0.8759\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 37ms/step - accuracy: 0.9404 - loss: 0.1441 - val_accuracy: 0.9382 - val_loss: 0.1487 - mcc: 0.8759\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9397 - loss: 0.1436\n",
      "Epoch 13 - MCC: 0.8777\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.9397 - loss: 0.1436 - val_accuracy: 0.9390 - val_loss: 0.1485 - mcc: 0.8777\n",
      "Epoch 14/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9434 - loss: 0.1366\n",
      "Epoch 14 - MCC: 0.8816\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 32ms/step - accuracy: 0.9434 - loss: 0.1367 - val_accuracy: 0.9410 - val_loss: 0.1439 - mcc: 0.8816\n",
      "Epoch 15/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9428 - loss: 0.1379\n",
      "Epoch 15 - MCC: 0.8804\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9428 - loss: 0.1380 - val_accuracy: 0.9404 - val_loss: 0.1447 - mcc: 0.8804\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9429 - loss: 0.1380\n",
      "Epoch 16 - MCC: 0.8819\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9429 - loss: 0.1380 - val_accuracy: 0.9411 - val_loss: 0.1429 - mcc: 0.8819\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9442 - loss: 0.1357\n",
      "Epoch 17 - MCC: 0.8838\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9442 - loss: 0.1357 - val_accuracy: 0.9421 - val_loss: 0.1417 - mcc: 0.8838\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9450 - loss: 0.1334\n",
      "Epoch 18 - MCC: 0.8780\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 33ms/step - accuracy: 0.9450 - loss: 0.1335 - val_accuracy: 0.9389 - val_loss: 0.1492 - mcc: 0.8780\n",
      "Epoch 19/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9460 - loss: 0.1326\n",
      "Epoch 19 - MCC: 0.8862\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 37ms/step - accuracy: 0.9460 - loss: 0.1327 - val_accuracy: 0.9432 - val_loss: 0.1404 - mcc: 0.8862\n",
      "Epoch 20/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9450 - loss: 0.1338\n",
      "Epoch 20 - MCC: 0.8835\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 40ms/step - accuracy: 0.9450 - loss: 0.1338 - val_accuracy: 0.9420 - val_loss: 0.1418 - mcc: 0.8835\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7299 - loss: 0.4846\n",
      "Epoch 1 - MCC: 0.8057\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 36ms/step - accuracy: 0.7305 - loss: 0.4840 - val_accuracy: 0.9031 - val_loss: 0.2289 - mcc: 0.8057\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9053 - loss: 0.2242\n",
      "Epoch 2 - MCC: 0.8259\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9053 - loss: 0.2241 - val_accuracy: 0.9131 - val_loss: 0.2032 - mcc: 0.8259\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9127 - loss: 0.2041\n",
      "Epoch 3 - MCC: 0.8408\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9127 - loss: 0.2040 - val_accuracy: 0.9205 - val_loss: 0.1883 - mcc: 0.8408\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9196 - loss: 0.1887\n",
      "Epoch 4 - MCC: 0.8508\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9196 - loss: 0.1887 - val_accuracy: 0.9251 - val_loss: 0.1805 - mcc: 0.8508\n",
      "Epoch 5/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9244 - loss: 0.1789\n",
      "Epoch 5 - MCC: 0.8575\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9244 - loss: 0.1788 - val_accuracy: 0.9288 - val_loss: 0.1690 - mcc: 0.8575\n",
      "Epoch 6/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9286 - loss: 0.1701\n",
      "Epoch 6 - MCC: 0.8512\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9286 - loss: 0.1701 - val_accuracy: 0.9250 - val_loss: 0.1765 - mcc: 0.8512\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9304 - loss: 0.1646\n",
      "Epoch 7 - MCC: 0.8648\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9304 - loss: 0.1646 - val_accuracy: 0.9326 - val_loss: 0.1591 - mcc: 0.8648\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9329 - loss: 0.1600\n",
      "Epoch 8 - MCC: 0.8704\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9329 - loss: 0.1600 - val_accuracy: 0.9352 - val_loss: 0.1539 - mcc: 0.8704\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9346 - loss: 0.1562\n",
      "Epoch 9 - MCC: 0.8716\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 32ms/step - accuracy: 0.9346 - loss: 0.1562 - val_accuracy: 0.9360 - val_loss: 0.1521 - mcc: 0.8716\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9358 - loss: 0.1535\n",
      "Epoch 10 - MCC: 0.8751\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9359 - loss: 0.1535 - val_accuracy: 0.9377 - val_loss: 0.1460 - mcc: 0.8751\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9393 - loss: 0.1454\n",
      "Epoch 11 - MCC: 0.8779\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9393 - loss: 0.1455 - val_accuracy: 0.9391 - val_loss: 0.1446 - mcc: 0.8779\n",
      "Epoch 12/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9376 - loss: 0.1493\n",
      "Epoch 12 - MCC: 0.8797\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 38ms/step - accuracy: 0.9376 - loss: 0.1493 - val_accuracy: 0.9400 - val_loss: 0.1438 - mcc: 0.8797\n",
      "Epoch 13/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9389 - loss: 0.1462\n",
      "Epoch 13 - MCC: 0.8807\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 33ms/step - accuracy: 0.9389 - loss: 0.1462 - val_accuracy: 0.9405 - val_loss: 0.1418 - mcc: 0.8807\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9411 - loss: 0.1429\n",
      "Epoch 14 - MCC: 0.8779\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9410 - loss: 0.1429 - val_accuracy: 0.9387 - val_loss: 0.1477 - mcc: 0.8779\n",
      "Epoch 15/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9399 - loss: 0.1439\n",
      "Epoch 15 - MCC: 0.8835\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9399 - loss: 0.1439 - val_accuracy: 0.9418 - val_loss: 0.1396 - mcc: 0.8835\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9415 - loss: 0.1408\n",
      "Epoch 16 - MCC: 0.8854\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9415 - loss: 0.1408 - val_accuracy: 0.9429 - val_loss: 0.1373 - mcc: 0.8854\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9432 - loss: 0.1376\n",
      "Epoch 17 - MCC: 0.8850\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9432 - loss: 0.1376 - val_accuracy: 0.9426 - val_loss: 0.1400 - mcc: 0.8850\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9413 - loss: 0.1418\n",
      "Epoch 18 - MCC: 0.8872\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9414 - loss: 0.1418 - val_accuracy: 0.9438 - val_loss: 0.1352 - mcc: 0.8872\n",
      "Epoch 19/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9425 - loss: 0.1391\n",
      "Epoch 19 - MCC: 0.8877\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9425 - loss: 0.1391 - val_accuracy: 0.9440 - val_loss: 0.1357 - mcc: 0.8877\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9417 - loss: 0.1406\n",
      "Epoch 20 - MCC: 0.8899\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9418 - loss: 0.1406 - val_accuracy: 0.9451 - val_loss: 0.1322 - mcc: 0.8899\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7197 - loss: 0.5083\n",
      "Epoch 1 - MCC: 0.7994\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 35ms/step - accuracy: 0.7208 - loss: 0.5069 - val_accuracy: 0.8997 - val_loss: 0.2430 - mcc: 0.7994\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9024 - loss: 0.2333\n",
      "Epoch 2 - MCC: 0.8209\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9024 - loss: 0.2332 - val_accuracy: 0.9108 - val_loss: 0.2097 - mcc: 0.8209\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9132 - loss: 0.2054\n",
      "Epoch 3 - MCC: 0.8265\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 38ms/step - accuracy: 0.9132 - loss: 0.2054 - val_accuracy: 0.9128 - val_loss: 0.2009 - mcc: 0.8265\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9187 - loss: 0.1919\n",
      "Epoch 4 - MCC: 0.8403\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9187 - loss: 0.1919 - val_accuracy: 0.9204 - val_loss: 0.1878 - mcc: 0.8403\n",
      "Epoch 5/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9230 - loss: 0.1817\n",
      "Epoch 5 - MCC: 0.8398\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 36ms/step - accuracy: 0.9230 - loss: 0.1816 - val_accuracy: 0.9199 - val_loss: 0.1867 - mcc: 0.8398\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9243 - loss: 0.1785\n",
      "Epoch 6 - MCC: 0.8545\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.9243 - loss: 0.1784 - val_accuracy: 0.9274 - val_loss: 0.1702 - mcc: 0.8545\n",
      "Epoch 7/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9280 - loss: 0.1700\n",
      "Epoch 7 - MCC: 0.8572\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 33ms/step - accuracy: 0.9280 - loss: 0.1700 - val_accuracy: 0.9289 - val_loss: 0.1671 - mcc: 0.8572\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9282 - loss: 0.1696\n",
      "Epoch 8 - MCC: 0.8634\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9282 - loss: 0.1695 - val_accuracy: 0.9319 - val_loss: 0.1604 - mcc: 0.8634\n",
      "Epoch 9/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9346 - loss: 0.1554\n",
      "Epoch 9 - MCC: 0.8634\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 37ms/step - accuracy: 0.9346 - loss: 0.1554 - val_accuracy: 0.9317 - val_loss: 0.1606 - mcc: 0.8634\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9349 - loss: 0.1547\n",
      "Epoch 10 - MCC: 0.8657\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.9349 - loss: 0.1547 - val_accuracy: 0.9330 - val_loss: 0.1580 - mcc: 0.8657\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9373 - loss: 0.1497\n",
      "Epoch 11 - MCC: 0.8725\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 32ms/step - accuracy: 0.9373 - loss: 0.1497 - val_accuracy: 0.9364 - val_loss: 0.1504 - mcc: 0.8725\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9352 - loss: 0.1549\n",
      "Epoch 12 - MCC: 0.8740\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9352 - loss: 0.1549 - val_accuracy: 0.9370 - val_loss: 0.1518 - mcc: 0.8740\n",
      "Epoch 13/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9383 - loss: 0.1475\n",
      "Epoch 13 - MCC: 0.8748\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9383 - loss: 0.1475 - val_accuracy: 0.9376 - val_loss: 0.1492 - mcc: 0.8748\n",
      "Epoch 14/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9397 - loss: 0.1460\n",
      "Epoch 14 - MCC: 0.8754\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9397 - loss: 0.1460 - val_accuracy: 0.9378 - val_loss: 0.1476 - mcc: 0.8754\n",
      "Epoch 15/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9388 - loss: 0.1460\n",
      "Epoch 15 - MCC: 0.8779\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 39ms/step - accuracy: 0.9388 - loss: 0.1460 - val_accuracy: 0.9392 - val_loss: 0.1440 - mcc: 0.8779\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9402 - loss: 0.1429\n",
      "Epoch 16 - MCC: 0.8773\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9402 - loss: 0.1429 - val_accuracy: 0.9387 - val_loss: 0.1470 - mcc: 0.8773\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9400 - loss: 0.1444\n",
      "Epoch 17 - MCC: 0.8803\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9400 - loss: 0.1444 - val_accuracy: 0.9403 - val_loss: 0.1418 - mcc: 0.8803\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9416 - loss: 0.1409\n",
      "Epoch 18 - MCC: 0.8790\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9415 - loss: 0.1409 - val_accuracy: 0.9397 - val_loss: 0.1444 - mcc: 0.8790\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9436 - loss: 0.1364\n",
      "Epoch 19 - MCC: 0.8812\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 34ms/step - accuracy: 0.9436 - loss: 0.1364 - val_accuracy: 0.9407 - val_loss: 0.1421 - mcc: 0.8812\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9394 - loss: 0.1446\n",
      "Epoch 20 - MCC: 0.8815\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 34ms/step - accuracy: 0.9394 - loss: 0.1445 - val_accuracy: 0.9409 - val_loss: 0.1412 - mcc: 0.8815\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.94508),\n",
      "              'mean': np.float64(0.9433850666666667),\n",
      "              'min': np.float64(0.9409093333333334),\n",
      "              'std': np.float64(0.0016637970816445412)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.0009490137100219727),\n",
      "                               'mean': np.float64(0.0008301729838053386),\n",
      "                               'min': np.float64(0.00046033414204915365),\n",
      "                               'std': np.float64(0.00018561850973012884)},\n",
      " 'MCC': {'max': np.float64(0.8899091067886056),\n",
      "         'mean': np.float64(0.8864477727035481),\n",
      "         'min': np.float64(0.8814607777394956),\n",
      "         'std': np.float64(0.0033723333279011857)},\n",
      " 'Parameters': 4445,\n",
      " 'Train Time (s)': {'max': np.float64(173.66012334823608),\n",
      "                    'mean': np.float64(166.18287076950074),\n",
      "                    'min': np.float64(161.59533786773682),\n",
      "                    'std': np.float64(4.25644715712428)},\n",
      " 'Training Accuracy': [[0.8232740759849548,\n",
      "                        0.904183566570282,\n",
      "                        0.9115927815437317,\n",
      "                        0.9158114194869995,\n",
      "                        0.9203125834465027,\n",
      "                        0.9227693676948547,\n",
      "                        0.9251018762588501,\n",
      "                        0.9272274374961853,\n",
      "                        0.9286382794380188,\n",
      "                        0.9307014346122742,\n",
      "                        0.9325026869773865,\n",
      "                        0.9343197345733643,\n",
      "                        0.9355493783950806,\n",
      "                        0.9366504549980164,\n",
      "                        0.938063383102417,\n",
      "                        0.9396356344223022,\n",
      "                        0.9401656985282898,\n",
      "                        0.9409580230712891,\n",
      "                        0.9416621327400208,\n",
      "                        0.9420533776283264],\n",
      "                       [0.8302121758460999,\n",
      "                        0.9045186638832092,\n",
      "                        0.9119062423706055,\n",
      "                        0.9182343482971191,\n",
      "                        0.9226738810539246,\n",
      "                        0.9267823696136475,\n",
      "                        0.9298973083496094,\n",
      "                        0.9314472079277039,\n",
      "                        0.9336022138595581,\n",
      "                        0.9344754219055176,\n",
      "                        0.9361149668693542,\n",
      "                        0.9361398220062256,\n",
      "                        0.9379757642745972,\n",
      "                        0.9385338425636292,\n",
      "                        0.9398941397666931,\n",
      "                        0.9400012493133545,\n",
      "                        0.9414664506912231,\n",
      "                        0.9415104985237122,\n",
      "                        0.9424821138381958,\n",
      "                        0.9429206252098083],\n",
      "                       [0.8281786441802979,\n",
      "                        0.9067848920822144,\n",
      "                        0.9152138829231262,\n",
      "                        0.9214564561843872,\n",
      "                        0.9256381988525391,\n",
      "                        0.9291853308677673,\n",
      "                        0.9316715598106384,\n",
      "                        0.9340721964836121,\n",
      "                        0.9358387589454651,\n",
      "                        0.9371277689933777,\n",
      "                        0.9388226866722107,\n",
      "                        0.9400465488433838,\n",
      "                        0.940661609172821,\n",
      "                        0.9417029619216919,\n",
      "                        0.9419556260108948,\n",
      "                        0.9429731369018555,\n",
      "                        0.9431297779083252,\n",
      "                        0.9439231753349304,\n",
      "                        0.9441853165626526,\n",
      "                        0.9453733563423157],\n",
      "                       [0.830702543258667,\n",
      "                        0.9085981249809265,\n",
      "                        0.9162280559539795,\n",
      "                        0.9207711815834045,\n",
      "                        0.9254055023193359,\n",
      "                        0.9288957715034485,\n",
      "                        0.9307026267051697,\n",
      "                        0.9336459040641785,\n",
      "                        0.9347126483917236,\n",
      "                        0.9364050030708313,\n",
      "                        0.9378635287284851,\n",
      "                        0.9383979439735413,\n",
      "                        0.9390597939491272,\n",
      "                        0.9403703808784485,\n",
      "                        0.9406991600990295,\n",
      "                        0.9413795471191406,\n",
      "                        0.9421020746231079,\n",
      "                        0.9424324631690979,\n",
      "                        0.9428884983062744,\n",
      "                        0.9432587623596191],\n",
      "                       [0.8231334090232849,\n",
      "                        0.9043886661529541,\n",
      "                        0.9139457941055298,\n",
      "                        0.9197201132774353,\n",
      "                        0.923051118850708,\n",
      "                        0.9257438778877258,\n",
      "                        0.9281975626945496,\n",
      "                        0.9306172728538513,\n",
      "                        0.9327505826950073,\n",
      "                        0.9338406324386597,\n",
      "                        0.9360055327415466,\n",
      "                        0.936593770980835,\n",
      "                        0.9382733702659607,\n",
      "                        0.9394002556800842,\n",
      "                        0.9397910237312317,\n",
      "                        0.9403708577156067,\n",
      "                        0.9408295154571533,\n",
      "                        0.9414615631103516,\n",
      "                        0.9420589804649353,\n",
      "                        0.942272961139679]],\n",
      " 'Training Loss': [[0.3857974112033844,\n",
      "                    0.22689199447631836,\n",
      "                    0.2075020968914032,\n",
      "                    0.1974979043006897,\n",
      "                    0.18776407837867737,\n",
      "                    0.18167446553707123,\n",
      "                    0.1756289303302765,\n",
      "                    0.17166537046432495,\n",
      "                    0.167784184217453,\n",
      "                    0.16390611231327057,\n",
      "                    0.15979860723018646,\n",
      "                    0.15553373098373413,\n",
      "                    0.15364867448806763,\n",
      "                    0.15084363520145416,\n",
      "                    0.14708344638347626,\n",
      "                    0.14456778764724731,\n",
      "                    0.14352072775363922,\n",
      "                    0.14183594286441803,\n",
      "                    0.14035210013389587,\n",
      "                    0.13945332169532776],\n",
      "                   [0.36691585183143616,\n",
      "                    0.22686541080474854,\n",
      "                    0.20730167627334595,\n",
      "                    0.193496435880661,\n",
      "                    0.18435898423194885,\n",
      "                    0.17427976429462433,\n",
      "                    0.16691824793815613,\n",
      "                    0.16337010264396667,\n",
      "                    0.1585094928741455,\n",
      "                    0.1555817425251007,\n",
      "                    0.15299589931964874,\n",
      "                    0.15220682322978973,\n",
      "                    0.14842548966407776,\n",
      "                    0.14704450964927673,\n",
      "                    0.14399784803390503,\n",
      "                    0.1445864588022232,\n",
      "                    0.14138641953468323,\n",
      "                    0.14094676077365875,\n",
      "                    0.1394193172454834,\n",
      "                    0.13837668299674988],\n",
      "                   [0.37793102860450745,\n",
      "                    0.22068235278129578,\n",
      "                    0.19947847723960876,\n",
      "                    0.18510618805885315,\n",
      "                    0.17466841638088226,\n",
      "                    0.16784518957138062,\n",
      "                    0.16229501366615295,\n",
      "                    0.15706203877925873,\n",
      "                    0.15368027985095978,\n",
      "                    0.15010160207748413,\n",
      "                    0.1468488723039627,\n",
      "                    0.14381632208824158,\n",
      "                    0.14216120541095734,\n",
      "                    0.14024347066879272,\n",
      "                    0.1401607096195221,\n",
      "                    0.13820217549800873,\n",
      "                    0.13806675374507904,\n",
      "                    0.13624531030654907,\n",
      "                    0.1356602907180786,\n",
      "                    0.133383646607399],\n",
      "                   [0.3559507727622986,\n",
      "                    0.21597088873386383,\n",
      "                    0.1972951591014862,\n",
      "                    0.18633633852005005,\n",
      "                    0.17595961689949036,\n",
      "                    0.16884057223796844,\n",
      "                    0.16424444317817688,\n",
      "                    0.15847401320934296,\n",
      "                    0.15583370625972748,\n",
      "                    0.1516476571559906,\n",
      "                    0.14916536211967468,\n",
      "                    0.14727093279361725,\n",
      "                    0.14598964154720306,\n",
      "                    0.14357919991016388,\n",
      "                    0.14284519851207733,\n",
      "                    0.1414669007062912,\n",
      "                    0.13990601897239685,\n",
      "                    0.1390799731016159,\n",
      "                    0.1387047916650772,\n",
      "                    0.13765355944633484],\n",
      "                   [0.37251996994018555,\n",
      "                    0.22678953409194946,\n",
      "                    0.20319817960262299,\n",
      "                    0.18933947384357452,\n",
      "                    0.18116873502731323,\n",
      "                    0.17497627437114716,\n",
      "                    0.1695089042186737,\n",
      "                    0.16393667459487915,\n",
      "                    0.15953683853149414,\n",
      "                    0.15741753578186035,\n",
      "                    0.15283648669719696,\n",
      "                    0.15077029168605804,\n",
      "                    0.14784324169158936,\n",
      "                    0.14608246088027954,\n",
      "                    0.14471659064292908,\n",
      "                    0.14359942078590393,\n",
      "                    0.14268703758716583,\n",
      "                    0.1414695382118225,\n",
      "                    0.13979783654212952,\n",
      "                    0.13958747684955597]],\n",
      " 'Validation Accuracy': [[0.8986106514930725,\n",
      "                          0.9092453718185425,\n",
      "                          0.9158614277839661,\n",
      "                          0.917890727519989,\n",
      "                          0.9221733212471008,\n",
      "                          0.922090470790863,\n",
      "                          0.9279385805130005,\n",
      "                          0.9293200969696045,\n",
      "                          0.9291065335273743,\n",
      "                          0.9320774078369141,\n",
      "                          0.9318666458129883,\n",
      "                          0.9339840412139893,\n",
      "                          0.9374400973320007,\n",
      "                          0.9386293292045593,\n",
      "                          0.9396665096282959,\n",
      "                          0.9410293698310852,\n",
      "                          0.9404080510139465,\n",
      "                          0.9421732425689697,\n",
      "                          0.9431922435760498,\n",
      "                          0.9440640211105347],\n",
      "                         [0.8920078873634338,\n",
      "                          0.9085065722465515,\n",
      "                          0.9164905548095703,\n",
      "                          0.9221599698066711,\n",
      "                          0.9253466725349426,\n",
      "                          0.9296266436576843,\n",
      "                          0.930589497089386,\n",
      "                          0.9347894787788391,\n",
      "                          0.9354425668716431,\n",
      "                          0.9365091323852539,\n",
      "                          0.9381787180900574,\n",
      "                          0.9396079778671265,\n",
      "                          0.9409947991371155,\n",
      "                          0.9409467577934265,\n",
      "                          0.941221296787262,\n",
      "                          0.941864013671875,\n",
      "                          0.9417064785957336,\n",
      "                          0.9427866339683533,\n",
      "                          0.9439733624458313,\n",
      "                          0.9449148178100586],\n",
      "                         [0.8958613872528076,\n",
      "                          0.9092960357666016,\n",
      "                          0.9182531833648682,\n",
      "                          0.9222826957702637,\n",
      "                          0.920386791229248,\n",
      "                          0.9288479089736938,\n",
      "                          0.9315624833106995,\n",
      "                          0.9334667921066284,\n",
      "                          0.9338828325271606,\n",
      "                          0.9356106519699097,\n",
      "                          0.9368321299552917,\n",
      "                          0.9381653070449829,\n",
      "                          0.939024031162262,\n",
      "                          0.9409707188606262,\n",
      "                          0.9403920769691467,\n",
      "                          0.9411358833312988,\n",
      "                          0.9421066045761108,\n",
      "                          0.9388666152954102,\n",
      "                          0.9432346224784851,\n",
      "                          0.941957414150238],\n",
      "                         [0.9031280279159546,\n",
      "                          0.913109302520752,\n",
      "                          0.9205331802368164,\n",
      "                          0.9251147508621216,\n",
      "                          0.9287920594215393,\n",
      "                          0.9249652624130249,\n",
      "                          0.9325785040855408,\n",
      "                          0.9351626634597778,\n",
      "                          0.9359732866287231,\n",
      "                          0.9377094507217407,\n",
      "                          0.9391092658042908,\n",
      "                          0.9399999976158142,\n",
      "                          0.9405066967010498,\n",
      "                          0.9387252330780029,\n",
      "                          0.9418134093284607,\n",
      "                          0.9428693652153015,\n",
      "                          0.9426186680793762,\n",
      "                          0.9437814354896545,\n",
      "                          0.9440292716026306,\n",
      "                          0.9450799822807312],\n",
      "                         [0.8996827602386475,\n",
      "                          0.9107919931411743,\n",
      "                          0.9128453135490417,\n",
      "                          0.9203972220420837,\n",
      "                          0.9199094176292419,\n",
      "                          0.9274187088012695,\n",
      "                          0.9288559556007385,\n",
      "                          0.9319117665290833,\n",
      "                          0.9317012429237366,\n",
      "                          0.9330320358276367,\n",
      "                          0.936445415019989,\n",
      "                          0.9370186924934387,\n",
      "                          0.937573254108429,\n",
      "                          0.9377519488334656,\n",
      "                          0.9391735196113586,\n",
      "                          0.9387438893318176,\n",
      "                          0.9402933120727539,\n",
      "                          0.9396613836288452,\n",
      "                          0.9407333135604858,\n",
      "                          0.9409094452857971]],\n",
      " 'Validation Loss': [0.24299995601177216,\n",
      "                     0.20966438949108124,\n",
      "                     0.20091815292835236,\n",
      "                     0.18776345252990723,\n",
      "                     0.18671594560146332,\n",
      "                     0.17020826041698456,\n",
      "                     0.1671462059020996,\n",
      "                     0.16037452220916748,\n",
      "                     0.1606358140707016,\n",
      "                     0.15798404812812805,\n",
      "                     0.15041357278823853,\n",
      "                     0.1517622470855713,\n",
      "                     0.1491728574037552,\n",
      "                     0.14764145016670227,\n",
      "                     0.1440075933933258,\n",
      "                     0.1469515860080719,\n",
      "                     0.14175085723400116,\n",
      "                     0.1444101184606552,\n",
      "                     0.14205288887023926,\n",
      "                     0.14120814204216003],\n",
      " 'Validation MCC': [[np.float64(0.7968177773768375),\n",
      "                     np.float64(0.8181183978246674),\n",
      "                     np.float64(0.8312897562844669),\n",
      "                     np.float64(0.8353183680245786),\n",
      "                     np.float64(0.8442093931142547),\n",
      "                     np.float64(0.8440706197875281),\n",
      "                     np.float64(0.8555763235488494),\n",
      "                     np.float64(0.8582772921476808),\n",
      "                     np.float64(0.858030730216874),\n",
      "                     np.float64(0.8641836714095784),\n",
      "                     np.float64(0.8633898201745394),\n",
      "                     np.float64(0.8680747689684303),\n",
      "                     np.float64(0.8747857452497957),\n",
      "                     np.float64(0.8770174485425566),\n",
      "                     np.float64(0.8790196284858355),\n",
      "                     np.float64(0.8817363831460782),\n",
      "                     np.float64(0.8807500677076586),\n",
      "                     np.float64(0.8843241238048902),\n",
      "                     np.float64(0.8862917033848463),\n",
      "                     np.float64(0.8878464959141792)],\n",
      "                    [np.float64(0.78706212246847),\n",
      "                     np.float64(0.8169398580448136),\n",
      "                     np.float64(0.8325810013441757),\n",
      "                     np.float64(0.8439794721248365),\n",
      "                     np.float64(0.8505618450800378),\n",
      "                     np.float64(0.8589166273733335),\n",
      "                     np.float64(0.8607684185599607),\n",
      "                     np.float64(0.8691942568743349),\n",
      "                     np.float64(0.8706772839350153),\n",
      "                     np.float64(0.8730245400205753),\n",
      "                     np.float64(0.8760156286346867),\n",
      "                     np.float64(0.878879384574017),\n",
      "                     np.float64(0.8816476468980728),\n",
      "                     np.float64(0.8816633357324645),\n",
      "                     np.float64(0.882103627527261),\n",
      "                     np.float64(0.8835780471995298),\n",
      "                     np.float64(0.8832707302814258),\n",
      "                     np.float64(0.8854446372782787),\n",
      "                     np.float64(0.8876200795925665),\n",
      "                     np.float64(0.8895152159672749)],\n",
      "                    [np.float64(0.790940127735378),\n",
      "                     np.float64(0.8179154762232151),\n",
      "                     np.float64(0.8360754545439244),\n",
      "                     np.float64(0.8441019033611225),\n",
      "                     np.float64(0.8403211035983268),\n",
      "                     np.float64(0.8571972443231531),\n",
      "                     np.float64(0.8630978786015601),\n",
      "                     np.float64(0.8664856844297102),\n",
      "                     np.float64(0.8680996543150173),\n",
      "                     np.float64(0.8707691700430539),\n",
      "                     np.float64(0.8732104014219583),\n",
      "                     np.float64(0.8758946286793494),\n",
      "                     np.float64(0.877682020109995),\n",
      "                     np.float64(0.8815791854031051),\n",
      "                     np.float64(0.8803696930743082),\n",
      "                     np.float64(0.8818504313023119),\n",
      "                     np.float64(0.8838242827256197),\n",
      "                     np.float64(0.8779729658254709),\n",
      "                     np.float64(0.8861841392178462),\n",
      "                     np.float64(0.8835072671081855)],\n",
      "                    [np.float64(0.805728865712),\n",
      "                     np.float64(0.8258886716234033),\n",
      "                     np.float64(0.8407570419457943),\n",
      "                     np.float64(0.8508481595167614),\n",
      "                     np.float64(0.8574755292901312),\n",
      "                     np.float64(0.8511515760278385),\n",
      "                     np.float64(0.8648267597331376),\n",
      "                     np.float64(0.8704226543851534),\n",
      "                     np.float64(0.8715917628668116),\n",
      "                     np.float64(0.8750819242126266),\n",
      "                     np.float64(0.8778901833034533),\n",
      "                     np.float64(0.8797114132702953),\n",
      "                     np.float64(0.8807399967891025),\n",
      "                     np.float64(0.8778598421666913),\n",
      "                     np.float64(0.8835084499082767),\n",
      "                     np.float64(0.8854409904942766),\n",
      "                     np.float64(0.8849901634473724),\n",
      "                     np.float64(0.8872411921280849),\n",
      "                     np.float64(0.8877396297296116),\n",
      "                     np.float64(0.8899091067886056)],\n",
      "                    [np.float64(0.799387661083298),\n",
      "                     np.float64(0.8209416749771457),\n",
      "                     np.float64(0.8265043456128931),\n",
      "                     np.float64(0.8403419288821674),\n",
      "                     np.float64(0.839836177238999),\n",
      "                     np.float64(0.8545348235278658),\n",
      "                     np.float64(0.8572114190405137),\n",
      "                     np.float64(0.8633514450017153),\n",
      "                     np.float64(0.8634451493607327),\n",
      "                     np.float64(0.8656870324579261),\n",
      "                     np.float64(0.8724721373197108),\n",
      "                     np.float64(0.8739849651770972),\n",
      "                     np.float64(0.874754138733673),\n",
      "                     np.float64(0.8753967298395492),\n",
      "                     np.float64(0.8779240833171297),\n",
      "                     np.float64(0.8773000730713115),\n",
      "                     np.float64(0.8802594155699365),\n",
      "                     np.float64(0.8789698212622594),\n",
      "                     np.float64(0.881183926029539),\n",
      "                     np.float64(0.8814607777394956)]]}\n",
      "Training Model: RNN, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.7922 - loss: 0.4381\n",
      "Epoch 1 - MCC: 0.7569\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 43ms/step - accuracy: 0.7924 - loss: 0.4377 - val_accuracy: 0.8788 - val_loss: 0.2830 - mcc: 0.7569\n",
      "Epoch 2/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.8799 - loss: 0.2783\n",
      "Epoch 2 - MCC: 0.7910\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 33ms/step - accuracy: 0.8800 - loss: 0.2782 - val_accuracy: 0.8953 - val_loss: 0.2442 - mcc: 0.7910\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8960 - loss: 0.2451\n",
      "Epoch 3 - MCC: 0.7728\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.8960 - loss: 0.2451 - val_accuracy: 0.8851 - val_loss: 0.2588 - mcc: 0.7728\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8948 - loss: 0.2475\n",
      "Epoch 4 - MCC: 0.8079\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 31ms/step - accuracy: 0.8948 - loss: 0.2474 - val_accuracy: 0.9042 - val_loss: 0.2235 - mcc: 0.8079\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9006 - loss: 0.2316\n",
      "Epoch 5 - MCC: 0.8130\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 31ms/step - accuracy: 0.9006 - loss: 0.2316 - val_accuracy: 0.9064 - val_loss: 0.2271 - mcc: 0.8130\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9077 - loss: 0.2177\n",
      "Epoch 6 - MCC: 0.8262\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9077 - loss: 0.2178 - val_accuracy: 0.9133 - val_loss: 0.2060 - mcc: 0.8262\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9035 - loss: 0.2260\n",
      "Epoch 7 - MCC: 0.8236\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 33ms/step - accuracy: 0.9035 - loss: 0.2259 - val_accuracy: 0.9119 - val_loss: 0.2069 - mcc: 0.8236\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9091 - loss: 0.2150\n",
      "Epoch 8 - MCC: 0.8257\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9091 - loss: 0.2150 - val_accuracy: 0.9129 - val_loss: 0.2062 - mcc: 0.8257\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9123 - loss: 0.2058\n",
      "Epoch 9 - MCC: 0.8331\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9123 - loss: 0.2058 - val_accuracy: 0.9166 - val_loss: 0.1988 - mcc: 0.8331\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9122 - loss: 0.2076\n",
      "Epoch 10 - MCC: 0.8283\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9122 - loss: 0.2076 - val_accuracy: 0.9144 - val_loss: 0.2026 - mcc: 0.8283\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9107 - loss: 0.2094\n",
      "Epoch 11 - MCC: 0.8311\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 31ms/step - accuracy: 0.9107 - loss: 0.2094 - val_accuracy: 0.9147 - val_loss: 0.2086 - mcc: 0.8311\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9128 - loss: 0.2061\n",
      "Epoch 12 - MCC: 0.8336\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 31ms/step - accuracy: 0.9128 - loss: 0.2061 - val_accuracy: 0.9168 - val_loss: 0.1966 - mcc: 0.8336\n",
      "Epoch 13/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9166 - loss: 0.1962\n",
      "Epoch 13 - MCC: 0.8375\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 34ms/step - accuracy: 0.9166 - loss: 0.1962 - val_accuracy: 0.9186 - val_loss: 0.1941 - mcc: 0.8375\n",
      "Epoch 14/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9159 - loss: 0.1990\n",
      "Epoch 14 - MCC: 0.8269\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 34ms/step - accuracy: 0.9159 - loss: 0.1990 - val_accuracy: 0.9128 - val_loss: 0.2018 - mcc: 0.8269\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9180 - loss: 0.1957\n",
      "Epoch 15 - MCC: 0.8225\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 30ms/step - accuracy: 0.9180 - loss: 0.1957 - val_accuracy: 0.9115 - val_loss: 0.2111 - mcc: 0.8225\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9174 - loss: 0.1952\n",
      "Epoch 16 - MCC: 0.8326\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 30ms/step - accuracy: 0.9174 - loss: 0.1952 - val_accuracy: 0.9164 - val_loss: 0.2030 - mcc: 0.8326\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9142 - loss: 0.2030\n",
      "Epoch 17 - MCC: 0.8383\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 33ms/step - accuracy: 0.9142 - loss: 0.2029 - val_accuracy: 0.9192 - val_loss: 0.1940 - mcc: 0.8383\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9168 - loss: 0.1976\n",
      "Epoch 18 - MCC: 0.8432\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 33ms/step - accuracy: 0.9168 - loss: 0.1976 - val_accuracy: 0.9217 - val_loss: 0.1886 - mcc: 0.8432\n",
      "Epoch 19/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9180 - loss: 0.1939\n",
      "Epoch 19 - MCC: 0.8233\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9180 - loss: 0.1939 - val_accuracy: 0.9115 - val_loss: 0.2121 - mcc: 0.8233\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9172 - loss: 0.1976\n",
      "Epoch 20 - MCC: 0.8392\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 33ms/step - accuracy: 0.9173 - loss: 0.1975 - val_accuracy: 0.9192 - val_loss: 0.2007 - mcc: 0.8392\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8011 - loss: 0.4258\n",
      "Epoch 1 - MCC: 0.7629\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 48ms/step - accuracy: 0.8014 - loss: 0.4254 - val_accuracy: 0.8818 - val_loss: 0.2791 - mcc: 0.7629\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8804 - loss: 0.2800\n",
      "Epoch 2 - MCC: 0.7903\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.8805 - loss: 0.2799 - val_accuracy: 0.8955 - val_loss: 0.2463 - mcc: 0.7903\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8925 - loss: 0.2506\n",
      "Epoch 3 - MCC: 0.7788\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.8925 - loss: 0.2508 - val_accuracy: 0.8897 - val_loss: 0.2602 - mcc: 0.7788\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8894 - loss: 0.2615\n",
      "Epoch 4 - MCC: 0.7870\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.8895 - loss: 0.2615 - val_accuracy: 0.8932 - val_loss: 0.2505 - mcc: 0.7870\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8955 - loss: 0.2466\n",
      "Epoch 5 - MCC: 0.7947\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.8955 - loss: 0.2466 - val_accuracy: 0.8964 - val_loss: 0.2370 - mcc: 0.7947\n",
      "Epoch 6/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9000 - loss: 0.2340\n",
      "Epoch 6 - MCC: 0.8117\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9000 - loss: 0.2340 - val_accuracy: 0.9055 - val_loss: 0.2359 - mcc: 0.8117\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9029 - loss: 0.2277\n",
      "Epoch 7 - MCC: 0.8182\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9029 - loss: 0.2277 - val_accuracy: 0.9093 - val_loss: 0.2140 - mcc: 0.8182\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9080 - loss: 0.2155\n",
      "Epoch 8 - MCC: 0.8200\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 33ms/step - accuracy: 0.9080 - loss: 0.2155 - val_accuracy: 0.9097 - val_loss: 0.2089 - mcc: 0.8200\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9048 - loss: 0.2218\n",
      "Epoch 9 - MCC: 0.8289\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 30ms/step - accuracy: 0.9049 - loss: 0.2217 - val_accuracy: 0.9144 - val_loss: 0.2150 - mcc: 0.8289\n",
      "Epoch 10/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9077 - loss: 0.2175\n",
      "Epoch 10 - MCC: 0.8206\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 33ms/step - accuracy: 0.9077 - loss: 0.2175 - val_accuracy: 0.9105 - val_loss: 0.2100 - mcc: 0.8206\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9085 - loss: 0.2144\n",
      "Epoch 11 - MCC: 0.8311\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 34ms/step - accuracy: 0.9085 - loss: 0.2144 - val_accuracy: 0.9158 - val_loss: 0.1995 - mcc: 0.8311\n",
      "Epoch 12/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9118 - loss: 0.2089\n",
      "Epoch 12 - MCC: 0.8176\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9118 - loss: 0.2089 - val_accuracy: 0.9090 - val_loss: 0.2114 - mcc: 0.8176\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9081 - loss: 0.2165\n",
      "Epoch 13 - MCC: 0.8334\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 34ms/step - accuracy: 0.9082 - loss: 0.2164 - val_accuracy: 0.9170 - val_loss: 0.1955 - mcc: 0.8334\n",
      "Epoch 14/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9141 - loss: 0.2032\n",
      "Epoch 14 - MCC: 0.8334\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 31ms/step - accuracy: 0.9141 - loss: 0.2032 - val_accuracy: 0.9168 - val_loss: 0.1950 - mcc: 0.8334\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9143 - loss: 0.2035\n",
      "Epoch 15 - MCC: 0.8314\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 31ms/step - accuracy: 0.9143 - loss: 0.2035 - val_accuracy: 0.9155 - val_loss: 0.2025 - mcc: 0.8314\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9134 - loss: 0.2065\n",
      "Epoch 16 - MCC: 0.8313\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 31ms/step - accuracy: 0.9134 - loss: 0.2064 - val_accuracy: 0.9153 - val_loss: 0.2026 - mcc: 0.8313\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9146 - loss: 0.2012\n",
      "Epoch 17 - MCC: 0.8325\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 31ms/step - accuracy: 0.9146 - loss: 0.2012 - val_accuracy: 0.9165 - val_loss: 0.1985 - mcc: 0.8325\n",
      "Epoch 18/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9112 - loss: 0.2114\n",
      "Epoch 18 - MCC: 0.8309\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 33ms/step - accuracy: 0.9112 - loss: 0.2113 - val_accuracy: 0.9153 - val_loss: 0.1977 - mcc: 0.8309\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9209 - loss: 0.1892\n",
      "Epoch 19 - MCC: 0.8386\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9208 - loss: 0.1892 - val_accuracy: 0.9195 - val_loss: 0.1904 - mcc: 0.8386\n",
      "Epoch 20/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9181 - loss: 0.1938\n",
      "Epoch 20 - MCC: 0.8379\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9181 - loss: 0.1939 - val_accuracy: 0.9192 - val_loss: 0.1907 - mcc: 0.8379\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8038 - loss: 0.4204\n",
      "Epoch 1 - MCC: 0.7702\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 45ms/step - accuracy: 0.8041 - loss: 0.4199 - val_accuracy: 0.8829 - val_loss: 0.2704 - mcc: 0.7702\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8926 - loss: 0.2502\n",
      "Epoch 2 - MCC: 0.7793\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.8926 - loss: 0.2502 - val_accuracy: 0.8888 - val_loss: 0.2564 - mcc: 0.7793\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8999 - loss: 0.2353\n",
      "Epoch 3 - MCC: 0.8082\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 30ms/step - accuracy: 0.8999 - loss: 0.2352 - val_accuracy: 0.9042 - val_loss: 0.2303 - mcc: 0.8082\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9056 - loss: 0.2206\n",
      "Epoch 4 - MCC: 0.8076\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 33ms/step - accuracy: 0.9056 - loss: 0.2207 - val_accuracy: 0.9041 - val_loss: 0.2257 - mcc: 0.8076\n",
      "Epoch 5/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9094 - loss: 0.2124\n",
      "Epoch 5 - MCC: 0.8047\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 30ms/step - accuracy: 0.9094 - loss: 0.2124 - val_accuracy: 0.9015 - val_loss: 0.2260 - mcc: 0.8047\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9095 - loss: 0.2132\n",
      "Epoch 6 - MCC: 0.8167\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9094 - loss: 0.2132 - val_accuracy: 0.9083 - val_loss: 0.2105 - mcc: 0.8167\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9114 - loss: 0.2077\n",
      "Epoch 7 - MCC: 0.8192\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 29ms/step - accuracy: 0.9114 - loss: 0.2077 - val_accuracy: 0.9096 - val_loss: 0.2128 - mcc: 0.8192\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9124 - loss: 0.2046\n",
      "Epoch 8 - MCC: 0.7951\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 32ms/step - accuracy: 0.9124 - loss: 0.2046 - val_accuracy: 0.8968 - val_loss: 0.2502 - mcc: 0.7951\n",
      "Epoch 9/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9115 - loss: 0.2090\n",
      "Epoch 9 - MCC: 0.8302\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 34ms/step - accuracy: 0.9115 - loss: 0.2090 - val_accuracy: 0.9154 - val_loss: 0.2016 - mcc: 0.8302\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9141 - loss: 0.2010\n",
      "Epoch 10 - MCC: 0.8310\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 30ms/step - accuracy: 0.9141 - loss: 0.2010 - val_accuracy: 0.9157 - val_loss: 0.2043 - mcc: 0.8310\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9128 - loss: 0.2060\n",
      "Epoch 11 - MCC: 0.8283\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 33ms/step - accuracy: 0.9128 - loss: 0.2059 - val_accuracy: 0.9145 - val_loss: 0.2027 - mcc: 0.8283\n",
      "Epoch 12/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9122 - loss: 0.2070\n",
      "Epoch 12 - MCC: 0.8021\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 30ms/step - accuracy: 0.9122 - loss: 0.2069 - val_accuracy: 0.9011 - val_loss: 0.2318 - mcc: 0.8021\n",
      "Epoch 13/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9089 - loss: 0.2151\n",
      "Epoch 13 - MCC: 0.8280\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 31ms/step - accuracy: 0.9089 - loss: 0.2150 - val_accuracy: 0.9138 - val_loss: 0.2023 - mcc: 0.8280\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9187 - loss: 0.1926\n",
      "Epoch 14 - MCC: 0.8317\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 33ms/step - accuracy: 0.9186 - loss: 0.1927 - val_accuracy: 0.9162 - val_loss: 0.1989 - mcc: 0.8317\n",
      "Epoch 15/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9168 - loss: 0.1958\n",
      "Epoch 15 - MCC: 0.8042\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9168 - loss: 0.1958 - val_accuracy: 0.9018 - val_loss: 0.2346 - mcc: 0.8042\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9112 - loss: 0.2093\n",
      "Epoch 16 - MCC: 0.8145\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 31ms/step - accuracy: 0.9113 - loss: 0.2092 - val_accuracy: 0.9068 - val_loss: 0.2170 - mcc: 0.8145\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9154 - loss: 0.2007\n",
      "Epoch 17 - MCC: 0.8377\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 31ms/step - accuracy: 0.9154 - loss: 0.2007 - val_accuracy: 0.9190 - val_loss: 0.1941 - mcc: 0.8377\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9195 - loss: 0.1915\n",
      "Epoch 18 - MCC: 0.8178\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9195 - loss: 0.1916 - val_accuracy: 0.9082 - val_loss: 0.2217 - mcc: 0.8178\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9144 - loss: 0.2059\n",
      "Epoch 19 - MCC: 0.8359\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9144 - loss: 0.2058 - val_accuracy: 0.9182 - val_loss: 0.1944 - mcc: 0.8359\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9199 - loss: 0.1910\n",
      "Epoch 20 - MCC: 0.8398\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 30ms/step - accuracy: 0.9199 - loss: 0.1910 - val_accuracy: 0.9202 - val_loss: 0.1921 - mcc: 0.8398\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8211 - loss: 0.3967\n",
      "Epoch 1 - MCC: 0.7555\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 48ms/step - accuracy: 0.8213 - loss: 0.3963 - val_accuracy: 0.8743 - val_loss: 0.2848 - mcc: 0.7555\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.8873 - loss: 0.2604\n",
      "Epoch 2 - MCC: 0.7859\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 33ms/step - accuracy: 0.8873 - loss: 0.2604 - val_accuracy: 0.8920 - val_loss: 0.2443 - mcc: 0.7859\n",
      "Epoch 3/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8959 - loss: 0.2434\n",
      "Epoch 3 - MCC: 0.8137\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 30ms/step - accuracy: 0.8959 - loss: 0.2434 - val_accuracy: 0.9071 - val_loss: 0.2136 - mcc: 0.8137\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9022 - loss: 0.2295\n",
      "Epoch 4 - MCC: 0.7744\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 30ms/step - accuracy: 0.9022 - loss: 0.2295 - val_accuracy: 0.8826 - val_loss: 0.2598 - mcc: 0.7744\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9016 - loss: 0.2290\n",
      "Epoch 5 - MCC: 0.8219\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9016 - loss: 0.2290 - val_accuracy: 0.9111 - val_loss: 0.2196 - mcc: 0.8219\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9023 - loss: 0.2296\n",
      "Epoch 6 - MCC: 0.8185\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9023 - loss: 0.2295 - val_accuracy: 0.9090 - val_loss: 0.2102 - mcc: 0.8185\n",
      "Epoch 7/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9062 - loss: 0.2187\n",
      "Epoch 7 - MCC: 0.8177\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9062 - loss: 0.2187 - val_accuracy: 0.9091 - val_loss: 0.2131 - mcc: 0.8177\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9117 - loss: 0.2053\n",
      "Epoch 8 - MCC: 0.8248\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9117 - loss: 0.2053 - val_accuracy: 0.9125 - val_loss: 0.2087 - mcc: 0.8248\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9064 - loss: 0.2217\n",
      "Epoch 9 - MCC: 0.8035\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 33ms/step - accuracy: 0.9064 - loss: 0.2217 - val_accuracy: 0.9000 - val_loss: 0.2278 - mcc: 0.8035\n",
      "Epoch 10/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9090 - loss: 0.2129\n",
      "Epoch 10 - MCC: 0.8299\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 30ms/step - accuracy: 0.9090 - loss: 0.2129 - val_accuracy: 0.9147 - val_loss: 0.2010 - mcc: 0.8299\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9066 - loss: 0.2179\n",
      "Epoch 11 - MCC: 0.7551\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 32ms/step - accuracy: 0.9065 - loss: 0.2180 - val_accuracy: 0.8773 - val_loss: 0.2843 - mcc: 0.7551\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8833 - loss: 0.2741\n",
      "Epoch 12 - MCC: 0.7725\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.8833 - loss: 0.2741 - val_accuracy: 0.8860 - val_loss: 0.2649 - mcc: 0.7725\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.8897 - loss: 0.2617\n",
      "Epoch 13 - MCC: 0.7948\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 33ms/step - accuracy: 0.8897 - loss: 0.2617 - val_accuracy: 0.8969 - val_loss: 0.2495 - mcc: 0.7948\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8959 - loss: 0.2511\n",
      "Epoch 14 - MCC: 0.8082\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 30ms/step - accuracy: 0.8960 - loss: 0.2510 - val_accuracy: 0.9038 - val_loss: 0.2336 - mcc: 0.8082\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8988 - loss: 0.2435\n",
      "Epoch 15 - MCC: 0.8147\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 30ms/step - accuracy: 0.8988 - loss: 0.2434 - val_accuracy: 0.9076 - val_loss: 0.2196 - mcc: 0.8147\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9067 - loss: 0.2222\n",
      "Epoch 16 - MCC: 0.8215\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9067 - loss: 0.2222 - val_accuracy: 0.9109 - val_loss: 0.2134 - mcc: 0.8215\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9016 - loss: 0.2337\n",
      "Epoch 17 - MCC: 0.7997\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9015 - loss: 0.2339 - val_accuracy: 0.9001 - val_loss: 0.2391 - mcc: 0.7997\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9003 - loss: 0.2389\n",
      "Epoch 18 - MCC: 0.8113\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9004 - loss: 0.2388 - val_accuracy: 0.9058 - val_loss: 0.2254 - mcc: 0.8113\n",
      "Epoch 19/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9077 - loss: 0.2202\n",
      "Epoch 19 - MCC: 0.8276\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 33ms/step - accuracy: 0.9077 - loss: 0.2202 - val_accuracy: 0.9140 - val_loss: 0.2024 - mcc: 0.8276\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9079 - loss: 0.2190\n",
      "Epoch 20 - MCC: 0.8239\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 30ms/step - accuracy: 0.9079 - loss: 0.2189 - val_accuracy: 0.9120 - val_loss: 0.2075 - mcc: 0.8239\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.8076 - loss: 0.4158\n",
      "Epoch 1 - MCC: 0.7530\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 43ms/step - accuracy: 0.8079 - loss: 0.4154 - val_accuracy: 0.8760 - val_loss: 0.2897 - mcc: 0.7530\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.8862 - loss: 0.2678\n",
      "Epoch 2 - MCC: 0.7887\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.8862 - loss: 0.2678 - val_accuracy: 0.8945 - val_loss: 0.2465 - mcc: 0.7887\n",
      "Epoch 3/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8943 - loss: 0.2478\n",
      "Epoch 3 - MCC: 0.8080\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.8943 - loss: 0.2478 - val_accuracy: 0.9043 - val_loss: 0.2220 - mcc: 0.8080\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9001 - loss: 0.2336\n",
      "Epoch 4 - MCC: 0.8047\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9001 - loss: 0.2337 - val_accuracy: 0.9026 - val_loss: 0.2254 - mcc: 0.8047\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9047 - loss: 0.2238\n",
      "Epoch 5 - MCC: 0.7968\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 30ms/step - accuracy: 0.9047 - loss: 0.2237 - val_accuracy: 0.8963 - val_loss: 0.2425 - mcc: 0.7968\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9066 - loss: 0.2202\n",
      "Epoch 6 - MCC: 0.8005\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 33ms/step - accuracy: 0.9066 - loss: 0.2202 - val_accuracy: 0.9006 - val_loss: 0.2363 - mcc: 0.8005\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9061 - loss: 0.2204\n",
      "Epoch 7 - MCC: 0.8244\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9062 - loss: 0.2204 - val_accuracy: 0.9125 - val_loss: 0.2034 - mcc: 0.8244\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9108 - loss: 0.2100\n",
      "Epoch 8 - MCC: 0.8225\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 30ms/step - accuracy: 0.9108 - loss: 0.2100 - val_accuracy: 0.9116 - val_loss: 0.2101 - mcc: 0.8225\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9106 - loss: 0.2112\n",
      "Epoch 9 - MCC: 0.8181\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9106 - loss: 0.2112 - val_accuracy: 0.9089 - val_loss: 0.2204 - mcc: 0.8181\n",
      "Epoch 10/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9123 - loss: 0.2073\n",
      "Epoch 10 - MCC: 0.8267\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9123 - loss: 0.2073 - val_accuracy: 0.9135 - val_loss: 0.2043 - mcc: 0.8267\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9132 - loss: 0.2036\n",
      "Epoch 11 - MCC: 0.8242\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 33ms/step - accuracy: 0.9132 - loss: 0.2036 - val_accuracy: 0.9123 - val_loss: 0.2047 - mcc: 0.8242\n",
      "Epoch 12/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9128 - loss: 0.2063\n",
      "Epoch 12 - MCC: 0.8286\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9128 - loss: 0.2063 - val_accuracy: 0.9139 - val_loss: 0.2056 - mcc: 0.8286\n",
      "Epoch 13/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9172 - loss: 0.1943\n",
      "Epoch 13 - MCC: 0.8392\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 31ms/step - accuracy: 0.9172 - loss: 0.1943 - val_accuracy: 0.9198 - val_loss: 0.1903 - mcc: 0.8392\n",
      "Epoch 14/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9107 - loss: 0.2073\n",
      "Epoch 14 - MCC: 0.8366\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9107 - loss: 0.2072 - val_accuracy: 0.9184 - val_loss: 0.1976 - mcc: 0.8366\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9200 - loss: 0.1911\n",
      "Epoch 15 - MCC: 0.8246\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 34ms/step - accuracy: 0.9200 - loss: 0.1911 - val_accuracy: 0.9126 - val_loss: 0.2083 - mcc: 0.8246\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9183 - loss: 0.1940\n",
      "Epoch 16 - MCC: 0.8307\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 34ms/step - accuracy: 0.9183 - loss: 0.1940 - val_accuracy: 0.9154 - val_loss: 0.2039 - mcc: 0.8307\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9181 - loss: 0.1932\n",
      "Epoch 17 - MCC: 0.8423\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9181 - loss: 0.1932 - val_accuracy: 0.9211 - val_loss: 0.1857 - mcc: 0.8423\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9200 - loss: 0.1899\n",
      "Epoch 18 - MCC: 0.8411\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9200 - loss: 0.1899 - val_accuracy: 0.9208 - val_loss: 0.1866 - mcc: 0.8411\n",
      "Epoch 19/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9209 - loss: 0.1876\n",
      "Epoch 19 - MCC: 0.8472\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 33ms/step - accuracy: 0.9209 - loss: 0.1876 - val_accuracy: 0.9239 - val_loss: 0.1794 - mcc: 0.8472\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9179 - loss: 0.1928\n",
      "Epoch 20 - MCC: 0.8432\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 30ms/step - accuracy: 0.9179 - loss: 0.1928 - val_accuracy: 0.9213 - val_loss: 0.1871 - mcc: 0.8432\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.9213173333333333),\n",
      "              'mean': np.float64(0.9183717333333334),\n",
      "              'min': np.float64(0.9119946666666666),\n",
      "              'std': np.float64(0.003284199198181113)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.0009547541936238607),\n",
      "                               'mean': np.float64(0.0007193874994913737),\n",
      "                               'min': np.float64(0.00041109848022460936),\n",
      "                               'std': np.float64(0.00025044195513743806)},\n",
      " 'MCC': {'max': np.float64(0.8431703558786776),\n",
      "         'mean': np.float64(0.836801201250448),\n",
      "         'min': np.float64(0.8239033388397788),\n",
      "         'std': np.float64(0.006678880583374802)},\n",
      " 'Parameters': 4758,\n",
      " 'Train Time (s)': {'max': np.float64(184.18863582611084),\n",
      "                    'mean': np.float64(167.6915153503418),\n",
      "                    'min': np.float64(157.64749097824097),\n",
      "                    'std': np.float64(9.113374887181726)},\n",
      " 'Training Accuracy': [[0.8429391384124756,\n",
      "                        0.8857247829437256,\n",
      "                        0.8963291645050049,\n",
      "                        0.8982860445976257,\n",
      "                        0.902212917804718,\n",
      "                        0.9066911339759827,\n",
      "                        0.9068775773048401,\n",
      "                        0.9092395305633545,\n",
      "                        0.9127223491668701,\n",
      "                        0.9115558862686157,\n",
      "                        0.912484347820282,\n",
      "                        0.9133108854293823,\n",
      "                        0.9162218570709229,\n",
      "                        0.9158827066421509,\n",
      "                        0.9160574674606323,\n",
      "                        0.9139354825019836,\n",
      "                        0.916292130947113,\n",
      "                        0.9170122146606445,\n",
      "                        0.9180691838264465,\n",
      "                        0.9191937446594238],\n",
      "                       [0.8493066430091858,\n",
      "                        0.8855795860290527,\n",
      "                        0.885614812374115,\n",
      "                        0.8908115029335022,\n",
      "                        0.896742045879364,\n",
      "                        0.9004443287849426,\n",
      "                        0.903847873210907,\n",
      "                        0.9078324437141418,\n",
      "                        0.9082770347595215,\n",
      "                        0.9070093035697937,\n",
      "                        0.9108918309211731,\n",
      "                        0.9113128781318665,\n",
      "                        0.9116771817207336,\n",
      "                        0.9137701988220215,\n",
      "                        0.9141075611114502,\n",
      "                        0.9147447347640991,\n",
      "                        0.9140673875808716,\n",
      "                        0.915542483329773,\n",
      "                        0.917884349822998,\n",
      "                        0.9157079458236694],\n",
      "                       [0.8580807447433472,\n",
      "                        0.8929492235183716,\n",
      "                        0.8999280333518982,\n",
      "                        0.9041327834129333,\n",
      "                        0.9076949954032898,\n",
      "                        0.9083923101425171,\n",
      "                        0.9089586734771729,\n",
      "                        0.9113608598709106,\n",
      "                        0.9139533638954163,\n",
      "                        0.9141855239868164,\n",
      "                        0.9132477045059204,\n",
      "                        0.9144380688667297,\n",
      "                        0.9137787222862244,\n",
      "                        0.9163221120834351,\n",
      "                        0.9165619015693665,\n",
      "                        0.9153746962547302,\n",
      "                        0.9166280627250671,\n",
      "                        0.9175968170166016,\n",
      "                        0.9171831011772156,\n",
      "                        0.9179487824440002],\n",
      "                       [0.8622413873672485,\n",
      "                        0.8887712359428406,\n",
      "                        0.8973876237869263,\n",
      "                        0.9031705856323242,\n",
      "                        0.9021356701850891,\n",
      "                        0.9026404619216919,\n",
      "                        0.9082997441291809,\n",
      "                        0.9100999236106873,\n",
      "                        0.9074646830558777,\n",
      "                        0.9094774723052979,\n",
      "                        0.8916126489639282,\n",
      "                        0.8858802318572998,\n",
      "                        0.8913595080375671,\n",
      "                        0.8993935585021973,\n",
      "                        0.9030991792678833,\n",
      "                        0.9067714810371399,\n",
      "                        0.8961827754974365,\n",
      "                        0.9023872017860413,\n",
      "                        0.9084758162498474,\n",
      "                        0.9098385572433472],\n",
      "                       [0.8500800132751465,\n",
      "                        0.8866719603538513,\n",
      "                        0.8945537209510803,\n",
      "                        0.8995538949966431,\n",
      "                        0.9047640562057495,\n",
      "                        0.9061574935913086,\n",
      "                        0.9071010947227478,\n",
      "                        0.9094868898391724,\n",
      "                        0.9111112356185913,\n",
      "                        0.9138426184654236,\n",
      "                        0.9144601225852966,\n",
      "                        0.9134482145309448,\n",
      "                        0.9169694781303406,\n",
      "                        0.9155480861663818,\n",
      "                        0.9179254770278931,\n",
      "                        0.9200651049613953,\n",
      "                        0.9194562435150146,\n",
      "                        0.9189266562461853,\n",
      "                        0.9206852912902832,\n",
      "                        0.9183595180511475]],\n",
      " 'Training Loss': [[0.3545651137828827,\n",
      "                    0.26731863617897034,\n",
      "                    0.2437124252319336,\n",
      "                    0.23935115337371826,\n",
      "                    0.22864243388175964,\n",
      "                    0.21909582614898682,\n",
      "                    0.21855604648590088,\n",
      "                    0.21431821584701538,\n",
      "                    0.20572930574417114,\n",
      "                    0.20892706513404846,\n",
      "                    0.20566928386688232,\n",
      "                    0.20381878316402435,\n",
      "                    0.19797737896442413,\n",
      "                    0.1989065408706665,\n",
      "                    0.19951224327087402,\n",
      "                    0.20249676704406738,\n",
      "                    0.19763901829719543,\n",
      "                    0.19663311541080475,\n",
      "                    0.19357505440711975,\n",
      "                    0.19211699068546295],\n",
      "                   [0.3447495996952057,\n",
      "                    0.2687947452068329,\n",
      "                    0.2658645212650299,\n",
      "                    0.2585919499397278,\n",
      "                    0.24315570294857025,\n",
      "                    0.23272892832756042,\n",
      "                    0.2245597541332245,\n",
      "                    0.21599948406219482,\n",
      "                    0.2154216766357422,\n",
      "                    0.21901552379131317,\n",
      "                    0.21076051890850067,\n",
      "                    0.20932786166667938,\n",
      "                    0.20892266929149628,\n",
      "                    0.20375579595565796,\n",
      "                    0.20370414853096008,\n",
      "                    0.20276403427124023,\n",
      "                    0.20222288370132446,\n",
      "                    0.20123109221458435,\n",
      "                    0.1954232007265091,\n",
      "                    0.1999172419309616],\n",
      "                   [0.32619190216064453,\n",
      "                    0.2493555247783661,\n",
      "                    0.23419189453125,\n",
      "                    0.2241118997335434,\n",
      "                    0.21609601378440857,\n",
      "                    0.2146768867969513,\n",
      "                    0.2126537263393402,\n",
      "                    0.20717421174049377,\n",
      "                    0.2032936066389084,\n",
      "                    0.2017812430858612,\n",
      "                    0.20384730398654938,\n",
      "                    0.2018277943134308,\n",
      "                    0.20283526182174683,\n",
      "                    0.19645385444164276,\n",
      "                    0.19675174355506897,\n",
      "                    0.20038893818855286,\n",
      "                    0.1967448890209198,\n",
      "                    0.19584359228610992,\n",
      "                    0.19748832285404205,\n",
      "                    0.19394294917583466],\n",
      "                   [0.31954824924468994,\n",
      "                    0.25798535346984863,\n",
      "                    0.2390984296798706,\n",
      "                    0.225638285279274,\n",
      "                    0.22862495481967926,\n",
      "                    0.2286425530910492,\n",
      "                    0.21368014812469482,\n",
      "                    0.21027472615242004,\n",
      "                    0.21824729442596436,\n",
      "                    0.21168605983257294,\n",
      "                    0.2489858865737915,\n",
      "                    0.26958662271499634,\n",
      "                    0.25844040513038635,\n",
      "                    0.24341259896755219,\n",
      "                    0.23344804346561432,\n",
      "                    0.2221699357032776,\n",
      "                    0.24725228548049927,\n",
      "                    0.23466145992279053,\n",
      "                    0.21714448928833008,\n",
      "                    0.21599283814430237],\n",
      "                   [0.34194108843803406,\n",
      "                    0.26640501618385315,\n",
      "                    0.24692568182945251,\n",
      "                    0.23514269292354584,\n",
      "                    0.22309331595897675,\n",
      "                    0.22058206796646118,\n",
      "                    0.2172575145959854,\n",
      "                    0.21332505345344543,\n",
      "                    0.20971377193927765,\n",
      "                    0.20406100153923035,\n",
      "                    0.20164580643177032,\n",
      "                    0.20470918715000153,\n",
      "                    0.19548536837100983,\n",
      "                    0.19828833639621735,\n",
      "                    0.19484587013721466,\n",
      "                    0.189377561211586,\n",
      "                    0.19033975899219513,\n",
      "                    0.1925748884677887,\n",
      "                    0.1884445995092392,\n",
      "                    0.1921539157629013]],\n",
      " 'Validation Accuracy': [[0.8787868618965149,\n",
      "                          0.8953067064285278,\n",
      "                          0.8850908279418945,\n",
      "                          0.9041574001312256,\n",
      "                          0.9063999056816101,\n",
      "                          0.9133279919624329,\n",
      "                          0.9119226932525635,\n",
      "                          0.9128881692886353,\n",
      "                          0.9165653586387634,\n",
      "                          0.9144081473350525,\n",
      "                          0.9147067666053772,\n",
      "                          0.916845440864563,\n",
      "                          0.9185519814491272,\n",
      "                          0.9127626419067383,\n",
      "                          0.9115121364593506,\n",
      "                          0.9163733720779419,\n",
      "                          0.9191707372665405,\n",
      "                          0.9217227101325989,\n",
      "                          0.9115014672279358,\n",
      "                          0.9192132949829102],\n",
      "                         [0.8818399906158447,\n",
      "                          0.8954774737358093,\n",
      "                          0.8897067904472351,\n",
      "                          0.8931653499603271,\n",
      "                          0.8963868021965027,\n",
      "                          0.9055014848709106,\n",
      "                          0.9093093276023865,\n",
      "                          0.9097307920455933,\n",
      "                          0.9143574237823486,\n",
      "                          0.910495936870575,\n",
      "                          0.9157760143280029,\n",
      "                          0.9089627861976624,\n",
      "                          0.9169654250144958,\n",
      "                          0.9168105721473694,\n",
      "                          0.915453314781189,\n",
      "                          0.9152880907058716,\n",
      "                          0.9164800047874451,\n",
      "                          0.9153413772583008,\n",
      "                          0.9194905757904053,\n",
      "                          0.9191545248031616],\n",
      "                         [0.8828801512718201,\n",
      "                          0.8887999653816223,\n",
      "                          0.9042452573776245,\n",
      "                          0.9040721654891968,\n",
      "                          0.9014505743980408,\n",
      "                          0.9083040952682495,\n",
      "                          0.9096187353134155,\n",
      "                          0.8968160152435303,\n",
      "                          0.915370762348175,\n",
      "                          0.9156666398048401,\n",
      "                          0.9144614338874817,\n",
      "                          0.9011014103889465,\n",
      "                          0.9138375520706177,\n",
      "                          0.9161681532859802,\n",
      "                          0.9018214344978333,\n",
      "                          0.9067520499229431,\n",
      "                          0.918957531452179,\n",
      "                          0.9082080125808716,\n",
      "                          0.9181733131408691,\n",
      "                          0.9201788902282715],\n",
      "                         [0.8743014335632324,\n",
      "                          0.8919973969459534,\n",
      "                          0.9071254730224609,\n",
      "                          0.8826159834861755,\n",
      "                          0.9110854268074036,\n",
      "                          0.9089787006378174,\n",
      "                          0.9091253280639648,\n",
      "                          0.9125468134880066,\n",
      "                          0.8999866247177124,\n",
      "                          0.9146853685379028,\n",
      "                          0.8773333430290222,\n",
      "                          0.886008083820343,\n",
      "                          0.8968505859375,\n",
      "                          0.9037731885910034,\n",
      "                          0.9076213240623474,\n",
      "                          0.9108746647834778,\n",
      "                          0.9001336097717285,\n",
      "                          0.905754804611206,\n",
      "                          0.9140424728393555,\n",
      "                          0.9119946956634521],\n",
      "                         [0.8760480880737305,\n",
      "                          0.8944907188415527,\n",
      "                          0.9043279886245728,\n",
      "                          0.9026133418083191,\n",
      "                          0.8962665796279907,\n",
      "                          0.9006348252296448,\n",
      "                          0.9125255346298218,\n",
      "                          0.9115548729896545,\n",
      "                          0.9089412689208984,\n",
      "                          0.9135172367095947,\n",
      "                          0.9122586250305176,\n",
      "                          0.913912296295166,\n",
      "                          0.9198428392410278,\n",
      "                          0.9184026718139648,\n",
      "                          0.9125974774360657,\n",
      "                          0.9154240489006042,\n",
      "                          0.9211201071739197,\n",
      "                          0.9207814931869507,\n",
      "                          0.9238668084144592,\n",
      "                          0.9213173985481262]],\n",
      " 'Validation Loss': [0.2896691560745239,\n",
      "                     0.24652601778507233,\n",
      "                     0.22203777730464935,\n",
      "                     0.22542957961559296,\n",
      "                     0.2425384670495987,\n",
      "                     0.23628932237625122,\n",
      "                     0.20341451466083527,\n",
      "                     0.21012377738952637,\n",
      "                     0.22041857242584229,\n",
      "                     0.2042841762304306,\n",
      "                     0.20473118126392365,\n",
      "                     0.20561279356479645,\n",
      "                     0.19026179611682892,\n",
      "                     0.1976107656955719,\n",
      "                     0.20826084911823273,\n",
      "                     0.20386025309562683,\n",
      "                     0.18573984503746033,\n",
      "                     0.18662558495998383,\n",
      "                     0.17941595613956451,\n",
      "                     0.18709364533424377],\n",
      " 'Validation MCC': [[np.float64(0.7569291502321559),\n",
      "                     np.float64(0.7910235483661366),\n",
      "                     np.float64(0.7728276680002543),\n",
      "                     np.float64(0.8078783450182141),\n",
      "                     np.float64(0.8130285594368951),\n",
      "                     np.float64(0.826216094693265),\n",
      "                     np.float64(0.8236410879969465),\n",
      "                     np.float64(0.8257395861523595),\n",
      "                     np.float64(0.8330595503619986),\n",
      "                     np.float64(0.8283314726744684),\n",
      "                     np.float64(0.831120865096778),\n",
      "                     np.float64(0.833622494905732),\n",
      "                     np.float64(0.837549756030464),\n",
      "                     np.float64(0.8269261049765988),\n",
      "                     np.float64(0.8225208676348124),\n",
      "                     np.float64(0.8325546828534588),\n",
      "                     np.float64(0.8382717881534609),\n",
      "                     np.float64(0.8431973666550201),\n",
      "                     np.float64(0.8233305300651329),\n",
      "                     np.float64(0.8392019181725058)],\n",
      "                    [np.float64(0.7629473510144162),\n",
      "                     np.float64(0.7903149903492037),\n",
      "                     np.float64(0.7787568799283381),\n",
      "                     np.float64(0.7869563741368177),\n",
      "                     np.float64(0.7946626840572746),\n",
      "                     np.float64(0.8117120229078905),\n",
      "                     np.float64(0.8181796451425982),\n",
      "                     np.float64(0.8200110588016923),\n",
      "                     np.float64(0.8288928086068835),\n",
      "                     np.float64(0.8206360598305118),\n",
      "                     np.float64(0.8310660172643615),\n",
      "                     np.float64(0.8175647774480534),\n",
      "                     np.float64(0.8334417959264289),\n",
      "                     np.float64(0.8333502776011154),\n",
      "                     np.float64(0.831435247037502),\n",
      "                     np.float64(0.831279105796543),\n",
      "                     np.float64(0.8325156189422457),\n",
      "                     np.float64(0.8309423023514982),\n",
      "                     np.float64(0.8386233507317056),\n",
      "                     np.float64(0.8379079485987654)],\n",
      "                    [np.float64(0.7702024814844178),\n",
      "                     np.float64(0.7793409980044276),\n",
      "                     np.float64(0.8082152795384393),\n",
      "                     np.float64(0.8076105499145396),\n",
      "                     np.float64(0.8047038033053261),\n",
      "                     np.float64(0.8166602913909291),\n",
      "                     np.float64(0.8191684354914298),\n",
      "                     np.float64(0.7950713724882016),\n",
      "                     np.float64(0.8302367282808985),\n",
      "                     np.float64(0.8309743875994035),\n",
      "                     np.float64(0.8283085043847922),\n",
      "                     np.float64(0.8020753496321461),\n",
      "                     np.float64(0.8279634615395491),\n",
      "                     np.float64(0.8317358887600945),\n",
      "                     np.float64(0.8041664488704873),\n",
      "                     np.float64(0.8145318057923073),\n",
      "                     np.float64(0.837725251699599),\n",
      "                     np.float64(0.8177500342590749),\n",
      "                     np.float64(0.835878970656449),\n",
      "                     np.float64(0.8398224447625124)],\n",
      "                    [np.float64(0.7554781554098108),\n",
      "                     np.float64(0.7859430568591744),\n",
      "                     np.float64(0.8137447552686515),\n",
      "                     np.float64(0.7743857271779359),\n",
      "                     np.float64(0.8218529790356903),\n",
      "                     np.float64(0.8185148213874104),\n",
      "                     np.float64(0.8177077950350449),\n",
      "                     np.float64(0.8248483349057185),\n",
      "                     np.float64(0.8035360331529495),\n",
      "                     np.float64(0.8299285077162014),\n",
      "                     np.float64(0.7550953875035344),\n",
      "                     np.float64(0.7725050455231279),\n",
      "                     np.float64(0.7948217650798838),\n",
      "                     np.float64(0.8082411722688311),\n",
      "                     np.float64(0.8147448187515428),\n",
      "                     np.float64(0.821497961385559),\n",
      "                     np.float64(0.7996841933059231),\n",
      "                     np.float64(0.8112572085796185),\n",
      "                     np.float64(0.8275947955814716),\n",
      "                     np.float64(0.8239033388397788)],\n",
      "                    [np.float64(0.7529914703440918),\n",
      "                     np.float64(0.7887045748419036),\n",
      "                     np.float64(0.8079864178401823),\n",
      "                     np.float64(0.8047340864092457),\n",
      "                     np.float64(0.7967663493544087),\n",
      "                     np.float64(0.8005435128511598),\n",
      "                     np.float64(0.824442726957939),\n",
      "                     np.float64(0.8224889592949722),\n",
      "                     np.float64(0.8180961594023393),\n",
      "                     np.float64(0.8266649746207736),\n",
      "                     np.float64(0.8241847391317566),\n",
      "                     np.float64(0.8285792556890856),\n",
      "                     np.float64(0.8391561432350453),\n",
      "                     np.float64(0.8365546840651967),\n",
      "                     np.float64(0.8245710782677741),\n",
      "                     np.float64(0.8306501090081526),\n",
      "                     np.float64(0.8422952155179281),\n",
      "                     np.float64(0.8410598612251884),\n",
      "                     np.float64(0.8471966909203106),\n",
      "                     np.float64(0.8431703558786776)]]}\n",
      "Training Model: GRU, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7457 - loss: 0.5234\n",
      "Epoch 1 - MCC: 0.7481\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 22ms/step - accuracy: 0.7467 - loss: 0.5215 - val_accuracy: 0.8744 - val_loss: 0.2912 - mcc: 0.7481\n",
      "Epoch 2/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8789 - loss: 0.2829\n",
      "Epoch 2 - MCC: 0.8033\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.8790 - loss: 0.2825 - val_accuracy: 0.9013 - val_loss: 0.2299 - mcc: 0.8033\n",
      "Epoch 3/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9051 - loss: 0.2228\n",
      "Epoch 3 - MCC: 0.8272\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.9051 - loss: 0.2226 - val_accuracy: 0.9138 - val_loss: 0.2036 - mcc: 0.8272\n",
      "Epoch 4/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9121 - loss: 0.2041\n",
      "Epoch 4 - MCC: 0.8300\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9121 - loss: 0.2041 - val_accuracy: 0.9150 - val_loss: 0.1995 - mcc: 0.8300\n",
      "Epoch 5/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9156 - loss: 0.1975\n",
      "Epoch 5 - MCC: 0.8375\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 24ms/step - accuracy: 0.9156 - loss: 0.1975 - val_accuracy: 0.9189 - val_loss: 0.1918 - mcc: 0.8375\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9164 - loss: 0.1962\n",
      "Epoch 6 - MCC: 0.8365\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9164 - loss: 0.1961 - val_accuracy: 0.9184 - val_loss: 0.1922 - mcc: 0.8365\n",
      "Epoch 7/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9203 - loss: 0.1882\n",
      "Epoch 7 - MCC: 0.8415\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9203 - loss: 0.1882 - val_accuracy: 0.9208 - val_loss: 0.1884 - mcc: 0.8415\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9197 - loss: 0.1885\n",
      "Epoch 8 - MCC: 0.8414\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9197 - loss: 0.1885 - val_accuracy: 0.9209 - val_loss: 0.1870 - mcc: 0.8414\n",
      "Epoch 9/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9196 - loss: 0.1885\n",
      "Epoch 9 - MCC: 0.8409\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9196 - loss: 0.1885 - val_accuracy: 0.9207 - val_loss: 0.1865 - mcc: 0.8409\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9224 - loss: 0.1837\n",
      "Epoch 10 - MCC: 0.8437\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9224 - loss: 0.1837 - val_accuracy: 0.9217 - val_loss: 0.1874 - mcc: 0.8437\n",
      "Epoch 11/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9211 - loss: 0.1863\n",
      "Epoch 11 - MCC: 0.8439\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 25ms/step - accuracy: 0.9211 - loss: 0.1862 - val_accuracy: 0.9221 - val_loss: 0.1843 - mcc: 0.8439\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9222 - loss: 0.1836\n",
      "Epoch 12 - MCC: 0.8433\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9222 - loss: 0.1836 - val_accuracy: 0.9219 - val_loss: 0.1842 - mcc: 0.8433\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9223 - loss: 0.1838\n",
      "Epoch 13 - MCC: 0.8483\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 21ms/step - accuracy: 0.9224 - loss: 0.1838 - val_accuracy: 0.9244 - val_loss: 0.1802 - mcc: 0.8483\n",
      "Epoch 14/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9237 - loss: 0.1786\n",
      "Epoch 14 - MCC: 0.8486\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9237 - loss: 0.1786 - val_accuracy: 0.9242 - val_loss: 0.1807 - mcc: 0.8486\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9255 - loss: 0.1761\n",
      "Epoch 15 - MCC: 0.8486\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9255 - loss: 0.1761 - val_accuracy: 0.9245 - val_loss: 0.1802 - mcc: 0.8486\n",
      "Epoch 16/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9255 - loss: 0.1767\n",
      "Epoch 16 - MCC: 0.8485\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9255 - loss: 0.1767 - val_accuracy: 0.9245 - val_loss: 0.1790 - mcc: 0.8485\n",
      "Epoch 17/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9265 - loss: 0.1731\n",
      "Epoch 17 - MCC: 0.8526\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9265 - loss: 0.1732 - val_accuracy: 0.9264 - val_loss: 0.1760 - mcc: 0.8526\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9250 - loss: 0.1779\n",
      "Epoch 18 - MCC: 0.8513\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9250 - loss: 0.1779 - val_accuracy: 0.9258 - val_loss: 0.1751 - mcc: 0.8513\n",
      "Epoch 19/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9276 - loss: 0.1718\n",
      "Epoch 19 - MCC: 0.8548\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.9276 - loss: 0.1718 - val_accuracy: 0.9275 - val_loss: 0.1738 - mcc: 0.8548\n",
      "Epoch 20/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9252 - loss: 0.1770\n",
      "Epoch 20 - MCC: 0.8553\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.9252 - loss: 0.1769 - val_accuracy: 0.9278 - val_loss: 0.1723 - mcc: 0.8553\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7539 - loss: 0.5245\n",
      "Epoch 1 - MCC: 0.7585\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.7550 - loss: 0.5227 - val_accuracy: 0.8796 - val_loss: 0.2816 - mcc: 0.7585\n",
      "Epoch 2/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8895 - loss: 0.2606\n",
      "Epoch 2 - MCC: 0.8006\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 24ms/step - accuracy: 0.8895 - loss: 0.2605 - val_accuracy: 0.8998 - val_loss: 0.2293 - mcc: 0.8006\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9080 - loss: 0.2171\n",
      "Epoch 3 - MCC: 0.8218\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9080 - loss: 0.2170 - val_accuracy: 0.9111 - val_loss: 0.2074 - mcc: 0.8218\n",
      "Epoch 4/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9130 - loss: 0.2044\n",
      "Epoch 4 - MCC: 0.8293\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.9130 - loss: 0.2044 - val_accuracy: 0.9148 - val_loss: 0.1992 - mcc: 0.8293\n",
      "Epoch 5/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9142 - loss: 0.2002\n",
      "Epoch 5 - MCC: 0.8332\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9142 - loss: 0.2002 - val_accuracy: 0.9168 - val_loss: 0.1949 - mcc: 0.8332\n",
      "Epoch 6/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9167 - loss: 0.1973\n",
      "Epoch 6 - MCC: 0.8372\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9167 - loss: 0.1973 - val_accuracy: 0.9188 - val_loss: 0.1906 - mcc: 0.8372\n",
      "Epoch 7/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9191 - loss: 0.1928\n",
      "Epoch 7 - MCC: 0.8373\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9191 - loss: 0.1928 - val_accuracy: 0.9188 - val_loss: 0.1906 - mcc: 0.8373\n",
      "Epoch 8/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9191 - loss: 0.1898\n",
      "Epoch 8 - MCC: 0.8382\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 22ms/step - accuracy: 0.9191 - loss: 0.1897 - val_accuracy: 0.9193 - val_loss: 0.1884 - mcc: 0.8382\n",
      "Epoch 9/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9216 - loss: 0.1843\n",
      "Epoch 9 - MCC: 0.8399\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9216 - loss: 0.1843 - val_accuracy: 0.9202 - val_loss: 0.1871 - mcc: 0.8399\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9220 - loss: 0.1834\n",
      "Epoch 10 - MCC: 0.8438\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9220 - loss: 0.1835 - val_accuracy: 0.9221 - val_loss: 0.1830 - mcc: 0.8438\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9209 - loss: 0.1869\n",
      "Epoch 11 - MCC: 0.8449\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9210 - loss: 0.1869 - val_accuracy: 0.9227 - val_loss: 0.1819 - mcc: 0.8449\n",
      "Epoch 12/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9222 - loss: 0.1839\n",
      "Epoch 12 - MCC: 0.8434\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9222 - loss: 0.1838 - val_accuracy: 0.9219 - val_loss: 0.1825 - mcc: 0.8434\n",
      "Epoch 13/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9244 - loss: 0.1794\n",
      "Epoch 13 - MCC: 0.8482\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9244 - loss: 0.1794 - val_accuracy: 0.9241 - val_loss: 0.1788 - mcc: 0.8482\n",
      "Epoch 14/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9244 - loss: 0.1796\n",
      "Epoch 14 - MCC: 0.8489\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9244 - loss: 0.1796 - val_accuracy: 0.9243 - val_loss: 0.1779 - mcc: 0.8489\n",
      "Epoch 15/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9275 - loss: 0.1718\n",
      "Epoch 15 - MCC: 0.8423\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9275 - loss: 0.1718 - val_accuracy: 0.9210 - val_loss: 0.1840 - mcc: 0.8423\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9236 - loss: 0.1803\n",
      "Epoch 16 - MCC: 0.8507\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9236 - loss: 0.1803 - val_accuracy: 0.9255 - val_loss: 0.1751 - mcc: 0.8507\n",
      "Epoch 17/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9260 - loss: 0.1746\n",
      "Epoch 17 - MCC: 0.8480\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9260 - loss: 0.1746 - val_accuracy: 0.9238 - val_loss: 0.1793 - mcc: 0.8480\n",
      "Epoch 18/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9259 - loss: 0.1742\n",
      "Epoch 18 - MCC: 0.8533\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9259 - loss: 0.1742 - val_accuracy: 0.9267 - val_loss: 0.1728 - mcc: 0.8533\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9247 - loss: 0.1775\n",
      "Epoch 19 - MCC: 0.8549\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9247 - loss: 0.1775 - val_accuracy: 0.9275 - val_loss: 0.1718 - mcc: 0.8549\n",
      "Epoch 20/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9256 - loss: 0.1754\n",
      "Epoch 20 - MCC: 0.8537\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 25ms/step - accuracy: 0.9256 - loss: 0.1754 - val_accuracy: 0.9271 - val_loss: 0.1711 - mcc: 0.8537\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7445 - loss: 0.5474\n",
      "Epoch 1 - MCC: 0.7549\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 22ms/step - accuracy: 0.7453 - loss: 0.5460 - val_accuracy: 0.8776 - val_loss: 0.2883 - mcc: 0.7549\n",
      "Epoch 2/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8864 - loss: 0.2677\n",
      "Epoch 2 - MCC: 0.8045\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.8864 - loss: 0.2676 - val_accuracy: 0.9021 - val_loss: 0.2303 - mcc: 0.8045\n",
      "Epoch 3/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9069 - loss: 0.2182\n",
      "Epoch 3 - MCC: 0.8249\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9069 - loss: 0.2180 - val_accuracy: 0.9127 - val_loss: 0.2063 - mcc: 0.8249\n",
      "Epoch 4/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9128 - loss: 0.2032\n",
      "Epoch 4 - MCC: 0.8208\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9128 - loss: 0.2032 - val_accuracy: 0.9103 - val_loss: 0.2070 - mcc: 0.8208\n",
      "Epoch 5/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9141 - loss: 0.1993\n",
      "Epoch 5 - MCC: 0.8337\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 24ms/step - accuracy: 0.9141 - loss: 0.1993 - val_accuracy: 0.9170 - val_loss: 0.1971 - mcc: 0.8337\n",
      "Epoch 6/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9193 - loss: 0.1891\n",
      "Epoch 6 - MCC: 0.8317\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9193 - loss: 0.1891 - val_accuracy: 0.9161 - val_loss: 0.1958 - mcc: 0.8317\n",
      "Epoch 7/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9186 - loss: 0.1900\n",
      "Epoch 7 - MCC: 0.8364\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.9186 - loss: 0.1900 - val_accuracy: 0.9185 - val_loss: 0.1936 - mcc: 0.8364\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9199 - loss: 0.1882\n",
      "Epoch 8 - MCC: 0.8364\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 25ms/step - accuracy: 0.9199 - loss: 0.1882 - val_accuracy: 0.9185 - val_loss: 0.1902 - mcc: 0.8364\n",
      "Epoch 9/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9214 - loss: 0.1848\n",
      "Epoch 9 - MCC: 0.8345\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9214 - loss: 0.1847 - val_accuracy: 0.9175 - val_loss: 0.1915 - mcc: 0.8345\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9196 - loss: 0.1881\n",
      "Epoch 10 - MCC: 0.8350\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9196 - loss: 0.1881 - val_accuracy: 0.9177 - val_loss: 0.1908 - mcc: 0.8350\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9217 - loss: 0.1833\n",
      "Epoch 11 - MCC: 0.8416\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 24ms/step - accuracy: 0.9217 - loss: 0.1833 - val_accuracy: 0.9211 - val_loss: 0.1866 - mcc: 0.8416\n",
      "Epoch 12/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9239 - loss: 0.1791\n",
      "Epoch 12 - MCC: 0.8465\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9239 - loss: 0.1791 - val_accuracy: 0.9233 - val_loss: 0.1835 - mcc: 0.8465\n",
      "Epoch 13/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9240 - loss: 0.1781\n",
      "Epoch 13 - MCC: 0.8426\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9240 - loss: 0.1781 - val_accuracy: 0.9214 - val_loss: 0.1857 - mcc: 0.8426\n",
      "Epoch 14/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9256 - loss: 0.1751\n",
      "Epoch 14 - MCC: 0.8480\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9256 - loss: 0.1751 - val_accuracy: 0.9239 - val_loss: 0.1818 - mcc: 0.8480\n",
      "Epoch 15/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9279 - loss: 0.1704\n",
      "Epoch 15 - MCC: 0.8462\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9279 - loss: 0.1704 - val_accuracy: 0.9233 - val_loss: 0.1811 - mcc: 0.8462\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9272 - loss: 0.1725\n",
      "Epoch 16 - MCC: 0.8478\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 24ms/step - accuracy: 0.9272 - loss: 0.1725 - val_accuracy: 0.9238 - val_loss: 0.1805 - mcc: 0.8478\n",
      "Epoch 17/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9261 - loss: 0.1740\n",
      "Epoch 17 - MCC: 0.8494\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9261 - loss: 0.1739 - val_accuracy: 0.9248 - val_loss: 0.1788 - mcc: 0.8494\n",
      "Epoch 18/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9290 - loss: 0.1682\n",
      "Epoch 18 - MCC: 0.8506\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9290 - loss: 0.1683 - val_accuracy: 0.9254 - val_loss: 0.1778 - mcc: 0.8506\n",
      "Epoch 19/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9284 - loss: 0.1696\n",
      "Epoch 19 - MCC: 0.8507\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.9284 - loss: 0.1696 - val_accuracy: 0.9255 - val_loss: 0.1773 - mcc: 0.8507\n",
      "Epoch 20/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9275 - loss: 0.1706\n",
      "Epoch 20 - MCC: 0.8536\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9275 - loss: 0.1706 - val_accuracy: 0.9269 - val_loss: 0.1739 - mcc: 0.8536\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.7257 - loss: 0.5170\n",
      "Epoch 1 - MCC: 0.7497\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 26ms/step - accuracy: 0.7266 - loss: 0.5158 - val_accuracy: 0.8752 - val_loss: 0.2926 - mcc: 0.7497\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8824 - loss: 0.2778\n",
      "Epoch 2 - MCC: 0.8091\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.8825 - loss: 0.2776 - val_accuracy: 0.9048 - val_loss: 0.2257 - mcc: 0.8091\n",
      "Epoch 3/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9085 - loss: 0.2177\n",
      "Epoch 3 - MCC: 0.8279\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.9085 - loss: 0.2177 - val_accuracy: 0.9142 - val_loss: 0.2020 - mcc: 0.8279\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9150 - loss: 0.2015\n",
      "Epoch 4 - MCC: 0.8327\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 24ms/step - accuracy: 0.9150 - loss: 0.2015 - val_accuracy: 0.9166 - val_loss: 0.1959 - mcc: 0.8327\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9168 - loss: 0.1970\n",
      "Epoch 5 - MCC: 0.8378\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9168 - loss: 0.1970 - val_accuracy: 0.9191 - val_loss: 0.1899 - mcc: 0.8378\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9207 - loss: 0.1878\n",
      "Epoch 6 - MCC: 0.8388\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9207 - loss: 0.1879 - val_accuracy: 0.9196 - val_loss: 0.1873 - mcc: 0.8388\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9176 - loss: 0.1934\n",
      "Epoch 7 - MCC: 0.8417\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 24ms/step - accuracy: 0.9176 - loss: 0.1934 - val_accuracy: 0.9210 - val_loss: 0.1844 - mcc: 0.8417\n",
      "Epoch 8/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9215 - loss: 0.1849\n",
      "Epoch 8 - MCC: 0.8436\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9215 - loss: 0.1849 - val_accuracy: 0.9220 - val_loss: 0.1815 - mcc: 0.8436\n",
      "Epoch 9/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9214 - loss: 0.1846\n",
      "Epoch 9 - MCC: 0.8433\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 21ms/step - accuracy: 0.9214 - loss: 0.1847 - val_accuracy: 0.9218 - val_loss: 0.1817 - mcc: 0.8433\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9214 - loss: 0.1848\n",
      "Epoch 10 - MCC: 0.8460\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9214 - loss: 0.1848 - val_accuracy: 0.9232 - val_loss: 0.1789 - mcc: 0.8460\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9233 - loss: 0.1810\n",
      "Epoch 11 - MCC: 0.8452\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9233 - loss: 0.1810 - val_accuracy: 0.9225 - val_loss: 0.1807 - mcc: 0.8452\n",
      "Epoch 12/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9230 - loss: 0.1825\n",
      "Epoch 12 - MCC: 0.8477\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9230 - loss: 0.1825 - val_accuracy: 0.9241 - val_loss: 0.1768 - mcc: 0.8477\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9241 - loss: 0.1790\n",
      "Epoch 13 - MCC: 0.8478\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9241 - loss: 0.1790 - val_accuracy: 0.9241 - val_loss: 0.1767 - mcc: 0.8478\n",
      "Epoch 14/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9245 - loss: 0.1792\n",
      "Epoch 14 - MCC: 0.8505\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9245 - loss: 0.1792 - val_accuracy: 0.9253 - val_loss: 0.1738 - mcc: 0.8505\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9252 - loss: 0.1776\n",
      "Epoch 15 - MCC: 0.8511\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9252 - loss: 0.1776 - val_accuracy: 0.9258 - val_loss: 0.1732 - mcc: 0.8511\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9246 - loss: 0.1768\n",
      "Epoch 16 - MCC: 0.8520\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9246 - loss: 0.1768 - val_accuracy: 0.9262 - val_loss: 0.1720 - mcc: 0.8520\n",
      "Epoch 17/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9269 - loss: 0.1728\n",
      "Epoch 17 - MCC: 0.8535\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9269 - loss: 0.1728 - val_accuracy: 0.9268 - val_loss: 0.1708 - mcc: 0.8535\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9268 - loss: 0.1727\n",
      "Epoch 18 - MCC: 0.8538\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9268 - loss: 0.1727 - val_accuracy: 0.9271 - val_loss: 0.1697 - mcc: 0.8538\n",
      "Epoch 19/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9275 - loss: 0.1713\n",
      "Epoch 19 - MCC: 0.8515\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.9275 - loss: 0.1714 - val_accuracy: 0.9259 - val_loss: 0.1736 - mcc: 0.8515\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9279 - loss: 0.1708\n",
      "Epoch 20 - MCC: 0.8539\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9279 - loss: 0.1708 - val_accuracy: 0.9271 - val_loss: 0.1702 - mcc: 0.8539\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.7379 - loss: 0.5226\n",
      "Epoch 1 - MCC: 0.7462\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 27ms/step - accuracy: 0.7391 - loss: 0.5208 - val_accuracy: 0.8734 - val_loss: 0.2948 - mcc: 0.7462\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8815 - loss: 0.2791\n",
      "Epoch 2 - MCC: 0.7987\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8816 - loss: 0.2789 - val_accuracy: 0.8997 - val_loss: 0.2385 - mcc: 0.7987\n",
      "Epoch 3/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9048 - loss: 0.2261\n",
      "Epoch 3 - MCC: 0.8188\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9049 - loss: 0.2260 - val_accuracy: 0.9096 - val_loss: 0.2122 - mcc: 0.8188\n",
      "Epoch 4/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9114 - loss: 0.2080\n",
      "Epoch 4 - MCC: 0.8272\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9114 - loss: 0.2080 - val_accuracy: 0.9139 - val_loss: 0.2014 - mcc: 0.8272\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9155 - loss: 0.1998\n",
      "Epoch 5 - MCC: 0.8309\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9155 - loss: 0.1998 - val_accuracy: 0.9157 - val_loss: 0.1974 - mcc: 0.8309\n",
      "Epoch 6/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9147 - loss: 0.2011\n",
      "Epoch 6 - MCC: 0.8323\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.9147 - loss: 0.2011 - val_accuracy: 0.9164 - val_loss: 0.1944 - mcc: 0.8323\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9183 - loss: 0.1919\n",
      "Epoch 7 - MCC: 0.8366\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.9183 - loss: 0.1919 - val_accuracy: 0.9186 - val_loss: 0.1918 - mcc: 0.8366\n",
      "Epoch 8/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9178 - loss: 0.1941\n",
      "Epoch 8 - MCC: 0.8316\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9178 - loss: 0.1940 - val_accuracy: 0.9160 - val_loss: 0.1949 - mcc: 0.8316\n",
      "Epoch 9/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9183 - loss: 0.1931\n",
      "Epoch 9 - MCC: 0.8418\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.9183 - loss: 0.1931 - val_accuracy: 0.9211 - val_loss: 0.1850 - mcc: 0.8418\n",
      "Epoch 10/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9180 - loss: 0.1916\n",
      "Epoch 10 - MCC: 0.8396\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 22ms/step - accuracy: 0.9180 - loss: 0.1916 - val_accuracy: 0.9200 - val_loss: 0.1881 - mcc: 0.8396\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9208 - loss: 0.1866\n",
      "Epoch 11 - MCC: 0.8433\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9208 - loss: 0.1866 - val_accuracy: 0.9219 - val_loss: 0.1832 - mcc: 0.8433\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9226 - loss: 0.1821\n",
      "Epoch 12 - MCC: 0.8443\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 22ms/step - accuracy: 0.9226 - loss: 0.1821 - val_accuracy: 0.9224 - val_loss: 0.1820 - mcc: 0.8443\n",
      "Epoch 13/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9214 - loss: 0.1854\n",
      "Epoch 13 - MCC: 0.8464\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9214 - loss: 0.1853 - val_accuracy: 0.9233 - val_loss: 0.1806 - mcc: 0.8464\n",
      "Epoch 14/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9223 - loss: 0.1820\n",
      "Epoch 14 - MCC: 0.8461\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9223 - loss: 0.1820 - val_accuracy: 0.9230 - val_loss: 0.1810 - mcc: 0.8461\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9243 - loss: 0.1792\n",
      "Epoch 15 - MCC: 0.8494\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9243 - loss: 0.1792 - val_accuracy: 0.9250 - val_loss: 0.1761 - mcc: 0.8494\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9259 - loss: 0.1746\n",
      "Epoch 16 - MCC: 0.8502\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9259 - loss: 0.1746 - val_accuracy: 0.9253 - val_loss: 0.1750 - mcc: 0.8502\n",
      "Epoch 17/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9257 - loss: 0.1752\n",
      "Epoch 17 - MCC: 0.8502\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9257 - loss: 0.1752 - val_accuracy: 0.9253 - val_loss: 0.1760 - mcc: 0.8502\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9260 - loss: 0.1733\n",
      "Epoch 18 - MCC: 0.8532\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9260 - loss: 0.1733 - val_accuracy: 0.9268 - val_loss: 0.1727 - mcc: 0.8532\n",
      "Epoch 19/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9281 - loss: 0.1716\n",
      "Epoch 19 - MCC: 0.8526\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9280 - loss: 0.1717 - val_accuracy: 0.9263 - val_loss: 0.1743 - mcc: 0.8526\n",
      "Epoch 20/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9227 - loss: 0.1809\n",
      "Epoch 20 - MCC: 0.8534\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9228 - loss: 0.1808 - val_accuracy: 0.9268 - val_loss: 0.1725 - mcc: 0.8534\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.9278053333333334),\n",
      "              'mean': np.float64(0.9271354666666667),\n",
      "              'min': np.float64(0.9268106666666667),\n",
      "              'std': np.float64(0.00035483865504073325)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.0005051705042521159),\n",
      "                               'mean': np.float64(0.0004744166056315104),\n",
      "                               'min': np.float64(0.00043900171915690103),\n",
      "                               'std': np.float64(2.1198358273592315e-05)},\n",
      " 'MCC': {'max': np.float64(0.8552703820495884),\n",
      "         'mean': np.float64(0.8539760629264224),\n",
      "         'min': np.float64(0.8534493309443517),\n",
      "         'std': np.float64(0.0006628434212835914)},\n",
      " 'Parameters': 4589,\n",
      " 'Train Time (s)': {'max': np.float64(97.17264461517334),\n",
      "                    'mean': np.float64(92.58644342422485),\n",
      "                    'min': np.float64(88.41980051994324),\n",
      "                    'std': np.float64(2.981414362697602)},\n",
      " 'Training Accuracy': [[0.8146133422851562,\n",
      "                        0.8886179327964783,\n",
      "                        0.9078896641731262,\n",
      "                        0.9136572480201721,\n",
      "                        0.9155247211456299,\n",
      "                        0.9173674583435059,\n",
      "                        0.9188513159751892,\n",
      "                        0.9200844764709473,\n",
      "                        0.9200206995010376,\n",
      "                        0.9211394786834717,\n",
      "                        0.92191481590271,\n",
      "                        0.9230669140815735,\n",
      "                        0.9233201742172241,\n",
      "                        0.923984706401825,\n",
      "                        0.9246059656143188,\n",
      "                        0.9244665503501892,\n",
      "                        0.9252423644065857,\n",
      "                        0.9261859655380249,\n",
      "                        0.9263238906860352,\n",
      "                        0.9263041019439697],\n",
      "                       [0.8195927739143372,\n",
      "                        0.896013617515564,\n",
      "                        0.9099805355072021,\n",
      "                        0.9134846329689026,\n",
      "                        0.915245532989502,\n",
      "                        0.9175771474838257,\n",
      "                        0.9189426302909851,\n",
      "                        0.919885516166687,\n",
      "                        0.9206364154815674,\n",
      "                        0.9211768507957458,\n",
      "                        0.9222510457038879,\n",
      "                        0.9235888719558716,\n",
      "                        0.9239144921302795,\n",
      "                        0.924297034740448,\n",
      "                        0.9249913692474365,\n",
      "                        0.9248318672180176,\n",
      "                        0.9259613156318665,\n",
      "                        0.9262502193450928,\n",
      "                        0.926659107208252,\n",
      "                        0.9265942573547363],\n",
      "                       [0.8181508183479309,\n",
      "                        0.8928351402282715,\n",
      "                        0.9093043804168701,\n",
      "                        0.9137994050979614,\n",
      "                        0.9161386489868164,\n",
      "                        0.918430507183075,\n",
      "                        0.9190643429756165,\n",
      "                        0.9203314781188965,\n",
      "                        0.9217813611030579,\n",
      "                        0.9222580790519714,\n",
      "                        0.9230607748031616,\n",
      "                        0.923840343952179,\n",
      "                        0.9246989488601685,\n",
      "                        0.9255748987197876,\n",
      "                        0.9260913133621216,\n",
      "                        0.9263579249382019,\n",
      "                        0.927508533000946,\n",
      "                        0.9275643825531006,\n",
      "                        0.9282295107841492,\n",
      "                        0.9285200834274292],\n",
      "                       [0.8095952868461609,\n",
      "                        0.8912059664726257,\n",
      "                        0.9089906215667725,\n",
      "                        0.9147090911865234,\n",
      "                        0.9173104763031006,\n",
      "                        0.9187760949134827,\n",
      "                        0.9201110601425171,\n",
      "                        0.9210875630378723,\n",
      "                        0.921315610408783,\n",
      "                        0.922886073589325,\n",
      "                        0.9234721660614014,\n",
      "                        0.9238818883895874,\n",
      "                        0.9243754744529724,\n",
      "                        0.9242411255836487,\n",
      "                        0.9251018762588501,\n",
      "                        0.9252339601516724,\n",
      "                        0.9257422685623169,\n",
      "                        0.9266093969345093,\n",
      "                        0.9270781874656677,\n",
      "                        0.9275510907173157],\n",
      "                       [0.8127099871635437,\n",
      "                        0.8882092833518982,\n",
      "                        0.9062392711639404,\n",
      "                        0.9112627506256104,\n",
      "                        0.9148045182228088,\n",
      "                        0.9165076613426208,\n",
      "                        0.9175354242324829,\n",
      "                        0.9188206195831299,\n",
      "                        0.9196206331253052,\n",
      "                        0.9201980829238892,\n",
      "                        0.9212388396263123,\n",
      "                        0.9221336245536804,\n",
      "                        0.9228163957595825,\n",
      "                        0.9230170845985413,\n",
      "                        0.9239841103553772,\n",
      "                        0.9240238666534424,\n",
      "                        0.9244596362113953,\n",
      "                        0.9254266023635864,\n",
      "                        0.9258890151977539,\n",
      "                        0.9259700775146484]],\n",
      " 'Training Loss': [[0.4069460332393646,\n",
      "                    0.2614764869213104,\n",
      "                    0.21599161624908447,\n",
      "                    0.2020542472600937,\n",
      "                    0.19771848618984222,\n",
      "                    0.19382740557193756,\n",
      "                    0.19091178476810455,\n",
      "                    0.1880102902650833,\n",
      "                    0.18748632073402405,\n",
      "                    0.1854945421218872,\n",
      "                    0.18404339253902435,\n",
      "                    0.18165500462055206,\n",
      "                    0.18150590360164642,\n",
      "                    0.17934779822826385,\n",
      "                    0.1783052384853363,\n",
      "                    0.1786566525697708,\n",
      "                    0.1765068918466568,\n",
      "                    0.17454266548156738,\n",
      "                    0.1740015298128128,\n",
      "                    0.1739148199558258],\n",
      "                   [0.40580037236213684,\n",
      "                    0.2447376549243927,\n",
      "                    0.2119792103767395,\n",
      "                    0.20341484248638153,\n",
      "                    0.19891011714935303,\n",
      "                    0.19461311399936676,\n",
      "                    0.19187265634536743,\n",
      "                    0.1891864389181137,\n",
      "                    0.1871827244758606,\n",
      "                    0.18597529828548431,\n",
      "                    0.18366847932338715,\n",
      "                    0.1808532178401947,\n",
      "                    0.18001632392406464,\n",
      "                    0.17836545407772064,\n",
      "                    0.17676092684268951,\n",
      "                    0.17726387083530426,\n",
      "                    0.17464807629585266,\n",
      "                    0.17389874160289764,\n",
      "                    0.1733098328113556,\n",
      "                    0.1730772703886032],\n",
      "                   [0.4176922142505646,\n",
      "                    0.25199273228645325,\n",
      "                    0.21255932748317719,\n",
      "                    0.20140570402145386,\n",
      "                    0.19555602967739105,\n",
      "                    0.190738245844841,\n",
      "                    0.18936604261398315,\n",
      "                    0.18643298745155334,\n",
      "                    0.18387871980667114,\n",
      "                    0.1822495460510254,\n",
      "                    0.18073561787605286,\n",
      "                    0.17910414934158325,\n",
      "                    0.17756369709968567,\n",
      "                    0.17511922121047974,\n",
      "                    0.17426270246505737,\n",
      "                    0.17346225678920746,\n",
      "                    0.17157535254955292,\n",
      "                    0.1707654446363449,\n",
      "                    0.16953013837337494,\n",
      "                    0.16866426169872284],\n",
      "                   [0.4044496715068817,\n",
      "                    0.25692132115364075,\n",
      "                    0.21559014916419983,\n",
      "                    0.20137208700180054,\n",
      "                    0.19532239437103271,\n",
      "                    0.19194112718105316,\n",
      "                    0.18812024593353271,\n",
      "                    0.18590877950191498,\n",
      "                    0.18516956269741058,\n",
      "                    0.18222518265247345,\n",
      "                    0.18078702688217163,\n",
      "                    0.179520383477211,\n",
      "                    0.17845655977725983,\n",
      "                    0.17799971997737885,\n",
      "                    0.1766931563615799,\n",
      "                    0.17597565054893494,\n",
      "                    0.17514678835868835,\n",
      "                    0.1731916069984436,\n",
      "                    0.1725439429283142,\n",
      "                    0.17107324302196503],\n",
      "                   [0.4075385630130768,\n",
      "                    0.2648759186267853,\n",
      "                    0.2224484086036682,\n",
      "                    0.20903484523296356,\n",
      "                    0.20072582364082336,\n",
      "                    0.19691523909568787,\n",
      "                    0.19417698681354523,\n",
      "                    0.19155851006507874,\n",
      "                    0.1897541880607605,\n",
      "                    0.18801939487457275,\n",
      "                    0.18578718602657318,\n",
      "                    0.18364858627319336,\n",
      "                    0.18243521451950073,\n",
      "                    0.18110530078411102,\n",
      "                    0.17968322336673737,\n",
      "                    0.1786281317472458,\n",
      "                    0.17781154811382294,\n",
      "                    0.1755719780921936,\n",
      "                    0.17524948716163635,\n",
      "                    0.17438271641731262]],\n",
      " 'Validation Accuracy': [[0.8744186162948608,\n",
      "                          0.9013091921806335,\n",
      "                          0.9138372540473938,\n",
      "                          0.9150400161743164,\n",
      "                          0.9189120531082153,\n",
      "                          0.9184160828590393,\n",
      "                          0.9208452701568604,\n",
      "                          0.9209146499633789,\n",
      "                          0.9206640720367432,\n",
      "                          0.9216933846473694,\n",
      "                          0.9220826625823975,\n",
      "                          0.9218801259994507,\n",
      "                          0.9243600368499756,\n",
      "                          0.9242026209831238,\n",
      "                          0.9244533777236938,\n",
      "                          0.9244587421417236,\n",
      "                          0.9263706207275391,\n",
      "                          0.9258453845977783,\n",
      "                          0.9274746179580688,\n",
      "                          0.9278054237365723],\n",
      "                         [0.879573404788971,\n",
      "                          0.8998294472694397,\n",
      "                          0.9111467003822327,\n",
      "                          0.9148160219192505,\n",
      "                          0.916842520236969,\n",
      "                          0.918842613697052,\n",
      "                          0.9188025593757629,\n",
      "                          0.9192959666252136,\n",
      "                          0.9201521277427673,\n",
      "                          0.9221360683441162,\n",
      "                          0.9226853847503662,\n",
      "                          0.9218558669090271,\n",
      "                          0.9241305589675903,\n",
      "                          0.924333393573761,\n",
      "                          0.9210346937179565,\n",
      "                          0.9255388379096985,\n",
      "                          0.9238320589065552,\n",
      "                          0.9267013072967529,\n",
      "                          0.9275013208389282,\n",
      "                          0.9270585775375366],\n",
      "                         [0.8775708079338074,\n",
      "                          0.9021305441856384,\n",
      "                          0.9126880764961243,\n",
      "                          0.9103493094444275,\n",
      "                          0.9169999957084656,\n",
      "                          0.916053295135498,\n",
      "                          0.9185120463371277,\n",
      "                          0.9185013175010681,\n",
      "                          0.9174878597259521,\n",
      "                          0.9176533222198486,\n",
      "                          0.921053409576416,\n",
      "                          0.9232560992240906,\n",
      "                          0.9214054942131042,\n",
      "                          0.9238932132720947,\n",
      "                          0.9233360290527344,\n",
      "                          0.9237866997718811,\n",
      "                          0.9247869253158569,\n",
      "                          0.9253919124603271,\n",
      "                          0.9254986047744751,\n",
      "                          0.9268721342086792],\n",
      "                         [0.8752452731132507,\n",
      "                          0.9048293232917786,\n",
      "                          0.9142214059829712,\n",
      "                          0.9165707230567932,\n",
      "                          0.9191119074821472,\n",
      "                          0.9196158647537231,\n",
      "                          0.9209734797477722,\n",
      "                          0.9220107197761536,\n",
      "                          0.9218479990959167,\n",
      "                          0.9232295155525208,\n",
      "                          0.9225466847419739,\n",
      "                          0.9240960478782654,\n",
      "                          0.924127995967865,\n",
      "                          0.9253493547439575,\n",
      "                          0.9257761240005493,\n",
      "                          0.9261946082115173,\n",
      "                          0.926773190498352,\n",
      "                          0.9271226525306702,\n",
      "                          0.9259386658668518,\n",
      "                          0.9271306395530701],\n",
      "                         [0.8733653426170349,\n",
      "                          0.8997147679328918,\n",
      "                          0.9096212387084961,\n",
      "                          0.9138586521148682,\n",
      "                          0.9157440066337585,\n",
      "                          0.9164159297943115,\n",
      "                          0.9185655117034912,\n",
      "                          0.9159842133522034,\n",
      "                          0.9211358428001404,\n",
      "                          0.9200295209884644,\n",
      "                          0.9219332933425903,\n",
      "                          0.9223759770393372,\n",
      "                          0.9233413934707642,\n",
      "                          0.9229627251625061,\n",
      "                          0.9249573349952698,\n",
      "                          0.9253413081169128,\n",
      "                          0.9253036975860596,\n",
      "                          0.9268000721931458,\n",
      "                          0.9263467788696289,\n",
      "                          0.9268105626106262]],\n",
      " 'Validation Loss': [0.294793039560318,\n",
      "                     0.23854008316993713,\n",
      "                     0.21224185824394226,\n",
      "                     0.2013562172651291,\n",
      "                     0.1974061131477356,\n",
      "                     0.19440944492816925,\n",
      "                     0.19179289042949677,\n",
      "                     0.19493243098258972,\n",
      "                     0.18498362600803375,\n",
      "                     0.18806898593902588,\n",
      "                     0.1831963062286377,\n",
      "                     0.18200907111167908,\n",
      "                     0.18056076765060425,\n",
      "                     0.1810038834810257,\n",
      "                     0.1761118620634079,\n",
      "                     0.17503567039966583,\n",
      "                     0.17601454257965088,\n",
      "                     0.17274436354637146,\n",
      "                     0.17431126534938812,\n",
      "                     0.1725175827741623],\n",
      " 'Validation MCC': [[np.float64(0.7480981101861237),\n",
      "                     np.float64(0.8032726280503313),\n",
      "                     np.float64(0.8272238256683835),\n",
      "                     np.float64(0.8299837953711459),\n",
      "                     np.float64(0.8375120056746151),\n",
      "                     np.float64(0.8364798048137597),\n",
      "                     np.float64(0.8414628833977185),\n",
      "                     np.float64(0.8414104616621836),\n",
      "                     np.float64(0.8408886917800882),\n",
      "                     np.float64(0.8436817676979963),\n",
      "                     np.float64(0.8438857615038869),\n",
      "                     np.float64(0.843329299033613),\n",
      "                     np.float64(0.8483103678290604),\n",
      "                     np.float64(0.8486403642100713),\n",
      "                     np.float64(0.8485937144591907),\n",
      "                     np.float64(0.8485074067470986),\n",
      "                     np.float64(0.852551583463421),\n",
      "                     np.float64(0.8513052737253052),\n",
      "                     np.float64(0.8547673684429633),\n",
      "                     np.float64(0.8552703820495884)],\n",
      "                    [np.float64(0.758457245688518),\n",
      "                     np.float64(0.8006166294712934),\n",
      "                     np.float64(0.821781838780022),\n",
      "                     np.float64(0.8293398905838438),\n",
      "                     np.float64(0.8331884309563321),\n",
      "                     np.float64(0.8372378324141146),\n",
      "                     np.float64(0.8373157841268135),\n",
      "                     np.float64(0.8381606640869431),\n",
      "                     np.float64(0.8398545238475538),\n",
      "                     np.float64(0.8438260266241143),\n",
      "                     np.float64(0.8449376671599621),\n",
      "                     np.float64(0.8434335656601575),\n",
      "                     np.float64(0.8481566234376404),\n",
      "                     np.float64(0.848934966224883),\n",
      "                     np.float64(0.8423445635756426),\n",
      "                     np.float64(0.8506517334870028),\n",
      "                     np.float64(0.847965228526653),\n",
      "                     np.float64(0.8532786902745829),\n",
      "                     np.float64(0.8549207356581968),\n",
      "                     np.float64(0.8537482254202309)],\n",
      "                    [np.float64(0.7548963948647088),\n",
      "                     np.float64(0.8045048733991239),\n",
      "                     np.float64(0.8248891479050593),\n",
      "                     np.float64(0.8208111121593952),\n",
      "                     np.float64(0.833728961577969),\n",
      "                     np.float64(0.831724140754428),\n",
      "                     np.float64(0.836445323889791),\n",
      "                     np.float64(0.8364125134044317),\n",
      "                     np.float64(0.8344991411296074),\n",
      "                     np.float64(0.8349992855126964),\n",
      "                     np.float64(0.8415589051718528),\n",
      "                     np.float64(0.8464596600695363),\n",
      "                     np.float64(0.8426130717862722),\n",
      "                     np.float64(0.8479994091438934),\n",
      "                     np.float64(0.8461562358390826),\n",
      "                     np.float64(0.8478087618418316),\n",
      "                     np.float64(0.8494049099789919),\n",
      "                     np.float64(0.8505763928886377),\n",
      "                     np.float64(0.8506506679087532),\n",
      "                     np.float64(0.8535536698006458)],\n",
      "                    [np.float64(0.7497076215169042),\n",
      "                     np.float64(0.8091050721016806),\n",
      "                     np.float64(0.8279375538520818),\n",
      "                     np.float64(0.8327387565125491),\n",
      "                     np.float64(0.8378230667936046),\n",
      "                     np.float64(0.8387996701803946),\n",
      "                     np.float64(0.8416836748278074),\n",
      "                     np.float64(0.8435897614058092),\n",
      "                     np.float64(0.843270282256085),\n",
      "                     np.float64(0.8460347576949138),\n",
      "                     np.float64(0.8452223924972962),\n",
      "                     np.float64(0.8477483441848148),\n",
      "                     np.float64(0.8478386676400231),\n",
      "                     np.float64(0.8504539061580019),\n",
      "                     np.float64(0.851145693475522),\n",
      "                     np.float64(0.8519937886966402),\n",
      "                     np.float64(0.8535132335643066),\n",
      "                     np.float64(0.8538471654797587),\n",
      "                     np.float64(0.8514658721425398),\n",
      "                     np.float64(0.8538587064172951)],\n",
      "                    [np.float64(0.746164368635013),\n",
      "                     np.float64(0.7986977030122586),\n",
      "                     np.float64(0.8188421553707657),\n",
      "                     np.float64(0.8272004742569462),\n",
      "                     np.float64(0.8309334604409405),\n",
      "                     np.float64(0.8323396680259547),\n",
      "                     np.float64(0.8366431034188123),\n",
      "                     np.float64(0.8316187358859134),\n",
      "                     np.float64(0.8418006771975585),\n",
      "                     np.float64(0.8395514942087908),\n",
      "                     np.float64(0.8433124562436106),\n",
      "                     np.float64(0.8442787212566992),\n",
      "                     np.float64(0.8464394896466239),\n",
      "                     np.float64(0.8461254246969809),\n",
      "                     np.float64(0.8494025443021035),\n",
      "                     np.float64(0.8502347924087771),\n",
      "                     np.float64(0.8502434152520787),\n",
      "                     np.float64(0.8531520596354785),\n",
      "                     np.float64(0.8526100470581375),\n",
      "                     np.float64(0.8534493309443517)]]}\n",
      "Training Model: TCN, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.6402 - loss: 0.9027\n",
      "Epoch 1 - MCC: 0.7546\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 47ms/step - accuracy: 0.6408 - loss: 0.9008 - val_accuracy: 0.8772 - val_loss: 0.2850 - mcc: 0.7546\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8851 - loss: 0.2669\n",
      "Epoch 2 - MCC: 0.8113\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8852 - loss: 0.2668 - val_accuracy: 0.9059 - val_loss: 0.2218 - mcc: 0.8113\n",
      "Epoch 3/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9072 - loss: 0.2171\n",
      "Epoch 3 - MCC: 0.8250\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9072 - loss: 0.2172 - val_accuracy: 0.9127 - val_loss: 0.2061 - mcc: 0.8250\n",
      "Epoch 4/20\n",
      "\u001B[1m175/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9115 - loss: 0.2063\n",
      "Epoch 4 - MCC: 0.8327\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9115 - loss: 0.2063 - val_accuracy: 0.9166 - val_loss: 0.1977 - mcc: 0.8327\n",
      "Epoch 5/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9162 - loss: 0.1968\n",
      "Epoch 5 - MCC: 0.8383\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9162 - loss: 0.1968 - val_accuracy: 0.9194 - val_loss: 0.1912 - mcc: 0.8383\n",
      "Epoch 6/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9172 - loss: 0.1937\n",
      "Epoch 6 - MCC: 0.8420\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9172 - loss: 0.1936 - val_accuracy: 0.9207 - val_loss: 0.1906 - mcc: 0.8420\n",
      "Epoch 7/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9188 - loss: 0.1906\n",
      "Epoch 7 - MCC: 0.8434\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9189 - loss: 0.1904 - val_accuracy: 0.9219 - val_loss: 0.1861 - mcc: 0.8434\n",
      "Epoch 8/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9203 - loss: 0.1877\n",
      "Epoch 8 - MCC: 0.8490\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9204 - loss: 0.1876 - val_accuracy: 0.9246 - val_loss: 0.1808 - mcc: 0.8490\n",
      "Epoch 9/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9215 - loss: 0.1842\n",
      "Epoch 9 - MCC: 0.8496\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - accuracy: 0.9216 - loss: 0.1842 - val_accuracy: 0.9245 - val_loss: 0.1816 - mcc: 0.8496\n",
      "Epoch 10/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9243 - loss: 0.1794\n",
      "Epoch 10 - MCC: 0.8489\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.9242 - loss: 0.1794 - val_accuracy: 0.9246 - val_loss: 0.1792 - mcc: 0.8489\n",
      "Epoch 11/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9243 - loss: 0.1796\n",
      "Epoch 11 - MCC: 0.8505\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9243 - loss: 0.1795 - val_accuracy: 0.9253 - val_loss: 0.1761 - mcc: 0.8505\n",
      "Epoch 12/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9270 - loss: 0.1720\n",
      "Epoch 12 - MCC: 0.8532\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9269 - loss: 0.1722 - val_accuracy: 0.9268 - val_loss: 0.1739 - mcc: 0.8532\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9270 - loss: 0.1727\n",
      "Epoch 13 - MCC: 0.8562\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9270 - loss: 0.1727 - val_accuracy: 0.9283 - val_loss: 0.1707 - mcc: 0.8562\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9257 - loss: 0.1747\n",
      "Epoch 14 - MCC: 0.8570\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9257 - loss: 0.1747 - val_accuracy: 0.9287 - val_loss: 0.1691 - mcc: 0.8570\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9253 - loss: 0.1774\n",
      "Epoch 15 - MCC: 0.8564\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9253 - loss: 0.1773 - val_accuracy: 0.9282 - val_loss: 0.1712 - mcc: 0.8564\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9274 - loss: 0.1707\n",
      "Epoch 16 - MCC: 0.8595\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9274 - loss: 0.1707 - val_accuracy: 0.9299 - val_loss: 0.1666 - mcc: 0.8595\n",
      "Epoch 17/20\n",
      "\u001B[1m175/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9284 - loss: 0.1689\n",
      "Epoch 17 - MCC: 0.8612\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9284 - loss: 0.1690 - val_accuracy: 0.9306 - val_loss: 0.1667 - mcc: 0.8612\n",
      "Epoch 18/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9292 - loss: 0.1665\n",
      "Epoch 18 - MCC: 0.8566\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9292 - loss: 0.1666 - val_accuracy: 0.9285 - val_loss: 0.1690 - mcc: 0.8566\n",
      "Epoch 19/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9285 - loss: 0.1698\n",
      "Epoch 19 - MCC: 0.8578\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9285 - loss: 0.1698 - val_accuracy: 0.9291 - val_loss: 0.1674 - mcc: 0.8578\n",
      "Epoch 20/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9269 - loss: 0.1720\n",
      "Epoch 20 - MCC: 0.8554\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.9269 - loss: 0.1720 - val_accuracy: 0.9277 - val_loss: 0.1701 - mcc: 0.8554\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: TCN, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6725 - loss: 0.7276\n",
      "Epoch 1 - MCC: 0.7647\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 41ms/step - accuracy: 0.6731 - loss: 0.7263 - val_accuracy: 0.8827 - val_loss: 0.2671 - mcc: 0.7647\n",
      "Epoch 2/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8895 - loss: 0.2531\n",
      "Epoch 2 - MCC: 0.8075\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8896 - loss: 0.2530 - val_accuracy: 0.9040 - val_loss: 0.2225 - mcc: 0.8075\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9093 - loss: 0.2125\n",
      "Epoch 3 - MCC: 0.8272\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9093 - loss: 0.2125 - val_accuracy: 0.9137 - val_loss: 0.2030 - mcc: 0.8272\n",
      "Epoch 4/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9145 - loss: 0.2016\n",
      "Epoch 4 - MCC: 0.8322\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9145 - loss: 0.2016 - val_accuracy: 0.9164 - val_loss: 0.1962 - mcc: 0.8322\n",
      "Epoch 5/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9179 - loss: 0.1931\n",
      "Epoch 5 - MCC: 0.8302\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9179 - loss: 0.1932 - val_accuracy: 0.9148 - val_loss: 0.1986 - mcc: 0.8302\n",
      "Epoch 6/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9197 - loss: 0.1908\n",
      "Epoch 6 - MCC: 0.8437\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9197 - loss: 0.1908 - val_accuracy: 0.9220 - val_loss: 0.1845 - mcc: 0.8437\n",
      "Epoch 7/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9211 - loss: 0.1874\n",
      "Epoch 7 - MCC: 0.8457\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9211 - loss: 0.1874 - val_accuracy: 0.9229 - val_loss: 0.1822 - mcc: 0.8457\n",
      "Epoch 8/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9211 - loss: 0.1853\n",
      "Epoch 8 - MCC: 0.8489\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9211 - loss: 0.1853 - val_accuracy: 0.9247 - val_loss: 0.1778 - mcc: 0.8489\n",
      "Epoch 9/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9223 - loss: 0.1840\n",
      "Epoch 9 - MCC: 0.8483\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.9224 - loss: 0.1839 - val_accuracy: 0.9243 - val_loss: 0.1786 - mcc: 0.8483\n",
      "Epoch 10/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9274 - loss: 0.1726\n",
      "Epoch 10 - MCC: 0.8495\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.9272 - loss: 0.1728 - val_accuracy: 0.9250 - val_loss: 0.1765 - mcc: 0.8495\n",
      "Epoch 11/20\n",
      "\u001B[1m176/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9250 - loss: 0.1776\n",
      "Epoch 11 - MCC: 0.8500\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.9250 - loss: 0.1776 - val_accuracy: 0.9247 - val_loss: 0.1785 - mcc: 0.8500\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9258 - loss: 0.1759\n",
      "Epoch 12 - MCC: 0.8536\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9258 - loss: 0.1759 - val_accuracy: 0.9270 - val_loss: 0.1722 - mcc: 0.8536\n",
      "Epoch 13/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9254 - loss: 0.1748\n",
      "Epoch 13 - MCC: 0.8557\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9254 - loss: 0.1748 - val_accuracy: 0.9281 - val_loss: 0.1699 - mcc: 0.8557\n",
      "Epoch 14/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9247 - loss: 0.1772\n",
      "Epoch 14 - MCC: 0.8575\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9248 - loss: 0.1770 - val_accuracy: 0.9290 - val_loss: 0.1682 - mcc: 0.8575\n",
      "Epoch 15/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9267 - loss: 0.1743\n",
      "Epoch 15 - MCC: 0.8579\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9267 - loss: 0.1742 - val_accuracy: 0.9291 - val_loss: 0.1677 - mcc: 0.8579\n",
      "Epoch 16/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9270 - loss: 0.1718\n",
      "Epoch 16 - MCC: 0.8587\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9270 - loss: 0.1718 - val_accuracy: 0.9295 - val_loss: 0.1670 - mcc: 0.8587\n",
      "Epoch 17/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9264 - loss: 0.1738\n",
      "Epoch 17 - MCC: 0.8494\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9264 - loss: 0.1737 - val_accuracy: 0.9248 - val_loss: 0.1763 - mcc: 0.8494\n",
      "Epoch 18/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9285 - loss: 0.1687\n",
      "Epoch 18 - MCC: 0.8567\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9285 - loss: 0.1688 - val_accuracy: 0.9286 - val_loss: 0.1684 - mcc: 0.8567\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9271 - loss: 0.1715\n",
      "Epoch 19 - MCC: 0.8551\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.9271 - loss: 0.1715 - val_accuracy: 0.9277 - val_loss: 0.1702 - mcc: 0.8551\n",
      "Epoch 20/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9278 - loss: 0.1697\n",
      "Epoch 20 - MCC: 0.8589\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.9278 - loss: 0.1697 - val_accuracy: 0.9296 - val_loss: 0.1662 - mcc: 0.8589\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: TCN, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.6647 - loss: 0.7583\n",
      "Epoch 1 - MCC: 0.7745\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.6654 - loss: 0.7567 - val_accuracy: 0.8876 - val_loss: 0.2610 - mcc: 0.7745\n",
      "Epoch 2/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8943 - loss: 0.2470\n",
      "Epoch 2 - MCC: 0.8042\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8943 - loss: 0.2469 - val_accuracy: 0.9024 - val_loss: 0.2289 - mcc: 0.8042\n",
      "Epoch 3/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9078 - loss: 0.2165\n",
      "Epoch 3 - MCC: 0.8194\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9078 - loss: 0.2165 - val_accuracy: 0.9100 - val_loss: 0.2120 - mcc: 0.8194\n",
      "Epoch 4/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9121 - loss: 0.2054\n",
      "Epoch 4 - MCC: 0.8264\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9122 - loss: 0.2052 - val_accuracy: 0.9134 - val_loss: 0.2031 - mcc: 0.8264\n",
      "Epoch 5/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9161 - loss: 0.1959\n",
      "Epoch 5 - MCC: 0.8361\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9162 - loss: 0.1956 - val_accuracy: 0.9182 - val_loss: 0.1934 - mcc: 0.8361\n",
      "Epoch 6/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9194 - loss: 0.1884\n",
      "Epoch 6 - MCC: 0.8405\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9195 - loss: 0.1882 - val_accuracy: 0.9205 - val_loss: 0.1876 - mcc: 0.8405\n",
      "Epoch 7/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9209 - loss: 0.1846\n",
      "Epoch 7 - MCC: 0.8351\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9210 - loss: 0.1844 - val_accuracy: 0.9179 - val_loss: 0.1931 - mcc: 0.8351\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9219 - loss: 0.1819\n",
      "Epoch 8 - MCC: 0.8425\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.9220 - loss: 0.1819 - val_accuracy: 0.9207 - val_loss: 0.1891 - mcc: 0.8425\n",
      "Epoch 9/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9243 - loss: 0.1787\n",
      "Epoch 9 - MCC: 0.8444\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.9243 - loss: 0.1785 - val_accuracy: 0.9225 - val_loss: 0.1826 - mcc: 0.8444\n",
      "Epoch 10/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9268 - loss: 0.1719\n",
      "Epoch 10 - MCC: 0.8485\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9268 - loss: 0.1719 - val_accuracy: 0.9245 - val_loss: 0.1778 - mcc: 0.8485\n",
      "Epoch 11/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9248 - loss: 0.1761\n",
      "Epoch 11 - MCC: 0.8479\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9249 - loss: 0.1758 - val_accuracy: 0.9242 - val_loss: 0.1783 - mcc: 0.8479\n",
      "Epoch 12/20\n",
      "\u001B[1m175/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9303 - loss: 0.1643\n",
      "Epoch 12 - MCC: 0.8508\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9301 - loss: 0.1647 - val_accuracy: 0.9255 - val_loss: 0.1774 - mcc: 0.8508\n",
      "Epoch 13/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9301 - loss: 0.1651\n",
      "Epoch 13 - MCC: 0.8531\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9301 - loss: 0.1653 - val_accuracy: 0.9268 - val_loss: 0.1737 - mcc: 0.8531\n",
      "Epoch 14/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9287 - loss: 0.1677\n",
      "Epoch 14 - MCC: 0.8521\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9287 - loss: 0.1677 - val_accuracy: 0.9263 - val_loss: 0.1746 - mcc: 0.8521\n",
      "Epoch 15/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9280 - loss: 0.1683\n",
      "Epoch 15 - MCC: 0.8542\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9281 - loss: 0.1682 - val_accuracy: 0.9274 - val_loss: 0.1720 - mcc: 0.8542\n",
      "Epoch 16/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9315 - loss: 0.1611\n",
      "Epoch 16 - MCC: 0.8531\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9314 - loss: 0.1613 - val_accuracy: 0.9265 - val_loss: 0.1753 - mcc: 0.8531\n",
      "Epoch 17/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9304 - loss: 0.1645\n",
      "Epoch 17 - MCC: 0.8488\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - accuracy: 0.9303 - loss: 0.1646 - val_accuracy: 0.9244 - val_loss: 0.1768 - mcc: 0.8488\n",
      "Epoch 18/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9289 - loss: 0.1669\n",
      "Epoch 18 - MCC: 0.8556\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.9290 - loss: 0.1669 - val_accuracy: 0.9281 - val_loss: 0.1709 - mcc: 0.8556\n",
      "Epoch 19/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9324 - loss: 0.1598\n",
      "Epoch 19 - MCC: 0.8563\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.9323 - loss: 0.1600 - val_accuracy: 0.9280 - val_loss: 0.1716 - mcc: 0.8563\n",
      "Epoch 20/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9322 - loss: 0.1611\n",
      "Epoch 20 - MCC: 0.8553\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9322 - loss: 0.1612 - val_accuracy: 0.9274 - val_loss: 0.1734 - mcc: 0.8553\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: TCN, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.6581 - loss: 0.9043\n",
      "Epoch 1 - MCC: 0.7647\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 43ms/step - accuracy: 0.6587 - loss: 0.9023 - val_accuracy: 0.8827 - val_loss: 0.2737 - mcc: 0.7647\n",
      "Epoch 2/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8869 - loss: 0.2627\n",
      "Epoch 2 - MCC: 0.8059\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8871 - loss: 0.2622 - val_accuracy: 0.9032 - val_loss: 0.2262 - mcc: 0.8059\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9041 - loss: 0.2237\n",
      "Epoch 3 - MCC: 0.8232\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9042 - loss: 0.2237 - val_accuracy: 0.9118 - val_loss: 0.2068 - mcc: 0.8232\n",
      "Epoch 4/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9121 - loss: 0.2071\n",
      "Epoch 4 - MCC: 0.8335\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9121 - loss: 0.2070 - val_accuracy: 0.9170 - val_loss: 0.1955 - mcc: 0.8335\n",
      "Epoch 5/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9154 - loss: 0.1986\n",
      "Epoch 5 - MCC: 0.8378\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9154 - loss: 0.1986 - val_accuracy: 0.9190 - val_loss: 0.1914 - mcc: 0.8378\n",
      "Epoch 6/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9183 - loss: 0.1921\n",
      "Epoch 6 - MCC: 0.8403\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9183 - loss: 0.1921 - val_accuracy: 0.9202 - val_loss: 0.1868 - mcc: 0.8403\n",
      "Epoch 7/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9188 - loss: 0.1912\n",
      "Epoch 7 - MCC: 0.8462\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.9189 - loss: 0.1911 - val_accuracy: 0.9231 - val_loss: 0.1817 - mcc: 0.8462\n",
      "Epoch 8/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9234 - loss: 0.1813\n",
      "Epoch 8 - MCC: 0.8498\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - accuracy: 0.9233 - loss: 0.1815 - val_accuracy: 0.9251 - val_loss: 0.1760 - mcc: 0.8498\n",
      "Epoch 9/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9235 - loss: 0.1822\n",
      "Epoch 9 - MCC: 0.8514\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9235 - loss: 0.1821 - val_accuracy: 0.9258 - val_loss: 0.1752 - mcc: 0.8514\n",
      "Epoch 10/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9227 - loss: 0.1813\n",
      "Epoch 10 - MCC: 0.8531\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9227 - loss: 0.1813 - val_accuracy: 0.9267 - val_loss: 0.1728 - mcc: 0.8531\n",
      "Epoch 11/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9262 - loss: 0.1736\n",
      "Epoch 11 - MCC: 0.8492\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9261 - loss: 0.1738 - val_accuracy: 0.9248 - val_loss: 0.1764 - mcc: 0.8492\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9247 - loss: 0.1765\n",
      "Epoch 12 - MCC: 0.8531\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9247 - loss: 0.1765 - val_accuracy: 0.9267 - val_loss: 0.1719 - mcc: 0.8531\n",
      "Epoch 13/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9265 - loss: 0.1746\n",
      "Epoch 13 - MCC: 0.8548\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9265 - loss: 0.1746 - val_accuracy: 0.9276 - val_loss: 0.1699 - mcc: 0.8548\n",
      "Epoch 14/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9265 - loss: 0.1721\n",
      "Epoch 14 - MCC: 0.8586\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9265 - loss: 0.1721 - val_accuracy: 0.9294 - val_loss: 0.1669 - mcc: 0.8586\n",
      "Epoch 15/20\n",
      "\u001B[1m176/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9259 - loss: 0.1735\n",
      "Epoch 15 - MCC: 0.8559\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9260 - loss: 0.1734 - val_accuracy: 0.9280 - val_loss: 0.1692 - mcc: 0.8559\n",
      "Epoch 16/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9287 - loss: 0.1700\n",
      "Epoch 16 - MCC: 0.8589\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9286 - loss: 0.1700 - val_accuracy: 0.9297 - val_loss: 0.1662 - mcc: 0.8589\n",
      "Epoch 17/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9287 - loss: 0.1688\n",
      "Epoch 17 - MCC: 0.8574\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.9287 - loss: 0.1689 - val_accuracy: 0.9288 - val_loss: 0.1682 - mcc: 0.8574\n",
      "Epoch 18/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9268 - loss: 0.1729\n",
      "Epoch 18 - MCC: 0.8558\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.9269 - loss: 0.1727 - val_accuracy: 0.9281 - val_loss: 0.1691 - mcc: 0.8558\n",
      "Epoch 19/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9287 - loss: 0.1692\n",
      "Epoch 19 - MCC: 0.8621\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9287 - loss: 0.1692 - val_accuracy: 0.9312 - val_loss: 0.1623 - mcc: 0.8621\n",
      "Epoch 20/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9299 - loss: 0.1661\n",
      "Epoch 20 - MCC: 0.8619\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9299 - loss: 0.1661 - val_accuracy: 0.9309 - val_loss: 0.1640 - mcc: 0.8619\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: TCN, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.6455 - loss: 1.0046\n",
      "Epoch 1 - MCC: 0.7429\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 49ms/step - accuracy: 0.6461 - loss: 1.0023 - val_accuracy: 0.8716 - val_loss: 0.2978 - mcc: 0.7429\n",
      "Epoch 2/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8860 - loss: 0.2699\n",
      "Epoch 2 - MCC: 0.8037\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 6ms/step - accuracy: 0.8863 - loss: 0.2692 - val_accuracy: 0.9021 - val_loss: 0.2277 - mcc: 0.8037\n",
      "Epoch 3/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9037 - loss: 0.2253\n",
      "Epoch 3 - MCC: 0.8129\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9038 - loss: 0.2251 - val_accuracy: 0.9067 - val_loss: 0.2164 - mcc: 0.8129\n",
      "Epoch 4/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9086 - loss: 0.2146\n",
      "Epoch 4 - MCC: 0.8238\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9087 - loss: 0.2144 - val_accuracy: 0.9122 - val_loss: 0.2045 - mcc: 0.8238\n",
      "Epoch 5/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9116 - loss: 0.2080\n",
      "Epoch 5 - MCC: 0.8330\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9117 - loss: 0.2076 - val_accuracy: 0.9167 - val_loss: 0.1962 - mcc: 0.8330\n",
      "Epoch 6/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9172 - loss: 0.1966\n",
      "Epoch 6 - MCC: 0.8367\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9172 - loss: 0.1964 - val_accuracy: 0.9185 - val_loss: 0.1915 - mcc: 0.8367\n",
      "Epoch 7/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9191 - loss: 0.1909\n",
      "Epoch 7 - MCC: 0.8397\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9192 - loss: 0.1909 - val_accuracy: 0.9200 - val_loss: 0.1883 - mcc: 0.8397\n",
      "Epoch 8/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9208 - loss: 0.1879\n",
      "Epoch 8 - MCC: 0.8379\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9208 - loss: 0.1879 - val_accuracy: 0.9193 - val_loss: 0.1900 - mcc: 0.8379\n",
      "Epoch 9/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9213 - loss: 0.1875\n",
      "Epoch 9 - MCC: 0.8454\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - accuracy: 0.9214 - loss: 0.1874 - val_accuracy: 0.9229 - val_loss: 0.1820 - mcc: 0.8454\n",
      "Epoch 10/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9243 - loss: 0.1804\n",
      "Epoch 10 - MCC: 0.8457\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.9243 - loss: 0.1804 - val_accuracy: 0.9226 - val_loss: 0.1832 - mcc: 0.8457\n",
      "Epoch 11/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9274 - loss: 0.1738\n",
      "Epoch 11 - MCC: 0.8479\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9273 - loss: 0.1740 - val_accuracy: 0.9242 - val_loss: 0.1792 - mcc: 0.8479\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9264 - loss: 0.1744\n",
      "Epoch 12 - MCC: 0.8517\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9264 - loss: 0.1744 - val_accuracy: 0.9260 - val_loss: 0.1760 - mcc: 0.8517\n",
      "Epoch 13/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9256 - loss: 0.1769\n",
      "Epoch 13 - MCC: 0.8519\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9256 - loss: 0.1767 - val_accuracy: 0.9261 - val_loss: 0.1756 - mcc: 0.8519\n",
      "Epoch 14/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9269 - loss: 0.1741\n",
      "Epoch 14 - MCC: 0.8530\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9269 - loss: 0.1741 - val_accuracy: 0.9267 - val_loss: 0.1735 - mcc: 0.8530\n",
      "Epoch 15/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9278 - loss: 0.1724\n",
      "Epoch 15 - MCC: 0.8507\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9278 - loss: 0.1724 - val_accuracy: 0.9252 - val_loss: 0.1776 - mcc: 0.8507\n",
      "Epoch 16/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9281 - loss: 0.1719\n",
      "Epoch 16 - MCC: 0.8549\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9281 - loss: 0.1718 - val_accuracy: 0.9275 - val_loss: 0.1724 - mcc: 0.8549\n",
      "Epoch 17/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9279 - loss: 0.1710\n",
      "Epoch 17 - MCC: 0.8516\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9279 - loss: 0.1710 - val_accuracy: 0.9261 - val_loss: 0.1742 - mcc: 0.8516\n",
      "Epoch 18/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9278 - loss: 0.1719\n",
      "Epoch 18 - MCC: 0.8505\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9278 - loss: 0.1719 - val_accuracy: 0.9248 - val_loss: 0.1777 - mcc: 0.8505\n",
      "Epoch 19/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9280 - loss: 0.1708\n",
      "Epoch 19 - MCC: 0.8573\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.9281 - loss: 0.1707 - val_accuracy: 0.9288 - val_loss: 0.1686 - mcc: 0.8573\n",
      "Epoch 20/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9322 - loss: 0.1619\n",
      "Epoch 20 - MCC: 0.8578\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - accuracy: 0.9321 - loss: 0.1621 - val_accuracy: 0.9290 - val_loss: 0.1689 - mcc: 0.8578\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.930872),\n",
      "              'mean': np.float64(0.9289034666666666),\n",
      "              'min': np.float64(0.9273626666666667),\n",
      "              'std': np.float64(0.0012795114623254536)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.00027530066172281903),\n",
      "                               'mean': np.float64(0.00021067676544189455),\n",
      "                               'min': np.float64(0.00016721026102701822),\n",
      "                               'std': np.float64(4.834353753958609e-05)},\n",
      " 'MCC': {'max': np.float64(0.8619348014807978),\n",
      "         'mean': np.float64(0.8578518778243568),\n",
      "         'min': np.float64(0.8553285100258943),\n",
      "         'std': np.float64(0.0024540500848528137)},\n",
      " 'Parameters': 4996,\n",
      " 'Train Time (s)': {'max': np.float64(49.517295837402344),\n",
      "                    'mean': np.float64(41.164320135116576),\n",
      "                    'min': np.float64(37.68754196166992),\n",
      "                    'std': np.float64(4.31845111468204)},\n",
      " 'Training Accuracy': [[0.7586565613746643,\n",
      "                        0.8919844031333923,\n",
      "                        0.9072111248970032,\n",
      "                        0.9122868776321411,\n",
      "                        0.915453314781189,\n",
      "                        0.9183859825134277,\n",
      "                        0.9200143814086914,\n",
      "                        0.9214335083961487,\n",
      "                        0.9224902391433716,\n",
      "                        0.9236365556716919,\n",
      "                        0.9246911406517029,\n",
      "                        0.925793468952179,\n",
      "                        0.9260463118553162,\n",
      "                        0.9270567297935486,\n",
      "                        0.9276747107505798,\n",
      "                        0.9278141856193542,\n",
      "                        0.927976131439209,\n",
      "                        0.9285773634910583,\n",
      "                        0.9294970631599426,\n",
      "                        0.9289047718048096],\n",
      "                       [0.7771388292312622,\n",
      "                        0.8966926336288452,\n",
      "                        0.9092181921005249,\n",
      "                        0.9140679240226746,\n",
      "                        0.9174349904060364,\n",
      "                        0.9194784164428711,\n",
      "                        0.921272873878479,\n",
      "                        0.9221540689468384,\n",
      "                        0.9234422445297241,\n",
      "                        0.9248999953269958,\n",
      "                        0.9251824021339417,\n",
      "                        0.9255912899971008,\n",
      "                        0.9261681437492371,\n",
      "                        0.9267327189445496,\n",
      "                        0.9266263842582703,\n",
      "                        0.9275419116020203,\n",
      "                        0.9281803965568542,\n",
      "                        0.9281206727027893,\n",
      "                        0.9278964996337891,\n",
      "                        0.9289224743843079],\n",
      "                       [0.7866562604904175,\n",
      "                        0.8984900116920471,\n",
      "                        0.9080488085746765,\n",
      "                        0.9134377241134644,\n",
      "                        0.9178826212882996,\n",
      "                        0.9209498167037964,\n",
      "                        0.9226550459861755,\n",
      "                        0.924062192440033,\n",
      "                        0.92569899559021,\n",
      "                        0.9262757301330566,\n",
      "                        0.9271665215492249,\n",
      "                        0.9278472661972046,\n",
      "                        0.9283206462860107,\n",
      "                        0.9290172457695007,\n",
      "                        0.9294515252113342,\n",
      "                        0.9299726486206055,\n",
      "                        0.9296714067459106,\n",
      "                        0.9302740693092346,\n",
      "                        0.9307459592819214,\n",
      "                        0.9308837056159973],\n",
      "                       [0.7678306698799133,\n",
      "                        0.8928670287132263,\n",
      "                        0.9057013392448425,\n",
      "                        0.9124782681465149,\n",
      "                        0.9155969023704529,\n",
      "                        0.9188424348831177,\n",
      "                        0.9199942946434021,\n",
      "                        0.9219063520431519,\n",
      "                        0.9233734011650085,\n",
      "                        0.922868013381958,\n",
      "                        0.9252410531044006,\n",
      "                        0.9256625175476074,\n",
      "                        0.9260929226875305,\n",
      "                        0.9268526434898376,\n",
      "                        0.9270852208137512,\n",
      "                        0.9275484085083008,\n",
      "                        0.9286348223686218,\n",
      "                        0.9287726283073425,\n",
      "                        0.9291196465492249,\n",
      "                        0.9298546314239502],\n",
      "                       [0.7545766830444336,\n",
      "                        0.8927252888679504,\n",
      "                        0.9057826399803162,\n",
      "                        0.911422848701477,\n",
      "                        0.9149113893508911,\n",
      "                        0.9181062579154968,\n",
      "                        0.9198049306869507,\n",
      "                        0.9216949939727783,\n",
      "                        0.9228070378303528,\n",
      "                        0.9243663549423218,\n",
      "                        0.9252757430076599,\n",
      "                        0.925785481929779,\n",
      "                        0.9269367456436157,\n",
      "                        0.927350640296936,\n",
      "                        0.9277426600456238,\n",
      "                        0.9284323453903198,\n",
      "                        0.9284027218818665,\n",
      "                        0.9281576871871948,\n",
      "                        0.929445743560791,\n",
      "                        0.9297610521316528]],\n",
      " 'Training Loss': [[0.5450224876403809,\n",
      "                    0.2511482834815979,\n",
      "                    0.21737685799598694,\n",
      "                    0.20526251196861267,\n",
      "                    0.19838358461856842,\n",
      "                    0.1923772245645523,\n",
      "                    0.18846280872821808,\n",
      "                    0.18555092811584473,\n",
      "                    0.18314023315906525,\n",
      "                    0.18040035665035248,\n",
      "                    0.1779092401266098,\n",
      "                    0.1752299666404724,\n",
      "                    0.17461326718330383,\n",
      "                    0.17213617265224457,\n",
      "                    0.17141985893249512,\n",
      "                    0.1705683022737503,\n",
      "                    0.1701468974351883,\n",
      "                    0.16879716515541077,\n",
      "                    0.1673259139060974,\n",
      "                    0.16806766390800476],\n",
      "                   [0.4724382758140564,\n",
      "                    0.2391536682844162,\n",
      "                    0.2129359096288681,\n",
      "                    0.2027720808982849,\n",
      "                    0.19544436037540436,\n",
      "                    0.19031685590744019,\n",
      "                    0.18704821169376373,\n",
      "                    0.18437078595161438,\n",
      "                    0.18137699365615845,\n",
      "                    0.17820687592029572,\n",
      "                    0.1774889975786209,\n",
      "                    0.1762276142835617,\n",
      "                    0.1743287742137909,\n",
      "                    0.1731596738100052,\n",
      "                    0.17330999672412872,\n",
      "                    0.17146234214305878,\n",
      "                    0.16996842622756958,\n",
      "                    0.16949257254600525,\n",
      "                    0.17025214433670044,\n",
      "                    0.16801701486110687],\n",
      "                   [0.459759920835495,\n",
      "                    0.2375059425830841,\n",
      "                    0.21567116677761078,\n",
      "                    0.20226360857486725,\n",
      "                    0.1918068379163742,\n",
      "                    0.1851256787776947,\n",
      "                    0.18133410811424255,\n",
      "                    0.17794464528560638,\n",
      "                    0.17498177289962769,\n",
      "                    0.17324599623680115,\n",
      "                    0.17113806307315826,\n",
      "                    0.16964758932590485,\n",
      "                    0.1688871532678604,\n",
      "                    0.16717490553855896,\n",
      "                    0.16633360087871552,\n",
      "                    0.16474410891532898,\n",
      "                    0.1657589077949524,\n",
      "                    0.16424745321273804,\n",
      "                    0.16325008869171143,\n",
      "                    0.1627611219882965],\n",
      "                   [0.5315884351730347,\n",
      "                    0.24883264303207397,\n",
      "                    0.22003409266471863,\n",
      "                    0.20540183782577515,\n",
      "                    0.19825337827205658,\n",
      "                    0.19069138169288635,\n",
      "                    0.18813535571098328,\n",
      "                    0.18431715667247772,\n",
      "                    0.1810963749885559,\n",
      "                    0.1815541535615921,\n",
      "                    0.17645330727100372,\n",
      "                    0.17563001811504364,\n",
      "                    0.17491285502910614,\n",
      "                    0.1725776344537735,\n",
      "                    0.17266851663589478,\n",
      "                    0.17148903012275696,\n",
      "                    0.16888456046581268,\n",
      "                    0.16856665909290314,\n",
      "                    0.16808290779590607,\n",
      "                    0.16632713377475739],\n",
      "                   [0.5728738307952881,\n",
      "                    0.2522531747817993,\n",
      "                    0.22070536017417908,\n",
      "                    0.2086767852306366,\n",
      "                    0.2006678283214569,\n",
      "                    0.1940123438835144,\n",
      "                    0.1900334656238556,\n",
      "                    0.18587471544742584,\n",
      "                    0.18374769389629364,\n",
      "                    0.1802884042263031,\n",
      "                    0.17804455757141113,\n",
      "                    0.17661318182945251,\n",
      "                    0.17421191930770874,\n",
      "                    0.17366233468055725,\n",
      "                    0.1722969114780426,\n",
      "                    0.1708821952342987,\n",
      "                    0.17048516869544983,\n",
      "                    0.17144937813282013,\n",
      "                    0.16823633015155792,\n",
      "                    0.1673296093940735]],\n",
      " 'Validation Accuracy': [[0.8772400617599487,\n",
      "                          0.9058960676193237,\n",
      "                          0.9127227663993835,\n",
      "                          0.9165600538253784,\n",
      "                          0.919365406036377,\n",
      "                          0.9206746220588684,\n",
      "                          0.9218881130218506,\n",
      "                          0.9246320724487305,\n",
      "                          0.9245042204856873,\n",
      "                          0.9245948195457458,\n",
      "                          0.925346851348877,\n",
      "                          0.9268054366111755,\n",
      "                          0.9282507300376892,\n",
      "                          0.9287039637565613,\n",
      "                          0.9282240271568298,\n",
      "                          0.9299120306968689,\n",
      "                          0.9305840134620667,\n",
      "                          0.9284534454345703,\n",
      "                          0.9290665984153748,\n",
      "                          0.9277094006538391],\n",
      "                         [0.8826532959938049,\n",
      "                          0.9039626717567444,\n",
      "                          0.91373610496521,\n",
      "                          0.9163519740104675,\n",
      "                          0.9148374199867249,\n",
      "                          0.9219600558280945,\n",
      "                          0.9228907227516174,\n",
      "                          0.9246747493743896,\n",
      "                          0.9242640137672424,\n",
      "                          0.924954891204834,\n",
      "                          0.9246640801429749,\n",
      "                          0.9269999861717224,\n",
      "                          0.9280829429626465,\n",
      "                          0.9289625883102417,\n",
      "                          0.9291174411773682,\n",
      "                          0.9294827580451965,\n",
      "                          0.9247547388076782,\n",
      "                          0.9285545945167542,\n",
      "                          0.9276880621910095,\n",
      "                          0.9296159744262695],\n",
      "                         [0.8876427412033081,\n",
      "                          0.9024426937103271,\n",
      "                          0.9099520444869995,\n",
      "                          0.9134001731872559,\n",
      "                          0.9182026982307434,\n",
      "                          0.9204747676849365,\n",
      "                          0.9178746938705444,\n",
      "                          0.920709490776062,\n",
      "                          0.9224771857261658,\n",
      "                          0.9245385527610779,\n",
      "                          0.9242052435874939,\n",
      "                          0.9255094528198242,\n",
      "                          0.9267734289169312,\n",
      "                          0.92633056640625,\n",
      "                          0.927362859249115,\n",
      "                          0.9264829158782959,\n",
      "                          0.9244348406791687,\n",
      "                          0.9280825853347778,\n",
      "                          0.928029477596283,\n",
      "                          0.9273626208305359],\n",
      "                         [0.882722795009613,\n",
      "                          0.9032161235809326,\n",
      "                          0.9118322134017944,\n",
      "                          0.9169572591781616,\n",
      "                          0.9189919233322144,\n",
      "                          0.9201920032501221,\n",
      "                          0.9230562448501587,\n",
      "                          0.9251039028167725,\n",
      "                          0.9257785677909851,\n",
      "                          0.9266932606697083,\n",
      "                          0.9247866868972778,\n",
      "                          0.9267468452453613,\n",
      "                          0.9275786876678467,\n",
      "                          0.9294480085372925,\n",
      "                          0.9280160069465637,\n",
      "                          0.929663896560669,\n",
      "                          0.9288292527198792,\n",
      "                          0.9280961155891418,\n",
      "                          0.9312293529510498,\n",
      "                          0.9308721423149109],\n",
      "                         [0.8716000914573669,\n",
      "                          0.9020987749099731,\n",
      "                          0.9067014455795288,\n",
      "                          0.9121572971343994,\n",
      "                          0.9166719317436218,\n",
      "                          0.9184666275978088,\n",
      "                          0.9199787378311157,\n",
      "                          0.9192507266998291,\n",
      "                          0.922922670841217,\n",
      "                          0.9226080179214478,\n",
      "                          0.9242239594459534,\n",
      "                          0.9259839653968811,\n",
      "                          0.9260960221290588,\n",
      "                          0.9267092943191528,\n",
      "                          0.9251894354820251,\n",
      "                          0.9274533987045288,\n",
      "                          0.9260746240615845,\n",
      "                          0.9247868657112122,\n",
      "                          0.9288294315338135,\n",
      "                          0.928957462310791]],\n",
      " 'Validation Loss': [0.29784107208251953,\n",
      "                     0.22774314880371094,\n",
      "                     0.21641652286052704,\n",
      "                     0.20453394949436188,\n",
      "                     0.19620151817798615,\n",
      "                     0.1915333867073059,\n",
      "                     0.18834584951400757,\n",
      "                     0.18996000289916992,\n",
      "                     0.18200911581516266,\n",
      "                     0.18315370380878448,\n",
      "                     0.17922067642211914,\n",
      "                     0.17597843706607819,\n",
      "                     0.17558139562606812,\n",
      "                     0.17353904247283936,\n",
      "                     0.17756296694278717,\n",
      "                     0.17244575917720795,\n",
      "                     0.17421993613243103,\n",
      "                     0.17769049108028412,\n",
      "                     0.16862918436527252,\n",
      "                     0.16887791454792023],\n",
      " 'Validation MCC': [[np.float64(0.7545689837425972),\n",
      "                     np.float64(0.8112872968879208),\n",
      "                     np.float64(0.824950812102042),\n",
      "                     np.float64(0.8326567292607989),\n",
      "                     np.float64(0.8382792520991328),\n",
      "                     np.float64(0.8419559025624316),\n",
      "                     np.float64(0.8434499783834817),\n",
      "                     np.float64(0.8489674459514822),\n",
      "                     np.float64(0.8495530338967952),\n",
      "                     np.float64(0.848883715605712),\n",
      "                     np.float64(0.8504607806095505),\n",
      "                     np.float64(0.8532406538037043),\n",
      "                     np.float64(0.8561767005487274),\n",
      "                     np.float64(0.8570118045201063),\n",
      "                     np.float64(0.8563507005687677),\n",
      "                     np.float64(0.8594617107427361),\n",
      "                     np.float64(0.8612187133931938),\n",
      "                     np.float64(0.8565902353744964),\n",
      "                     np.float64(0.8578257593360149),\n",
      "                     np.float64(0.855390085533108)],\n",
      "                    [np.float64(0.7647044403000576),\n",
      "                     np.float64(0.8074837169280794),\n",
      "                     np.float64(0.8271567786403292),\n",
      "                     np.float64(0.8322067115389846),\n",
      "                     np.float64(0.8302479595038094),\n",
      "                     np.float64(0.8436745179171212),\n",
      "                     np.float64(0.8457259757767586),\n",
      "                     np.float64(0.8489123963432796),\n",
      "                     np.float64(0.8483138721410378),\n",
      "                     np.float64(0.8494634891798213),\n",
      "                     np.float64(0.8499726620365917),\n",
      "                     np.float64(0.853609868724019),\n",
      "                     np.float64(0.8557378402612537),\n",
      "                     np.float64(0.8575165282949582),\n",
      "                     np.float64(0.8578512913544529),\n",
      "                     np.float64(0.8586628585131527),\n",
      "                     np.float64(0.8493875014601435),\n",
      "                     np.float64(0.8567198825018258),\n",
      "                     np.float64(0.8551051107081543),\n",
      "                     np.float64(0.8588537781613331)],\n",
      "                    [np.float64(0.7745341266830211),\n",
      "                     np.float64(0.8041619684654215),\n",
      "                     np.float64(0.8193657025126697),\n",
      "                     np.float64(0.8263700567929643),\n",
      "                     np.float64(0.8361454035731625),\n",
      "                     np.float64(0.8405399791276159),\n",
      "                     np.float64(0.8351467932064556),\n",
      "                     np.float64(0.8425102117751475),\n",
      "                     np.float64(0.8444046134068748),\n",
      "                     np.float64(0.8485297463844587),\n",
      "                     np.float64(0.8478847606355957),\n",
      "                     np.float64(0.8508012812660252),\n",
      "                     np.float64(0.8530842807503923),\n",
      "                     np.float64(0.8521340873700016),\n",
      "                     np.float64(0.8542101786699692),\n",
      "                     np.float64(0.8530521255123009),\n",
      "                     np.float64(0.848840926098182),\n",
      "                     np.float64(0.8556496936931406),\n",
      "                     np.float64(0.8563429504310069),\n",
      "                     np.float64(0.8553285100258943)],\n",
      "                    [np.float64(0.7647182732405462),\n",
      "                     np.float64(0.8059306126916864),\n",
      "                     np.float64(0.8232057516926458),\n",
      "                     np.float64(0.8335189860604459),\n",
      "                     np.float64(0.8378427933172371),\n",
      "                     np.float64(0.8403136279472091),\n",
      "                     np.float64(0.8462233679271864),\n",
      "                     np.float64(0.8498232391905243),\n",
      "                     np.float64(0.8514120524759471),\n",
      "                     np.float64(0.8531066920697699),\n",
      "                     np.float64(0.8491586649768518),\n",
      "                     np.float64(0.8531255649774638),\n",
      "                     np.float64(0.8547507930071863),\n",
      "                     np.float64(0.8585521812310349),\n",
      "                     np.float64(0.8558848768076281),\n",
      "                     np.float64(0.8589201180117615),\n",
      "                     np.float64(0.8573889093197935),\n",
      "                     np.float64(0.8557744046000877),\n",
      "                     np.float64(0.8620633759243246),\n",
      "                     np.float64(0.8619348014807978)],\n",
      "                    [np.float64(0.7429008663456879),\n",
      "                     np.float64(0.8037478711327436),\n",
      "                     np.float64(0.8128626785292457),\n",
      "                     np.float64(0.8237735699813995),\n",
      "                     np.float64(0.8330432109113345),\n",
      "                     np.float64(0.8366622830602941),\n",
      "                     np.float64(0.8396979261895964),\n",
      "                     np.float64(0.8379422479934397),\n",
      "                     np.float64(0.8454195866218818),\n",
      "                     np.float64(0.8456558001609875),\n",
      "                     np.float64(0.8479221187359482),\n",
      "                     np.float64(0.8517031700993294),\n",
      "                     np.float64(0.8518976372587459),\n",
      "                     np.float64(0.8530143730757608),\n",
      "                     np.float64(0.8507227831753377),\n",
      "                     np.float64(0.8548970058795535),\n",
      "                     np.float64(0.8516466687607995),\n",
      "                     np.float64(0.8505311848129711),\n",
      "                     np.float64(0.8573427739644557),\n",
      "                     np.float64(0.8577522139206503)]]}\n",
      "Training Model: MLP, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7013 - loss: 0.5209\n",
      "Epoch 1 - MCC: 0.7024\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 16ms/step - accuracy: 0.7018 - loss: 0.5203 - val_accuracy: 0.8513 - val_loss: 0.3198 - mcc: 0.7024\n",
      "Epoch 2/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8468 - loss: 0.3271\n",
      "Epoch 2 - MCC: 0.7024\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.8468 - loss: 0.3270 - val_accuracy: 0.8510 - val_loss: 0.3175 - mcc: 0.7024\n",
      "Epoch 3/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8469 - loss: 0.3259\n",
      "Epoch 3 - MCC: 0.7001\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8469 - loss: 0.3258 - val_accuracy: 0.8505 - val_loss: 0.3164 - mcc: 0.7001\n",
      "Epoch 4/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8470 - loss: 0.3225\n",
      "Epoch 4 - MCC: 0.6993\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8470 - loss: 0.3225 - val_accuracy: 0.8501 - val_loss: 0.3161 - mcc: 0.6993\n",
      "Epoch 5/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8457 - loss: 0.3252\n",
      "Epoch 5 - MCC: 0.6954\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8457 - loss: 0.3251 - val_accuracy: 0.8476 - val_loss: 0.3205 - mcc: 0.6954\n",
      "Epoch 6/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8495 - loss: 0.3177\n",
      "Epoch 6 - MCC: 0.7010\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8495 - loss: 0.3178 - val_accuracy: 0.8510 - val_loss: 0.3148 - mcc: 0.7010\n",
      "Epoch 7/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8481 - loss: 0.3206\n",
      "Epoch 7 - MCC: 0.7030\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8482 - loss: 0.3206 - val_accuracy: 0.8513 - val_loss: 0.3153 - mcc: 0.7030\n",
      "Epoch 8/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8499 - loss: 0.3169\n",
      "Epoch 8 - MCC: 0.7008\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8498 - loss: 0.3170 - val_accuracy: 0.8509 - val_loss: 0.3144 - mcc: 0.7008\n",
      "Epoch 9/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8454 - loss: 0.3247\n",
      "Epoch 9 - MCC: 0.7024\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8455 - loss: 0.3245 - val_accuracy: 0.8516 - val_loss: 0.3137 - mcc: 0.7024\n",
      "Epoch 10/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8504 - loss: 0.3157\n",
      "Epoch 10 - MCC: 0.7031\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8503 - loss: 0.3159 - val_accuracy: 0.8516 - val_loss: 0.3137 - mcc: 0.7031\n",
      "Epoch 11/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8493 - loss: 0.3171\n",
      "Epoch 11 - MCC: 0.7008\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8493 - loss: 0.3172 - val_accuracy: 0.8509 - val_loss: 0.3145 - mcc: 0.7008\n",
      "Epoch 12/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8503 - loss: 0.3164\n",
      "Epoch 12 - MCC: 0.7025\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8502 - loss: 0.3165 - val_accuracy: 0.8512 - val_loss: 0.3143 - mcc: 0.7025\n",
      "Epoch 13/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8489 - loss: 0.3174\n",
      "Epoch 13 - MCC: 0.7017\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8489 - loss: 0.3174 - val_accuracy: 0.8493 - val_loss: 0.3179 - mcc: 0.7017\n",
      "Epoch 14/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8472 - loss: 0.3197\n",
      "Epoch 14 - MCC: 0.7016\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8473 - loss: 0.3196 - val_accuracy: 0.8512 - val_loss: 0.3139 - mcc: 0.7016\n",
      "Epoch 15/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8506 - loss: 0.3151\n",
      "Epoch 15 - MCC: 0.7033\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8506 - loss: 0.3152 - val_accuracy: 0.8515 - val_loss: 0.3137 - mcc: 0.7033\n",
      "Epoch 16/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8489 - loss: 0.3177\n",
      "Epoch 16 - MCC: 0.7002\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8489 - loss: 0.3177 - val_accuracy: 0.8506 - val_loss: 0.3144 - mcc: 0.7002\n",
      "Epoch 17/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8464 - loss: 0.3198\n",
      "Epoch 17 - MCC: 0.7033\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8465 - loss: 0.3198 - val_accuracy: 0.8517 - val_loss: 0.3132 - mcc: 0.7033\n",
      "Epoch 18/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8511 - loss: 0.3133\n",
      "Epoch 18 - MCC: 0.7036\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8511 - loss: 0.3134 - val_accuracy: 0.8517 - val_loss: 0.3131 - mcc: 0.7036\n",
      "Epoch 19/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8487 - loss: 0.3178\n",
      "Epoch 19 - MCC: 0.7028\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8487 - loss: 0.3179 - val_accuracy: 0.8515 - val_loss: 0.3133 - mcc: 0.7028\n",
      "Epoch 20/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8484 - loss: 0.3182\n",
      "Epoch 20 - MCC: 0.7034\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8484 - loss: 0.3182 - val_accuracy: 0.8511 - val_loss: 0.3141 - mcc: 0.7034\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: MLP, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6931 - loss: 0.5198\n",
      "Epoch 1 - MCC: 0.6898\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 14ms/step - accuracy: 0.6936 - loss: 0.5192 - val_accuracy: 0.8446 - val_loss: 0.3292 - mcc: 0.6898\n",
      "Epoch 2/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8458 - loss: 0.3272\n",
      "Epoch 2 - MCC: 0.6930\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8459 - loss: 0.3270 - val_accuracy: 0.8467 - val_loss: 0.3223 - mcc: 0.6930\n",
      "Epoch 3/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8494 - loss: 0.3192\n",
      "Epoch 3 - MCC: 0.6993\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8493 - loss: 0.3194 - val_accuracy: 0.8501 - val_loss: 0.3169 - mcc: 0.6993\n",
      "Epoch 4/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8488 - loss: 0.3194\n",
      "Epoch 4 - MCC: 0.6971\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8488 - loss: 0.3194 - val_accuracy: 0.8490 - val_loss: 0.3174 - mcc: 0.6971\n",
      "Epoch 5/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8492 - loss: 0.3182\n",
      "Epoch 5 - MCC: 0.6989\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - accuracy: 0.8491 - loss: 0.3183 - val_accuracy: 0.8499 - val_loss: 0.3166 - mcc: 0.6989\n",
      "Epoch 6/20\n",
      "\u001B[1m176/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8485 - loss: 0.3201\n",
      "Epoch 6 - MCC: 0.6951\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8485 - loss: 0.3201 - val_accuracy: 0.8479 - val_loss: 0.3190 - mcc: 0.6951\n",
      "Epoch 7/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8465 - loss: 0.3227\n",
      "Epoch 7 - MCC: 0.6968\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8465 - loss: 0.3226 - val_accuracy: 0.8489 - val_loss: 0.3181 - mcc: 0.6968\n",
      "Epoch 8/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8501 - loss: 0.3168\n",
      "Epoch 8 - MCC: 0.6988\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8501 - loss: 0.3168 - val_accuracy: 0.8499 - val_loss: 0.3162 - mcc: 0.6988\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8454 - loss: 0.3235\n",
      "Epoch 9 - MCC: 0.6941\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8454 - loss: 0.3235 - val_accuracy: 0.8473 - val_loss: 0.3208 - mcc: 0.6941\n",
      "Epoch 10/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8501 - loss: 0.3153\n",
      "Epoch 10 - MCC: 0.6936\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8500 - loss: 0.3153 - val_accuracy: 0.8470 - val_loss: 0.3198 - mcc: 0.6936\n",
      "Epoch 11/20\n",
      "\u001B[1m172/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8460 - loss: 0.3228\n",
      "Epoch 11 - MCC: 0.6979\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8463 - loss: 0.3223 - val_accuracy: 0.8494 - val_loss: 0.3162 - mcc: 0.6979\n",
      "Epoch 12/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8476 - loss: 0.3193\n",
      "Epoch 12 - MCC: 0.7002\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8476 - loss: 0.3193 - val_accuracy: 0.8504 - val_loss: 0.3154 - mcc: 0.7002\n",
      "Epoch 13/20\n",
      "\u001B[1m167/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8513 - loss: 0.3135\n",
      "Epoch 13 - MCC: 0.6977\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8510 - loss: 0.3139 - val_accuracy: 0.8493 - val_loss: 0.3163 - mcc: 0.6977\n",
      "Epoch 14/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8506 - loss: 0.3156\n",
      "Epoch 14 - MCC: 0.7000\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8506 - loss: 0.3157 - val_accuracy: 0.8495 - val_loss: 0.3178 - mcc: 0.7000\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8499 - loss: 0.3132\n",
      "Epoch 15 - MCC: 0.7004\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8499 - loss: 0.3133 - val_accuracy: 0.8498 - val_loss: 0.3161 - mcc: 0.7004\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8467 - loss: 0.3223\n",
      "Epoch 16 - MCC: 0.7000\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8467 - loss: 0.3223 - val_accuracy: 0.8504 - val_loss: 0.3152 - mcc: 0.7000\n",
      "Epoch 17/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8501 - loss: 0.3147\n",
      "Epoch 17 - MCC: 0.6969\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8501 - loss: 0.3148 - val_accuracy: 0.8489 - val_loss: 0.3171 - mcc: 0.6969\n",
      "Epoch 18/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8500 - loss: 0.3162\n",
      "Epoch 18 - MCC: 0.7001\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - accuracy: 0.8500 - loss: 0.3162 - val_accuracy: 0.8502 - val_loss: 0.3151 - mcc: 0.7001\n",
      "Epoch 19/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8532 - loss: 0.3100\n",
      "Epoch 19 - MCC: 0.6969\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8530 - loss: 0.3103 - val_accuracy: 0.8489 - val_loss: 0.3170 - mcc: 0.6969\n",
      "Epoch 20/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8515 - loss: 0.3132\n",
      "Epoch 20 - MCC: 0.6970\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8515 - loss: 0.3132 - val_accuracy: 0.8490 - val_loss: 0.3169 - mcc: 0.6970\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: MLP, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6829 - loss: 0.5484\n",
      "Epoch 1 - MCC: 0.6871\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 14ms/step - accuracy: 0.6834 - loss: 0.5478 - val_accuracy: 0.8439 - val_loss: 0.3298 - mcc: 0.6871\n",
      "Epoch 2/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8517 - loss: 0.3169\n",
      "Epoch 2 - MCC: 0.6862\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 4ms/step - accuracy: 0.8517 - loss: 0.3170 - val_accuracy: 0.8436 - val_loss: 0.3284 - mcc: 0.6862\n",
      "Epoch 3/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8503 - loss: 0.3194\n",
      "Epoch 3 - MCC: 0.6836\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8503 - loss: 0.3194 - val_accuracy: 0.8419 - val_loss: 0.3306 - mcc: 0.6836\n",
      "Epoch 4/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8491 - loss: 0.3187\n",
      "Epoch 4 - MCC: 0.6887\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8491 - loss: 0.3187 - val_accuracy: 0.8449 - val_loss: 0.3233 - mcc: 0.6887\n",
      "Epoch 5/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8487 - loss: 0.3197\n",
      "Epoch 5 - MCC: 0.6897\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8487 - loss: 0.3196 - val_accuracy: 0.8453 - val_loss: 0.3232 - mcc: 0.6897\n",
      "Epoch 6/20\n",
      "\u001B[1m175/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8511 - loss: 0.3152\n",
      "Epoch 6 - MCC: 0.6879\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8509 - loss: 0.3154 - val_accuracy: 0.8421 - val_loss: 0.3326 - mcc: 0.6879\n",
      "Epoch 7/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8510 - loss: 0.3165\n",
      "Epoch 7 - MCC: 0.6893\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8509 - loss: 0.3165 - val_accuracy: 0.8450 - val_loss: 0.3231 - mcc: 0.6893\n",
      "Epoch 8/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8498 - loss: 0.3168\n",
      "Epoch 8 - MCC: 0.6873\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8498 - loss: 0.3168 - val_accuracy: 0.8443 - val_loss: 0.3241 - mcc: 0.6873\n",
      "Epoch 9/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8512 - loss: 0.3154\n",
      "Epoch 9 - MCC: 0.6895\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8512 - loss: 0.3155 - val_accuracy: 0.8448 - val_loss: 0.3237 - mcc: 0.6895\n",
      "Epoch 10/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8507 - loss: 0.3145\n",
      "Epoch 10 - MCC: 0.6892\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8507 - loss: 0.3145 - val_accuracy: 0.8449 - val_loss: 0.3236 - mcc: 0.6892\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8485 - loss: 0.3200\n",
      "Epoch 11 - MCC: 0.6892\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8485 - loss: 0.3200 - val_accuracy: 0.8437 - val_loss: 0.3263 - mcc: 0.6892\n",
      "Epoch 12/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8519 - loss: 0.3136\n",
      "Epoch 12 - MCC: 0.6893\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8518 - loss: 0.3138 - val_accuracy: 0.8447 - val_loss: 0.3237 - mcc: 0.6893\n",
      "Epoch 13/20\n",
      "\u001B[1m170/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8483 - loss: 0.3176\n",
      "Epoch 13 - MCC: 0.6883\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8485 - loss: 0.3175 - val_accuracy: 0.8448 - val_loss: 0.3228 - mcc: 0.6883\n",
      "Epoch 14/20\n",
      "\u001B[1m170/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8515 - loss: 0.3129\n",
      "Epoch 14 - MCC: 0.6891\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8514 - loss: 0.3132 - val_accuracy: 0.8451 - val_loss: 0.3220 - mcc: 0.6891\n",
      "Epoch 15/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8506 - loss: 0.3159\n",
      "Epoch 15 - MCC: 0.6888\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8506 - loss: 0.3159 - val_accuracy: 0.8451 - val_loss: 0.3220 - mcc: 0.6888\n",
      "Epoch 16/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8491 - loss: 0.3164\n",
      "Epoch 16 - MCC: 0.6897\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8491 - loss: 0.3164 - val_accuracy: 0.8453 - val_loss: 0.3220 - mcc: 0.6897\n",
      "Epoch 17/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8492 - loss: 0.3180\n",
      "Epoch 17 - MCC: 0.6894\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8492 - loss: 0.3180 - val_accuracy: 0.8450 - val_loss: 0.3223 - mcc: 0.6894\n",
      "Epoch 18/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8521 - loss: 0.3127\n",
      "Epoch 18 - MCC: 0.6892\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8521 - loss: 0.3128 - val_accuracy: 0.8437 - val_loss: 0.3247 - mcc: 0.6892\n",
      "Epoch 19/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8500 - loss: 0.3163\n",
      "Epoch 19 - MCC: 0.6892\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8500 - loss: 0.3163 - val_accuracy: 0.8444 - val_loss: 0.3232 - mcc: 0.6892\n",
      "Epoch 20/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8494 - loss: 0.3167\n",
      "Epoch 20 - MCC: 0.6896\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8494 - loss: 0.3167 - val_accuracy: 0.8453 - val_loss: 0.3216 - mcc: 0.6896\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: MLP, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6941 - loss: 0.5159\n",
      "Epoch 1 - MCC: 0.7024\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 14ms/step - accuracy: 0.6946 - loss: 0.5153 - val_accuracy: 0.8517 - val_loss: 0.3201 - mcc: 0.7024\n",
      "Epoch 2/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8472 - loss: 0.3255\n",
      "Epoch 2 - MCC: 0.7032\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.8472 - loss: 0.3255 - val_accuracy: 0.8519 - val_loss: 0.3163 - mcc: 0.7032\n",
      "Epoch 3/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8466 - loss: 0.3246\n",
      "Epoch 3 - MCC: 0.7038\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8467 - loss: 0.3246 - val_accuracy: 0.8521 - val_loss: 0.3157 - mcc: 0.7038\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8478 - loss: 0.3210\n",
      "Epoch 4 - MCC: 0.7022\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.8478 - loss: 0.3210 - val_accuracy: 0.8516 - val_loss: 0.3152 - mcc: 0.7022\n",
      "Epoch 5/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8479 - loss: 0.3203\n",
      "Epoch 5 - MCC: 0.7036\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8479 - loss: 0.3203 - val_accuracy: 0.8519 - val_loss: 0.3155 - mcc: 0.7036\n",
      "Epoch 6/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8449 - loss: 0.3244\n",
      "Epoch 6 - MCC: 0.7016\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8449 - loss: 0.3243 - val_accuracy: 0.8513 - val_loss: 0.3149 - mcc: 0.7016\n",
      "Epoch 7/20\n",
      "\u001B[1m168/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8514 - loss: 0.3138\n",
      "Epoch 7 - MCC: 0.6990\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8510 - loss: 0.3144 - val_accuracy: 0.8498 - val_loss: 0.3169 - mcc: 0.6990\n",
      "Epoch 8/20\n",
      "\u001B[1m168/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8498 - loss: 0.3179\n",
      "Epoch 8 - MCC: 0.7021\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8497 - loss: 0.3180 - val_accuracy: 0.8515 - val_loss: 0.3147 - mcc: 0.7021\n",
      "Epoch 9/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8495 - loss: 0.3167\n",
      "Epoch 9 - MCC: 0.7032\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8494 - loss: 0.3168 - val_accuracy: 0.8519 - val_loss: 0.3144 - mcc: 0.7032\n",
      "Epoch 10/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8478 - loss: 0.3208\n",
      "Epoch 10 - MCC: 0.7039\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8479 - loss: 0.3207 - val_accuracy: 0.8522 - val_loss: 0.3144 - mcc: 0.7039\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8453 - loss: 0.3245\n",
      "Epoch 11 - MCC: 0.7042\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8453 - loss: 0.3244 - val_accuracy: 0.8522 - val_loss: 0.3141 - mcc: 0.7042\n",
      "Epoch 12/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8479 - loss: 0.3196\n",
      "Epoch 12 - MCC: 0.6993\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8479 - loss: 0.3196 - val_accuracy: 0.8501 - val_loss: 0.3165 - mcc: 0.6993\n",
      "Epoch 13/20\n",
      "\u001B[1m170/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8469 - loss: 0.3205\n",
      "Epoch 13 - MCC: 0.7044\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8469 - loss: 0.3203 - val_accuracy: 0.8518 - val_loss: 0.3156 - mcc: 0.7044\n",
      "Epoch 14/20\n",
      "\u001B[1m176/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8480 - loss: 0.3200\n",
      "Epoch 14 - MCC: 0.7023\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8480 - loss: 0.3199 - val_accuracy: 0.8516 - val_loss: 0.3143 - mcc: 0.7023\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8498 - loss: 0.3166\n",
      "Epoch 15 - MCC: 0.7037\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8498 - loss: 0.3166 - val_accuracy: 0.8517 - val_loss: 0.3147 - mcc: 0.7037\n",
      "Epoch 16/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8473 - loss: 0.3195\n",
      "Epoch 16 - MCC: 0.7023\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8473 - loss: 0.3195 - val_accuracy: 0.8516 - val_loss: 0.3139 - mcc: 0.7023\n",
      "Epoch 17/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8503 - loss: 0.3149\n",
      "Epoch 17 - MCC: 0.7002\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8503 - loss: 0.3150 - val_accuracy: 0.8505 - val_loss: 0.3162 - mcc: 0.7002\n",
      "Epoch 18/20\n",
      "\u001B[1m172/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8468 - loss: 0.3202\n",
      "Epoch 18 - MCC: 0.7046\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8469 - loss: 0.3201 - val_accuracy: 0.8523 - val_loss: 0.3135 - mcc: 0.7046\n",
      "Epoch 19/20\n",
      "\u001B[1m168/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8499 - loss: 0.3166\n",
      "Epoch 19 - MCC: 0.7034\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8497 - loss: 0.3167 - val_accuracy: 0.8520 - val_loss: 0.3132 - mcc: 0.7034\n",
      "Epoch 20/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8470 - loss: 0.3190\n",
      "Epoch 20 - MCC: 0.7017\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8471 - loss: 0.3190 - val_accuracy: 0.8513 - val_loss: 0.3148 - mcc: 0.7017\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: MLP, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.7246 - loss: 0.5676\n",
      "Epoch 1 - MCC: 0.6968\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 11ms/step - accuracy: 0.7250 - loss: 0.5670 - val_accuracy: 0.8481 - val_loss: 0.3250 - mcc: 0.6968\n",
      "Epoch 2/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8478 - loss: 0.3237\n",
      "Epoch 2 - MCC: 0.6961\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8478 - loss: 0.3237 - val_accuracy: 0.8486 - val_loss: 0.3205 - mcc: 0.6961\n",
      "Epoch 3/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8474 - loss: 0.3225\n",
      "Epoch 3 - MCC: 0.6978\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8475 - loss: 0.3224 - val_accuracy: 0.8492 - val_loss: 0.3195 - mcc: 0.6978\n",
      "Epoch 4/20\n",
      "\u001B[1m174/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8476 - loss: 0.3212\n",
      "Epoch 4 - MCC: 0.6974\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8476 - loss: 0.3212 - val_accuracy: 0.8480 - val_loss: 0.3233 - mcc: 0.6974\n",
      "Epoch 5/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8449 - loss: 0.3254\n",
      "Epoch 5 - MCC: 0.6968\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8449 - loss: 0.3253 - val_accuracy: 0.8490 - val_loss: 0.3186 - mcc: 0.6968\n",
      "Epoch 6/20\n",
      "\u001B[1m167/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8497 - loss: 0.3168\n",
      "Epoch 6 - MCC: 0.6969\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8496 - loss: 0.3170 - val_accuracy: 0.8489 - val_loss: 0.3189 - mcc: 0.6969\n",
      "Epoch 7/20\n",
      "\u001B[1m169/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8471 - loss: 0.3220\n",
      "Epoch 7 - MCC: 0.6974\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8472 - loss: 0.3216 - val_accuracy: 0.8480 - val_loss: 0.3212 - mcc: 0.6974\n",
      "Epoch 8/20\n",
      "\u001B[1m173/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8484 - loss: 0.3207\n",
      "Epoch 8 - MCC: 0.6973\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8485 - loss: 0.3205 - val_accuracy: 0.8491 - val_loss: 0.3178 - mcc: 0.6973\n",
      "Epoch 9/20\n",
      "\u001B[1m172/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8484 - loss: 0.3181\n",
      "Epoch 9 - MCC: 0.6980\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8484 - loss: 0.3181 - val_accuracy: 0.8488 - val_loss: 0.3186 - mcc: 0.6980\n",
      "Epoch 10/20\n",
      "\u001B[1m168/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8465 - loss: 0.3206\n",
      "Epoch 10 - MCC: 0.6963\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8468 - loss: 0.3203 - val_accuracy: 0.8468 - val_loss: 0.3222 - mcc: 0.6963\n",
      "Epoch 11/20\n",
      "\u001B[1m171/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8475 - loss: 0.3211\n",
      "Epoch 11 - MCC: 0.6975\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8477 - loss: 0.3208 - val_accuracy: 0.8493 - val_loss: 0.3173 - mcc: 0.6975\n",
      "Epoch 12/20\n",
      "\u001B[1m173/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8487 - loss: 0.3170\n",
      "Epoch 12 - MCC: 0.6979\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8487 - loss: 0.3171 - val_accuracy: 0.8484 - val_loss: 0.3197 - mcc: 0.6979\n",
      "Epoch 13/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8494 - loss: 0.3177\n",
      "Epoch 13 - MCC: 0.6962\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8494 - loss: 0.3177 - val_accuracy: 0.8487 - val_loss: 0.3174 - mcc: 0.6962\n",
      "Epoch 14/20\n",
      "\u001B[1m174/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8500 - loss: 0.3160\n",
      "Epoch 14 - MCC: 0.6973\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8499 - loss: 0.3160 - val_accuracy: 0.8491 - val_loss: 0.3167 - mcc: 0.6973\n",
      "Epoch 15/20\n",
      "\u001B[1m174/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8461 - loss: 0.3219\n",
      "Epoch 15 - MCC: 0.6975\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8463 - loss: 0.3216 - val_accuracy: 0.8489 - val_loss: 0.3174 - mcc: 0.6975\n",
      "Epoch 16/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8531 - loss: 0.3095\n",
      "Epoch 16 - MCC: 0.6982\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8530 - loss: 0.3096 - val_accuracy: 0.8488 - val_loss: 0.3178 - mcc: 0.6982\n",
      "Epoch 17/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8520 - loss: 0.3141\n",
      "Epoch 17 - MCC: 0.6955\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8519 - loss: 0.3142 - val_accuracy: 0.8483 - val_loss: 0.3174 - mcc: 0.6955\n",
      "Epoch 18/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8471 - loss: 0.3191\n",
      "Epoch 18 - MCC: 0.6972\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8472 - loss: 0.3191 - val_accuracy: 0.8481 - val_loss: 0.3186 - mcc: 0.6972\n",
      "Epoch 19/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8523 - loss: 0.3115\n",
      "Epoch 19 - MCC: 0.6972\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8522 - loss: 0.3117 - val_accuracy: 0.8491 - val_loss: 0.3166 - mcc: 0.6972\n",
      "Epoch 20/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8488 - loss: 0.3176\n",
      "Epoch 20 - MCC: 0.6956\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8488 - loss: 0.3176 - val_accuracy: 0.8484 - val_loss: 0.3181 - mcc: 0.6956\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.8512853333333333),\n",
      "              'mean': np.float64(0.8490144000000001),\n",
      "              'min': np.float64(0.8453173333333334),\n",
      "              'std': np.float64(0.002176319976474028)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.0002574790318806966),\n",
      "                               'mean': np.float64(0.00021616274515787762),\n",
      "                               'min': np.float64(0.00015666325887044272),\n",
      "                               'std': np.float64(4.828813564362842e-05)},\n",
      " 'MCC': {'max': np.float64(0.7034255604036633),\n",
      "         'mean': np.float64(0.6974780768638038),\n",
      "         'min': np.float64(0.6896298482187477),\n",
      "         'std': np.float64(0.004875984816136057)},\n",
      " 'Parameters': 4713,\n",
      " 'Train Time (s)': {'max': np.float64(27.538688898086548),\n",
      "                    'mean': np.float64(26.18506588935852),\n",
      "                    'min': np.float64(24.72655439376831),\n",
      "                    'std': np.float64(1.001956715369044)},\n",
      " 'Training Accuracy': [[0.7957436442375183,\n",
      "                        0.8472412824630737,\n",
      "                        0.8479732871055603,\n",
      "                        0.848187267780304,\n",
      "                        0.8478994965553284,\n",
      "                        0.848487377166748,\n",
      "                        0.8483254313468933,\n",
      "                        0.8484449982643127,\n",
      "                        0.8481608629226685,\n",
      "                        0.848070502281189,\n",
      "                        0.8479944467544556,\n",
      "                        0.8485475182533264,\n",
      "                        0.8483654856681824,\n",
      "                        0.8483848571777344,\n",
      "                        0.8483820557594299,\n",
      "                        0.8482873439788818,\n",
      "                        0.848450779914856,\n",
      "                        0.8483859300613403,\n",
      "                        0.8483506441116333,\n",
      "                        0.8479959964752197],\n",
      "                       [0.7911694049835205,\n",
      "                        0.8484488129615784,\n",
      "                        0.8474751710891724,\n",
      "                        0.8479835391044617,\n",
      "                        0.8485501408576965,\n",
      "                        0.8482766151428223,\n",
      "                        0.8485755324363708,\n",
      "                        0.8486319780349731,\n",
      "                        0.848479151725769,\n",
      "                        0.8487129807472229,\n",
      "                        0.8490500450134277,\n",
      "                        0.8488926887512207,\n",
      "                        0.8488276600837708,\n",
      "                        0.8490274548530579,\n",
      "                        0.8486228585243225,\n",
      "                        0.8488303422927856,\n",
      "                        0.8489095568656921,\n",
      "                        0.8489335775375366,\n",
      "                        0.8493609428405762,\n",
      "                        0.8487713932991028],\n",
      "                       [0.7842200398445129,\n",
      "                        0.8489858508110046,\n",
      "                        0.8499451279640198,\n",
      "                        0.8496967554092407,\n",
      "                        0.8498027920722961,\n",
      "                        0.8498176336288452,\n",
      "                        0.8499648571014404,\n",
      "                        0.8499316573143005,\n",
      "                        0.8501191139221191,\n",
      "                        0.8497582077980042,\n",
      "                        0.8495237827301025,\n",
      "                        0.8496786952018738,\n",
      "                        0.8500945568084717,\n",
      "                        0.8503009676933289,\n",
      "                        0.8501286506652832,\n",
      "                        0.8490020632743835,\n",
      "                        0.8501569032669067,\n",
      "                        0.850112795829773,\n",
      "                        0.8503426909446716,\n",
      "                        0.8497379422187805],\n",
      "                       [0.7923955321311951,\n",
      "                        0.8478045463562012,\n",
      "                        0.848030686378479,\n",
      "                        0.8478544354438782,\n",
      "                        0.8477426171302795,\n",
      "                        0.8478865623474121,\n",
      "                        0.848082423210144,\n",
      "                        0.848349392414093,\n",
      "                        0.8483665585517883,\n",
      "                        0.8480367660522461,\n",
      "                        0.84816575050354,\n",
      "                        0.8481741547584534,\n",
      "                        0.847547173500061,\n",
      "                        0.8480892181396484,\n",
      "                        0.8482151031494141,\n",
      "                        0.8478427529335022,\n",
      "                        0.8482760190963745,\n",
      "                        0.8481500744819641,\n",
      "                        0.8482608795166016,\n",
      "                        0.8483928442001343],\n",
      "                       [0.8030678629875183,\n",
      "                        0.84792560338974,\n",
      "                        0.8485686182975769,\n",
      "                        0.8480529189109802,\n",
      "                        0.848599910736084,\n",
      "                        0.8488771915435791,\n",
      "                        0.8485973477363586,\n",
      "                        0.8488198518753052,\n",
      "                        0.8487780094146729,\n",
      "                        0.8492358922958374,\n",
      "                        0.8491752743721008,\n",
      "                        0.8487921357154846,\n",
      "                        0.8489112854003906,\n",
      "                        0.849205493927002,\n",
      "                        0.8488187789916992,\n",
      "                        0.8490467667579651,\n",
      "                        0.8494821190834045,\n",
      "                        0.8490145802497864,\n",
      "                        0.8495541214942932,\n",
      "                        0.8487626314163208]],\n",
      " 'Training Loss': [[0.4127543866634369,\n",
      "                    0.325101375579834,\n",
      "                    0.322674036026001,\n",
      "                    0.3209398686885834,\n",
      "                    0.32076138257980347,\n",
      "                    0.3196149170398712,\n",
      "                    0.31988999247550964,\n",
      "                    0.3192780613899231,\n",
      "                    0.31906118988990784,\n",
      "                    0.3193979561328888,\n",
      "                    0.3190787434577942,\n",
      "                    0.3186551630496979,\n",
      "                    0.31825247406959534,\n",
      "                    0.3181385397911072,\n",
      "                    0.31831541657447815,\n",
      "                    0.31824642419815063,\n",
      "                    0.3180816173553467,\n",
      "                    0.31799057126045227,\n",
      "                    0.3180188238620758,\n",
      "                    0.3183918297290802],\n",
      "                   [0.4117891788482666,\n",
      "                    0.3217505216598511,\n",
      "                    0.32200297713279724,\n",
      "                    0.32046449184417725,\n",
      "                    0.31902554631233215,\n",
      "                    0.31935518980026245,\n",
      "                    0.3188154995441437,\n",
      "                    0.3184483051300049,\n",
      "                    0.3183923363685608,\n",
      "                    0.31801867485046387,\n",
      "                    0.31745630502700806,\n",
      "                    0.31751054525375366,\n",
      "                    0.3174200654029846,\n",
      "                    0.3175968825817108,\n",
      "                    0.3173868954181671,\n",
      "                    0.31745943427085876,\n",
      "                    0.31716182827949524,\n",
      "                    0.31705984473228455,\n",
      "                    0.316782146692276,\n",
      "                    0.31747928261756897],\n",
      "                   [0.4282638430595398,\n",
      "                    0.3218722641468048,\n",
      "                    0.3193502426147461,\n",
      "                    0.31857237219810486,\n",
      "                    0.3177086114883423,\n",
      "                    0.31754469871520996,\n",
      "                    0.3172578811645508,\n",
      "                    0.3175128698348999,\n",
      "                    0.31710389256477356,\n",
      "                    0.3171050548553467,\n",
      "                    0.3178757131099701,\n",
      "                    0.31716787815093994,\n",
      "                    0.3165145814418793,\n",
      "                    0.31619566679000854,\n",
      "                    0.31660106778144836,\n",
      "                    0.31804075837135315,\n",
      "                    0.31598803400993347,\n",
      "                    0.31593701243400574,\n",
      "                    0.31591030955314636,\n",
      "                    0.3168853521347046],\n",
      "                   [0.4104057550430298,\n",
      "                    0.3236510157585144,\n",
      "                    0.32130855321884155,\n",
      "                    0.32119518518447876,\n",
      "                    0.3204953372478485,\n",
      "                    0.3203790783882141,\n",
      "                    0.3197292685508728,\n",
      "                    0.3191845715045929,\n",
      "                    0.31944990158081055,\n",
      "                    0.31908494234085083,\n",
      "                    0.31875374913215637,\n",
      "                    0.31875383853912354,\n",
      "                    0.31916943192481995,\n",
      "                    0.31870952248573303,\n",
      "                    0.3184186518192291,\n",
      "                    0.3187010884284973,\n",
      "                    0.3181510269641876,\n",
      "                    0.31802427768707275,\n",
      "                    0.3176080584526062,\n",
      "                    0.31771910190582275],\n",
      "                   [0.44326379895210266,\n",
      "                    0.3230116069316864,\n",
      "                    0.3204270005226135,\n",
      "                    0.3206946551799774,\n",
      "                    0.3191125690937042,\n",
      "                    0.31870436668395996,\n",
      "                    0.3185584843158722,\n",
      "                    0.31840330362319946,\n",
      "                    0.31803011894226074,\n",
      "                    0.31715673208236694,\n",
      "                    0.317624032497406,\n",
      "                    0.31777703762054443,\n",
      "                    0.3176276385784149,\n",
      "                    0.31686046719551086,\n",
      "                    0.31770262122154236,\n",
      "                    0.31690579652786255,\n",
      "                    0.3166152536869049,\n",
      "                    0.31697073578834534,\n",
      "                    0.3165751099586487,\n",
      "                    0.3172939419746399]],\n",
      " 'Validation Accuracy': [[0.8512773513793945,\n",
      "                          0.8509868383407593,\n",
      "                          0.850493311882019,\n",
      "                          0.8500587344169617,\n",
      "                          0.8476452827453613,\n",
      "                          0.8509600162506104,\n",
      "                          0.8512666821479797,\n",
      "                          0.8508773446083069,\n",
      "                          0.8515707850456238,\n",
      "                          0.8516241312026978,\n",
      "                          0.8508506417274475,\n",
      "                          0.8512372970581055,\n",
      "                          0.8493227362632751,\n",
      "                          0.8512104749679565,\n",
      "                          0.8514693975448608,\n",
      "                          0.8505761027336121,\n",
      "                          0.8516587615013123,\n",
      "                          0.8517226576805115,\n",
      "                          0.85152268409729,\n",
      "                          0.8511252999305725],\n",
      "                         [0.8446212410926819,\n",
      "                          0.8466880917549133,\n",
      "                          0.8500987887382507,\n",
      "                          0.8490347266197205,\n",
      "                          0.8499361276626587,\n",
      "                          0.8479308485984802,\n",
      "                          0.848898708820343,\n",
      "                          0.8498746156692505,\n",
      "                          0.8473334312438965,\n",
      "                          0.8470079898834229,\n",
      "                          0.8494400978088379,\n",
      "                          0.8503600358963013,\n",
      "                          0.8493226766586304,\n",
      "                          0.8494880199432373,\n",
      "                          0.8498265743255615,\n",
      "                          0.8503734469413757,\n",
      "                          0.8489091992378235,\n",
      "                          0.8502345085144043,\n",
      "                          0.8489068150520325,\n",
      "                          0.8489599823951721],\n",
      "                         [0.843909502029419,\n",
      "                          0.8436134457588196,\n",
      "                          0.8418880105018616,\n",
      "                          0.8449040651321411,\n",
      "                          0.8452534079551697,\n",
      "                          0.8420667052268982,\n",
      "                          0.8450241088867188,\n",
      "                          0.8442667722702026,\n",
      "                          0.8447840213775635,\n",
      "                          0.8449335098266602,\n",
      "                          0.8437308073043823,\n",
      "                          0.8446800708770752,\n",
      "                          0.8447548747062683,\n",
      "                          0.8451120853424072,\n",
      "                          0.8450533151626587,\n",
      "                          0.8453332781791687,\n",
      "                          0.8449575304985046,\n",
      "                          0.8436560034751892,\n",
      "                          0.844378650188446,\n",
      "                          0.8453172445297241],\n",
      "                         [0.8516534566879272,\n",
      "                          0.8519254326820374,\n",
      "                          0.8520667552947998,\n",
      "                          0.8515894412994385,\n",
      "                          0.851919949054718,\n",
      "                          0.8512640595436096,\n",
      "                          0.8498401641845703,\n",
      "                          0.8515307903289795,\n",
      "                          0.8519467711448669,\n",
      "                          0.8521786332130432,\n",
      "                          0.8521761298179626,\n",
      "                          0.8500561714172363,\n",
      "                          0.851837158203125,\n",
      "                          0.851599931716919,\n",
      "                          0.8517278432846069,\n",
      "                          0.8516375422477722,\n",
      "                          0.850501298904419,\n",
      "                          0.8523095846176147,\n",
      "                          0.8520347476005554,\n",
      "                          0.8512855768203735],\n",
      "                         [0.8481334447860718,\n",
      "                          0.8486294150352478,\n",
      "                          0.8492135405540466,\n",
      "                          0.8479785919189453,\n",
      "                          0.8489789366722107,\n",
      "                          0.8488693833351135,\n",
      "                          0.8480267524719238,\n",
      "                          0.8491386771202087,\n",
      "                          0.8488267660140991,\n",
      "                          0.8467733263969421,\n",
      "                          0.8492640256881714,\n",
      "                          0.8484106659889221,\n",
      "                          0.8487119674682617,\n",
      "                          0.8491439819335938,\n",
      "                          0.8489173054695129,\n",
      "                          0.8488081097602844,\n",
      "                          0.8483228087425232,\n",
      "                          0.8481042385101318,\n",
      "                          0.8490986227989197,\n",
      "                          0.8483841419219971]],\n",
      " 'Validation Loss': [0.3250178396701813,\n",
      "                     0.3205167353153229,\n",
      "                     0.3195054829120636,\n",
      "                     0.3232559263706207,\n",
      "                     0.31855309009552,\n",
      "                     0.3189229667186737,\n",
      "                     0.32119041681289673,\n",
      "                     0.3178463876247406,\n",
      "                     0.31855231523513794,\n",
      "                     0.3221539556980133,\n",
      "                     0.3173275589942932,\n",
      "                     0.3196834921836853,\n",
      "                     0.31735116243362427,\n",
      "                     0.3166811168193817,\n",
      "                     0.3174491226673126,\n",
      "                     0.3178189992904663,\n",
      "                     0.31739386916160583,\n",
      "                     0.3185914158821106,\n",
      "                     0.3166276514530182,\n",
      "                     0.3181005120277405],\n",
      " 'Validation MCC': [[np.float64(0.7023684864348342),\n",
      "                     np.float64(0.7024180483235306),\n",
      "                     np.float64(0.7000874781330755),\n",
      "                     np.float64(0.6992768427225367),\n",
      "                     np.float64(0.6954090125808751),\n",
      "                     np.float64(0.7010052576908409),\n",
      "                     np.float64(0.7030095392641763),\n",
      "                     np.float64(0.7008315852575525),\n",
      "                     np.float64(0.7024190209846286),\n",
      "                     np.float64(0.7031011258828072),\n",
      "                     np.float64(0.7007793921436972),\n",
      "                     np.float64(0.7025224602274418),\n",
      "                     np.float64(0.7016898122558249),\n",
      "                     np.float64(0.701641961417537),\n",
      "                     np.float64(0.7033228667525209),\n",
      "                     np.float64(0.700234535559492),\n",
      "                     np.float64(0.7033314594428302),\n",
      "                     np.float64(0.7035602910556381),\n",
      "                     np.float64(0.7028393147262836),\n",
      "                     np.float64(0.7034255604036633)],\n",
      "                    [np.float64(0.6897721175223125),\n",
      "                     np.float64(0.693047128457595),\n",
      "                     np.float64(0.6993175799811256),\n",
      "                     np.float64(0.6970949350796539),\n",
      "                     np.float64(0.6989292161763347),\n",
      "                     np.float64(0.6950973373641762),\n",
      "                     np.float64(0.6968046377723335),\n",
      "                     np.float64(0.6987551823639044),\n",
      "                     np.float64(0.6941242317202503),\n",
      "                     np.float64(0.6935552289503214),\n",
      "                     np.float64(0.6978755472213539),\n",
      "                     np.float64(0.7001944118147373),\n",
      "                     np.float64(0.6976645394771187),\n",
      "                     np.float64(0.6999602406381266),\n",
      "                     np.float64(0.7004379695177847),\n",
      "                     np.float64(0.6999885507715174),\n",
      "                     np.float64(0.6968831359890268),\n",
      "                     np.float64(0.7000728302736707),\n",
      "                     np.float64(0.6968504588288327),\n",
      "                     np.float64(0.6970169877575771)],\n",
      "                    [np.float64(0.6871023449999533),\n",
      "                     np.float64(0.6861606461490627),\n",
      "                     np.float64(0.6836087325408048),\n",
      "                     np.float64(0.6887024349515134),\n",
      "                     np.float64(0.6896882310188827),\n",
      "                     np.float64(0.6878584036513508),\n",
      "                     np.float64(0.6893066924132225),\n",
      "                     np.float64(0.6873018667735927),\n",
      "                     np.float64(0.6894603699918467),\n",
      "                     np.float64(0.6891778285149568),\n",
      "                     np.float64(0.689204950220006),\n",
      "                     np.float64(0.68926326380343),\n",
      "                     np.float64(0.6883191709765777),\n",
      "                     np.float64(0.689090050547157),\n",
      "                     np.float64(0.6888400785835929),\n",
      "                     np.float64(0.6896928120123317),\n",
      "                     np.float64(0.6894358695314656),\n",
      "                     np.float64(0.6891852133855573),\n",
      "                     np.float64(0.6891698151549374),\n",
      "                     np.float64(0.6896298482187477)],\n",
      "                    [np.float64(0.7024121309191638),\n",
      "                     np.float64(0.7032129433282569),\n",
      "                     np.float64(0.7038065415692202),\n",
      "                     np.float64(0.702216045369338),\n",
      "                     np.float64(0.7035995795801168),\n",
      "                     np.float64(0.7015582306328498),\n",
      "                     np.float64(0.6989527583006447),\n",
      "                     np.float64(0.7021396060918977),\n",
      "                     np.float64(0.7032223520157492),\n",
      "                     np.float64(0.7038743063943268),\n",
      "                     np.float64(0.7041633766866863),\n",
      "                     np.float64(0.6993429773202201),\n",
      "                     np.float64(0.7043682522873596),\n",
      "                     np.float64(0.7023310894157478),\n",
      "                     np.float64(0.7037234948364504),\n",
      "                     np.float64(0.7023377790253612),\n",
      "                     np.float64(0.7001569840414187),\n",
      "                     np.float64(0.7046287882969589),\n",
      "                     np.float64(0.7033825616405049),\n",
      "                     np.float64(0.7017336608400042)],\n",
      "                    [np.float64(0.6968058230765533),\n",
      "                     np.float64(0.6961007915290741),\n",
      "                     np.float64(0.6978153346153726),\n",
      "                     np.float64(0.6973972672284516),\n",
      "                     np.float64(0.6968484088243598),\n",
      "                     np.float64(0.6969250067748135),\n",
      "                     np.float64(0.6973945587430509),\n",
      "                     np.float64(0.6972598173297829),\n",
      "                     np.float64(0.6980246471317907),\n",
      "                     np.float64(0.6962759987732267),\n",
      "                     np.float64(0.6975348048682727),\n",
      "                     np.float64(0.6979129639092272),\n",
      "                     np.float64(0.6962434364727984),\n",
      "                     np.float64(0.6973312236065181),\n",
      "                     np.float64(0.6975256314161277),\n",
      "                     np.float64(0.6981734016323091),\n",
      "                     np.float64(0.695464757914429),\n",
      "                     np.float64(0.6972373342835089),\n",
      "                     np.float64(0.6971520161131979),\n",
      "                     np.float64(0.6955843270990266)]]}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# All Features Binary\n",
    "\n",
    "model_results, trained_models = train_and_evaluate(simple_models_dict, X=all_data_vec_binary, y=label_binary, epochs=20, basePath=basePath, dir_name='allF_binary')\n",
    "\n",
    "filePath = f\"{basePath}/AllF_Binary_Model_Results.json\"\n",
    "\n",
    "with open(filePath, 'w') as f:\n",
    "        json.dump(model_results, f, indent=4)  # indent=4 for pretty formatting\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9XGIaP7mUlj",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1744804521537,
     "user_tz": -120,
     "elapsed": 3030332,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     }
    },
    "outputId": "4bb0ac03-fda3-4371-b00d-0f1aaf233433",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Binary: True\n",
      "Training Model: LSTM, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7434 - loss: 0.4606\n",
      "Epoch 1 - MCC: 0.8189\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.7439 - loss: 0.4600 - val_accuracy: 0.9096 - val_loss: 0.2192 - mcc: 0.8189\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9129 - loss: 0.2120\n",
      "Epoch 2 - MCC: 0.8397\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9129 - loss: 0.2120 - val_accuracy: 0.9199 - val_loss: 0.1968 - mcc: 0.8397\n",
      "Epoch 3/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9181 - loss: 0.1983\n",
      "Epoch 3 - MCC: 0.8444\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9181 - loss: 0.1983 - val_accuracy: 0.9223 - val_loss: 0.1882 - mcc: 0.8444\n",
      "Epoch 4/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9219 - loss: 0.1870\n",
      "Epoch 4 - MCC: 0.8531\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.9219 - loss: 0.1870 - val_accuracy: 0.9267 - val_loss: 0.1790 - mcc: 0.8531\n",
      "Epoch 5/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9262 - loss: 0.1791\n",
      "Epoch 5 - MCC: 0.8514\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.9262 - loss: 0.1791 - val_accuracy: 0.9259 - val_loss: 0.1772 - mcc: 0.8514\n",
      "Epoch 6/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9258 - loss: 0.1778\n",
      "Epoch 6 - MCC: 0.8574\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9258 - loss: 0.1777 - val_accuracy: 0.9289 - val_loss: 0.1715 - mcc: 0.8574\n",
      "Epoch 7/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9289 - loss: 0.1716\n",
      "Epoch 7 - MCC: 0.8610\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9289 - loss: 0.1716 - val_accuracy: 0.9305 - val_loss: 0.1672 - mcc: 0.8610\n",
      "Epoch 8/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9303 - loss: 0.1687\n",
      "Epoch 8 - MCC: 0.8636\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9304 - loss: 0.1687 - val_accuracy: 0.9318 - val_loss: 0.1662 - mcc: 0.8636\n",
      "Epoch 9/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9337 - loss: 0.1608\n",
      "Epoch 9 - MCC: 0.8676\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9336 - loss: 0.1608 - val_accuracy: 0.9340 - val_loss: 0.1610 - mcc: 0.8676\n",
      "Epoch 10/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9323 - loss: 0.1635\n",
      "Epoch 10 - MCC: 0.8688\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 25ms/step - accuracy: 0.9323 - loss: 0.1635 - val_accuracy: 0.9345 - val_loss: 0.1590 - mcc: 0.8688\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9319 - loss: 0.1645\n",
      "Epoch 11 - MCC: 0.8708\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9319 - loss: 0.1644 - val_accuracy: 0.9356 - val_loss: 0.1573 - mcc: 0.8708\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9348 - loss: 0.1584\n",
      "Epoch 12 - MCC: 0.8683\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9348 - loss: 0.1584 - val_accuracy: 0.9343 - val_loss: 0.1577 - mcc: 0.8683\n",
      "Epoch 13/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9348 - loss: 0.1578\n",
      "Epoch 13 - MCC: 0.8717\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9348 - loss: 0.1578 - val_accuracy: 0.9360 - val_loss: 0.1557 - mcc: 0.8717\n",
      "Epoch 14/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9372 - loss: 0.1530\n",
      "Epoch 14 - MCC: 0.8704\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9371 - loss: 0.1531 - val_accuracy: 0.9353 - val_loss: 0.1568 - mcc: 0.8704\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9336 - loss: 0.1582\n",
      "Epoch 15 - MCC: 0.8748\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 20ms/step - accuracy: 0.9336 - loss: 0.1582 - val_accuracy: 0.9374 - val_loss: 0.1527 - mcc: 0.8748\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9359 - loss: 0.1536\n",
      "Epoch 16 - MCC: 0.8760\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.9359 - loss: 0.1536 - val_accuracy: 0.9381 - val_loss: 0.1512 - mcc: 0.8760\n",
      "Epoch 17/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9397 - loss: 0.1465\n",
      "Epoch 17 - MCC: 0.8769\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9397 - loss: 0.1466 - val_accuracy: 0.9386 - val_loss: 0.1495 - mcc: 0.8769\n",
      "Epoch 18/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9377 - loss: 0.1493\n",
      "Epoch 18 - MCC: 0.8754\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 22ms/step - accuracy: 0.9377 - loss: 0.1493 - val_accuracy: 0.9376 - val_loss: 0.1512 - mcc: 0.8754\n",
      "Epoch 19/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9373 - loss: 0.1501\n",
      "Epoch 19 - MCC: 0.8697\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9373 - loss: 0.1501 - val_accuracy: 0.9350 - val_loss: 0.1563 - mcc: 0.8697\n",
      "Epoch 20/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9382 - loss: 0.1487\n",
      "Epoch 20 - MCC: 0.8744\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9382 - loss: 0.1487 - val_accuracy: 0.9374 - val_loss: 0.1525 - mcc: 0.8744\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7247 - loss: 0.5077\n",
      "Epoch 1 - MCC: 0.8164\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.7269 - loss: 0.5048 - val_accuracy: 0.9084 - val_loss: 0.2282 - mcc: 0.8164\n",
      "Epoch 2/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9069 - loss: 0.2263\n",
      "Epoch 2 - MCC: 0.8314\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9069 - loss: 0.2262 - val_accuracy: 0.9155 - val_loss: 0.2066 - mcc: 0.8314\n",
      "Epoch 3/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9169 - loss: 0.2021\n",
      "Epoch 3 - MCC: 0.8419\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9169 - loss: 0.2021 - val_accuracy: 0.9211 - val_loss: 0.1907 - mcc: 0.8419\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9203 - loss: 0.1932\n",
      "Epoch 4 - MCC: 0.8487\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9204 - loss: 0.1931 - val_accuracy: 0.9246 - val_loss: 0.1834 - mcc: 0.8487\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9224 - loss: 0.1868\n",
      "Epoch 5 - MCC: 0.8465\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9224 - loss: 0.1867 - val_accuracy: 0.9234 - val_loss: 0.1824 - mcc: 0.8465\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9235 - loss: 0.1827\n",
      "Epoch 6 - MCC: 0.8557\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 22ms/step - accuracy: 0.9235 - loss: 0.1827 - val_accuracy: 0.9281 - val_loss: 0.1741 - mcc: 0.8557\n",
      "Epoch 7/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9244 - loss: 0.1827\n",
      "Epoch 7 - MCC: 0.8538\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9244 - loss: 0.1826 - val_accuracy: 0.9270 - val_loss: 0.1760 - mcc: 0.8538\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9284 - loss: 0.1724\n",
      "Epoch 8 - MCC: 0.8598\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9284 - loss: 0.1724 - val_accuracy: 0.9300 - val_loss: 0.1695 - mcc: 0.8598\n",
      "Epoch 9/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9292 - loss: 0.1694\n",
      "Epoch 9 - MCC: 0.8577\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9292 - loss: 0.1694 - val_accuracy: 0.9291 - val_loss: 0.1687 - mcc: 0.8577\n",
      "Epoch 10/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9338 - loss: 0.1601\n",
      "Epoch 10 - MCC: 0.8630\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9337 - loss: 0.1602 - val_accuracy: 0.9317 - val_loss: 0.1658 - mcc: 0.8630\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9322 - loss: 0.1641\n",
      "Epoch 11 - MCC: 0.8639\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9322 - loss: 0.1641 - val_accuracy: 0.9321 - val_loss: 0.1618 - mcc: 0.8639\n",
      "Epoch 12/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9333 - loss: 0.1611\n",
      "Epoch 12 - MCC: 0.8682\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9333 - loss: 0.1611 - val_accuracy: 0.9339 - val_loss: 0.1595 - mcc: 0.8682\n",
      "Epoch 13/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9336 - loss: 0.1605\n",
      "Epoch 13 - MCC: 0.8720\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9336 - loss: 0.1605 - val_accuracy: 0.9361 - val_loss: 0.1559 - mcc: 0.8720\n",
      "Epoch 14/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9351 - loss: 0.1570\n",
      "Epoch 14 - MCC: 0.8718\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 20ms/step - accuracy: 0.9351 - loss: 0.1570 - val_accuracy: 0.9360 - val_loss: 0.1545 - mcc: 0.8718\n",
      "Epoch 15/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9350 - loss: 0.1570\n",
      "Epoch 15 - MCC: 0.8731\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.9350 - loss: 0.1570 - val_accuracy: 0.9367 - val_loss: 0.1529 - mcc: 0.8731\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9368 - loss: 0.1530\n",
      "Epoch 16 - MCC: 0.8758\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9368 - loss: 0.1530 - val_accuracy: 0.9379 - val_loss: 0.1495 - mcc: 0.8758\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9376 - loss: 0.1511\n",
      "Epoch 17 - MCC: 0.8724\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.9376 - loss: 0.1511 - val_accuracy: 0.9364 - val_loss: 0.1556 - mcc: 0.8724\n",
      "Epoch 18/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9361 - loss: 0.1542\n",
      "Epoch 18 - MCC: 0.8758\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9361 - loss: 0.1541 - val_accuracy: 0.9381 - val_loss: 0.1495 - mcc: 0.8758\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9379 - loss: 0.1501\n",
      "Epoch 19 - MCC: 0.8760\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9379 - loss: 0.1501 - val_accuracy: 0.9381 - val_loss: 0.1512 - mcc: 0.8760\n",
      "Epoch 20/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9379 - loss: 0.1509\n",
      "Epoch 20 - MCC: 0.8775\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9379 - loss: 0.1509 - val_accuracy: 0.9389 - val_loss: 0.1475 - mcc: 0.8775\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7120 - loss: 0.4766\n",
      "Epoch 1 - MCC: 0.8212\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.7127 - loss: 0.4758 - val_accuracy: 0.9109 - val_loss: 0.2240 - mcc: 0.8212\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9111 - loss: 0.2166\n",
      "Epoch 2 - MCC: 0.8312\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9112 - loss: 0.2165 - val_accuracy: 0.9158 - val_loss: 0.2039 - mcc: 0.8312\n",
      "Epoch 3/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9172 - loss: 0.2008\n",
      "Epoch 3 - MCC: 0.8402\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9172 - loss: 0.2008 - val_accuracy: 0.9204 - val_loss: 0.1922 - mcc: 0.8402\n",
      "Epoch 4/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9236 - loss: 0.1858\n",
      "Epoch 4 - MCC: 0.8451\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9235 - loss: 0.1858 - val_accuracy: 0.9229 - val_loss: 0.1886 - mcc: 0.8451\n",
      "Epoch 5/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9216 - loss: 0.1892\n",
      "Epoch 5 - MCC: 0.8447\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9217 - loss: 0.1891 - val_accuracy: 0.9221 - val_loss: 0.1925 - mcc: 0.8447\n",
      "Epoch 6/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9260 - loss: 0.1781\n",
      "Epoch 6 - MCC: 0.8527\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9260 - loss: 0.1781 - val_accuracy: 0.9266 - val_loss: 0.1774 - mcc: 0.8527\n",
      "Epoch 7/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9273 - loss: 0.1755\n",
      "Epoch 7 - MCC: 0.8522\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9273 - loss: 0.1755 - val_accuracy: 0.9262 - val_loss: 0.1840 - mcc: 0.8522\n",
      "Epoch 8/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9304 - loss: 0.1697\n",
      "Epoch 8 - MCC: 0.8549\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9304 - loss: 0.1697 - val_accuracy: 0.9276 - val_loss: 0.1743 - mcc: 0.8549\n",
      "Epoch 9/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9302 - loss: 0.1673\n",
      "Epoch 9 - MCC: 0.8631\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9302 - loss: 0.1673 - val_accuracy: 0.9316 - val_loss: 0.1679 - mcc: 0.8631\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9310 - loss: 0.1664\n",
      "Epoch 10 - MCC: 0.8616\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9310 - loss: 0.1663 - val_accuracy: 0.9309 - val_loss: 0.1678 - mcc: 0.8616\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9319 - loss: 0.1650\n",
      "Epoch 11 - MCC: 0.8646\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 22ms/step - accuracy: 0.9319 - loss: 0.1650 - val_accuracy: 0.9325 - val_loss: 0.1634 - mcc: 0.8646\n",
      "Epoch 12/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9345 - loss: 0.1594\n",
      "Epoch 12 - MCC: 0.8632\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9345 - loss: 0.1594 - val_accuracy: 0.9318 - val_loss: 0.1645 - mcc: 0.8632\n",
      "Epoch 13/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9347 - loss: 0.1577\n",
      "Epoch 13 - MCC: 0.8649\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9348 - loss: 0.1577 - val_accuracy: 0.9325 - val_loss: 0.1655 - mcc: 0.8649\n",
      "Epoch 14/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9365 - loss: 0.1545\n",
      "Epoch 14 - MCC: 0.8668\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9365 - loss: 0.1545 - val_accuracy: 0.9336 - val_loss: 0.1615 - mcc: 0.8668\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9357 - loss: 0.1554\n",
      "Epoch 15 - MCC: 0.8631\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 20ms/step - accuracy: 0.9357 - loss: 0.1554 - val_accuracy: 0.9317 - val_loss: 0.1634 - mcc: 0.8631\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9368 - loss: 0.1525\n",
      "Epoch 16 - MCC: 0.8689\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 24ms/step - accuracy: 0.9368 - loss: 0.1525 - val_accuracy: 0.9347 - val_loss: 0.1575 - mcc: 0.8689\n",
      "Epoch 17/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9368 - loss: 0.1520\n",
      "Epoch 17 - MCC: 0.8689\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9368 - loss: 0.1520 - val_accuracy: 0.9346 - val_loss: 0.1581 - mcc: 0.8689\n",
      "Epoch 18/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9369 - loss: 0.1529\n",
      "Epoch 18 - MCC: 0.8710\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9369 - loss: 0.1529 - val_accuracy: 0.9357 - val_loss: 0.1560 - mcc: 0.8710\n",
      "Epoch 19/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9403 - loss: 0.1452\n",
      "Epoch 19 - MCC: 0.8714\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9402 - loss: 0.1453 - val_accuracy: 0.9359 - val_loss: 0.1566 - mcc: 0.8714\n",
      "Epoch 20/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9380 - loss: 0.1489\n",
      "Epoch 20 - MCC: 0.8639\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9380 - loss: 0.1489 - val_accuracy: 0.9321 - val_loss: 0.1610 - mcc: 0.8639\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.7191 - loss: 0.4882\n",
      "Epoch 1 - MCC: 0.8132\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 25ms/step - accuracy: 0.7202 - loss: 0.4869 - val_accuracy: 0.9067 - val_loss: 0.2272 - mcc: 0.8132\n",
      "Epoch 2/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9080 - loss: 0.2250\n",
      "Epoch 2 - MCC: 0.8313\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9080 - loss: 0.2249 - val_accuracy: 0.9156 - val_loss: 0.2004 - mcc: 0.8313\n",
      "Epoch 3/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9186 - loss: 0.1968\n",
      "Epoch 3 - MCC: 0.8361\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9186 - loss: 0.1968 - val_accuracy: 0.9181 - val_loss: 0.1971 - mcc: 0.8361\n",
      "Epoch 4/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9193 - loss: 0.1951\n",
      "Epoch 4 - MCC: 0.8459\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 24ms/step - accuracy: 0.9193 - loss: 0.1950 - val_accuracy: 0.9230 - val_loss: 0.1836 - mcc: 0.8459\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9230 - loss: 0.1859\n",
      "Epoch 5 - MCC: 0.8471\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9230 - loss: 0.1859 - val_accuracy: 0.9233 - val_loss: 0.1842 - mcc: 0.8471\n",
      "Epoch 6/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9235 - loss: 0.1841\n",
      "Epoch 6 - MCC: 0.8537\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.9236 - loss: 0.1840 - val_accuracy: 0.9271 - val_loss: 0.1744 - mcc: 0.8537\n",
      "Epoch 7/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9275 - loss: 0.1748\n",
      "Epoch 7 - MCC: 0.8556\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9276 - loss: 0.1748 - val_accuracy: 0.9273 - val_loss: 0.1730 - mcc: 0.8556\n",
      "Epoch 8/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9286 - loss: 0.1716\n",
      "Epoch 8 - MCC: 0.8632\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9286 - loss: 0.1716 - val_accuracy: 0.9318 - val_loss: 0.1647 - mcc: 0.8632\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9317 - loss: 0.1656\n",
      "Epoch 9 - MCC: 0.8644\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.9317 - loss: 0.1656 - val_accuracy: 0.9323 - val_loss: 0.1612 - mcc: 0.8644\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9313 - loss: 0.1646\n",
      "Epoch 10 - MCC: 0.8672\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 22ms/step - accuracy: 0.9313 - loss: 0.1646 - val_accuracy: 0.9334 - val_loss: 0.1598 - mcc: 0.8672\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9339 - loss: 0.1605\n",
      "Epoch 11 - MCC: 0.8694\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.9338 - loss: 0.1605 - val_accuracy: 0.9348 - val_loss: 0.1577 - mcc: 0.8694\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9326 - loss: 0.1640\n",
      "Epoch 12 - MCC: 0.8727\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9326 - loss: 0.1640 - val_accuracy: 0.9365 - val_loss: 0.1539 - mcc: 0.8727\n",
      "Epoch 13/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9342 - loss: 0.1593\n",
      "Epoch 13 - MCC: 0.8732\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9342 - loss: 0.1593 - val_accuracy: 0.9367 - val_loss: 0.1525 - mcc: 0.8732\n",
      "Epoch 14/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9368 - loss: 0.1532\n",
      "Epoch 14 - MCC: 0.8723\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 24ms/step - accuracy: 0.9368 - loss: 0.1532 - val_accuracy: 0.9363 - val_loss: 0.1531 - mcc: 0.8723\n",
      "Epoch 15/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9361 - loss: 0.1560\n",
      "Epoch 15 - MCC: 0.8759\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9361 - loss: 0.1560 - val_accuracy: 0.9381 - val_loss: 0.1491 - mcc: 0.8759\n",
      "Epoch 16/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9366 - loss: 0.1549\n",
      "Epoch 16 - MCC: 0.8750\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 21ms/step - accuracy: 0.9366 - loss: 0.1549 - val_accuracy: 0.9374 - val_loss: 0.1509 - mcc: 0.8750\n",
      "Epoch 17/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9367 - loss: 0.1527\n",
      "Epoch 17 - MCC: 0.8776\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9367 - loss: 0.1527 - val_accuracy: 0.9390 - val_loss: 0.1486 - mcc: 0.8776\n",
      "Epoch 18/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9395 - loss: 0.1480\n",
      "Epoch 18 - MCC: 0.8719\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9395 - loss: 0.1481 - val_accuracy: 0.9356 - val_loss: 0.1537 - mcc: 0.8719\n",
      "Epoch 19/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9366 - loss: 0.1537\n",
      "Epoch 19 - MCC: 0.8765\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.9366 - loss: 0.1537 - val_accuracy: 0.9384 - val_loss: 0.1479 - mcc: 0.8765\n",
      "Epoch 20/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9372 - loss: 0.1517\n",
      "Epoch 20 - MCC: 0.8783\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9372 - loss: 0.1517 - val_accuracy: 0.9391 - val_loss: 0.1457 - mcc: 0.8783\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7382 - loss: 0.4863\n",
      "Epoch 1 - MCC: 0.8190\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 22ms/step - accuracy: 0.7392 - loss: 0.4849 - val_accuracy: 0.9098 - val_loss: 0.2203 - mcc: 0.8190\n",
      "Epoch 2/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9100 - loss: 0.2171\n",
      "Epoch 2 - MCC: 0.8278\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 25ms/step - accuracy: 0.9100 - loss: 0.2170 - val_accuracy: 0.9140 - val_loss: 0.2043 - mcc: 0.8278\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9158 - loss: 0.2011\n",
      "Epoch 3 - MCC: 0.8420\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9158 - loss: 0.2011 - val_accuracy: 0.9212 - val_loss: 0.1937 - mcc: 0.8420\n",
      "Epoch 4/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9204 - loss: 0.1923\n",
      "Epoch 4 - MCC: 0.8461\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9204 - loss: 0.1922 - val_accuracy: 0.9233 - val_loss: 0.1858 - mcc: 0.8461\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9240 - loss: 0.1836\n",
      "Epoch 5 - MCC: 0.8487\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 24ms/step - accuracy: 0.9240 - loss: 0.1837 - val_accuracy: 0.9246 - val_loss: 0.1812 - mcc: 0.8487\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9251 - loss: 0.1802\n",
      "Epoch 6 - MCC: 0.8495\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9251 - loss: 0.1802 - val_accuracy: 0.9249 - val_loss: 0.1790 - mcc: 0.8495\n",
      "Epoch 7/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9274 - loss: 0.1747\n",
      "Epoch 7 - MCC: 0.8541\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9274 - loss: 0.1748 - val_accuracy: 0.9271 - val_loss: 0.1759 - mcc: 0.8541\n",
      "Epoch 8/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9284 - loss: 0.1728\n",
      "Epoch 8 - MCC: 0.8568\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 21ms/step - accuracy: 0.9284 - loss: 0.1728 - val_accuracy: 0.9285 - val_loss: 0.1725 - mcc: 0.8568\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9289 - loss: 0.1710\n",
      "Epoch 9 - MCC: 0.8575\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.9289 - loss: 0.1710 - val_accuracy: 0.9290 - val_loss: 0.1706 - mcc: 0.8575\n",
      "Epoch 10/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9308 - loss: 0.1671\n",
      "Epoch 10 - MCC: 0.8588\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9308 - loss: 0.1672 - val_accuracy: 0.9296 - val_loss: 0.1685 - mcc: 0.8588\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9319 - loss: 0.1654\n",
      "Epoch 11 - MCC: 0.8583\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9319 - loss: 0.1654 - val_accuracy: 0.9293 - val_loss: 0.1694 - mcc: 0.8583\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9315 - loss: 0.1652\n",
      "Epoch 12 - MCC: 0.8627\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9315 - loss: 0.1652 - val_accuracy: 0.9316 - val_loss: 0.1632 - mcc: 0.8627\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9333 - loss: 0.1605\n",
      "Epoch 13 - MCC: 0.8641\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9333 - loss: 0.1605 - val_accuracy: 0.9323 - val_loss: 0.1623 - mcc: 0.8641\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9339 - loss: 0.1590\n",
      "Epoch 14 - MCC: 0.8640\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9339 - loss: 0.1590 - val_accuracy: 0.9321 - val_loss: 0.1620 - mcc: 0.8640\n",
      "Epoch 15/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9340 - loss: 0.1585\n",
      "Epoch 15 - MCC: 0.8675\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9340 - loss: 0.1585 - val_accuracy: 0.9340 - val_loss: 0.1591 - mcc: 0.8675\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9333 - loss: 0.1608\n",
      "Epoch 16 - MCC: 0.8685\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.9333 - loss: 0.1608 - val_accuracy: 0.9344 - val_loss: 0.1562 - mcc: 0.8685\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9372 - loss: 0.1518\n",
      "Epoch 17 - MCC: 0.8714\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 20ms/step - accuracy: 0.9372 - loss: 0.1518 - val_accuracy: 0.9359 - val_loss: 0.1542 - mcc: 0.8714\n",
      "Epoch 18/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9365 - loss: 0.1533\n",
      "Epoch 18 - MCC: 0.8699\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9365 - loss: 0.1532 - val_accuracy: 0.9351 - val_loss: 0.1560 - mcc: 0.8699\n",
      "Epoch 19/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9374 - loss: 0.1518\n",
      "Epoch 19 - MCC: 0.8710\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 22ms/step - accuracy: 0.9374 - loss: 0.1518 - val_accuracy: 0.9356 - val_loss: 0.1544 - mcc: 0.8710\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9389 - loss: 0.1473\n",
      "Epoch 20 - MCC: 0.8737\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9389 - loss: 0.1473 - val_accuracy: 0.9371 - val_loss: 0.1511 - mcc: 0.8737\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.9391493333333333),\n",
      "              'mean': np.float64(0.9369136000000001),\n",
      "              'min': np.float64(0.932104),\n",
      "              'std': np.float64(0.0025379122688628047)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.0009512027104695638),\n",
      "                               'mean': np.float64(0.0005437355677286784),\n",
      "                               'min': np.float64(0.00032804361979166664),\n",
      "                               'std': np.float64(0.0002120592684477958)},\n",
      " 'MCC': {'max': np.float64(0.8782617453884171),\n",
      "         'mean': np.float64(0.8735404624840294),\n",
      "         'min': np.float64(0.863858289759176),\n",
      "         'std': np.float64(0.005142694199234297)},\n",
      " 'Parameters': 5153,\n",
      " 'Train Time (s)': {'max': np.float64(95.66712832450867),\n",
      "                    'mean': np.float64(92.07193493843079),\n",
      "                    'min': np.float64(88.39696860313416),\n",
      "                    'std': np.float64(2.6301459110184946)},\n",
      " 'Training Accuracy': [[0.8424381613731384,\n",
      "                        0.9134491086006165,\n",
      "                        0.9184505343437195,\n",
      "                        0.9231081008911133,\n",
      "                        0.9258714914321899,\n",
      "                        0.9275158643722534,\n",
      "                        0.9292718172073364,\n",
      "                        0.9306079745292664,\n",
      "                        0.9317872524261475,\n",
      "                        0.9325608611106873,\n",
      "                        0.9336704015731812,\n",
      "                        0.9343298077583313,\n",
      "                        0.9351149797439575,\n",
      "                        0.9358645677566528,\n",
      "                        0.9358134865760803,\n",
      "                        0.9368720650672913,\n",
      "                        0.9378700256347656,\n",
      "                        0.9377140402793884,\n",
      "                        0.9379453659057617,\n",
      "                        0.938300609588623],\n",
      "                       [0.8289595246315002,\n",
      "                        0.9104399681091309,\n",
      "                        0.9173403978347778,\n",
      "                        0.9210278987884521,\n",
      "                        0.9224953651428223,\n",
      "                        0.9248274564743042,\n",
      "                        0.9258552193641663,\n",
      "                        0.9280157685279846,\n",
      "                        0.9297780990600586,\n",
      "                        0.9311138391494751,\n",
      "                        0.9321955442428589,\n",
      "                        0.9334509372711182,\n",
      "                        0.9346449971199036,\n",
      "                        0.9349058270454407,\n",
      "                        0.9362140893936157,\n",
      "                        0.9368099570274353,\n",
      "                        0.9375126361846924,\n",
      "                        0.9373977780342102,\n",
      "                        0.9382746815681458,\n",
      "                        0.9387184977531433],\n",
      "                       [0.8304734826087952,\n",
      "                        0.9139497876167297,\n",
      "                        0.9186181426048279,\n",
      "                        0.9224209189414978,\n",
      "                        0.9241253137588501,\n",
      "                        0.9262511134147644,\n",
      "                        0.9284774661064148,\n",
      "                        0.9302136301994324,\n",
      "                        0.9312949776649475,\n",
      "                        0.9323514699935913,\n",
      "                        0.9330399632453918,\n",
      "                        0.9340488314628601,\n",
      "                        0.9350165724754333,\n",
      "                        0.9355806708335876,\n",
      "                        0.9358984231948853,\n",
      "                        0.9367300868034363,\n",
      "                        0.9363492727279663,\n",
      "                        0.9378562569618225,\n",
      "                        0.9377536773681641,\n",
      "                        0.9381083846092224],\n",
      "                       [0.8270434737205505,\n",
      "                        0.9106599688529968,\n",
      "                        0.9177399277687073,\n",
      "                        0.9214450120925903,\n",
      "                        0.9238328337669373,\n",
      "                        0.9259423613548279,\n",
      "                        0.928172767162323,\n",
      "                        0.9292517304420471,\n",
      "                        0.9315756559371948,\n",
      "                        0.9321126937866211,\n",
      "                        0.9328540563583374,\n",
      "                        0.9337854981422424,\n",
      "                        0.935015082359314,\n",
      "                        0.9358676671981812,\n",
      "                        0.9364294409751892,\n",
      "                        0.9359980225563049,\n",
      "                        0.9372670650482178,\n",
      "                        0.9378599524497986,\n",
      "                        0.9381811618804932,\n",
      "                        0.9380170702934265],\n",
      "                       [0.8368260860443115,\n",
      "                        0.9122980237007141,\n",
      "                        0.9171327948570251,\n",
      "                        0.921353280544281,\n",
      "                        0.922838032245636,\n",
      "                        0.9249946475028992,\n",
      "                        0.9263148307800293,\n",
      "                        0.9281603097915649,\n",
      "                        0.9291954040527344,\n",
      "                        0.9304680228233337,\n",
      "                        0.9313898682594299,\n",
      "                        0.9323446154594421,\n",
      "                        0.9334052801132202,\n",
      "                        0.9339892864227295,\n",
      "                        0.9347797632217407,\n",
      "                        0.935718834400177,\n",
      "                        0.9363547563552856,\n",
      "                        0.9368953704833984,\n",
      "                        0.9376327395439148,\n",
      "                        0.9377307295799255]],\n",
      " 'Training Loss': [[0.33592239022254944,\n",
      "                    0.20993079245090485,\n",
      "                    0.19663028419017792,\n",
      "                    0.18456535041332245,\n",
      "                    0.17887862026691437,\n",
      "                    0.17480438947677612,\n",
      "                    0.17086736857891083,\n",
      "                    0.16772738099098206,\n",
      "                    0.16473127901554108,\n",
      "                    0.16224552690982819,\n",
      "                    0.1604573130607605,\n",
      "                    0.15858258306980133,\n",
      "                    0.15642382204532623,\n",
      "                    0.15499350428581238,\n",
      "                    0.15453092753887177,\n",
      "                    0.15173403918743134,\n",
      "                    0.15065087378025055,\n",
      "                    0.15039297938346863,\n",
      "                    0.14913764595985413,\n",
      "                    0.14909778535366058],\n",
      "                   [0.3676544725894928,\n",
      "                    0.21796463429927826,\n",
      "                    0.20018458366394043,\n",
      "                    0.1904597133398056,\n",
      "                    0.18607431650161743,\n",
      "                    0.18044404685497284,\n",
      "                    0.17839501798152924,\n",
      "                    0.17345261573791504,\n",
      "                    0.16921879351139069,\n",
      "                    0.16613449156284332,\n",
      "                    0.16406261920928955,\n",
      "                    0.16095024347305298,\n",
      "                    0.1586960256099701,\n",
      "                    0.15734392404556274,\n",
      "                    0.15496958792209625,\n",
      "                    0.1530541032552719,\n",
      "                    0.1513732522726059,\n",
      "                    0.15127892792224884,\n",
      "                    0.1495346873998642,\n",
      "                    0.14834097027778625],\n",
      "                   [0.3429151475429535,\n",
      "                    0.21003670990467072,\n",
      "                    0.19739538431167603,\n",
      "                    0.18808701634407043,\n",
      "                    0.1831211894750595,\n",
      "                    0.17845629155635834,\n",
      "                    0.1731935292482376,\n",
      "                    0.16856062412261963,\n",
      "                    0.16602912545204163,\n",
      "                    0.1632271707057953,\n",
      "                    0.16179940104484558,\n",
      "                    0.1591903418302536,\n",
      "                    0.15698622167110443,\n",
      "                    0.15589259564876556,\n",
      "                    0.15446804463863373,\n",
      "                    0.15289892256259918,\n",
      "                    0.1530102640390396,\n",
      "                    0.15067991614341736,\n",
      "                    0.1506626456975937,\n",
      "                    0.14947901666164398],\n",
      "                   [0.35800230503082275,\n",
      "                    0.21742942929267883,\n",
      "                    0.19830305874347687,\n",
      "                    0.18946486711502075,\n",
      "                    0.18278677761554718,\n",
      "                    0.17887549102306366,\n",
      "                    0.17303262650966644,\n",
      "                    0.17015399038791656,\n",
      "                    0.16553765535354614,\n",
      "                    0.1638728231191635,\n",
      "                    0.1625719964504242,\n",
      "                    0.16060729324817657,\n",
      "                    0.1577831506729126,\n",
      "                    0.15518930554389954,\n",
      "                    0.15443037450313568,\n",
      "                    0.1549331545829773,\n",
      "                    0.15212783217430115,\n",
      "                    0.15111950039863586,\n",
      "                    0.15050524473190308,\n",
      "                    0.1500665694475174],\n",
      "                   [0.3543938398361206,\n",
      "                    0.21144089102745056,\n",
      "                    0.19912084937095642,\n",
      "                    0.1895371973514557,\n",
      "                    0.18541988730430603,\n",
      "                    0.1803571581840515,\n",
      "                    0.17716491222381592,\n",
      "                    0.17342829704284668,\n",
      "                    0.1700364053249359,\n",
      "                    0.16810369491577148,\n",
      "                    0.1656826138496399,\n",
      "                    0.16305112838745117,\n",
      "                    0.16054987907409668,\n",
      "                    0.15930522978305817,\n",
      "                    0.1571532040834427,\n",
      "                    0.15521632134914398,\n",
      "                    0.15365608036518097,\n",
      "                    0.15216822922229767,\n",
      "                    0.1504218578338623,\n",
      "                    0.15009072422981262]],\n",
      " 'Validation Accuracy': [[0.9096214175224304,\n",
      "                          0.9199466705322266,\n",
      "                          0.922279953956604,\n",
      "                          0.9267439842224121,\n",
      "                          0.9259253144264221,\n",
      "                          0.9288960099220276,\n",
      "                          0.9305492639541626,\n",
      "                          0.9317944049835205,\n",
      "                          0.9340000748634338,\n",
      "                          0.9345200061798096,\n",
      "                          0.935573160648346,\n",
      "                          0.9343359470367432,\n",
      "                          0.936029314994812,\n",
      "                          0.9353307485580444,\n",
      "                          0.9373973608016968,\n",
      "                          0.9380960464477539,\n",
      "                          0.9386053681373596,\n",
      "                          0.9376133680343628,\n",
      "                          0.9350372552871704,\n",
      "                          0.9373786449432373],\n",
      "                         [0.9083786606788635,\n",
      "                          0.9154666066169739,\n",
      "                          0.9211494326591492,\n",
      "                          0.9245890974998474,\n",
      "                          0.9234026670455933,\n",
      "                          0.9280558824539185,\n",
      "                          0.9269571304321289,\n",
      "                          0.9299651980400085,\n",
      "                          0.9290532469749451,\n",
      "                          0.9317226409912109,\n",
      "                          0.9321333765983582,\n",
      "                          0.9338851571083069,\n",
      "                          0.9361066818237305,\n",
      "                          0.9359625577926636,\n",
      "                          0.9366586208343506,\n",
      "                          0.9379441142082214,\n",
      "                          0.936373233795166,\n",
      "                          0.9380720853805542,\n",
      "                          0.9381067156791687,\n",
      "                          0.9388719797134399],\n",
      "                         [0.9108850955963135,\n",
      "                          0.9158452749252319,\n",
      "                          0.9204025864601135,\n",
      "                          0.9228531718254089,\n",
      "                          0.9220800995826721,\n",
      "                          0.9266054630279541,\n",
      "                          0.9262345433235168,\n",
      "                          0.9276266098022461,\n",
      "                          0.9315733313560486,\n",
      "                          0.9309359788894653,\n",
      "                          0.9325307011604309,\n",
      "                          0.931797444820404,\n",
      "                          0.9324772357940674,\n",
      "                          0.9335547089576721,\n",
      "                          0.9316638708114624,\n",
      "                          0.9347066879272461,\n",
      "                          0.9346215128898621,\n",
      "                          0.9356959462165833,\n",
      "                          0.9358853101730347,\n",
      "                          0.9321039915084839],\n",
      "                         [0.9067360162734985,\n",
      "                          0.915621280670166,\n",
      "                          0.9181360602378845,\n",
      "                          0.9230453968048096,\n",
      "                          0.9232532382011414,\n",
      "                          0.9270772933959961,\n",
      "                          0.9273385405540466,\n",
      "                          0.9317654371261597,\n",
      "                          0.9323440790176392,\n",
      "                          0.9334480166435242,\n",
      "                          0.9348265528678894,\n",
      "                          0.9364906549453735,\n",
      "                          0.9367227554321289,\n",
      "                          0.9363412857055664,\n",
      "                          0.9381011724472046,\n",
      "                          0.9373973608016968,\n",
      "                          0.9389894008636475,\n",
      "                          0.9356426000595093,\n",
      "                          0.9383972883224487,\n",
      "                          0.9391493201255798],\n",
      "                         [0.9098238945007324,\n",
      "                          0.9139549136161804,\n",
      "                          0.9211522340774536,\n",
      "                          0.9233149290084839,\n",
      "                          0.9245786666870117,\n",
      "                          0.924936056137085,\n",
      "                          0.9271386861801147,\n",
      "                          0.928522527217865,\n",
      "                          0.9289920330047607,\n",
      "                          0.9295626878738403,\n",
      "                          0.929253339767456,\n",
      "                          0.9315519332885742,\n",
      "                          0.93229079246521,\n",
      "                          0.932130753993988,\n",
      "                          0.9339786767959595,\n",
      "                          0.9343785047531128,\n",
      "                          0.9358800649642944,\n",
      "                          0.9351067543029785,\n",
      "                          0.9356347918510437,\n",
      "                          0.937063992023468]],\n",
      " 'Validation Loss': [0.22026842832565308,\n",
      "                     0.20426422357559204,\n",
      "                     0.19372674822807312,\n",
      "                     0.18579359352588654,\n",
      "                     0.1812419891357422,\n",
      "                     0.17903219163417816,\n",
      "                     0.1759183555841446,\n",
      "                     0.17251501977443695,\n",
      "                     0.17061057686805725,\n",
      "                     0.16847077012062073,\n",
      "                     0.1694001406431198,\n",
      "                     0.163157656788826,\n",
      "                     0.16233161091804504,\n",
      "                     0.16203200817108154,\n",
      "                     0.15906615555286407,\n",
      "                     0.15619497001171112,\n",
      "                     0.15419094264507294,\n",
      "                     0.15595796704292297,\n",
      "                     0.15435731410980225,\n",
      "                     0.1511131078004837],\n",
      " 'Validation MCC': [[np.float64(0.8188696837916755),\n",
      "                     np.float64(0.8396905504042933),\n",
      "                     np.float64(0.8443505810767173),\n",
      "                     np.float64(0.8530873217749223),\n",
      "                     np.float64(0.8514410988780566),\n",
      "                     np.float64(0.8574025322009491),\n",
      "                     np.float64(0.861021971040396),\n",
      "                     np.float64(0.8635706698029006),\n",
      "                     np.float64(0.8676365807606041),\n",
      "                     np.float64(0.8687756244034939),\n",
      "                     np.float64(0.8707968555015897),\n",
      "                     np.float64(0.8683097986041728),\n",
      "                     np.float64(0.8717122564462161),\n",
      "                     np.float64(0.8703867244168277),\n",
      "                     np.float64(0.8747995085379191),\n",
      "                     np.float64(0.8759723512537105),\n",
      "                     np.float64(0.876890727600361),\n",
      "                     np.float64(0.8754372587964356),\n",
      "                     np.float64(0.8697236751022698),\n",
      "                     np.float64(0.8744174247635944)],\n",
      "                    [np.float64(0.816404140874306),\n",
      "                     np.float64(0.8314364599114134),\n",
      "                     np.float64(0.8418554224695808),\n",
      "                     np.float64(0.848738948216033),\n",
      "                     np.float64(0.8464637199265981),\n",
      "                     np.float64(0.8556843748573707),\n",
      "                     np.float64(0.8538216279483125),\n",
      "                     np.float64(0.8597820763034192),\n",
      "                     np.float64(0.8576894204868707),\n",
      "                     np.float64(0.8630411532366826),\n",
      "                     np.float64(0.8638955320193372),\n",
      "                     np.float64(0.8681534613150119),\n",
      "                     np.float64(0.8719986017110847),\n",
      "                     np.float64(0.8717513142110362),\n",
      "                     np.float64(0.8730669592356058),\n",
      "                     np.float64(0.8758315267921738),\n",
      "                     np.float64(0.8723958202586712),\n",
      "                     np.float64(0.8757803809716266),\n",
      "                     np.float64(0.8760372857257369),\n",
      "                     np.float64(0.8774656737524986)],\n",
      "                    [np.float64(0.8211748688220301),\n",
      "                     np.float64(0.8312330182847923),\n",
      "                     np.float64(0.8402392735602862),\n",
      "                     np.float64(0.8451462178257105),\n",
      "                     np.float64(0.8446745045449743),\n",
      "                     np.float64(0.8526961288474167),\n",
      "                     np.float64(0.852220761662343),\n",
      "                     np.float64(0.8549339656752962),\n",
      "                     np.float64(0.863098453945203),\n",
      "                     np.float64(0.8616448138404346),\n",
      "                     np.float64(0.8645855688864881),\n",
      "                     np.float64(0.8632102275529714),\n",
      "                     np.float64(0.8648857417694115),\n",
      "                     np.float64(0.8668346950626131),\n",
      "                     np.float64(0.863099126068871),\n",
      "                     np.float64(0.8689431299985303),\n",
      "                     np.float64(0.8689103478278262),\n",
      "                     np.float64(0.8710124063709438),\n",
      "                     np.float64(0.871431695094256),\n",
      "                     np.float64(0.863858289759176)],\n",
      "                    [np.float64(0.813190154564365),\n",
      "                     np.float64(0.8313298039451761),\n",
      "                     np.float64(0.8360548208783298),\n",
      "                     np.float64(0.8458666729622455),\n",
      "                     np.float64(0.8471346102910686),\n",
      "                     np.float64(0.8537345916400472),\n",
      "                     np.float64(0.8555933688622969),\n",
      "                     np.float64(0.8632080696719108),\n",
      "                     np.float64(0.8644416301224364),\n",
      "                     np.float64(0.8672478400465868),\n",
      "                     np.float64(0.8694166688065913),\n",
      "                     np.float64(0.8726984392942342),\n",
      "                     np.float64(0.8732321984657662),\n",
      "                     np.float64(0.8723385511552156),\n",
      "                     np.float64(0.8758792202473819),\n",
      "                     np.float64(0.8749877888487292),\n",
      "                     np.float64(0.8776458855631072),\n",
      "                     np.float64(0.8718962249453175),\n",
      "                     np.float64(0.8764728506705114),\n",
      "                     np.float64(0.8782617453884171)],\n",
      "                    [np.float64(0.8190040603099465),\n",
      "                     np.float64(0.8277849696889757),\n",
      "                     np.float64(0.8419883646758467),\n",
      "                     np.float64(0.8460987420687536),\n",
      "                     np.float64(0.8487012572136304),\n",
      "                     np.float64(0.8494752977022383),\n",
      "                     np.float64(0.8540924508522897),\n",
      "                     np.float64(0.8567594658114464),\n",
      "                     np.float64(0.8575237405740792),\n",
      "                     np.float64(0.8588366821596937),\n",
      "                     np.float64(0.8582578586598548),\n",
      "                     np.float64(0.8626865614535539),\n",
      "                     np.float64(0.8641345742067992),\n",
      "                     np.float64(0.8639741370693166),\n",
      "                     np.float64(0.8675451734835198),\n",
      "                     np.float64(0.8684556556957851),\n",
      "                     np.float64(0.8714423967186015),\n",
      "                     np.float64(0.8699367510716205),\n",
      "                     np.float64(0.8710065540642511),\n",
      "                     np.float64(0.8736991787564611)]]}\n",
      "Training Model: BiLSTM, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.7766 - loss: 0.4779\n",
      "Epoch 1 - MCC: 0.8201\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 40ms/step - accuracy: 0.7770 - loss: 0.4772 - val_accuracy: 0.9101 - val_loss: 0.2151 - mcc: 0.8201\n",
      "Epoch 2/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9112 - loss: 0.2114\n",
      "Epoch 2 - MCC: 0.8330\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 34ms/step - accuracy: 0.9112 - loss: 0.2114 - val_accuracy: 0.9163 - val_loss: 0.1979 - mcc: 0.8330\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9195 - loss: 0.1922\n",
      "Epoch 3 - MCC: 0.8502\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9195 - loss: 0.1921 - val_accuracy: 0.9249 - val_loss: 0.1793 - mcc: 0.8502\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9266 - loss: 0.1762\n",
      "Epoch 4 - MCC: 0.8657\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9266 - loss: 0.1761 - val_accuracy: 0.9328 - val_loss: 0.1660 - mcc: 0.8657\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9321 - loss: 0.1632\n",
      "Epoch 5 - MCC: 0.8734\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.9322 - loss: 0.1632 - val_accuracy: 0.9368 - val_loss: 0.1563 - mcc: 0.8734\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9346 - loss: 0.1581\n",
      "Epoch 6 - MCC: 0.8767\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 32ms/step - accuracy: 0.9346 - loss: 0.1580 - val_accuracy: 0.9385 - val_loss: 0.1516 - mcc: 0.8767\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9359 - loss: 0.1570\n",
      "Epoch 7 - MCC: 0.8784\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9360 - loss: 0.1570 - val_accuracy: 0.9391 - val_loss: 0.1490 - mcc: 0.8784\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9424 - loss: 0.1416\n",
      "Epoch 8 - MCC: 0.8817\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9424 - loss: 0.1417 - val_accuracy: 0.9410 - val_loss: 0.1447 - mcc: 0.8817\n",
      "Epoch 9/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9407 - loss: 0.1458\n",
      "Epoch 9 - MCC: 0.8842\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9407 - loss: 0.1458 - val_accuracy: 0.9421 - val_loss: 0.1410 - mcc: 0.8842\n",
      "Epoch 10/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9446 - loss: 0.1355\n",
      "Epoch 10 - MCC: 0.8823\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 33ms/step - accuracy: 0.9446 - loss: 0.1355 - val_accuracy: 0.9411 - val_loss: 0.1442 - mcc: 0.8823\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9453 - loss: 0.1350\n",
      "Epoch 11 - MCC: 0.8934\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 37ms/step - accuracy: 0.9453 - loss: 0.1350 - val_accuracy: 0.9468 - val_loss: 0.1329 - mcc: 0.8934\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9470 - loss: 0.1296\n",
      "Epoch 12 - MCC: 0.8978\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.9470 - loss: 0.1296 - val_accuracy: 0.9490 - val_loss: 0.1277 - mcc: 0.8978\n",
      "Epoch 13/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9469 - loss: 0.1315\n",
      "Epoch 13 - MCC: 0.8985\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 34ms/step - accuracy: 0.9469 - loss: 0.1315 - val_accuracy: 0.9494 - val_loss: 0.1256 - mcc: 0.8985\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9477 - loss: 0.1281\n",
      "Epoch 14 - MCC: 0.8991\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 36ms/step - accuracy: 0.9477 - loss: 0.1281 - val_accuracy: 0.9495 - val_loss: 0.1262 - mcc: 0.8991\n",
      "Epoch 15/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9505 - loss: 0.1228\n",
      "Epoch 15 - MCC: 0.8975\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 39ms/step - accuracy: 0.9505 - loss: 0.1228 - val_accuracy: 0.9489 - val_loss: 0.1254 - mcc: 0.8975\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9495 - loss: 0.1251\n",
      "Epoch 16 - MCC: 0.9035\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9495 - loss: 0.1251 - val_accuracy: 0.9518 - val_loss: 0.1215 - mcc: 0.9035\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9492 - loss: 0.1249\n",
      "Epoch 17 - MCC: 0.9031\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9492 - loss: 0.1249 - val_accuracy: 0.9514 - val_loss: 0.1236 - mcc: 0.9031\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9494 - loss: 0.1257\n",
      "Epoch 18 - MCC: 0.9024\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 35ms/step - accuracy: 0.9494 - loss: 0.1257 - val_accuracy: 0.9513 - val_loss: 0.1209 - mcc: 0.9024\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9501 - loss: 0.1240\n",
      "Epoch 19 - MCC: 0.9045\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 34ms/step - accuracy: 0.9501 - loss: 0.1239 - val_accuracy: 0.9524 - val_loss: 0.1188 - mcc: 0.9045\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9525 - loss: 0.1178\n",
      "Epoch 20 - MCC: 0.9035\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 37ms/step - accuracy: 0.9524 - loss: 0.1178 - val_accuracy: 0.9517 - val_loss: 0.1207 - mcc: 0.9035\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.7035 - loss: 0.5182\n",
      "Epoch 1 - MCC: 0.8202\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 40ms/step - accuracy: 0.7041 - loss: 0.5174 - val_accuracy: 0.9104 - val_loss: 0.2167 - mcc: 0.8202\n",
      "Epoch 2/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9116 - loss: 0.2132\n",
      "Epoch 2 - MCC: 0.8401\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 35ms/step - accuracy: 0.9117 - loss: 0.2131 - val_accuracy: 0.9200 - val_loss: 0.1911 - mcc: 0.8401\n",
      "Epoch 3/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9236 - loss: 0.1860\n",
      "Epoch 3 - MCC: 0.8590\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 33ms/step - accuracy: 0.9236 - loss: 0.1860 - val_accuracy: 0.9297 - val_loss: 0.1718 - mcc: 0.8590\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9303 - loss: 0.1700\n",
      "Epoch 4 - MCC: 0.8658\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 36ms/step - accuracy: 0.9303 - loss: 0.1700 - val_accuracy: 0.9331 - val_loss: 0.1615 - mcc: 0.8658\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9315 - loss: 0.1656\n",
      "Epoch 5 - MCC: 0.8752\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.9315 - loss: 0.1655 - val_accuracy: 0.9378 - val_loss: 0.1531 - mcc: 0.8752\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9376 - loss: 0.1532\n",
      "Epoch 6 - MCC: 0.8750\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9376 - loss: 0.1532 - val_accuracy: 0.9375 - val_loss: 0.1537 - mcc: 0.8750\n",
      "Epoch 7/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9381 - loss: 0.1529\n",
      "Epoch 7 - MCC: 0.8805\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 35ms/step - accuracy: 0.9381 - loss: 0.1529 - val_accuracy: 0.9403 - val_loss: 0.1458 - mcc: 0.8805\n",
      "Epoch 8/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9408 - loss: 0.1448\n",
      "Epoch 8 - MCC: 0.8835\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 33ms/step - accuracy: 0.9408 - loss: 0.1448 - val_accuracy: 0.9419 - val_loss: 0.1427 - mcc: 0.8835\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9420 - loss: 0.1429\n",
      "Epoch 9 - MCC: 0.8834\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9420 - loss: 0.1429 - val_accuracy: 0.9417 - val_loss: 0.1423 - mcc: 0.8834\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9429 - loss: 0.1410\n",
      "Epoch 10 - MCC: 0.8867\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9429 - loss: 0.1410 - val_accuracy: 0.9435 - val_loss: 0.1383 - mcc: 0.8867\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9457 - loss: 0.1342\n",
      "Epoch 11 - MCC: 0.8878\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 38ms/step - accuracy: 0.9457 - loss: 0.1342 - val_accuracy: 0.9441 - val_loss: 0.1354 - mcc: 0.8878\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9448 - loss: 0.1364\n",
      "Epoch 12 - MCC: 0.8926\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9448 - loss: 0.1364 - val_accuracy: 0.9464 - val_loss: 0.1288 - mcc: 0.8926\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9449 - loss: 0.1342\n",
      "Epoch 13 - MCC: 0.8953\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9449 - loss: 0.1342 - val_accuracy: 0.9478 - val_loss: 0.1280 - mcc: 0.8953\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9467 - loss: 0.1313\n",
      "Epoch 14 - MCC: 0.8987\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9467 - loss: 0.1313 - val_accuracy: 0.9495 - val_loss: 0.1247 - mcc: 0.8987\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9492 - loss: 0.1256\n",
      "Epoch 15 - MCC: 0.8969\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9492 - loss: 0.1257 - val_accuracy: 0.9486 - val_loss: 0.1260 - mcc: 0.8969\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9504 - loss: 0.1226\n",
      "Epoch 16 - MCC: 0.8969\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 32ms/step - accuracy: 0.9504 - loss: 0.1226 - val_accuracy: 0.9486 - val_loss: 0.1253 - mcc: 0.8969\n",
      "Epoch 17/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9504 - loss: 0.1223\n",
      "Epoch 17 - MCC: 0.9012\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9504 - loss: 0.1223 - val_accuracy: 0.9507 - val_loss: 0.1199 - mcc: 0.9012\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9510 - loss: 0.1204\n",
      "Epoch 18 - MCC: 0.9034\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9510 - loss: 0.1205 - val_accuracy: 0.9518 - val_loss: 0.1190 - mcc: 0.9034\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9490 - loss: 0.1254\n",
      "Epoch 19 - MCC: 0.9027\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9490 - loss: 0.1253 - val_accuracy: 0.9515 - val_loss: 0.1200 - mcc: 0.9027\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9511 - loss: 0.1209\n",
      "Epoch 20 - MCC: 0.9012\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9511 - loss: 0.1208 - val_accuracy: 0.9507 - val_loss: 0.1208 - mcc: 0.9012\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.7155 - loss: 0.5222\n",
      "Epoch 1 - MCC: 0.8196\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 44ms/step - accuracy: 0.7166 - loss: 0.5206 - val_accuracy: 0.9101 - val_loss: 0.2178 - mcc: 0.8196\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9162 - loss: 0.2025\n",
      "Epoch 2 - MCC: 0.8452\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 37ms/step - accuracy: 0.9162 - loss: 0.2024 - val_accuracy: 0.9228 - val_loss: 0.1851 - mcc: 0.8452\n",
      "Epoch 3/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9261 - loss: 0.1779\n",
      "Epoch 3 - MCC: 0.8570\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 32ms/step - accuracy: 0.9261 - loss: 0.1778 - val_accuracy: 0.9287 - val_loss: 0.1745 - mcc: 0.8570\n",
      "Epoch 4/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9354 - loss: 0.1595\n",
      "Epoch 4 - MCC: 0.8642\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9354 - loss: 0.1595 - val_accuracy: 0.9323 - val_loss: 0.1647 - mcc: 0.8642\n",
      "Epoch 5/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9367 - loss: 0.1553\n",
      "Epoch 5 - MCC: 0.8734\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 38ms/step - accuracy: 0.9367 - loss: 0.1553 - val_accuracy: 0.9369 - val_loss: 0.1568 - mcc: 0.8734\n",
      "Epoch 6/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9384 - loss: 0.1520\n",
      "Epoch 6 - MCC: 0.8737\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 32ms/step - accuracy: 0.9384 - loss: 0.1520 - val_accuracy: 0.9371 - val_loss: 0.1528 - mcc: 0.8737\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9389 - loss: 0.1504\n",
      "Epoch 7 - MCC: 0.8790\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9389 - loss: 0.1504 - val_accuracy: 0.9397 - val_loss: 0.1495 - mcc: 0.8790\n",
      "Epoch 8/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9402 - loss: 0.1458\n",
      "Epoch 8 - MCC: 0.8816\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9403 - loss: 0.1458 - val_accuracy: 0.9410 - val_loss: 0.1454 - mcc: 0.8816\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9429 - loss: 0.1387\n",
      "Epoch 9 - MCC: 0.8802\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9429 - loss: 0.1387 - val_accuracy: 0.9403 - val_loss: 0.1483 - mcc: 0.8802\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9430 - loss: 0.1405\n",
      "Epoch 10 - MCC: 0.8830\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9430 - loss: 0.1405 - val_accuracy: 0.9417 - val_loss: 0.1445 - mcc: 0.8830\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9438 - loss: 0.1365\n",
      "Epoch 11 - MCC: 0.8850\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9438 - loss: 0.1365 - val_accuracy: 0.9426 - val_loss: 0.1415 - mcc: 0.8850\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9458 - loss: 0.1336\n",
      "Epoch 12 - MCC: 0.8885\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9458 - loss: 0.1335 - val_accuracy: 0.9445 - val_loss: 0.1372 - mcc: 0.8885\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9467 - loss: 0.1313\n",
      "Epoch 13 - MCC: 0.8904\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 36ms/step - accuracy: 0.9467 - loss: 0.1313 - val_accuracy: 0.9454 - val_loss: 0.1351 - mcc: 0.8904\n",
      "Epoch 14/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9481 - loss: 0.1278\n",
      "Epoch 14 - MCC: 0.8937\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9481 - loss: 0.1278 - val_accuracy: 0.9469 - val_loss: 0.1327 - mcc: 0.8937\n",
      "Epoch 15/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9497 - loss: 0.1248\n",
      "Epoch 15 - MCC: 0.8935\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9497 - loss: 0.1248 - val_accuracy: 0.9469 - val_loss: 0.1323 - mcc: 0.8935\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9506 - loss: 0.1224\n",
      "Epoch 16 - MCC: 0.8913\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9506 - loss: 0.1224 - val_accuracy: 0.9458 - val_loss: 0.1329 - mcc: 0.8913\n",
      "Epoch 17/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9497 - loss: 0.1235\n",
      "Epoch 17 - MCC: 0.8944\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9497 - loss: 0.1235 - val_accuracy: 0.9474 - val_loss: 0.1294 - mcc: 0.8944\n",
      "Epoch 18/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9506 - loss: 0.1214\n",
      "Epoch 18 - MCC: 0.8960\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9506 - loss: 0.1214 - val_accuracy: 0.9482 - val_loss: 0.1279 - mcc: 0.8960\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9537 - loss: 0.1147\n",
      "Epoch 19 - MCC: 0.8964\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 36ms/step - accuracy: 0.9537 - loss: 0.1148 - val_accuracy: 0.9483 - val_loss: 0.1285 - mcc: 0.8964\n",
      "Epoch 20/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9498 - loss: 0.1236\n",
      "Epoch 20 - MCC: 0.8989\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9499 - loss: 0.1236 - val_accuracy: 0.9495 - val_loss: 0.1252 - mcc: 0.8989\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7385 - loss: 0.4724\n",
      "Epoch 1 - MCC: 0.8194\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 39ms/step - accuracy: 0.7395 - loss: 0.4709 - val_accuracy: 0.9098 - val_loss: 0.2133 - mcc: 0.8194\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9123 - loss: 0.2091\n",
      "Epoch 2 - MCC: 0.8536\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 34ms/step - accuracy: 0.9124 - loss: 0.2090 - val_accuracy: 0.9269 - val_loss: 0.1792 - mcc: 0.8536\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9253 - loss: 0.1816\n",
      "Epoch 3 - MCC: 0.8581\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 36ms/step - accuracy: 0.9253 - loss: 0.1815 - val_accuracy: 0.9290 - val_loss: 0.1730 - mcc: 0.8581\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9319 - loss: 0.1656\n",
      "Epoch 4 - MCC: 0.8656\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 35ms/step - accuracy: 0.9319 - loss: 0.1655 - val_accuracy: 0.9329 - val_loss: 0.1631 - mcc: 0.8656\n",
      "Epoch 5/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9338 - loss: 0.1613\n",
      "Epoch 5 - MCC: 0.8706\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9338 - loss: 0.1613 - val_accuracy: 0.9355 - val_loss: 0.1588 - mcc: 0.8706\n",
      "Epoch 6/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9336 - loss: 0.1618\n",
      "Epoch 6 - MCC: 0.8781\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9336 - loss: 0.1617 - val_accuracy: 0.9392 - val_loss: 0.1485 - mcc: 0.8781\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9390 - loss: 0.1497\n",
      "Epoch 7 - MCC: 0.8800\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 40ms/step - accuracy: 0.9390 - loss: 0.1497 - val_accuracy: 0.9401 - val_loss: 0.1473 - mcc: 0.8800\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9404 - loss: 0.1472\n",
      "Epoch 8 - MCC: 0.8784\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 32ms/step - accuracy: 0.9403 - loss: 0.1472 - val_accuracy: 0.9392 - val_loss: 0.1480 - mcc: 0.8784\n",
      "Epoch 9/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9399 - loss: 0.1470\n",
      "Epoch 9 - MCC: 0.8823\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9399 - loss: 0.1470 - val_accuracy: 0.9413 - val_loss: 0.1435 - mcc: 0.8823\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9435 - loss: 0.1401\n",
      "Epoch 10 - MCC: 0.8870\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9435 - loss: 0.1402 - val_accuracy: 0.9436 - val_loss: 0.1385 - mcc: 0.8870\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9410 - loss: 0.1437\n",
      "Epoch 11 - MCC: 0.8883\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9410 - loss: 0.1437 - val_accuracy: 0.9442 - val_loss: 0.1367 - mcc: 0.8883\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9432 - loss: 0.1396\n",
      "Epoch 12 - MCC: 0.8895\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9432 - loss: 0.1396 - val_accuracy: 0.9449 - val_loss: 0.1346 - mcc: 0.8895\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9463 - loss: 0.1320\n",
      "Epoch 13 - MCC: 0.8906\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9463 - loss: 0.1321 - val_accuracy: 0.9454 - val_loss: 0.1334 - mcc: 0.8906\n",
      "Epoch 14/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9437 - loss: 0.1381\n",
      "Epoch 14 - MCC: 0.8921\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 40ms/step - accuracy: 0.9438 - loss: 0.1380 - val_accuracy: 0.9460 - val_loss: 0.1327 - mcc: 0.8921\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9458 - loss: 0.1323\n",
      "Epoch 15 - MCC: 0.8898\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 34ms/step - accuracy: 0.9458 - loss: 0.1323 - val_accuracy: 0.9451 - val_loss: 0.1335 - mcc: 0.8898\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9467 - loss: 0.1315\n",
      "Epoch 16 - MCC: 0.8956\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9467 - loss: 0.1315 - val_accuracy: 0.9478 - val_loss: 0.1282 - mcc: 0.8956\n",
      "Epoch 17/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9469 - loss: 0.1309\n",
      "Epoch 17 - MCC: 0.8956\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9469 - loss: 0.1309 - val_accuracy: 0.9479 - val_loss: 0.1280 - mcc: 0.8956\n",
      "Epoch 18/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9481 - loss: 0.1272\n",
      "Epoch 18 - MCC: 0.8949\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9481 - loss: 0.1272 - val_accuracy: 0.9475 - val_loss: 0.1278 - mcc: 0.8949\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9483 - loss: 0.1275\n",
      "Epoch 19 - MCC: 0.8997\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 33ms/step - accuracy: 0.9483 - loss: 0.1275 - val_accuracy: 0.9500 - val_loss: 0.1230 - mcc: 0.8997\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9493 - loss: 0.1248\n",
      "Epoch 20 - MCC: 0.9009\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9493 - loss: 0.1248 - val_accuracy: 0.9504 - val_loss: 0.1234 - mcc: 0.9009\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7211 - loss: 0.4855\n",
      "Epoch 1 - MCC: 0.8162\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 38ms/step - accuracy: 0.7223 - loss: 0.4840 - val_accuracy: 0.9080 - val_loss: 0.2184 - mcc: 0.8162\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9153 - loss: 0.2023\n",
      "Epoch 2 - MCC: 0.8475\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.9154 - loss: 0.2023 - val_accuracy: 0.9239 - val_loss: 0.1810 - mcc: 0.8475\n",
      "Epoch 3/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9263 - loss: 0.1760\n",
      "Epoch 3 - MCC: 0.8623\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 39ms/step - accuracy: 0.9263 - loss: 0.1760 - val_accuracy: 0.9312 - val_loss: 0.1658 - mcc: 0.8623\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9337 - loss: 0.1606\n",
      "Epoch 4 - MCC: 0.8692\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 32ms/step - accuracy: 0.9337 - loss: 0.1606 - val_accuracy: 0.9348 - val_loss: 0.1588 - mcc: 0.8692\n",
      "Epoch 5/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9348 - loss: 0.1584\n",
      "Epoch 5 - MCC: 0.8713\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9348 - loss: 0.1584 - val_accuracy: 0.9357 - val_loss: 0.1550 - mcc: 0.8713\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9373 - loss: 0.1531\n",
      "Epoch 6 - MCC: 0.8767\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9373 - loss: 0.1531 - val_accuracy: 0.9385 - val_loss: 0.1491 - mcc: 0.8767\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9399 - loss: 0.1474\n",
      "Epoch 7 - MCC: 0.8809\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9399 - loss: 0.1474 - val_accuracy: 0.9406 - val_loss: 0.1451 - mcc: 0.8809\n",
      "Epoch 8/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9412 - loss: 0.1439\n",
      "Epoch 8 - MCC: 0.8843\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9412 - loss: 0.1439 - val_accuracy: 0.9423 - val_loss: 0.1424 - mcc: 0.8843\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9441 - loss: 0.1380\n",
      "Epoch 9 - MCC: 0.8876\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9441 - loss: 0.1380 - val_accuracy: 0.9440 - val_loss: 0.1399 - mcc: 0.8876\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9441 - loss: 0.1375\n",
      "Epoch 10 - MCC: 0.8801\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9441 - loss: 0.1375 - val_accuracy: 0.9401 - val_loss: 0.1460 - mcc: 0.8801\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9450 - loss: 0.1357\n",
      "Epoch 11 - MCC: 0.8890\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 36ms/step - accuracy: 0.9450 - loss: 0.1357 - val_accuracy: 0.9445 - val_loss: 0.1377 - mcc: 0.8890\n",
      "Epoch 12/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9470 - loss: 0.1302\n",
      "Epoch 12 - MCC: 0.8926\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9470 - loss: 0.1302 - val_accuracy: 0.9465 - val_loss: 0.1331 - mcc: 0.8926\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9453 - loss: 0.1350\n",
      "Epoch 13 - MCC: 0.8899\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.9453 - loss: 0.1349 - val_accuracy: 0.9450 - val_loss: 0.1351 - mcc: 0.8899\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9459 - loss: 0.1328\n",
      "Epoch 14 - MCC: 0.8925\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 33ms/step - accuracy: 0.9459 - loss: 0.1328 - val_accuracy: 0.9464 - val_loss: 0.1332 - mcc: 0.8925\n",
      "Epoch 15/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9482 - loss: 0.1281\n",
      "Epoch 15 - MCC: 0.8946\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 34ms/step - accuracy: 0.9482 - loss: 0.1281 - val_accuracy: 0.9474 - val_loss: 0.1297 - mcc: 0.8946\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9488 - loss: 0.1260\n",
      "Epoch 16 - MCC: 0.8830\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.9488 - loss: 0.1260 - val_accuracy: 0.9417 - val_loss: 0.1454 - mcc: 0.8830\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9458 - loss: 0.1317\n",
      "Epoch 17 - MCC: 0.8980\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9459 - loss: 0.1317 - val_accuracy: 0.9492 - val_loss: 0.1241 - mcc: 0.8980\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9516 - loss: 0.1201\n",
      "Epoch 18 - MCC: 0.8953\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.9515 - loss: 0.1201 - val_accuracy: 0.9476 - val_loss: 0.1274 - mcc: 0.8953\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9496 - loss: 0.1255\n",
      "Epoch 19 - MCC: 0.8965\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9496 - loss: 0.1255 - val_accuracy: 0.9484 - val_loss: 0.1284 - mcc: 0.8965\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9509 - loss: 0.1225\n",
      "Epoch 20 - MCC: 0.8971\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 39ms/step - accuracy: 0.9509 - loss: 0.1225 - val_accuracy: 0.9486 - val_loss: 0.1265 - mcc: 0.8971\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.951728),\n",
      "              'mean': np.float64(0.9501909333333334),\n",
      "              'min': np.float64(0.948624),\n",
      "              'std': np.float64(0.0010621150889721113)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.0009430964787801106),\n",
      "                               'mean': np.float64(0.0006562078475952148),\n",
      "                               'min': np.float64(0.0004892133076985677),\n",
      "                               'std': np.float64(0.00015684887600377452)},\n",
      " 'MCC': {'max': np.float64(0.9034762642492482),\n",
      "         'mean': np.float64(0.900316315198023),\n",
      "         'min': np.float64(0.8971047698307418),\n",
      "         'std': np.float64(0.0021596621265831638)},\n",
      " 'Parameters': 5325,\n",
      " 'Train Time (s)': {'max': np.float64(180.97033953666687),\n",
      "                    'mean': np.float64(172.4997435569763),\n",
      "                    'min': np.float64(165.08567023277283),\n",
      "                    'std': np.float64(6.014372954378033)},\n",
      " 'Training Accuracy': [[0.852057933807373,\n",
      "                        0.9129630327224731,\n",
      "                        0.9220832586288452,\n",
      "                        0.9294155836105347,\n",
      "                        0.9330152869224548,\n",
      "                        0.936105489730835,\n",
      "                        0.9373636245727539,\n",
      "                        0.9411160349845886,\n",
      "                        0.9419384598731995,\n",
      "                        0.943311870098114,\n",
      "                        0.9450193643569946,\n",
      "                        0.9465490579605103,\n",
      "                        0.947780430316925,\n",
      "                        0.9481588006019592,\n",
      "                        0.9490440487861633,\n",
      "                        0.9501931071281433,\n",
      "                        0.9500157833099365,\n",
      "                        0.950319230556488,\n",
      "                        0.9516599774360657,\n",
      "                        0.9515861868858337],\n",
      "                       [0.8217029571533203,\n",
      "                        0.9144598841667175,\n",
      "                        0.9244111180305481,\n",
      "                        0.9307488799095154,\n",
      "                        0.933861494064331,\n",
      "                        0.9364904165267944,\n",
      "                        0.9391201734542847,\n",
      "                        0.9399639368057251,\n",
      "                        0.942632794380188,\n",
      "                        0.9437134861946106,\n",
      "                        0.9452574849128723,\n",
      "                        0.946100115776062,\n",
      "                        0.9475710391998291,\n",
      "                        0.9478285908699036,\n",
      "                        0.948462724685669,\n",
      "                        0.9492896199226379,\n",
      "                        0.9502509236335754,\n",
      "                        0.9502861499786377,\n",
      "                        0.9506909847259521,\n",
      "                        0.9518046975135803],\n",
      "                       [0.8249078989028931,\n",
      "                        0.9201052188873291,\n",
      "                        0.9282034635543823,\n",
      "                        0.9346246123313904,\n",
      "                        0.936989963054657,\n",
      "                        0.938729465007782,\n",
      "                        0.9401180148124695,\n",
      "                        0.9418490529060364,\n",
      "                        0.9426425695419312,\n",
      "                        0.9432179927825928,\n",
      "                        0.9445053935050964,\n",
      "                        0.9459752440452576,\n",
      "                        0.9468875527381897,\n",
      "                        0.9483330249786377,\n",
      "                        0.9497627019882202,\n",
      "                        0.9503312706947327,\n",
      "                        0.9509076476097107,\n",
      "                        0.9518486857414246,\n",
      "                        0.9526132941246033,\n",
      "                        0.9523536562919617],\n",
      "                       [0.8408840894699097,\n",
      "                        0.9170999526977539,\n",
      "                        0.9269847273826599,\n",
      "                        0.9325109124183655,\n",
      "                        0.9349857568740845,\n",
      "                        0.9368326663970947,\n",
      "                        0.9385366439819336,\n",
      "                        0.9394041299819946,\n",
      "                        0.9399352073669434,\n",
      "                        0.9416846632957458,\n",
      "                        0.9417830109596252,\n",
      "                        0.9439328908920288,\n",
      "                        0.9445440173149109,\n",
      "                        0.9451025128364563,\n",
      "                        0.9462598562240601,\n",
      "                        0.9470873475074768,\n",
      "                        0.9474177956581116,\n",
      "                        0.9483799934387207,\n",
      "                        0.9487549662590027,\n",
      "                        0.9493380784988403],\n",
      "                       [0.8335342407226562,\n",
      "                        0.9182411432266235,\n",
      "                        0.9278831481933594,\n",
      "                        0.9336205124855042,\n",
      "                        0.9354597330093384,\n",
      "                        0.938119649887085,\n",
      "                        0.9399875402450562,\n",
      "                        0.9414096474647522,\n",
      "                        0.9430047869682312,\n",
      "                        0.943753719329834,\n",
      "                        0.944674015045166,\n",
      "                        0.9458994269371033,\n",
      "                        0.9466766715049744,\n",
      "                        0.9474308490753174,\n",
      "                        0.9482760429382324,\n",
      "                        0.947552502155304,\n",
      "                        0.9485419392585754,\n",
      "                        0.9503915905952454,\n",
      "                        0.9508782625198364,\n",
      "                        0.9511562585830688]],\n",
      " 'Training Loss': [[0.3408539891242981,\n",
      "                    0.20757627487182617,\n",
      "                    0.1862315833568573,\n",
      "                    0.17016543447971344,\n",
      "                    0.1615847945213318,\n",
      "                    0.1553308069705963,\n",
      "                    0.15344159305095673,\n",
      "                    0.14452669024467468,\n",
      "                    0.14184711873531342,\n",
      "                    0.13902753591537476,\n",
      "                    0.135011687874794,\n",
      "                    0.13148441910743713,\n",
      "                    0.12926475703716278,\n",
      "                    0.12808459997177124,\n",
      "                    0.12588289380073547,\n",
      "                    0.1238628402352333,\n",
      "                    0.12328730523586273,\n",
      "                    0.12283850461244583,\n",
      "                    0.11993170529603958,\n",
      "                    0.11993197351694107],\n",
      "                   [0.3684512674808502,\n",
      "                    0.20693829655647278,\n",
      "                    0.18388523161411285,\n",
      "                    0.16907989978790283,\n",
      "                    0.16133713722229004,\n",
      "                    0.1550782322883606,\n",
      "                    0.1499014049768448,\n",
      "                    0.14716610312461853,\n",
      "                    0.14169126749038696,\n",
      "                    0.13832460343837738,\n",
      "                    0.1354597806930542,\n",
      "                    0.13278520107269287,\n",
      "                    0.12926112115383148,\n",
      "                    0.12852153182029724,\n",
      "                    0.12746697664260864,\n",
      "                    0.12511727213859558,\n",
      "                    0.12266203761100769,\n",
      "                    0.12271779030561447,\n",
      "                    0.12168790400028229,\n",
      "                    0.11933895945549011],\n",
      "                   [0.3703537881374359,\n",
      "                    0.19284942746162415,\n",
      "                    0.17402714490890503,\n",
      "                    0.16055338084697723,\n",
      "                    0.15443438291549683,\n",
      "                    0.15004052221775055,\n",
      "                    0.14696122705936432,\n",
      "                    0.14256298542022705,\n",
      "                    0.14037877321243286,\n",
      "                    0.13898710906505585,\n",
      "                    0.1357174515724182,\n",
      "                    0.1325761377811432,\n",
      "                    0.13000606000423431,\n",
      "                    0.12757299840450287,\n",
      "                    0.12393957376480103,\n",
      "                    0.12227732688188553,\n",
      "                    0.12060569226741791,\n",
      "                    0.1187983900308609,\n",
      "                    0.11718711256980896,\n",
      "                    0.11846306174993515],\n",
      "                   [0.3350394070148468,\n",
      "                    0.19847245514392853,\n",
      "                    0.17618049681186676,\n",
      "                    0.16420984268188477,\n",
      "                    0.15909133851528168,\n",
      "                    0.15476679801940918,\n",
      "                    0.1509171426296234,\n",
      "                    0.14880754053592682,\n",
      "                    0.14659671485424042,\n",
      "                    0.14365702867507935,\n",
      "                    0.14261318743228912,\n",
      "                    0.13845881819725037,\n",
      "                    0.13637585937976837,\n",
      "                    0.1355324685573578,\n",
      "                    0.1319124698638916,\n",
      "                    0.130467027425766,\n",
      "                    0.12948502600193024,\n",
      "                    0.12663017213344574,\n",
      "                    0.12651513516902924,\n",
      "                    0.12473979592323303],\n",
      "                   [0.3442375361919403,\n",
      "                    0.19440409541130066,\n",
      "                    0.17285574972629547,\n",
      "                    0.1606251746416092,\n",
      "                    0.15695694088935852,\n",
      "                    0.15113508701324463,\n",
      "                    0.1473526507616043,\n",
      "                    0.14385218918323517,\n",
      "                    0.14029240608215332,\n",
      "                    0.13867570459842682,\n",
      "                    0.13627177476882935,\n",
      "                    0.1332985907793045,\n",
      "                    0.13169993460178375,\n",
      "                    0.12987636029720306,\n",
      "                    0.1282285749912262,\n",
      "                    0.12933307886123657,\n",
      "                    0.12703244388103485,\n",
      "                    0.12341885268688202,\n",
      "                    0.12265487760305405,\n",
      "                    0.12199632823467255]],\n",
      " 'Validation Accuracy': [[0.9101146459579468,\n",
      "                          0.9162744879722595,\n",
      "                          0.9249441623687744,\n",
      "                          0.9327601194381714,\n",
      "                          0.9367865920066833,\n",
      "                          0.9384694695472717,\n",
      "                          0.9391334056854248,\n",
      "                          0.9410185813903809,\n",
      "                          0.9421386122703552,\n",
      "                          0.9410986304283142,\n",
      "                          0.9467840790748596,\n",
      "                          0.9490159749984741,\n",
      "                          0.9493680596351624,\n",
      "                          0.9495387077331543,\n",
      "                          0.9488773345947266,\n",
      "                          0.9517679810523987,\n",
      "                          0.9513866305351257,\n",
      "                          0.9513171911239624,\n",
      "                          0.9523811936378479,\n",
      "                          0.9517279267311096],\n",
      "                         [0.9103522300720215,\n",
      "                          0.9200214147567749,\n",
      "                          0.929677426815033,\n",
      "                          0.9331067800521851,\n",
      "                          0.9377840757369995,\n",
      "                          0.93746417760849,\n",
      "                          0.9402880072593689,\n",
      "                          0.9418506026268005,\n",
      "                          0.9417199492454529,\n",
      "                          0.9435280561447144,\n",
      "                          0.9440534114837646,\n",
      "                          0.9464372396469116,\n",
      "                          0.9478240013122559,\n",
      "                          0.949458658695221,\n",
      "                          0.9485787153244019,\n",
      "                          0.9485705494880676,\n",
      "                          0.9507306218147278,\n",
      "                          0.9517732858657837,\n",
      "                          0.9514800906181335,\n",
      "                          0.950698733329773],\n",
      "                         [0.910119891166687,\n",
      "                          0.9228132367134094,\n",
      "                          0.928695797920227,\n",
      "                          0.9323253631591797,\n",
      "                          0.9368799924850464,\n",
      "                          0.9370800256729126,\n",
      "                          0.939709484577179,\n",
      "                          0.9410133361816406,\n",
      "                          0.9402561187744141,\n",
      "                          0.9417068958282471,\n",
      "                          0.9425681233406067,\n",
      "                          0.9444664120674133,\n",
      "                          0.9453840255737305,\n",
      "                          0.9468666315078735,\n",
      "                          0.9469038844108582,\n",
      "                          0.9457999467849731,\n",
      "                          0.947386622428894,\n",
      "                          0.9481787085533142,\n",
      "                          0.9483388662338257,\n",
      "                          0.9494773149490356],\n",
      "                         [0.9098027348518372,\n",
      "                          0.9269439578056335,\n",
      "                          0.9289600253105164,\n",
      "                          0.9329411387443542,\n",
      "                          0.9354639649391174,\n",
      "                          0.9392319917678833,\n",
      "                          0.9401013851165771,\n",
      "                          0.9391600489616394,\n",
      "                          0.9412745833396912,\n",
      "                          0.9436478614807129,\n",
      "                          0.9442268013954163,\n",
      "                          0.944920003414154,\n",
      "                          0.9453601241111755,\n",
      "                          0.9459680914878845,\n",
      "                          0.9450721144676208,\n",
      "                          0.9477947354316711,\n",
      "                          0.9479332566261292,\n",
      "                          0.9475467205047607,\n",
      "                          0.9499653577804565,\n",
      "                          0.9504266977310181],\n",
      "                         [0.907960057258606,\n",
      "                          0.9238932132720947,\n",
      "                          0.9311918020248413,\n",
      "                          0.9347813129425049,\n",
      "                          0.9356879591941833,\n",
      "                          0.9384772777557373,\n",
      "                          0.9406239986419678,\n",
      "                          0.9423173666000366,\n",
      "                          0.9439812302589417,\n",
      "                          0.9400721192359924,\n",
      "                          0.9445174932479858,\n",
      "                          0.9464535117149353,\n",
      "                          0.9449864029884338,\n",
      "                          0.9464400410652161,\n",
      "                          0.9474107027053833,\n",
      "                          0.9417067766189575,\n",
      "                          0.9491785764694214,\n",
      "                          0.9476131796836853,\n",
      "                          0.9484214782714844,\n",
      "                          0.9486239552497864]],\n",
      " 'Validation Loss': [0.2183702141046524,\n",
      "                     0.18096153438091278,\n",
      "                     0.1657985895872116,\n",
      "                     0.1587739735841751,\n",
      "                     0.15500187873840332,\n",
      "                     0.14914332330226898,\n",
      "                     0.14505800604820251,\n",
      "                     0.14243510365486145,\n",
      "                     0.13986100256443024,\n",
      "                     0.14598916471004486,\n",
      "                     0.13769154250621796,\n",
      "                     0.13310883939266205,\n",
      "                     0.13510626554489136,\n",
      "                     0.13317616283893585,\n",
      "                     0.1296546757221222,\n",
      "                     0.14544378221035004,\n",
      "                     0.12413833290338516,\n",
      "                     0.12737534940242767,\n",
      "                     0.128379687666893,\n",
      "                     0.12653741240501404],\n",
      " 'Validation MCC': [[np.float64(0.8200732612503407),\n",
      "                     np.float64(0.833031683435488),\n",
      "                     np.float64(0.8502334733740854),\n",
      "                     np.float64(0.8657396201736659),\n",
      "                     np.float64(0.8733942206745104),\n",
      "                     np.float64(0.8766966245937163),\n",
      "                     np.float64(0.878382402395111),\n",
      "                     np.float64(0.8817256452981209),\n",
      "                     np.float64(0.8842134354321688),\n",
      "                     np.float64(0.8823136167297366),\n",
      "                     np.float64(0.8933928268321879),\n",
      "                     np.float64(0.8978417782109347),\n",
      "                     np.float64(0.8985037095762802),\n",
      "                     np.float64(0.8990548427178175),\n",
      "                     np.float64(0.8974995433140167),\n",
      "                     np.float64(0.9035321267098891),\n",
      "                     np.float64(0.9030535821108173),\n",
      "                     np.float64(0.9024001253923141),\n",
      "                     np.float64(0.9045230898950783),\n",
      "                     np.float64(0.9034762642492482)],\n",
      "                    [np.float64(0.8201701156538166),\n",
      "                     np.float64(0.8400930220259942),\n",
      "                     np.float64(0.8590284937833903),\n",
      "                     np.float64(0.8658271658613006),\n",
      "                     np.float64(0.8752326054884653),\n",
      "                     np.float64(0.8749519883538707),\n",
      "                     np.float64(0.8804606929642051),\n",
      "                     np.float64(0.8835183449695303),\n",
      "                     np.float64(0.8833957665517532),\n",
      "                     np.float64(0.8867339943934768),\n",
      "                     np.float64(0.8878221579306287),\n",
      "                     np.float64(0.8926353015480538),\n",
      "                     np.float64(0.8953493820831073),\n",
      "                     np.float64(0.8986999635236007),\n",
      "                     np.float64(0.8968932727182678),\n",
      "                     np.float64(0.8968995864659677),\n",
      "                     np.float64(0.901204939018763),\n",
      "                     np.float64(0.9034122468393199),\n",
      "                     np.float64(0.902709760636068),\n",
      "                     np.float64(0.9011811000101918)],\n",
      "                    [np.float64(0.8196170324092763),\n",
      "                     np.float64(0.8451714785946852),\n",
      "                     np.float64(0.8570365173511256),\n",
      "                     np.float64(0.8641781779863467),\n",
      "                     np.float64(0.873408174250298),\n",
      "                     np.float64(0.8737072083719087),\n",
      "                     np.float64(0.8789968296070186),\n",
      "                     np.float64(0.8816108148291816),\n",
      "                     np.float64(0.8801876969787759),\n",
      "                     np.float64(0.883046021941795),\n",
      "                     np.float64(0.8850262101330936),\n",
      "                     np.float64(0.8885480121387989),\n",
      "                     np.float64(0.8903789380758574),\n",
      "                     np.float64(0.8937457259616057),\n",
      "                     np.float64(0.8935132816625662),\n",
      "                     np.float64(0.8912840733587016),\n",
      "                     np.float64(0.8944202503941481),\n",
      "                     np.float64(0.8960329347287883),\n",
      "                     np.float64(0.8964430095678277),\n",
      "                     np.float64(0.8989240967020704)],\n",
      "                    [np.float64(0.819433063660845),\n",
      "                     np.float64(0.8536003533761432),\n",
      "                     np.float64(0.8580684804234947),\n",
      "                     np.float64(0.8656046064646393),\n",
      "                     np.float64(0.8705557339950504),\n",
      "                     np.float64(0.8781200666106204),\n",
      "                     np.float64(0.879985230742651),\n",
      "                     np.float64(0.878401426111667),\n",
      "                     np.float64(0.8823086090055068),\n",
      "                     np.float64(0.8869961296313928),\n",
      "                     np.float64(0.8882677127037044),\n",
      "                     np.float64(0.889527127029852),\n",
      "                     np.float64(0.8905901264906506),\n",
      "                     np.float64(0.8920586500317816),\n",
      "                     np.float64(0.8898303150363299),\n",
      "                     np.float64(0.8956136717395224),\n",
      "                     np.float64(0.8956473582214066),\n",
      "                     np.float64(0.8949360691914612),\n",
      "                     np.float64(0.8997274784496213),\n",
      "                     np.float64(0.9008953451978624)],\n",
      "                    [np.float64(0.8162431127965672),\n",
      "                     np.float64(0.8475247744195361),\n",
      "                     np.float64(0.8622554121927111),\n",
      "                     np.float64(0.8692213905745124),\n",
      "                     np.float64(0.8712810379240353),\n",
      "                     np.float64(0.8767224018563179),\n",
      "                     np.float64(0.8809054833611467),\n",
      "                     np.float64(0.8843117592363845),\n",
      "                     np.float64(0.8875924892492705),\n",
      "                     np.float64(0.8800773131454036),\n",
      "                     np.float64(0.8890371792148103),\n",
      "                     np.float64(0.8926073591471594),\n",
      "                     np.float64(0.88993892003596),\n",
      "                     np.float64(0.8925114965658065),\n",
      "                     np.float64(0.894588789911813),\n",
      "                     np.float64(0.8830182739745615),\n",
      "                     np.float64(0.8980270685661322),\n",
      "                     np.float64(0.8953179133359773),\n",
      "                     np.float64(0.8964959225424923),\n",
      "                     np.float64(0.8971047698307418)]]}\n",
      "Training Model: RNN, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.8347 - loss: 0.3748\n",
      "Epoch 1 - MCC: 0.8110\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 51ms/step - accuracy: 0.8349 - loss: 0.3744 - val_accuracy: 0.9057 - val_loss: 0.2311 - mcc: 0.8110\n",
      "Epoch 2/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9047 - loss: 0.2299\n",
      "Epoch 2 - MCC: 0.8153\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 36ms/step - accuracy: 0.9047 - loss: 0.2299 - val_accuracy: 0.9077 - val_loss: 0.2168 - mcc: 0.8153\n",
      "Epoch 3/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9093 - loss: 0.2163\n",
      "Epoch 3 - MCC: 0.8315\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9093 - loss: 0.2163 - val_accuracy: 0.9158 - val_loss: 0.2009 - mcc: 0.8315\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9152 - loss: 0.2034\n",
      "Epoch 4 - MCC: 0.8289\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9152 - loss: 0.2034 - val_accuracy: 0.9147 - val_loss: 0.2041 - mcc: 0.8289\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9151 - loss: 0.2017\n",
      "Epoch 5 - MCC: 0.8392\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9150 - loss: 0.2018 - val_accuracy: 0.9198 - val_loss: 0.1938 - mcc: 0.8392\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9181 - loss: 0.1946\n",
      "Epoch 6 - MCC: 0.8345\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9181 - loss: 0.1946 - val_accuracy: 0.9171 - val_loss: 0.1968 - mcc: 0.8345\n",
      "Epoch 7/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9175 - loss: 0.1961\n",
      "Epoch 7 - MCC: 0.8423\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9175 - loss: 0.1961 - val_accuracy: 0.9213 - val_loss: 0.1851 - mcc: 0.8423\n",
      "Epoch 8/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9187 - loss: 0.1937\n",
      "Epoch 8 - MCC: 0.8391\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9188 - loss: 0.1936 - val_accuracy: 0.9190 - val_loss: 0.1944 - mcc: 0.8391\n",
      "Epoch 9/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9165 - loss: 0.1975\n",
      "Epoch 9 - MCC: 0.8500\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9165 - loss: 0.1975 - val_accuracy: 0.9252 - val_loss: 0.1799 - mcc: 0.8500\n",
      "Epoch 10/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9224 - loss: 0.1847\n",
      "Epoch 10 - MCC: 0.8378\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9224 - loss: 0.1847 - val_accuracy: 0.9191 - val_loss: 0.1928 - mcc: 0.8378\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9239 - loss: 0.1834\n",
      "Epoch 11 - MCC: 0.8442\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.9239 - loss: 0.1834 - val_accuracy: 0.9223 - val_loss: 0.1848 - mcc: 0.8442\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9243 - loss: 0.1792\n",
      "Epoch 12 - MCC: 0.8273\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9243 - loss: 0.1793 - val_accuracy: 0.9132 - val_loss: 0.2118 - mcc: 0.8273\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9255 - loss: 0.1772\n",
      "Epoch 13 - MCC: 0.8507\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9255 - loss: 0.1772 - val_accuracy: 0.9248 - val_loss: 0.1791 - mcc: 0.8507\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9241 - loss: 0.1808\n",
      "Epoch 14 - MCC: 0.8370\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9241 - loss: 0.1807 - val_accuracy: 0.9186 - val_loss: 0.1937 - mcc: 0.8370\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9185 - loss: 0.1942\n",
      "Epoch 15 - MCC: 0.8502\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 35ms/step - accuracy: 0.9185 - loss: 0.1941 - val_accuracy: 0.9248 - val_loss: 0.1859 - mcc: 0.8502\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9272 - loss: 0.1753\n",
      "Epoch 16 - MCC: 0.8542\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9272 - loss: 0.1753 - val_accuracy: 0.9271 - val_loss: 0.1766 - mcc: 0.8542\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9267 - loss: 0.1740\n",
      "Epoch 17 - MCC: 0.8583\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9267 - loss: 0.1740 - val_accuracy: 0.9292 - val_loss: 0.1693 - mcc: 0.8583\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9319 - loss: 0.1646\n",
      "Epoch 18 - MCC: 0.8599\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9319 - loss: 0.1646 - val_accuracy: 0.9300 - val_loss: 0.1660 - mcc: 0.8599\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9309 - loss: 0.1665\n",
      "Epoch 19 - MCC: 0.8666\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9309 - loss: 0.1665 - val_accuracy: 0.9335 - val_loss: 0.1605 - mcc: 0.8666\n",
      "Epoch 20/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9293 - loss: 0.1678\n",
      "Epoch 20 - MCC: 0.8618\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9293 - loss: 0.1678 - val_accuracy: 0.9311 - val_loss: 0.1650 - mcc: 0.8618\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.8343 - loss: 0.3800\n",
      "Epoch 1 - MCC: 0.7959\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 50ms/step - accuracy: 0.8345 - loss: 0.3796 - val_accuracy: 0.8974 - val_loss: 0.2464 - mcc: 0.7959\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8965 - loss: 0.2477\n",
      "Epoch 2 - MCC: 0.8080\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.8966 - loss: 0.2476 - val_accuracy: 0.9039 - val_loss: 0.2309 - mcc: 0.8080\n",
      "Epoch 3/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9041 - loss: 0.2273\n",
      "Epoch 3 - MCC: 0.8308\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9041 - loss: 0.2273 - val_accuracy: 0.9157 - val_loss: 0.2003 - mcc: 0.8308\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9124 - loss: 0.2075\n",
      "Epoch 4 - MCC: 0.8267\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9124 - loss: 0.2075 - val_accuracy: 0.9134 - val_loss: 0.2018 - mcc: 0.8267\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9136 - loss: 0.2049\n",
      "Epoch 5 - MCC: 0.8372\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9136 - loss: 0.2049 - val_accuracy: 0.9187 - val_loss: 0.1943 - mcc: 0.8372\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9169 - loss: 0.1968\n",
      "Epoch 6 - MCC: 0.8430\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9169 - loss: 0.1968 - val_accuracy: 0.9217 - val_loss: 0.1863 - mcc: 0.8430\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9164 - loss: 0.1983\n",
      "Epoch 7 - MCC: 0.8423\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9164 - loss: 0.1983 - val_accuracy: 0.9213 - val_loss: 0.1864 - mcc: 0.8423\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9189 - loss: 0.1936\n",
      "Epoch 8 - MCC: 0.8452\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9189 - loss: 0.1936 - val_accuracy: 0.9228 - val_loss: 0.1884 - mcc: 0.8452\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9190 - loss: 0.1913\n",
      "Epoch 9 - MCC: 0.8265\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9190 - loss: 0.1913 - val_accuracy: 0.9135 - val_loss: 0.2057 - mcc: 0.8265\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9196 - loss: 0.1921\n",
      "Epoch 10 - MCC: 0.8456\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9197 - loss: 0.1920 - val_accuracy: 0.9230 - val_loss: 0.1812 - mcc: 0.8456\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9232 - loss: 0.1839\n",
      "Epoch 11 - MCC: 0.8551\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9232 - loss: 0.1840 - val_accuracy: 0.9278 - val_loss: 0.1733 - mcc: 0.8551\n",
      "Epoch 12/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9245 - loss: 0.1803\n",
      "Epoch 12 - MCC: 0.8611\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9245 - loss: 0.1803 - val_accuracy: 0.9307 - val_loss: 0.1644 - mcc: 0.8611\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9234 - loss: 0.1839\n",
      "Epoch 13 - MCC: 0.8608\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9234 - loss: 0.1839 - val_accuracy: 0.9302 - val_loss: 0.1694 - mcc: 0.8608\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9229 - loss: 0.1840\n",
      "Epoch 14 - MCC: 0.8600\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9229 - loss: 0.1840 - val_accuracy: 0.9301 - val_loss: 0.1688 - mcc: 0.8600\n",
      "Epoch 15/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9271 - loss: 0.1749\n",
      "Epoch 15 - MCC: 0.8575\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9271 - loss: 0.1749 - val_accuracy: 0.9288 - val_loss: 0.1730 - mcc: 0.8575\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9278 - loss: 0.1726\n",
      "Epoch 16 - MCC: 0.8628\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9278 - loss: 0.1726 - val_accuracy: 0.9312 - val_loss: 0.1660 - mcc: 0.8628\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9286 - loss: 0.1709\n",
      "Epoch 17 - MCC: 0.8673\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9286 - loss: 0.1709 - val_accuracy: 0.9339 - val_loss: 0.1577 - mcc: 0.8673\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9296 - loss: 0.1695\n",
      "Epoch 18 - MCC: 0.8675\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9296 - loss: 0.1696 - val_accuracy: 0.9339 - val_loss: 0.1599 - mcc: 0.8675\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9285 - loss: 0.1697\n",
      "Epoch 19 - MCC: 0.8656\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9285 - loss: 0.1697 - val_accuracy: 0.9328 - val_loss: 0.1620 - mcc: 0.8656\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9301 - loss: 0.1669\n",
      "Epoch 20 - MCC: 0.8596\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9301 - loss: 0.1669 - val_accuracy: 0.9300 - val_loss: 0.1668 - mcc: 0.8596\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.8337 - loss: 0.3848\n",
      "Epoch 1 - MCC: 0.7958\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 47ms/step - accuracy: 0.8339 - loss: 0.3844 - val_accuracy: 0.8982 - val_loss: 0.2484 - mcc: 0.7958\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9022 - loss: 0.2376\n",
      "Epoch 2 - MCC: 0.8174\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9022 - loss: 0.2376 - val_accuracy: 0.9090 - val_loss: 0.2195 - mcc: 0.8174\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9123 - loss: 0.2102\n",
      "Epoch 3 - MCC: 0.8152\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9123 - loss: 0.2102 - val_accuracy: 0.9069 - val_loss: 0.2231 - mcc: 0.8152\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9106 - loss: 0.2123\n",
      "Epoch 4 - MCC: 0.8190\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9106 - loss: 0.2122 - val_accuracy: 0.9091 - val_loss: 0.2117 - mcc: 0.8190\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9140 - loss: 0.2038\n",
      "Epoch 5 - MCC: 0.8208\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9140 - loss: 0.2037 - val_accuracy: 0.9094 - val_loss: 0.2142 - mcc: 0.8208\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9204 - loss: 0.1914\n",
      "Epoch 6 - MCC: 0.8415\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9204 - loss: 0.1915 - val_accuracy: 0.9210 - val_loss: 0.1914 - mcc: 0.8415\n",
      "Epoch 7/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9158 - loss: 0.2022\n",
      "Epoch 7 - MCC: 0.8308\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9158 - loss: 0.2022 - val_accuracy: 0.9151 - val_loss: 0.2014 - mcc: 0.8308\n",
      "Epoch 8/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9202 - loss: 0.1910\n",
      "Epoch 8 - MCC: 0.8315\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9202 - loss: 0.1910 - val_accuracy: 0.9151 - val_loss: 0.2039 - mcc: 0.8315\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9261 - loss: 0.1766\n",
      "Epoch 9 - MCC: 0.8482\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9261 - loss: 0.1766 - val_accuracy: 0.9241 - val_loss: 0.1865 - mcc: 0.8482\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9248 - loss: 0.1817\n",
      "Epoch 10 - MCC: 0.8462\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9248 - loss: 0.1817 - val_accuracy: 0.9233 - val_loss: 0.1820 - mcc: 0.8462\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9263 - loss: 0.1776\n",
      "Epoch 11 - MCC: 0.8425\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9263 - loss: 0.1776 - val_accuracy: 0.9212 - val_loss: 0.1977 - mcc: 0.8425\n",
      "Epoch 12/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9217 - loss: 0.1890\n",
      "Epoch 12 - MCC: 0.8479\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9217 - loss: 0.1889 - val_accuracy: 0.9241 - val_loss: 0.1808 - mcc: 0.8479\n",
      "Epoch 13/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9305 - loss: 0.1677\n",
      "Epoch 13 - MCC: 0.8505\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 35ms/step - accuracy: 0.9305 - loss: 0.1678 - val_accuracy: 0.9252 - val_loss: 0.1794 - mcc: 0.8505\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9279 - loss: 0.1743\n",
      "Epoch 14 - MCC: 0.8575\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9279 - loss: 0.1743 - val_accuracy: 0.9289 - val_loss: 0.1716 - mcc: 0.8575\n",
      "Epoch 15/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9310 - loss: 0.1669\n",
      "Epoch 15 - MCC: 0.8510\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9310 - loss: 0.1670 - val_accuracy: 0.9256 - val_loss: 0.1798 - mcc: 0.8510\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9297 - loss: 0.1692\n",
      "Epoch 16 - MCC: 0.8533\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9298 - loss: 0.1692 - val_accuracy: 0.9268 - val_loss: 0.1740 - mcc: 0.8533\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9291 - loss: 0.1709\n",
      "Epoch 17 - MCC: 0.8374\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9290 - loss: 0.1709 - val_accuracy: 0.9190 - val_loss: 0.1965 - mcc: 0.8374\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9268 - loss: 0.1777\n",
      "Epoch 18 - MCC: 0.8349\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9268 - loss: 0.1777 - val_accuracy: 0.9170 - val_loss: 0.2043 - mcc: 0.8349\n",
      "Epoch 19/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9265 - loss: 0.1795\n",
      "Epoch 19 - MCC: 0.8477\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9265 - loss: 0.1794 - val_accuracy: 0.9241 - val_loss: 0.1833 - mcc: 0.8477\n",
      "Epoch 20/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9288 - loss: 0.1746\n",
      "Epoch 20 - MCC: 0.8425\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9288 - loss: 0.1746 - val_accuracy: 0.9216 - val_loss: 0.1925 - mcc: 0.8425\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.8216 - loss: 0.4039\n",
      "Epoch 1 - MCC: 0.7977\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 49ms/step - accuracy: 0.8219 - loss: 0.4034 - val_accuracy: 0.8990 - val_loss: 0.2448 - mcc: 0.7977\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8971 - loss: 0.2483\n",
      "Epoch 2 - MCC: 0.8121\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.8971 - loss: 0.2482 - val_accuracy: 0.9060 - val_loss: 0.2281 - mcc: 0.8121\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9090 - loss: 0.2180\n",
      "Epoch 3 - MCC: 0.8160\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9090 - loss: 0.2180 - val_accuracy: 0.9079 - val_loss: 0.2292 - mcc: 0.8160\n",
      "Epoch 4/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9098 - loss: 0.2157\n",
      "Epoch 4 - MCC: 0.8369\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9098 - loss: 0.2156 - val_accuracy: 0.9184 - val_loss: 0.1932 - mcc: 0.8369\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9166 - loss: 0.1986\n",
      "Epoch 5 - MCC: 0.8409\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9166 - loss: 0.1986 - val_accuracy: 0.9206 - val_loss: 0.1874 - mcc: 0.8409\n",
      "Epoch 6/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9178 - loss: 0.1952\n",
      "Epoch 6 - MCC: 0.8464\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9178 - loss: 0.1952 - val_accuracy: 0.9234 - val_loss: 0.1824 - mcc: 0.8464\n",
      "Epoch 7/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9183 - loss: 0.1930\n",
      "Epoch 7 - MCC: 0.8427\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9183 - loss: 0.1930 - val_accuracy: 0.9214 - val_loss: 0.1894 - mcc: 0.8427\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9211 - loss: 0.1879\n",
      "Epoch 8 - MCC: 0.8527\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 34ms/step - accuracy: 0.9211 - loss: 0.1879 - val_accuracy: 0.9264 - val_loss: 0.1763 - mcc: 0.8527\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9256 - loss: 0.1779\n",
      "Epoch 9 - MCC: 0.8490\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9256 - loss: 0.1780 - val_accuracy: 0.9245 - val_loss: 0.1812 - mcc: 0.8490\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9235 - loss: 0.1830\n",
      "Epoch 10 - MCC: 0.8408\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9235 - loss: 0.1830 - val_accuracy: 0.9199 - val_loss: 0.1899 - mcc: 0.8408\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9275 - loss: 0.1754\n",
      "Epoch 11 - MCC: 0.8527\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9275 - loss: 0.1754 - val_accuracy: 0.9265 - val_loss: 0.1803 - mcc: 0.8527\n",
      "Epoch 12/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9259 - loss: 0.1775\n",
      "Epoch 12 - MCC: 0.8459\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9259 - loss: 0.1775 - val_accuracy: 0.9224 - val_loss: 0.1845 - mcc: 0.8459\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9266 - loss: 0.1769\n",
      "Epoch 13 - MCC: 0.8570\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9266 - loss: 0.1769 - val_accuracy: 0.9287 - val_loss: 0.1702 - mcc: 0.8570\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9296 - loss: 0.1697\n",
      "Epoch 14 - MCC: 0.8648\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9296 - loss: 0.1697 - val_accuracy: 0.9325 - val_loss: 0.1642 - mcc: 0.8648\n",
      "Epoch 15/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9294 - loss: 0.1700\n",
      "Epoch 15 - MCC: 0.8547\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9294 - loss: 0.1701 - val_accuracy: 0.9276 - val_loss: 0.1724 - mcc: 0.8547\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9300 - loss: 0.1684\n",
      "Epoch 16 - MCC: 0.8655\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9300 - loss: 0.1684 - val_accuracy: 0.9329 - val_loss: 0.1619 - mcc: 0.8655\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9312 - loss: 0.1651\n",
      "Epoch 17 - MCC: 0.8676\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9312 - loss: 0.1651 - val_accuracy: 0.9340 - val_loss: 0.1597 - mcc: 0.8676\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9299 - loss: 0.1685\n",
      "Epoch 18 - MCC: 0.8599\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9299 - loss: 0.1684 - val_accuracy: 0.9300 - val_loss: 0.1716 - mcc: 0.8599\n",
      "Epoch 19/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9309 - loss: 0.1677\n",
      "Epoch 19 - MCC: 0.8662\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9309 - loss: 0.1677 - val_accuracy: 0.9333 - val_loss: 0.1601 - mcc: 0.8662\n",
      "Epoch 20/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9318 - loss: 0.1649\n",
      "Epoch 20 - MCC: 0.8691\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9318 - loss: 0.1649 - val_accuracy: 0.9346 - val_loss: 0.1590 - mcc: 0.8691\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.8202 - loss: 0.3928\n",
      "Epoch 1 - MCC: 0.7946\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 49ms/step - accuracy: 0.8205 - loss: 0.3924 - val_accuracy: 0.8976 - val_loss: 0.2435 - mcc: 0.7946\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9005 - loss: 0.2379\n",
      "Epoch 2 - MCC: 0.8158\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9005 - loss: 0.2379 - val_accuracy: 0.9082 - val_loss: 0.2180 - mcc: 0.8158\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9071 - loss: 0.2224\n",
      "Epoch 3 - MCC: 0.8082\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 35ms/step - accuracy: 0.9071 - loss: 0.2224 - val_accuracy: 0.9043 - val_loss: 0.2199 - mcc: 0.8082\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9110 - loss: 0.2110\n",
      "Epoch 4 - MCC: 0.8258\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9111 - loss: 0.2109 - val_accuracy: 0.9127 - val_loss: 0.2049 - mcc: 0.8258\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9151 - loss: 0.2029\n",
      "Epoch 5 - MCC: 0.8334\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9151 - loss: 0.2029 - val_accuracy: 0.9169 - val_loss: 0.1952 - mcc: 0.8334\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9160 - loss: 0.2003\n",
      "Epoch 6 - MCC: 0.8244\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9160 - loss: 0.2003 - val_accuracy: 0.9120 - val_loss: 0.2122 - mcc: 0.8244\n",
      "Epoch 7/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9179 - loss: 0.1984\n",
      "Epoch 7 - MCC: 0.8344\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9179 - loss: 0.1984 - val_accuracy: 0.9171 - val_loss: 0.2008 - mcc: 0.8344\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9195 - loss: 0.1927\n",
      "Epoch 8 - MCC: 0.8463\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9195 - loss: 0.1927 - val_accuracy: 0.9234 - val_loss: 0.1861 - mcc: 0.8463\n",
      "Epoch 9/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9241 - loss: 0.1824\n",
      "Epoch 9 - MCC: 0.8496\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9241 - loss: 0.1824 - val_accuracy: 0.9246 - val_loss: 0.1856 - mcc: 0.8496\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9256 - loss: 0.1788\n",
      "Epoch 10 - MCC: 0.8472\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9256 - loss: 0.1788 - val_accuracy: 0.9234 - val_loss: 0.1812 - mcc: 0.8472\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9238 - loss: 0.1829\n",
      "Epoch 11 - MCC: 0.8483\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9238 - loss: 0.1829 - val_accuracy: 0.9244 - val_loss: 0.1839 - mcc: 0.8483\n",
      "Epoch 12/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9270 - loss: 0.1759\n",
      "Epoch 12 - MCC: 0.8453\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9270 - loss: 0.1759 - val_accuracy: 0.9229 - val_loss: 0.1831 - mcc: 0.8453\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9254 - loss: 0.1804\n",
      "Epoch 13 - MCC: 0.8396\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9254 - loss: 0.1804 - val_accuracy: 0.9192 - val_loss: 0.1900 - mcc: 0.8396\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9280 - loss: 0.1732\n",
      "Epoch 14 - MCC: 0.8600\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9280 - loss: 0.1732 - val_accuracy: 0.9301 - val_loss: 0.1718 - mcc: 0.8600\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9277 - loss: 0.1749\n",
      "Epoch 15 - MCC: 0.8578\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9277 - loss: 0.1749 - val_accuracy: 0.9289 - val_loss: 0.1706 - mcc: 0.8578\n",
      "Epoch 16/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9266 - loss: 0.1771\n",
      "Epoch 16 - MCC: 0.8506\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9266 - loss: 0.1771 - val_accuracy: 0.9254 - val_loss: 0.1793 - mcc: 0.8506\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9282 - loss: 0.1733\n",
      "Epoch 17 - MCC: 0.8502\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 35ms/step - accuracy: 0.9282 - loss: 0.1733 - val_accuracy: 0.9251 - val_loss: 0.1765 - mcc: 0.8502\n",
      "Epoch 18/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9272 - loss: 0.1759\n",
      "Epoch 18 - MCC: 0.8240\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9272 - loss: 0.1760 - val_accuracy: 0.9123 - val_loss: 0.2108 - mcc: 0.8240\n",
      "Epoch 19/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9221 - loss: 0.1901\n",
      "Epoch 19 - MCC: 0.8439\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 35ms/step - accuracy: 0.9221 - loss: 0.1901 - val_accuracy: 0.9211 - val_loss: 0.1860 - mcc: 0.8439\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9293 - loss: 0.1707\n",
      "Epoch 20 - MCC: 0.8569\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.9293 - loss: 0.1708 - val_accuracy: 0.9281 - val_loss: 0.1781 - mcc: 0.8569\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.9346266666666667),\n",
      "              'mean': np.float64(0.9290672000000001),\n",
      "              'min': np.float64(0.921552),\n",
      "              'std': np.float64(0.004318030629297985)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.0006419747670491536),\n",
      "                               'mean': np.float64(0.000569025484720866),\n",
      "                               'min': np.float64(0.0004794362386067708),\n",
      "                               'std': np.float64(7.38913987689966e-05)},\n",
      " 'MCC': {'max': np.float64(0.8691262421361776),\n",
      "         'mean': np.float64(0.8579971964337698),\n",
      "         'min': np.float64(0.8425496595436448),\n",
      "         'std': np.float64(0.00872156131443764)},\n",
      " 'Parameters': 5093,\n",
      " 'Train Time (s)': {'max': np.float64(195.84590911865234),\n",
      "                    'mean': np.float64(175.14931211471557),\n",
      "                    'min': np.float64(162.9545361995697),\n",
      "                    'std': np.float64(11.276416927113463)},\n",
      " 'Training Accuracy': [[0.875359058380127,\n",
      "                        0.9053776264190674,\n",
      "                        0.909692645072937,\n",
      "                        0.9130418300628662,\n",
      "                        0.9138699769973755,\n",
      "                        0.9174851775169373,\n",
      "                        0.9177820682525635,\n",
      "                        0.9199808239936829,\n",
      "                        0.91973477602005,\n",
      "                        0.9228183627128601,\n",
      "                        0.9228935837745667,\n",
      "                        0.9242197871208191,\n",
      "                        0.9250622391700745,\n",
      "                        0.9261233806610107,\n",
      "                        0.9216974973678589,\n",
      "                        0.9268366098403931,\n",
      "                        0.9274098873138428,\n",
      "                        0.9297676682472229,\n",
      "                        0.9304503798484802,\n",
      "                        0.9293097853660583],\n",
      "                       [0.8701359033584595,\n",
      "                        0.9015939831733704,\n",
      "                        0.9057922959327698,\n",
      "                        0.9116742610931396,\n",
      "                        0.9138681888580322,\n",
      "                        0.9155572652816772,\n",
      "                        0.9169099926948547,\n",
      "                        0.9189851880073547,\n",
      "                        0.919262707233429,\n",
      "                        0.9204662442207336,\n",
      "                        0.9216537475585938,\n",
      "                        0.9248245358467102,\n",
      "                        0.9253131747245789,\n",
      "                        0.9252614974975586,\n",
      "                        0.9272563457489014,\n",
      "                        0.9267733693122864,\n",
      "                        0.9288172721862793,\n",
      "                        0.9291519522666931,\n",
      "                        0.9305742383003235,\n",
      "                        0.9298781156539917],\n",
      "                       [0.8717702031135559,\n",
      "                        0.9036760926246643,\n",
      "                        0.9122835397720337,\n",
      "                        0.9145273566246033,\n",
      "                        0.9174177050590515,\n",
      "                        0.9173970818519592,\n",
      "                        0.9191511869430542,\n",
      "                        0.9238370656967163,\n",
      "                        0.9257878661155701,\n",
      "                        0.9253622889518738,\n",
      "                        0.9257295727729797,\n",
      "                        0.9258579015731812,\n",
      "                        0.9258278608322144,\n",
      "                        0.9285801649093628,\n",
      "                        0.9296137690544128,\n",
      "                        0.9300553202629089,\n",
      "                        0.9278740882873535,\n",
      "                        0.9275312423706055,\n",
      "                        0.9281910061836243,\n",
      "                        0.9254972338676453],\n",
      "                       [0.868678629398346,\n",
      "                        0.9005964994430542,\n",
      "                        0.9081995487213135,\n",
      "                        0.9125350117683411,\n",
      "                        0.9169748425483704,\n",
      "                        0.9191483855247498,\n",
      "                        0.9195823669433594,\n",
      "                        0.922346830368042,\n",
      "                        0.924680769443512,\n",
      "                        0.9251729249954224,\n",
      "                        0.9265518188476562,\n",
      "                        0.9254773855209351,\n",
      "                        0.9278454780578613,\n",
      "                        0.9282582998275757,\n",
      "                        0.9286510348320007,\n",
      "                        0.928268551826477,\n",
      "                        0.930090069770813,\n",
      "                        0.9304580688476562,\n",
      "                        0.9310557246208191,\n",
      "                        0.9313456416130066],\n",
      "                       [0.8689484596252441,\n",
      "                        0.901796817779541,\n",
      "                        0.9075067639350891,\n",
      "                        0.9127886295318604,\n",
      "                        0.9158288836479187,\n",
      "                        0.9163960814476013,\n",
      "                        0.9188314080238342,\n",
      "                        0.9208980202674866,\n",
      "                        0.9240111708641052,\n",
      "                        0.9251214861869812,\n",
      "                        0.9239787459373474,\n",
      "                        0.92557692527771,\n",
      "                        0.926626980304718,\n",
      "                        0.9284871220588684,\n",
      "                        0.9275239109992981,\n",
      "                        0.9266969561576843,\n",
      "                        0.9294139742851257,\n",
      "                        0.9224659204483032,\n",
      "                        0.9238722324371338,\n",
      "                        0.9290359020233154]],\n",
      " 'Training Loss': [[0.29703909158706665,\n",
      "                    0.22683146595954895,\n",
      "                    0.21635709702968597,\n",
      "                    0.208011656999588,\n",
      "                    0.20515000820159912,\n",
      "                    0.19583173096179962,\n",
      "                    0.195468470454216,\n",
      "                    0.19110926985740662,\n",
      "                    0.1900639832019806,\n",
      "                    0.18413370847702026,\n",
      "                    0.18433047831058502,\n",
      "                    0.18077856302261353,\n",
      "                    0.17880116403102875,\n",
      "                    0.17627127468585968,\n",
      "                    0.18759103119373322,\n",
      "                    0.17514295876026154,\n",
      "                    0.17290572822093964,\n",
      "                    0.16811324656009674,\n",
      "                    0.16636960208415985,\n",
      "                    0.16876041889190674],\n",
      "                   [0.30957329273223877,\n",
      "                    0.23616889119148254,\n",
      "                    0.22330468893051147,\n",
      "                    0.20891086757183075,\n",
      "                    0.20458991825580597,\n",
      "                    0.199571892619133,\n",
      "                    0.19706521928310394,\n",
      "                    0.19429552555084229,\n",
      "                    0.19173061847686768,\n",
      "                    0.18989959359169006,\n",
      "                    0.1875796914100647,\n",
      "                    0.17945879697799683,\n",
      "                    0.1796354353427887,\n",
      "                    0.17888537049293518,\n",
      "                    0.17433491349220276,\n",
      "                    0.17464996874332428,\n",
      "                    0.17050059139728546,\n",
      "                    0.1705838143825531,\n",
      "                    0.1669052094221115,\n",
      "                    0.16778524219989777],\n",
      "                   [0.3070652484893799,\n",
      "                    0.232091024518013,\n",
      "                    0.20845282077789307,\n",
      "                    0.20312494039535522,\n",
      "                    0.1964121311903,\n",
      "                    0.19844946265220642,\n",
      "                    0.19446347653865814,\n",
      "                    0.18269120156764984,\n",
      "                    0.1779545545578003,\n",
      "                    0.1797008514404297,\n",
      "                    0.17851965129375458,\n",
      "                    0.17926912009716034,\n",
      "                    0.17759782075881958,\n",
      "                    0.1727263629436493,\n",
      "                    0.16987645626068115,\n",
      "                    0.16868393123149872,\n",
      "                    0.17380428314208984,\n",
      "                    0.17712831497192383,\n",
      "                    0.1741734892129898,\n",
      "                    0.18413734436035156],\n",
      "                   [0.31408268213272095,\n",
      "                    0.23971246182918549,\n",
      "                    0.21968595683574677,\n",
      "                    0.20843593776226044,\n",
      "                    0.1974399983882904,\n",
      "                    0.19292236864566803,\n",
      "                    0.19179372489452362,\n",
      "                    0.18541277945041656,\n",
      "                    0.18074379861354828,\n",
      "                    0.17964321374893188,\n",
      "                    0.17671282589435577,\n",
      "                    0.17818807065486908,\n",
      "                    0.1729244589805603,\n",
      "                    0.17156007885932922,\n",
      "                    0.1714673638343811,\n",
      "                    0.1720140427350998,\n",
      "                    0.1681753695011139,\n",
      "                    0.1670314073562622,\n",
      "                    0.16673484444618225,\n",
      "                    0.16592925786972046],\n",
      "                   [0.3086102306842804,\n",
      "                    0.2344813197851181,\n",
      "                    0.22090183198451996,\n",
      "                    0.20808634161949158,\n",
      "                    0.20114310085773468,\n",
      "                    0.20013076066970825,\n",
      "                    0.1953192502260208,\n",
      "                    0.18961022794246674,\n",
      "                    0.18298675119876862,\n",
      "                    0.18020305037498474,\n",
      "                    0.18329884111881256,\n",
      "                    0.17954015731811523,\n",
      "                    0.17777924239635468,\n",
      "                    0.17264550924301147,\n",
      "                    0.17576026916503906,\n",
      "                    0.17782719433307648,\n",
      "                    0.17089124023914337,\n",
      "                    0.18836469948291779,\n",
      "                    0.18474596738815308,\n",
      "                    0.17217038571834564]],\n",
      " 'Validation Accuracy': [[0.9057040214538574,\n",
      "                          0.907656192779541,\n",
      "                          0.9158214330673218,\n",
      "                          0.9146852493286133,\n",
      "                          0.9198401570320129,\n",
      "                          0.9171333909034729,\n",
      "                          0.9213093519210815,\n",
      "                          0.9190319776535034,\n",
      "                          0.9251599311828613,\n",
      "                          0.9190987348556519,\n",
      "                          0.9222826361656189,\n",
      "                          0.9131917953491211,\n",
      "                          0.9247519373893738,\n",
      "                          0.9186132550239563,\n",
      "                          0.9247705340385437,\n",
      "                          0.9270720481872559,\n",
      "                          0.9291867613792419,\n",
      "                          0.9300346970558167,\n",
      "                          0.9334722757339478,\n",
      "                          0.9310612678527832],\n",
      "                         [0.8974426984786987,\n",
      "                          0.9039012789726257,\n",
      "                          0.9156694412231445,\n",
      "                          0.9134293794631958,\n",
      "                          0.9186692833900452,\n",
      "                          0.9217438101768494,\n",
      "                          0.92134690284729,\n",
      "                          0.9228158593177795,\n",
      "                          0.9134562015533447,\n",
      "                          0.9230344891548157,\n",
      "                          0.9277545809745789,\n",
      "                          0.9307282567024231,\n",
      "                          0.9302452802658081,\n",
      "                          0.9301385879516602,\n",
      "                          0.9287893176078796,\n",
      "                          0.9312401413917542,\n",
      "                          0.9338534474372864,\n",
      "                          0.93393874168396,\n",
      "                          0.9328373074531555,\n",
      "                          0.9300134181976318],\n",
      "                         [0.8981680274009705,\n",
      "                          0.9089627265930176,\n",
      "                          0.906856119632721,\n",
      "                          0.9091386198997498,\n",
      "                          0.9093814492225647,\n",
      "                          0.9209544062614441,\n",
      "                          0.9151281118392944,\n",
      "                          0.9150800704956055,\n",
      "                          0.9240719676017761,\n",
      "                          0.923338770866394,\n",
      "                          0.9211652874946594,\n",
      "                          0.9240907430648804,\n",
      "                          0.9252027869224548,\n",
      "                          0.9289039969444275,\n",
      "                          0.9255841374397278,\n",
      "                          0.9268347024917603,\n",
      "                          0.919018566608429,\n",
      "                          0.9170186519622803,\n",
      "                          0.9240960478782654,\n",
      "                          0.9215520620346069],\n",
      "                         [0.8990347385406494,\n",
      "                          0.9059785008430481,\n",
      "                          0.907896101474762,\n",
      "                          0.9184373617172241,\n",
      "                          0.9206187129020691,\n",
      "                          0.9233866930007935,\n",
      "                          0.9214266538619995,\n",
      "                          0.926423966884613,\n",
      "                          0.924549400806427,\n",
      "                          0.9198535084724426,\n",
      "                          0.9264587163925171,\n",
      "                          0.922437310218811,\n",
      "                          0.9287013411521912,\n",
      "                          0.9325441122055054,\n",
      "                          0.927557110786438,\n",
      "                          0.9329147934913635,\n",
      "                          0.9339680075645447,\n",
      "                          0.9299546480178833,\n",
      "                          0.9332801103591919,\n",
      "                          0.9346268773078918],\n",
      "                         [0.8975999355316162,\n",
      "                          0.9082080721855164,\n",
      "                          0.9042906761169434,\n",
      "                          0.9127094149589539,\n",
      "                          0.9169359803199768,\n",
      "                          0.9119679927825928,\n",
      "                          0.9171227216720581,\n",
      "                          0.9233600497245789,\n",
      "                          0.9245521426200867,\n",
      "                          0.9233971238136292,\n",
      "                          0.9243600964546204,\n",
      "                          0.9228640794754028,\n",
      "                          0.9192373156547546,\n",
      "                          0.9301281571388245,\n",
      "                          0.9288641810417175,\n",
      "                          0.9254186749458313,\n",
      "                          0.9251040816307068,\n",
      "                          0.912277340888977,\n",
      "                          0.9211202263832092,\n",
      "                          0.9280824661254883]],\n",
      " 'Validation Loss': [0.2434624284505844,\n",
      "                     0.21795639395713806,\n",
      "                     0.21990543603897095,\n",
      "                     0.20486938953399658,\n",
      "                     0.1951703280210495,\n",
      "                     0.2122194468975067,\n",
      "                     0.2007986605167389,\n",
      "                     0.1860848367214203,\n",
      "                     0.18560105562210083,\n",
      "                     0.18121337890625,\n",
      "                     0.1838962435722351,\n",
      "                     0.18312998116016388,\n",
      "                     0.19000773131847382,\n",
      "                     0.1718256175518036,\n",
      "                     0.1706002950668335,\n",
      "                     0.17928096652030945,\n",
      "                     0.17652180790901184,\n",
      "                     0.21082378923892975,\n",
      "                     0.18599727749824524,\n",
      "                     0.1781221330165863],\n",
      " 'Validation MCC': [[np.float64(0.8109819432507852),\n",
      "                     np.float64(0.8153189645921876),\n",
      "                     np.float64(0.8315051651311923),\n",
      "                     np.float64(0.8288883242371222),\n",
      "                     np.float64(0.8392490527715005),\n",
      "                     np.float64(0.8344612264204),\n",
      "                     np.float64(0.8423062722158714),\n",
      "                     np.float64(0.8390913371161499),\n",
      "                     np.float64(0.8500314007745332),\n",
      "                     np.float64(0.8377519236784189),\n",
      "                     np.float64(0.844217363232781),\n",
      "                     np.float64(0.8273323879515777),\n",
      "                     np.float64(0.8506572215840763),\n",
      "                     np.float64(0.837027342111402),\n",
      "                     np.float64(0.8501921213168923),\n",
      "                     np.float64(0.8542235897380401),\n",
      "                     np.float64(0.8582854682589508),\n",
      "                     np.float64(0.8599238698875832),\n",
      "                     np.float64(0.866583794048179),\n",
      "                     np.float64(0.8617536911112065)],\n",
      "                    [np.float64(0.795895950425251),\n",
      "                     np.float64(0.8079882024351873),\n",
      "                     np.float64(0.830829931619857),\n",
      "                     np.float64(0.8267297142042325),\n",
      "                     np.float64(0.8372187428645422),\n",
      "                     np.float64(0.8430363292093754),\n",
      "                     np.float64(0.8423075057930636),\n",
      "                     np.float64(0.8451927021068588),\n",
      "                     np.float64(0.8265033212904215),\n",
      "                     np.float64(0.8456186211567667),\n",
      "                     np.float64(0.8551052526104219),\n",
      "                     np.float64(0.8610710449673595),\n",
      "                     np.float64(0.8607954375856989),\n",
      "                     np.float64(0.8599691339382413),\n",
      "                     np.float64(0.8574822245292065),\n",
      "                     np.float64(0.8628222203332172),\n",
      "                     np.float64(0.8673176066835576),\n",
      "                     np.float64(0.8675420863300108),\n",
      "                     np.float64(0.8655937308973594),\n",
      "                     np.float64(0.8596155301533743)],\n",
      "                    [np.float64(0.7957740708919847),\n",
      "                     np.float64(0.8173571384410376),\n",
      "                     np.float64(0.8152099711801325),\n",
      "                     np.float64(0.8189857678533714),\n",
      "                     np.float64(0.8208085618121101),\n",
      "                     np.float64(0.841514060405094),\n",
      "                     np.float64(0.8307777003265158),\n",
      "                     np.float64(0.8315228524191466),\n",
      "                     np.float64(0.8481975533536503),\n",
      "                     np.float64(0.8461842316529631),\n",
      "                     np.float64(0.8424862728213559),\n",
      "                     np.float64(0.8479077432730855),\n",
      "                     np.float64(0.8504615749354426),\n",
      "                     np.float64(0.8575288963473126),\n",
      "                     np.float64(0.8509607571308703),\n",
      "                     np.float64(0.853255382181925),\n",
      "                     np.float64(0.837441197174202),\n",
      "                     np.float64(0.8348570339830211),\n",
      "                     np.float64(0.8476718963021811),\n",
      "                     np.float64(0.8425496595436448)],\n",
      "                    [np.float64(0.7977051665603953),\n",
      "                     np.float64(0.8120711546841799),\n",
      "                     np.float64(0.8159798489758553),\n",
      "                     np.float64(0.8368823843403057),\n",
      "                     np.float64(0.8408513889617477),\n",
      "                     np.float64(0.8463926567895802),\n",
      "                     np.float64(0.8426796749336126),\n",
      "                     np.float64(0.852653250529962),\n",
      "                     np.float64(0.8489532666331122),\n",
      "                     np.float64(0.8408379239394276),\n",
      "                     np.float64(0.8526746592971393),\n",
      "                     np.float64(0.845948477276451),\n",
      "                     np.float64(0.8569883340500606),\n",
      "                     np.float64(0.864846059180803),\n",
      "                     np.float64(0.8547416313269838),\n",
      "                     np.float64(0.8654662970668173),\n",
      "                     np.float64(0.8675596840785644),\n",
      "                     np.float64(0.8599353195214847),\n",
      "                     np.float64(0.8661832295319005),\n",
      "                     np.float64(0.8691262421361776)],\n",
      "                    [np.float64(0.7945980958799932),\n",
      "                     np.float64(0.8157541416425554),\n",
      "                     np.float64(0.8082395802028189),\n",
      "                     np.float64(0.825812835931223),\n",
      "                     np.float64(0.8333800982040864),\n",
      "                     np.float64(0.8244400288595369),\n",
      "                     np.float64(0.8343731487087562),\n",
      "                     np.float64(0.8462584023371229),\n",
      "                     np.float64(0.8495791586496807),\n",
      "                     np.float64(0.8471549314936118),\n",
      "                     np.float64(0.8483281738010298),\n",
      "                     np.float64(0.8452638763057628),\n",
      "                     np.float64(0.8396413877063796),\n",
      "                     np.float64(0.8600123020882654),\n",
      "                     np.float64(0.8578175491410471),\n",
      "                     np.float64(0.8506002090939069),\n",
      "                     np.float64(0.8501569934649204),\n",
      "                     np.float64(0.8239542194992674),\n",
      "                     np.float64(0.8438755608272214),\n",
      "                     np.float64(0.8569408592244459)]]}\n",
      "Training Model: GRU, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7114 - loss: 0.4860\n",
      "Epoch 1 - MCC: 0.7763\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.7130 - loss: 0.4842 - val_accuracy: 0.8879 - val_loss: 0.2745 - mcc: 0.7763\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8972 - loss: 0.2530\n",
      "Epoch 2 - MCC: 0.8274\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 23ms/step - accuracy: 0.8973 - loss: 0.2529 - val_accuracy: 0.9139 - val_loss: 0.2114 - mcc: 0.8274\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9149 - loss: 0.2064\n",
      "Epoch 3 - MCC: 0.8413\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9149 - loss: 0.2063 - val_accuracy: 0.9208 - val_loss: 0.1913 - mcc: 0.8413\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9191 - loss: 0.1933\n",
      "Epoch 4 - MCC: 0.8462\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9191 - loss: 0.1932 - val_accuracy: 0.9232 - val_loss: 0.1854 - mcc: 0.8462\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9233 - loss: 0.1829\n",
      "Epoch 5 - MCC: 0.8520\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 22ms/step - accuracy: 0.9233 - loss: 0.1829 - val_accuracy: 0.9261 - val_loss: 0.1772 - mcc: 0.8520\n",
      "Epoch 6/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9265 - loss: 0.1752\n",
      "Epoch 6 - MCC: 0.8528\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9265 - loss: 0.1752 - val_accuracy: 0.9266 - val_loss: 0.1756 - mcc: 0.8528\n",
      "Epoch 7/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9278 - loss: 0.1717\n",
      "Epoch 7 - MCC: 0.8517\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9278 - loss: 0.1717 - val_accuracy: 0.9260 - val_loss: 0.1734 - mcc: 0.8517\n",
      "Epoch 8/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9302 - loss: 0.1669\n",
      "Epoch 8 - MCC: 0.8529\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9302 - loss: 0.1669 - val_accuracy: 0.9266 - val_loss: 0.1734 - mcc: 0.8529\n",
      "Epoch 9/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9289 - loss: 0.1695\n",
      "Epoch 9 - MCC: 0.8599\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9289 - loss: 0.1695 - val_accuracy: 0.9301 - val_loss: 0.1673 - mcc: 0.8599\n",
      "Epoch 10/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9303 - loss: 0.1665\n",
      "Epoch 10 - MCC: 0.8600\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9303 - loss: 0.1665 - val_accuracy: 0.9302 - val_loss: 0.1662 - mcc: 0.8600\n",
      "Epoch 11/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9282 - loss: 0.1704\n",
      "Epoch 11 - MCC: 0.8621\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 22ms/step - accuracy: 0.9283 - loss: 0.1703 - val_accuracy: 0.9312 - val_loss: 0.1637 - mcc: 0.8621\n",
      "Epoch 12/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9313 - loss: 0.1656\n",
      "Epoch 12 - MCC: 0.8616\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9314 - loss: 0.1655 - val_accuracy: 0.9310 - val_loss: 0.1633 - mcc: 0.8616\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9334 - loss: 0.1583\n",
      "Epoch 13 - MCC: 0.8640\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9334 - loss: 0.1583 - val_accuracy: 0.9321 - val_loss: 0.1602 - mcc: 0.8640\n",
      "Epoch 14/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9337 - loss: 0.1590\n",
      "Epoch 14 - MCC: 0.8647\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9337 - loss: 0.1590 - val_accuracy: 0.9325 - val_loss: 0.1596 - mcc: 0.8647\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9326 - loss: 0.1595\n",
      "Epoch 15 - MCC: 0.8654\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9326 - loss: 0.1595 - val_accuracy: 0.9329 - val_loss: 0.1585 - mcc: 0.8654\n",
      "Epoch 16/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9354 - loss: 0.1539\n",
      "Epoch 16 - MCC: 0.8674\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 22ms/step - accuracy: 0.9354 - loss: 0.1540 - val_accuracy: 0.9339 - val_loss: 0.1570 - mcc: 0.8674\n",
      "Epoch 17/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9356 - loss: 0.1522\n",
      "Epoch 17 - MCC: 0.8724\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9356 - loss: 0.1522 - val_accuracy: 0.9362 - val_loss: 0.1545 - mcc: 0.8724\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9352 - loss: 0.1553\n",
      "Epoch 18 - MCC: 0.8744\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.9353 - loss: 0.1553 - val_accuracy: 0.9373 - val_loss: 0.1500 - mcc: 0.8744\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9384 - loss: 0.1488\n",
      "Epoch 19 - MCC: 0.8745\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 22ms/step - accuracy: 0.9384 - loss: 0.1488 - val_accuracy: 0.9374 - val_loss: 0.1512 - mcc: 0.8745\n",
      "Epoch 20/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9374 - loss: 0.1500\n",
      "Epoch 20 - MCC: 0.8758\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9374 - loss: 0.1499 - val_accuracy: 0.9377 - val_loss: 0.1526 - mcc: 0.8758\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.7247 - loss: 0.5138\n",
      "Epoch 1 - MCC: 0.7813\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 25ms/step - accuracy: 0.7261 - loss: 0.5118 - val_accuracy: 0.8910 - val_loss: 0.2669 - mcc: 0.7813\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8974 - loss: 0.2555\n",
      "Epoch 2 - MCC: 0.8176\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8975 - loss: 0.2555 - val_accuracy: 0.9090 - val_loss: 0.2256 - mcc: 0.8176\n",
      "Epoch 3/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9096 - loss: 0.2199\n",
      "Epoch 3 - MCC: 0.8393\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9096 - loss: 0.2198 - val_accuracy: 0.9198 - val_loss: 0.1938 - mcc: 0.8393\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9183 - loss: 0.1947\n",
      "Epoch 4 - MCC: 0.8482\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 24ms/step - accuracy: 0.9183 - loss: 0.1946 - val_accuracy: 0.9243 - val_loss: 0.1839 - mcc: 0.8482\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9231 - loss: 0.1827\n",
      "Epoch 5 - MCC: 0.8505\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9231 - loss: 0.1827 - val_accuracy: 0.9254 - val_loss: 0.1785 - mcc: 0.8505\n",
      "Epoch 6/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9255 - loss: 0.1775\n",
      "Epoch 6 - MCC: 0.8556\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9254 - loss: 0.1776 - val_accuracy: 0.9280 - val_loss: 0.1738 - mcc: 0.8556\n",
      "Epoch 7/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9259 - loss: 0.1769\n",
      "Epoch 7 - MCC: 0.8569\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9259 - loss: 0.1769 - val_accuracy: 0.9286 - val_loss: 0.1716 - mcc: 0.8569\n",
      "Epoch 8/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9275 - loss: 0.1742\n",
      "Epoch 8 - MCC: 0.8601\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9275 - loss: 0.1741 - val_accuracy: 0.9303 - val_loss: 0.1675 - mcc: 0.8601\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9286 - loss: 0.1702\n",
      "Epoch 9 - MCC: 0.8566\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 21ms/step - accuracy: 0.9286 - loss: 0.1702 - val_accuracy: 0.9285 - val_loss: 0.1696 - mcc: 0.8566\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9307 - loss: 0.1663\n",
      "Epoch 10 - MCC: 0.8601\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9307 - loss: 0.1663 - val_accuracy: 0.9302 - val_loss: 0.1662 - mcc: 0.8601\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9327 - loss: 0.1607\n",
      "Epoch 11 - MCC: 0.8649\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9327 - loss: 0.1608 - val_accuracy: 0.9326 - val_loss: 0.1612 - mcc: 0.8649\n",
      "Epoch 12/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9317 - loss: 0.1633\n",
      "Epoch 12 - MCC: 0.8662\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9317 - loss: 0.1633 - val_accuracy: 0.9333 - val_loss: 0.1596 - mcc: 0.8662\n",
      "Epoch 13/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9335 - loss: 0.1595\n",
      "Epoch 13 - MCC: 0.8609\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9335 - loss: 0.1595 - val_accuracy: 0.9305 - val_loss: 0.1640 - mcc: 0.8609\n",
      "Epoch 14/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9336 - loss: 0.1591\n",
      "Epoch 14 - MCC: 0.8674\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9336 - loss: 0.1591 - val_accuracy: 0.9339 - val_loss: 0.1578 - mcc: 0.8674\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9332 - loss: 0.1592\n",
      "Epoch 15 - MCC: 0.8714\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9332 - loss: 0.1592 - val_accuracy: 0.9358 - val_loss: 0.1546 - mcc: 0.8714\n",
      "Epoch 16/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9348 - loss: 0.1550\n",
      "Epoch 16 - MCC: 0.8720\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 22ms/step - accuracy: 0.9348 - loss: 0.1551 - val_accuracy: 0.9361 - val_loss: 0.1533 - mcc: 0.8720\n",
      "Epoch 17/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9354 - loss: 0.1549\n",
      "Epoch 17 - MCC: 0.8716\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9354 - loss: 0.1549 - val_accuracy: 0.9360 - val_loss: 0.1529 - mcc: 0.8716\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9385 - loss: 0.1475\n",
      "Epoch 18 - MCC: 0.8728\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9384 - loss: 0.1475 - val_accuracy: 0.9366 - val_loss: 0.1504 - mcc: 0.8728\n",
      "Epoch 19/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9364 - loss: 0.1528\n",
      "Epoch 19 - MCC: 0.8672\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9364 - loss: 0.1528 - val_accuracy: 0.9337 - val_loss: 0.1562 - mcc: 0.8672\n",
      "Epoch 20/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9384 - loss: 0.1484\n",
      "Epoch 20 - MCC: 0.8775\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9384 - loss: 0.1484 - val_accuracy: 0.9388 - val_loss: 0.1473 - mcc: 0.8775\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6511 - loss: 0.5504\n",
      "Epoch 1 - MCC: 0.7845\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 23ms/step - accuracy: 0.6526 - loss: 0.5488 - val_accuracy: 0.8924 - val_loss: 0.2693 - mcc: 0.7845\n",
      "Epoch 2/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8952 - loss: 0.2589\n",
      "Epoch 2 - MCC: 0.8130\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.8953 - loss: 0.2586 - val_accuracy: 0.9068 - val_loss: 0.2255 - mcc: 0.8130\n",
      "Epoch 3/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9128 - loss: 0.2126\n",
      "Epoch 3 - MCC: 0.8334\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9128 - loss: 0.2125 - val_accuracy: 0.9170 - val_loss: 0.1993 - mcc: 0.8334\n",
      "Epoch 4/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9174 - loss: 0.1973\n",
      "Epoch 4 - MCC: 0.8396\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 21ms/step - accuracy: 0.9174 - loss: 0.1972 - val_accuracy: 0.9200 - val_loss: 0.1921 - mcc: 0.8396\n",
      "Epoch 5/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9226 - loss: 0.1850\n",
      "Epoch 5 - MCC: 0.8436\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9226 - loss: 0.1850 - val_accuracy: 0.9221 - val_loss: 0.1857 - mcc: 0.8436\n",
      "Epoch 6/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9258 - loss: 0.1775\n",
      "Epoch 6 - MCC: 0.8488\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.9258 - loss: 0.1775 - val_accuracy: 0.9247 - val_loss: 0.1806 - mcc: 0.8488\n",
      "Epoch 7/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9243 - loss: 0.1810\n",
      "Epoch 7 - MCC: 0.8465\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9243 - loss: 0.1810 - val_accuracy: 0.9235 - val_loss: 0.1815 - mcc: 0.8465\n",
      "Epoch 8/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9274 - loss: 0.1745\n",
      "Epoch 8 - MCC: 0.8513\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.9274 - loss: 0.1745 - val_accuracy: 0.9258 - val_loss: 0.1774 - mcc: 0.8513\n",
      "Epoch 9/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9285 - loss: 0.1707\n",
      "Epoch 9 - MCC: 0.8545\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9285 - loss: 0.1707 - val_accuracy: 0.9274 - val_loss: 0.1740 - mcc: 0.8545\n",
      "Epoch 10/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9300 - loss: 0.1662\n",
      "Epoch 10 - MCC: 0.8583\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9300 - loss: 0.1662 - val_accuracy: 0.9293 - val_loss: 0.1700 - mcc: 0.8583\n",
      "Epoch 11/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9309 - loss: 0.1655\n",
      "Epoch 11 - MCC: 0.8586\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9309 - loss: 0.1655 - val_accuracy: 0.9293 - val_loss: 0.1707 - mcc: 0.8586\n",
      "Epoch 12/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9298 - loss: 0.1665\n",
      "Epoch 12 - MCC: 0.8612\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9299 - loss: 0.1665 - val_accuracy: 0.9306 - val_loss: 0.1666 - mcc: 0.8612\n",
      "Epoch 13/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9325 - loss: 0.1610\n",
      "Epoch 13 - MCC: 0.8625\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9325 - loss: 0.1609 - val_accuracy: 0.9314 - val_loss: 0.1667 - mcc: 0.8625\n",
      "Epoch 14/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9343 - loss: 0.1567\n",
      "Epoch 14 - MCC: 0.8641\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9343 - loss: 0.1568 - val_accuracy: 0.9322 - val_loss: 0.1629 - mcc: 0.8641\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9338 - loss: 0.1584\n",
      "Epoch 15 - MCC: 0.8678\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9338 - loss: 0.1584 - val_accuracy: 0.9341 - val_loss: 0.1580 - mcc: 0.8678\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9361 - loss: 0.1545\n",
      "Epoch 16 - MCC: 0.8691\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 24ms/step - accuracy: 0.9361 - loss: 0.1545 - val_accuracy: 0.9347 - val_loss: 0.1571 - mcc: 0.8691\n",
      "Epoch 17/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9372 - loss: 0.1513\n",
      "Epoch 17 - MCC: 0.8713\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9372 - loss: 0.1513 - val_accuracy: 0.9358 - val_loss: 0.1545 - mcc: 0.8713\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9380 - loss: 0.1481\n",
      "Epoch 18 - MCC: 0.8721\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9380 - loss: 0.1481 - val_accuracy: 0.9363 - val_loss: 0.1537 - mcc: 0.8721\n",
      "Epoch 19/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9391 - loss: 0.1463\n",
      "Epoch 19 - MCC: 0.8718\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9391 - loss: 0.1463 - val_accuracy: 0.9361 - val_loss: 0.1557 - mcc: 0.8718\n",
      "Epoch 20/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9377 - loss: 0.1500\n",
      "Epoch 20 - MCC: 0.8724\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9377 - loss: 0.1499 - val_accuracy: 0.9364 - val_loss: 0.1527 - mcc: 0.8724\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.7265 - loss: 0.4957\n",
      "Epoch 1 - MCC: 0.7920\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 27ms/step - accuracy: 0.7275 - loss: 0.4944 - val_accuracy: 0.8963 - val_loss: 0.2569 - mcc: 0.7920\n",
      "Epoch 2/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8996 - loss: 0.2481\n",
      "Epoch 2 - MCC: 0.8265\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.8996 - loss: 0.2478 - val_accuracy: 0.9135 - val_loss: 0.2086 - mcc: 0.8265\n",
      "Epoch 3/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9118 - loss: 0.2117\n",
      "Epoch 3 - MCC: 0.8343\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.9119 - loss: 0.2116 - val_accuracy: 0.9173 - val_loss: 0.1976 - mcc: 0.8343\n",
      "Epoch 4/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9182 - loss: 0.1952\n",
      "Epoch 4 - MCC: 0.8435\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9182 - loss: 0.1952 - val_accuracy: 0.9219 - val_loss: 0.1857 - mcc: 0.8435\n",
      "Epoch 5/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9187 - loss: 0.1934\n",
      "Epoch 5 - MCC: 0.8443\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9188 - loss: 0.1932 - val_accuracy: 0.9223 - val_loss: 0.1828 - mcc: 0.8443\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9243 - loss: 0.1810\n",
      "Epoch 6 - MCC: 0.8475\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9243 - loss: 0.1810 - val_accuracy: 0.9238 - val_loss: 0.1806 - mcc: 0.8475\n",
      "Epoch 7/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9253 - loss: 0.1797\n",
      "Epoch 7 - MCC: 0.8511\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 24ms/step - accuracy: 0.9253 - loss: 0.1797 - val_accuracy: 0.9257 - val_loss: 0.1753 - mcc: 0.8511\n",
      "Epoch 8/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9263 - loss: 0.1760\n",
      "Epoch 8 - MCC: 0.8546\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9263 - loss: 0.1760 - val_accuracy: 0.9274 - val_loss: 0.1718 - mcc: 0.8546\n",
      "Epoch 9/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9268 - loss: 0.1748\n",
      "Epoch 9 - MCC: 0.8557\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9269 - loss: 0.1747 - val_accuracy: 0.9281 - val_loss: 0.1691 - mcc: 0.8557\n",
      "Epoch 10/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9291 - loss: 0.1696\n",
      "Epoch 10 - MCC: 0.8597\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9291 - loss: 0.1696 - val_accuracy: 0.9300 - val_loss: 0.1660 - mcc: 0.8597\n",
      "Epoch 11/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9300 - loss: 0.1668\n",
      "Epoch 11 - MCC: 0.8609\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9300 - loss: 0.1668 - val_accuracy: 0.9307 - val_loss: 0.1634 - mcc: 0.8609\n",
      "Epoch 12/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9306 - loss: 0.1646\n",
      "Epoch 12 - MCC: 0.8584\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9306 - loss: 0.1646 - val_accuracy: 0.9293 - val_loss: 0.1653 - mcc: 0.8584\n",
      "Epoch 13/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.9316 - loss: 0.1637\n",
      "Epoch 13 - MCC: 0.8640\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 39ms/step - accuracy: 0.9316 - loss: 0.1637 - val_accuracy: 0.9322 - val_loss: 0.1608 - mcc: 0.8640\n",
      "Epoch 14/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.9319 - loss: 0.1628\n",
      "Epoch 14 - MCC: 0.8637\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 27ms/step - accuracy: 0.9319 - loss: 0.1628 - val_accuracy: 0.9320 - val_loss: 0.1599 - mcc: 0.8637\n",
      "Epoch 15/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9331 - loss: 0.1612\n",
      "Epoch 15 - MCC: 0.8662\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.9331 - loss: 0.1612 - val_accuracy: 0.9332 - val_loss: 0.1574 - mcc: 0.8662\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9336 - loss: 0.1589\n",
      "Epoch 16 - MCC: 0.8675\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9336 - loss: 0.1589 - val_accuracy: 0.9339 - val_loss: 0.1565 - mcc: 0.8675\n",
      "Epoch 17/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9348 - loss: 0.1563\n",
      "Epoch 17 - MCC: 0.8683\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9348 - loss: 0.1563 - val_accuracy: 0.9343 - val_loss: 0.1555 - mcc: 0.8683\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9338 - loss: 0.1578\n",
      "Epoch 18 - MCC: 0.8703\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9338 - loss: 0.1578 - val_accuracy: 0.9353 - val_loss: 0.1527 - mcc: 0.8703\n",
      "Epoch 19/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9325 - loss: 0.1599\n",
      "Epoch 19 - MCC: 0.8701\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9325 - loss: 0.1598 - val_accuracy: 0.9352 - val_loss: 0.1542 - mcc: 0.8701\n",
      "Epoch 20/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9360 - loss: 0.1538\n",
      "Epoch 20 - MCC: 0.8738\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 21ms/step - accuracy: 0.9360 - loss: 0.1538 - val_accuracy: 0.9371 - val_loss: 0.1496 - mcc: 0.8738\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7242 - loss: 0.5030\n",
      "Epoch 1 - MCC: 0.7843\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.7263 - loss: 0.5004 - val_accuracy: 0.8926 - val_loss: 0.2672 - mcc: 0.7843\n",
      "Epoch 2/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8952 - loss: 0.2614\n",
      "Epoch 2 - MCC: 0.8096\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.8952 - loss: 0.2612 - val_accuracy: 0.9051 - val_loss: 0.2367 - mcc: 0.8096\n",
      "Epoch 3/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9080 - loss: 0.2269\n",
      "Epoch 3 - MCC: 0.8251\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9080 - loss: 0.2268 - val_accuracy: 0.9123 - val_loss: 0.2119 - mcc: 0.8251\n",
      "Epoch 4/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9136 - loss: 0.2076\n",
      "Epoch 4 - MCC: 0.8413\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9136 - loss: 0.2075 - val_accuracy: 0.9209 - val_loss: 0.1897 - mcc: 0.8413\n",
      "Epoch 5/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9196 - loss: 0.1921\n",
      "Epoch 5 - MCC: 0.8491\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9196 - loss: 0.1920 - val_accuracy: 0.9248 - val_loss: 0.1820 - mcc: 0.8491\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9237 - loss: 0.1828\n",
      "Epoch 6 - MCC: 0.8516\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.9237 - loss: 0.1828 - val_accuracy: 0.9261 - val_loss: 0.1779 - mcc: 0.8516\n",
      "Epoch 7/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9249 - loss: 0.1801\n",
      "Epoch 7 - MCC: 0.8541\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9250 - loss: 0.1801 - val_accuracy: 0.9272 - val_loss: 0.1746 - mcc: 0.8541\n",
      "Epoch 8/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9282 - loss: 0.1729\n",
      "Epoch 8 - MCC: 0.8581\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.9282 - loss: 0.1729 - val_accuracy: 0.9292 - val_loss: 0.1702 - mcc: 0.8581\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9283 - loss: 0.1711\n",
      "Epoch 9 - MCC: 0.8613\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.9283 - loss: 0.1711 - val_accuracy: 0.9308 - val_loss: 0.1663 - mcc: 0.8613\n",
      "Epoch 10/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9310 - loss: 0.1662\n",
      "Epoch 10 - MCC: 0.8620\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.9310 - loss: 0.1662 - val_accuracy: 0.9311 - val_loss: 0.1661 - mcc: 0.8620\n",
      "Epoch 11/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9328 - loss: 0.1614\n",
      "Epoch 11 - MCC: 0.8651\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9328 - loss: 0.1614 - val_accuracy: 0.9328 - val_loss: 0.1610 - mcc: 0.8651\n",
      "Epoch 12/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9332 - loss: 0.1596\n",
      "Epoch 12 - MCC: 0.8668\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 24ms/step - accuracy: 0.9332 - loss: 0.1596 - val_accuracy: 0.9336 - val_loss: 0.1591 - mcc: 0.8668\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9325 - loss: 0.1616\n",
      "Epoch 13 - MCC: 0.8670\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9325 - loss: 0.1615 - val_accuracy: 0.9335 - val_loss: 0.1597 - mcc: 0.8670\n",
      "Epoch 14/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9356 - loss: 0.1552\n",
      "Epoch 14 - MCC: 0.8659\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.9356 - loss: 0.1552 - val_accuracy: 0.9332 - val_loss: 0.1588 - mcc: 0.8659\n",
      "Epoch 15/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9341 - loss: 0.1554\n",
      "Epoch 15 - MCC: 0.8699\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 25ms/step - accuracy: 0.9341 - loss: 0.1554 - val_accuracy: 0.9351 - val_loss: 0.1545 - mcc: 0.8699\n",
      "Epoch 16/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9377 - loss: 0.1496\n",
      "Epoch 16 - MCC: 0.8722\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.9377 - loss: 0.1497 - val_accuracy: 0.9363 - val_loss: 0.1528 - mcc: 0.8722\n",
      "Epoch 17/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9364 - loss: 0.1519\n",
      "Epoch 17 - MCC: 0.8734\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.9364 - loss: 0.1519 - val_accuracy: 0.9368 - val_loss: 0.1521 - mcc: 0.8734\n",
      "Epoch 18/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9372 - loss: 0.1511\n",
      "Epoch 18 - MCC: 0.8730\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.9372 - loss: 0.1510 - val_accuracy: 0.9366 - val_loss: 0.1513 - mcc: 0.8730\n",
      "Epoch 19/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9352 - loss: 0.1534\n",
      "Epoch 19 - MCC: 0.8761\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.9352 - loss: 0.1534 - val_accuracy: 0.9382 - val_loss: 0.1486 - mcc: 0.8761\n",
      "Epoch 20/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9377 - loss: 0.1484\n",
      "Epoch 20 - MCC: 0.8763\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.9377 - loss: 0.1484 - val_accuracy: 0.9383 - val_loss: 0.1479 - mcc: 0.8763\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.9387706666666666),\n",
      "              'mean': np.float64(0.9376448),\n",
      "              'min': np.float64(0.9364213333333333),\n",
      "              'std': np.float64(0.0008429812071188446)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.0004906091690063477),\n",
      "                               'mean': np.float64(0.0004232266108194987),\n",
      "                               'min': np.float64(0.00033845074971516925),\n",
      "                               'std': np.float64(6.295481972890092e-05)},\n",
      " 'MCC': {'max': np.float64(0.87746126602697),\n",
      "         'mean': np.float64(0.8751665643444262),\n",
      "         'min': np.float64(0.8724406593284383),\n",
      "         'std': np.float64(0.0018130467662699678)},\n",
      " 'Parameters': 5144,\n",
      " 'Train Time (s)': {'max': np.float64(97.7631983757019),\n",
      "                    'mean': np.float64(92.20869069099426),\n",
      "                    'min': np.float64(87.75095534324646),\n",
      "                    'std': np.float64(3.4711571297977155)},\n",
      " 'Training Accuracy': [[0.8158388733863831,\n",
      "                        0.901970386505127,\n",
      "                        0.916898787021637,\n",
      "                        0.9214200973510742,\n",
      "                        0.9237655401229858,\n",
      "                        0.9260685443878174,\n",
      "                        0.9275485873222351,\n",
      "                        0.9286180138587952,\n",
      "                        0.9294117093086243,\n",
      "                        0.9305342435836792,\n",
      "                        0.930971622467041,\n",
      "                        0.9316989779472351,\n",
      "                        0.9324830770492554,\n",
      "                        0.9333851933479309,\n",
      "                        0.9341424107551575,\n",
      "                        0.9347028732299805,\n",
      "                        0.9360184669494629,\n",
      "                        0.9365251660346985,\n",
      "                        0.9371338486671448,\n",
      "                        0.9375973343849182],\n",
      "                       [0.8177817463874817,\n",
      "                        0.9001514315605164,\n",
      "                        0.9135304093360901,\n",
      "                        0.9193426370620728,\n",
      "                        0.9229244589805603,\n",
      "                        0.9251559376716614,\n",
      "                        0.9268048405647278,\n",
      "                        0.9279070496559143,\n",
      "                        0.9291253089904785,\n",
      "                        0.9305931925773621,\n",
      "                        0.9312536716461182,\n",
      "                        0.9317647218704224,\n",
      "                        0.9328435659408569,\n",
      "                        0.9333513379096985,\n",
      "                        0.9335498213768005,\n",
      "                        0.9349247217178345,\n",
      "                        0.9355120658874512,\n",
      "                        0.9360414743423462,\n",
      "                        0.9367112517356873,\n",
      "                        0.9372104406356812],\n",
      "                       [0.7883875966072083,\n",
      "                        0.9022559523582458,\n",
      "                        0.9150586724281311,\n",
      "                        0.9204201698303223,\n",
      "                        0.9225947260856628,\n",
      "                        0.9252512454986572,\n",
      "                        0.9266117215156555,\n",
      "                        0.9276815056800842,\n",
      "                        0.9288294315338135,\n",
      "                        0.9298603534698486,\n",
      "                        0.9305752515792847,\n",
      "                        0.9318954944610596,\n",
      "                        0.9327531456947327,\n",
      "                        0.9336645603179932,\n",
      "                        0.9351008534431458,\n",
      "                        0.9361411929130554,\n",
      "                        0.9371638298034668,\n",
      "                        0.937795102596283,\n",
      "                        0.9383792877197266,\n",
      "                        0.9389160871505737],\n",
      "                       [0.8239031434059143,\n",
      "                        0.9046208262443542,\n",
      "                        0.9146206974983215,\n",
      "                        0.9188051223754883,\n",
      "                        0.9220966100692749,\n",
      "                        0.9236688017845154,\n",
      "                        0.9256209135055542,\n",
      "                        0.9268150925636292,\n",
      "                        0.9276770949363708,\n",
      "                        0.9288873076438904,\n",
      "                        0.9297478795051575,\n",
      "                        0.9304524660110474,\n",
      "                        0.9308803677558899,\n",
      "                        0.9318944215774536,\n",
      "                        0.9324142932891846,\n",
      "                        0.9334793090820312,\n",
      "                        0.9343916177749634,\n",
      "                        0.935150146484375,\n",
      "                        0.9359620809555054,\n",
      "                        0.9366005659103394],\n",
      "                       [0.8216005563735962,\n",
      "                        0.8986899256706238,\n",
      "                        0.9098320603370667,\n",
      "                        0.9176941514015198,\n",
      "                        0.9209269881248474,\n",
      "                        0.9241692423820496,\n",
      "                        0.9260307550430298,\n",
      "                        0.9278265237808228,\n",
      "                        0.928904116153717,\n",
      "                        0.929929256439209,\n",
      "                        0.9318246841430664,\n",
      "                        0.9328970313072205,\n",
      "                        0.9333202838897705,\n",
      "                        0.9351794719696045,\n",
      "                        0.9355087280273438,\n",
      "                        0.9363306760787964,\n",
      "                        0.9367638230323792,\n",
      "                        0.9376357197761536,\n",
      "                        0.9376196265220642,\n",
      "                        0.9385632276535034]],\n",
      " 'Training Loss': [[0.375139981508255,\n",
      "                    0.24153965711593628,\n",
      "                    0.20058509707450867,\n",
      "                    0.187773659825325,\n",
      "                    0.1813592165708542,\n",
      "                    0.17579539120197296,\n",
      "                    0.1726665496826172,\n",
      "                    0.1702592372894287,\n",
      "                    0.16829894483089447,\n",
      "                    0.16542057693004608,\n",
      "                    0.16450077295303345,\n",
      "                    0.16379112005233765,\n",
      "                    0.1609300971031189,\n",
      "                    0.1592406928539276,\n",
      "                    0.1570505052804947,\n",
      "                    0.15571950376033783,\n",
      "                    0.1526760458946228,\n",
      "                    0.15176863968372345,\n",
      "                    0.14972823858261108,\n",
      "                    0.14895904064178467],\n",
      "                   [0.38798174262046814,\n",
      "                    0.24821533262729645,\n",
      "                    0.20968182384967804,\n",
      "                    0.19200319051742554,\n",
      "                    0.18352819979190826,\n",
      "                    0.17835380136966705,\n",
      "                    0.17490175366401672,\n",
      "                    0.17198577523231506,\n",
      "                    0.1691340208053589,\n",
      "                    0.1665387749671936,\n",
      "                    0.164840966463089,\n",
      "                    0.1638440489768982,\n",
      "                    0.16110029816627502,\n",
      "                    0.15974637866020203,\n",
      "                    0.15893866121768951,\n",
      "                    0.15594226121902466,\n",
      "                    0.15456140041351318,\n",
      "                    0.1528036743402481,\n",
      "                    0.1520204097032547,\n",
      "                    0.15079352259635925],\n",
      "                   [0.40464794635772705,\n",
      "                    0.2414371371269226,\n",
      "                    0.20516754686832428,\n",
      "                    0.19020794332027435,\n",
      "                    0.18456898629665375,\n",
      "                    0.17864398658275604,\n",
      "                    0.17540018260478973,\n",
      "                    0.17333795130252838,\n",
      "                    0.16982388496398926,\n",
      "                    0.1670723706483841,\n",
      "                    0.16570302844047546,\n",
      "                    0.1625232696533203,\n",
      "                    0.1604992002248764,\n",
      "                    0.1583608239889145,\n",
      "                    0.15536370873451233,\n",
      "                    0.1534581333398819,\n",
      "                    0.1507711261510849,\n",
      "                    0.1494159996509552,\n",
      "                    0.1479734629392624,\n",
      "                    0.14680005609989166],\n",
      "                   [0.37674564123153687,\n",
      "                    0.23311559855937958,\n",
      "                    0.2050720602273941,\n",
      "                    0.19395314157009125,\n",
      "                    0.1859101951122284,\n",
      "                    0.18184354901313782,\n",
      "                    0.17798079550266266,\n",
      "                    0.17487892508506775,\n",
      "                    0.17260023951530457,\n",
      "                    0.17020155489444733,\n",
      "                    0.16809572279453278,\n",
      "                    0.16641077399253845,\n",
      "                    0.16503721475601196,\n",
      "                    0.16325117647647858,\n",
      "                    0.16168221831321716,\n",
      "                    0.15949571132659912,\n",
      "                    0.1567714512348175,\n",
      "                    0.1547754853963852,\n",
      "                    0.15310736000537872,\n",
      "                    0.1520475447177887],\n",
      "                   [0.3815804123878479,\n",
      "                    0.252481073141098,\n",
      "                    0.22000527381896973,\n",
      "                    0.1980903297662735,\n",
      "                    0.18935078382492065,\n",
      "                    0.18162457644939423,\n",
      "                    0.17720729112625122,\n",
      "                    0.17307838797569275,\n",
      "                    0.16976256668567657,\n",
      "                    0.16729995608329773,\n",
      "                    0.16284587979316711,\n",
      "                    0.16044196486473083,\n",
      "                    0.15889205038547516,\n",
      "                    0.1554168462753296,\n",
      "                    0.15442661941051483,\n",
      "                    0.15229931473731995,\n",
      "                    0.1513529121875763,\n",
      "                    0.1496557742357254,\n",
      "                    0.14886543154716492,\n",
      "                    0.1472047120332718]],\n",
      " 'Validation Accuracy': [[0.8879064917564392,\n",
      "                          0.9139493703842163,\n",
      "                          0.92083740234375,\n",
      "                          0.9232320189476013,\n",
      "                          0.9261412620544434,\n",
      "                          0.9265547394752502,\n",
      "                          0.9259519577026367,\n",
      "                          0.9266160726547241,\n",
      "                          0.9301040768623352,\n",
      "                          0.9301920533180237,\n",
      "                          0.9312372803688049,\n",
      "                          0.9309758543968201,\n",
      "                          0.932144045829773,\n",
      "                          0.932493269443512,\n",
      "                          0.932856023311615,\n",
      "                          0.9338693022727966,\n",
      "                          0.9362267851829529,\n",
      "                          0.9373440742492676,\n",
      "                          0.9373975396156311,\n",
      "                          0.9376720190048218],\n",
      "                         [0.8909574151039124,\n",
      "                          0.9090158939361572,\n",
      "                          0.9198107123374939,\n",
      "                          0.9243066310882568,\n",
      "                          0.925437331199646,\n",
      "                          0.9279787540435791,\n",
      "                          0.9286293983459473,\n",
      "                          0.9302773475646973,\n",
      "                          0.9285119771957397,\n",
      "                          0.9302213788032532,\n",
      "                          0.9325547814369202,\n",
      "                          0.9332613945007324,\n",
      "                          0.9305332899093628,\n",
      "                          0.9338960647583008,\n",
      "                          0.9357892870903015,\n",
      "                          0.9361094832420349,\n",
      "                          0.9359679222106934,\n",
      "                          0.9366054534912109,\n",
      "                          0.93367999792099,\n",
      "                          0.9387706518173218],\n",
      "                         [0.8924319744110107,\n",
      "                          0.9067679047584534,\n",
      "                          0.9170079827308655,\n",
      "                          0.9199627041816711,\n",
      "                          0.9220587611198425,\n",
      "                          0.9246693253517151,\n",
      "                          0.9234797954559326,\n",
      "                          0.9257839918136597,\n",
      "                          0.9274320602416992,\n",
      "                          0.9293226599693298,\n",
      "                          0.9293466806411743,\n",
      "                          0.9306479692459106,\n",
      "                          0.9313546419143677,\n",
      "                          0.9321547746658325,\n",
      "                          0.9341278672218323,\n",
      "                          0.9346665740013123,\n",
      "                          0.9357627034187317,\n",
      "                          0.9362934827804565,\n",
      "                          0.9361255168914795,\n",
      "                          0.9364213943481445],\n",
      "                         [0.8963227272033691,\n",
      "                          0.9134878516197205,\n",
      "                          0.917269229888916,\n",
      "                          0.9219415783882141,\n",
      "                          0.922309398651123,\n",
      "                          0.9238026738166809,\n",
      "                          0.925738513469696,\n",
      "                          0.927365243434906,\n",
      "                          0.9280667304992676,\n",
      "                          0.930031955242157,\n",
      "                          0.9306507706642151,\n",
      "                          0.9292746782302856,\n",
      "                          0.9321680665016174,\n",
      "                          0.931994616985321,\n",
      "                          0.9331733584403992,\n",
      "                          0.9338802695274353,\n",
      "                          0.9343174695968628,\n",
      "                          0.9352931976318359,\n",
      "                          0.9351521730422974,\n",
      "                          0.9370534420013428],\n",
      "                         [0.8925707936286926,\n",
      "                          0.905072033405304,\n",
      "                          0.9122826457023621,\n",
      "                          0.9208533763885498,\n",
      "                          0.9247705340385437,\n",
      "                          0.9260721206665039,\n",
      "                          0.9272239804267883,\n",
      "                          0.9292001128196716,\n",
      "                          0.9308133125305176,\n",
      "                          0.9311144948005676,\n",
      "                          0.932802677154541,\n",
      "                          0.9335998296737671,\n",
      "                          0.9335306286811829,\n",
      "                          0.9331600666046143,\n",
      "                          0.9351227879524231,\n",
      "                          0.9363147616386414,\n",
      "                          0.9368106126785278,\n",
      "                          0.9366185069084167,\n",
      "                          0.9381654262542725,\n",
      "                          0.9383066296577454]],\n",
      " 'Validation Loss': [0.26716917753219604,\n",
      "                     0.2366654872894287,\n",
      "                     0.21194280683994293,\n",
      "                     0.18967990577220917,\n",
      "                     0.1820119172334671,\n",
      "                     0.17787332832813263,\n",
      "                     0.17456166446208954,\n",
      "                     0.17022766172885895,\n",
      "                     0.16631394624710083,\n",
      "                     0.16613489389419556,\n",
      "                     0.16099587082862854,\n",
      "                     0.15908528864383698,\n",
      "                     0.15967386960983276,\n",
      "                     0.1588212549686432,\n",
      "                     0.15445037186145782,\n",
      "                     0.15284951031208038,\n",
      "                     0.15205584466457367,\n",
      "                     0.15125678479671478,\n",
      "                     0.1485525369644165,\n",
      "                     0.1478825956583023],\n",
      " 'Validation MCC': [[np.float64(0.7762940013981869),\n",
      "                     np.float64(0.8274109988210274),\n",
      "                     np.float64(0.8412554131927298),\n",
      "                     np.float64(0.846160006680545),\n",
      "                     np.float64(0.8519541689453192),\n",
      "                     np.float64(0.8527520940640514),\n",
      "                     np.float64(0.8517248683840555),\n",
      "                     np.float64(0.8528820281119128),\n",
      "                     np.float64(0.8599330995430282),\n",
      "                     np.float64(0.860019558443374),\n",
      "                     np.float64(0.8621029251028697),\n",
      "                     np.float64(0.861573858662707),\n",
      "                     np.float64(0.8639694834761045),\n",
      "                     np.float64(0.8647147442581374),\n",
      "                     np.float64(0.8653669285205988),\n",
      "                     np.float64(0.8674487886338738),\n",
      "                     np.float64(0.8723966434215866),\n",
      "                     np.float64(0.8743830180770942),\n",
      "                     np.float64(0.8745078049959937),\n",
      "                     np.float64(0.8758096095490152)],\n",
      "                    [np.float64(0.781271663690311),\n",
      "                     np.float64(0.8175687744177605),\n",
      "                     np.float64(0.8393104415453592),\n",
      "                     np.float64(0.848212616589144),\n",
      "                     np.float64(0.8504568726617207),\n",
      "                     np.float64(0.8555787119571733),\n",
      "                     np.float64(0.8568781349515406),\n",
      "                     np.float64(0.8601486524596104),\n",
      "                     np.float64(0.8566490688671212),\n",
      "                     np.float64(0.8601476957325613),\n",
      "                     np.float64(0.8648637194790282),\n",
      "                     np.float64(0.8661750871588793),\n",
      "                     np.float64(0.8609103459648274),\n",
      "                     np.float64(0.8674275929522355),\n",
      "                     np.float64(0.8713963125592744),\n",
      "                     np.float64(0.872035940437093),\n",
      "                     np.float64(0.8716228585943246),\n",
      "                     np.float64(0.8728393397471573),\n",
      "                     np.float64(0.8671723353222808),\n",
      "                     np.float64(0.87746126602697)],\n",
      "                    [np.float64(0.7845162423577805),\n",
      "                     np.float64(0.81296841971468),\n",
      "                     np.float64(0.8334391101025312),\n",
      "                     np.float64(0.8396021175230942),\n",
      "                     np.float64(0.8435551150497317),\n",
      "                     np.float64(0.8487902330844841),\n",
      "                     np.float64(0.8465064192464387),\n",
      "                     np.float64(0.851346350899333),\n",
      "                     np.float64(0.8545046440047427),\n",
      "                     np.float64(0.8582697806056422),\n",
      "                     np.float64(0.8586279436765696),\n",
      "                     np.float64(0.861174870006747),\n",
      "                     np.float64(0.862495523542984),\n",
      "                     np.float64(0.8640649349999461),\n",
      "                     np.float64(0.8678012384190305),\n",
      "                     np.float64(0.8691392645348006),\n",
      "                     np.float64(0.8712596131873198),\n",
      "                     np.float64(0.872128151601531),\n",
      "                     np.float64(0.8718332276244093),\n",
      "                     np.float64(0.8724406593284383)],\n",
      "                    [np.float64(0.7920145742614064),\n",
      "                     np.float64(0.826549752177502),\n",
      "                     np.float64(0.8343155889540597),\n",
      "                     np.float64(0.8435150855347436),\n",
      "                     np.float64(0.844344308857594),\n",
      "                     np.float64(0.8474648307553789),\n",
      "                     np.float64(0.8511327775472068),\n",
      "                     np.float64(0.8545834984015208),\n",
      "                     np.float64(0.855741068497809),\n",
      "                     np.float64(0.8596584527239987),\n",
      "                     np.float64(0.8609217384986426),\n",
      "                     np.float64(0.8583864380225085),\n",
      "                     np.float64(0.8640489118548655),\n",
      "                     np.float64(0.86366418029165),\n",
      "                     np.float64(0.8662129552996652),\n",
      "                     np.float64(0.8674563525675681),\n",
      "                     np.float64(0.8682854025672718),\n",
      "                     np.float64(0.8702670327936008),\n",
      "                     np.float64(0.8701339444258799),\n",
      "                     np.float64(0.8737754326691263)],\n",
      "                    [np.float64(0.784349147503648),\n",
      "                     np.float64(0.8096176775006393),\n",
      "                     np.float64(0.8251406369580429),\n",
      "                     np.float64(0.8412848470859355),\n",
      "                     np.float64(0.849103893404036),\n",
      "                     np.float64(0.8516432042165618),\n",
      "                     np.float64(0.8541436245672169),\n",
      "                     np.float64(0.8580832699537458),\n",
      "                     np.float64(0.8612571969662782),\n",
      "                     np.float64(0.8620436241203033),\n",
      "                     np.float64(0.8651380003187343),\n",
      "                     np.float64(0.8668171307868329),\n",
      "                     np.float64(0.8669612444159284),\n",
      "                     np.float64(0.86589549138786),\n",
      "                     np.float64(0.8698680973604731),\n",
      "                     np.float64(0.8722305516727306),\n",
      "                     np.float64(0.8733607504250619),\n",
      "                     np.float64(0.8729636849623168),\n",
      "                     np.float64(0.876126508431183),\n",
      "                     np.float64(0.8763458541485815)]]}\n",
      "Training Model: TCN, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.7446 - loss: 0.4775\n",
      "Epoch 1 - MCC: 0.8315\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 48ms/step - accuracy: 0.7452 - loss: 0.4767 - val_accuracy: 0.9155 - val_loss: 0.2033 - mcc: 0.8315\n",
      "Epoch 2/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9162 - loss: 0.1992\n",
      "Epoch 2 - MCC: 0.8511\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 7ms/step - accuracy: 0.9163 - loss: 0.1992 - val_accuracy: 0.9257 - val_loss: 0.1786 - mcc: 0.8511\n",
      "Epoch 3/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9250 - loss: 0.1789\n",
      "Epoch 3 - MCC: 0.8524\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9250 - loss: 0.1788 - val_accuracy: 0.9262 - val_loss: 0.1757 - mcc: 0.8524\n",
      "Epoch 4/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9301 - loss: 0.1667\n",
      "Epoch 4 - MCC: 0.8652\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9301 - loss: 0.1667 - val_accuracy: 0.9328 - val_loss: 0.1616 - mcc: 0.8652\n",
      "Epoch 5/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9300 - loss: 0.1665\n",
      "Epoch 5 - MCC: 0.8680\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9301 - loss: 0.1664 - val_accuracy: 0.9341 - val_loss: 0.1585 - mcc: 0.8680\n",
      "Epoch 6/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9339 - loss: 0.1576\n",
      "Epoch 6 - MCC: 0.8682\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9339 - loss: 0.1576 - val_accuracy: 0.9342 - val_loss: 0.1575 - mcc: 0.8682\n",
      "Epoch 7/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9343 - loss: 0.1565\n",
      "Epoch 7 - MCC: 0.8721\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9343 - loss: 0.1565 - val_accuracy: 0.9362 - val_loss: 0.1541 - mcc: 0.8721\n",
      "Epoch 8/20\n",
      "\u001B[1m175/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9342 - loss: 0.1578\n",
      "Epoch 8 - MCC: 0.8728\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9343 - loss: 0.1576 - val_accuracy: 0.9364 - val_loss: 0.1534 - mcc: 0.8728\n",
      "Epoch 9/20\n",
      "\u001B[1m176/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9357 - loss: 0.1532\n",
      "Epoch 9 - MCC: 0.8757\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9358 - loss: 0.1531 - val_accuracy: 0.9380 - val_loss: 0.1499 - mcc: 0.8757\n",
      "Epoch 10/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9359 - loss: 0.1523\n",
      "Epoch 10 - MCC: 0.8761\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9359 - loss: 0.1522 - val_accuracy: 0.9382 - val_loss: 0.1486 - mcc: 0.8761\n",
      "Epoch 11/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9384 - loss: 0.1470\n",
      "Epoch 11 - MCC: 0.8776\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.9384 - loss: 0.1471 - val_accuracy: 0.9390 - val_loss: 0.1469 - mcc: 0.8776\n",
      "Epoch 12/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9386 - loss: 0.1479\n",
      "Epoch 12 - MCC: 0.8709\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.9386 - loss: 0.1479 - val_accuracy: 0.9356 - val_loss: 0.1534 - mcc: 0.8709\n",
      "Epoch 13/20\n",
      "\u001B[1m175/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9394 - loss: 0.1449\n",
      "Epoch 13 - MCC: 0.8801\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.9393 - loss: 0.1450 - val_accuracy: 0.9400 - val_loss: 0.1454 - mcc: 0.8801\n",
      "Epoch 14/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9375 - loss: 0.1493\n",
      "Epoch 14 - MCC: 0.8801\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9376 - loss: 0.1491 - val_accuracy: 0.9402 - val_loss: 0.1437 - mcc: 0.8801\n",
      "Epoch 15/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9411 - loss: 0.1427\n",
      "Epoch 15 - MCC: 0.8802\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9410 - loss: 0.1428 - val_accuracy: 0.9402 - val_loss: 0.1432 - mcc: 0.8802\n",
      "Epoch 16/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9418 - loss: 0.1404\n",
      "Epoch 16 - MCC: 0.8773\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9417 - loss: 0.1406 - val_accuracy: 0.9388 - val_loss: 0.1470 - mcc: 0.8773\n",
      "Epoch 17/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9405 - loss: 0.1418\n",
      "Epoch 17 - MCC: 0.8795\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9405 - loss: 0.1419 - val_accuracy: 0.9399 - val_loss: 0.1452 - mcc: 0.8795\n",
      "Epoch 18/20\n",
      "\u001B[1m176/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9401 - loss: 0.1438\n",
      "Epoch 18 - MCC: 0.8797\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9401 - loss: 0.1437 - val_accuracy: 0.9400 - val_loss: 0.1440 - mcc: 0.8797\n",
      "Epoch 19/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9415 - loss: 0.1394\n",
      "Epoch 19 - MCC: 0.8831\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9414 - loss: 0.1395 - val_accuracy: 0.9415 - val_loss: 0.1419 - mcc: 0.8831\n",
      "Epoch 20/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9415 - loss: 0.1407\n",
      "Epoch 20 - MCC: 0.8847\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.9415 - loss: 0.1407 - val_accuracy: 0.9424 - val_loss: 0.1396 - mcc: 0.8847\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: TCN, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6940 - loss: 0.6082\n",
      "Epoch 1 - MCC: 0.8225\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 37ms/step - accuracy: 0.6947 - loss: 0.6070 - val_accuracy: 0.9114 - val_loss: 0.2158 - mcc: 0.8225\n",
      "Epoch 2/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9121 - loss: 0.2118\n",
      "Epoch 2 - MCC: 0.8385\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.9123 - loss: 0.2114 - val_accuracy: 0.9192 - val_loss: 0.1924 - mcc: 0.8385\n",
      "Epoch 3/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9216 - loss: 0.1887\n",
      "Epoch 3 - MCC: 0.8539\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9216 - loss: 0.1886 - val_accuracy: 0.9272 - val_loss: 0.1749 - mcc: 0.8539\n",
      "Epoch 4/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9268 - loss: 0.1760\n",
      "Epoch 4 - MCC: 0.8625\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9268 - loss: 0.1760 - val_accuracy: 0.9313 - val_loss: 0.1659 - mcc: 0.8625\n",
      "Epoch 5/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9297 - loss: 0.1695\n",
      "Epoch 5 - MCC: 0.8648\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9296 - loss: 0.1695 - val_accuracy: 0.9326 - val_loss: 0.1624 - mcc: 0.8648\n",
      "Epoch 6/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9301 - loss: 0.1677\n",
      "Epoch 6 - MCC: 0.8661\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9302 - loss: 0.1675 - val_accuracy: 0.9332 - val_loss: 0.1593 - mcc: 0.8661\n",
      "Epoch 7/20\n",
      "\u001B[1m175/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9291 - loss: 0.1690\n",
      "Epoch 7 - MCC: 0.8713\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9294 - loss: 0.1684 - val_accuracy: 0.9357 - val_loss: 0.1535 - mcc: 0.8713\n",
      "Epoch 8/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9346 - loss: 0.1572\n",
      "Epoch 8 - MCC: 0.8682\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9346 - loss: 0.1572 - val_accuracy: 0.9341 - val_loss: 0.1559 - mcc: 0.8682\n",
      "Epoch 9/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9348 - loss: 0.1569\n",
      "Epoch 9 - MCC: 0.8748\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9349 - loss: 0.1568 - val_accuracy: 0.9375 - val_loss: 0.1493 - mcc: 0.8748\n",
      "Epoch 10/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9371 - loss: 0.1517\n",
      "Epoch 10 - MCC: 0.8760\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9371 - loss: 0.1518 - val_accuracy: 0.9380 - val_loss: 0.1488 - mcc: 0.8760\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9386 - loss: 0.1475\n",
      "Epoch 11 - MCC: 0.8788\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9386 - loss: 0.1475 - val_accuracy: 0.9396 - val_loss: 0.1449 - mcc: 0.8788\n",
      "Epoch 12/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9386 - loss: 0.1482\n",
      "Epoch 12 - MCC: 0.8807\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.9386 - loss: 0.1482 - val_accuracy: 0.9404 - val_loss: 0.1433 - mcc: 0.8807\n",
      "Epoch 13/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9381 - loss: 0.1487\n",
      "Epoch 13 - MCC: 0.8809\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.9381 - loss: 0.1485 - val_accuracy: 0.9406 - val_loss: 0.1423 - mcc: 0.8809\n",
      "Epoch 14/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9408 - loss: 0.1432\n",
      "Epoch 14 - MCC: 0.8814\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9407 - loss: 0.1433 - val_accuracy: 0.9409 - val_loss: 0.1416 - mcc: 0.8814\n",
      "Epoch 15/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9411 - loss: 0.1417\n",
      "Epoch 15 - MCC: 0.8812\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9410 - loss: 0.1418 - val_accuracy: 0.9402 - val_loss: 0.1444 - mcc: 0.8812\n",
      "Epoch 16/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9389 - loss: 0.1453\n",
      "Epoch 16 - MCC: 0.8823\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9390 - loss: 0.1453 - val_accuracy: 0.9412 - val_loss: 0.1412 - mcc: 0.8823\n",
      "Epoch 17/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9420 - loss: 0.1387\n",
      "Epoch 17 - MCC: 0.8841\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9420 - loss: 0.1388 - val_accuracy: 0.9421 - val_loss: 0.1394 - mcc: 0.8841\n",
      "Epoch 18/20\n",
      "\u001B[1m176/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9405 - loss: 0.1429\n",
      "Epoch 18 - MCC: 0.8846\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9406 - loss: 0.1429 - val_accuracy: 0.9424 - val_loss: 0.1373 - mcc: 0.8846\n",
      "Epoch 19/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9394 - loss: 0.1459\n",
      "Epoch 19 - MCC: 0.8848\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9396 - loss: 0.1457 - val_accuracy: 0.9423 - val_loss: 0.1390 - mcc: 0.8848\n",
      "Epoch 20/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9428 - loss: 0.1385\n",
      "Epoch 20 - MCC: 0.8834\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9428 - loss: 0.1385 - val_accuracy: 0.9416 - val_loss: 0.1408 - mcc: 0.8834\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: TCN, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7486 - loss: 0.4762\n",
      "Epoch 1 - MCC: 0.8093\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 43ms/step - accuracy: 0.7490 - loss: 0.4755 - val_accuracy: 0.9049 - val_loss: 0.2259 - mcc: 0.8093\n",
      "Epoch 2/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9091 - loss: 0.2158\n",
      "Epoch 2 - MCC: 0.8358\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.9093 - loss: 0.2155 - val_accuracy: 0.9178 - val_loss: 0.1956 - mcc: 0.8358\n",
      "Epoch 3/20\n",
      "\u001B[1m175/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9184 - loss: 0.1940\n",
      "Epoch 3 - MCC: 0.8438\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9188 - loss: 0.1933 - val_accuracy: 0.9221 - val_loss: 0.1856 - mcc: 0.8438\n",
      "Epoch 4/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9273 - loss: 0.1738\n",
      "Epoch 4 - MCC: 0.8572\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9273 - loss: 0.1738 - val_accuracy: 0.9288 - val_loss: 0.1712 - mcc: 0.8572\n",
      "Epoch 5/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9293 - loss: 0.1699\n",
      "Epoch 5 - MCC: 0.8596\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9293 - loss: 0.1698 - val_accuracy: 0.9300 - val_loss: 0.1679 - mcc: 0.8596\n",
      "Epoch 6/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9315 - loss: 0.1635\n",
      "Epoch 6 - MCC: 0.8588\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9315 - loss: 0.1635 - val_accuracy: 0.9296 - val_loss: 0.1683 - mcc: 0.8588\n",
      "Epoch 7/20\n",
      "\u001B[1m175/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9347 - loss: 0.1577\n",
      "Epoch 7 - MCC: 0.8628\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9346 - loss: 0.1578 - val_accuracy: 0.9313 - val_loss: 0.1636 - mcc: 0.8628\n",
      "Epoch 8/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9348 - loss: 0.1574\n",
      "Epoch 8 - MCC: 0.8662\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9348 - loss: 0.1572 - val_accuracy: 0.9328 - val_loss: 0.1617 - mcc: 0.8662\n",
      "Epoch 9/20\n",
      "\u001B[1m175/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9357 - loss: 0.1544\n",
      "Epoch 9 - MCC: 0.8634\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9357 - loss: 0.1543 - val_accuracy: 0.9319 - val_loss: 0.1627 - mcc: 0.8634\n",
      "Epoch 10/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9382 - loss: 0.1491\n",
      "Epoch 10 - MCC: 0.8716\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9382 - loss: 0.1492 - val_accuracy: 0.9359 - val_loss: 0.1538 - mcc: 0.8716\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9369 - loss: 0.1517\n",
      "Epoch 11 - MCC: 0.8688\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.9369 - loss: 0.1517 - val_accuracy: 0.9339 - val_loss: 0.1586 - mcc: 0.8688\n",
      "Epoch 12/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9386 - loss: 0.1479\n",
      "Epoch 12 - MCC: 0.8746\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.9386 - loss: 0.1479 - val_accuracy: 0.9375 - val_loss: 0.1509 - mcc: 0.8746\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9390 - loss: 0.1469\n",
      "Epoch 13 - MCC: 0.8745\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.9390 - loss: 0.1469 - val_accuracy: 0.9374 - val_loss: 0.1504 - mcc: 0.8745\n",
      "Epoch 14/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9392 - loss: 0.1467\n",
      "Epoch 14 - MCC: 0.8736\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9393 - loss: 0.1467 - val_accuracy: 0.9367 - val_loss: 0.1520 - mcc: 0.8736\n",
      "Epoch 15/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9431 - loss: 0.1382\n",
      "Epoch 15 - MCC: 0.8729\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9431 - loss: 0.1383 - val_accuracy: 0.9367 - val_loss: 0.1526 - mcc: 0.8729\n",
      "Epoch 16/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9407 - loss: 0.1419\n",
      "Epoch 16 - MCC: 0.8664\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9407 - loss: 0.1419 - val_accuracy: 0.9325 - val_loss: 0.1626 - mcc: 0.8664\n",
      "Epoch 17/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9405 - loss: 0.1434\n",
      "Epoch 17 - MCC: 0.8747\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9405 - loss: 0.1434 - val_accuracy: 0.9375 - val_loss: 0.1495 - mcc: 0.8747\n",
      "Epoch 18/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9406 - loss: 0.1425\n",
      "Epoch 18 - MCC: 0.8766\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9406 - loss: 0.1424 - val_accuracy: 0.9385 - val_loss: 0.1485 - mcc: 0.8766\n",
      "Epoch 19/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9405 - loss: 0.1425\n",
      "Epoch 19 - MCC: 0.8779\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9406 - loss: 0.1424 - val_accuracy: 0.9391 - val_loss: 0.1469 - mcc: 0.8779\n",
      "Epoch 20/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9398 - loss: 0.1441\n",
      "Epoch 20 - MCC: 0.8747\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.9398 - loss: 0.1440 - val_accuracy: 0.9369 - val_loss: 0.1524 - mcc: 0.8747\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: TCN, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6957 - loss: 0.7044\n",
      "Epoch 1 - MCC: 0.7984\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 45ms/step - accuracy: 0.6963 - loss: 0.7030 - val_accuracy: 0.8995 - val_loss: 0.2384 - mcc: 0.7984\n",
      "Epoch 2/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9045 - loss: 0.2275\n",
      "Epoch 2 - MCC: 0.8370\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 6ms/step - accuracy: 0.9047 - loss: 0.2270 - val_accuracy: 0.9187 - val_loss: 0.1952 - mcc: 0.8370\n",
      "Epoch 3/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9197 - loss: 0.1932\n",
      "Epoch 3 - MCC: 0.8508\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9197 - loss: 0.1932 - val_accuracy: 0.9256 - val_loss: 0.1787 - mcc: 0.8508\n",
      "Epoch 4/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9241 - loss: 0.1823\n",
      "Epoch 4 - MCC: 0.8551\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9242 - loss: 0.1822 - val_accuracy: 0.9271 - val_loss: 0.1752 - mcc: 0.8551\n",
      "Epoch 5/20\n",
      "\u001B[1m175/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9287 - loss: 0.1716\n",
      "Epoch 5 - MCC: 0.8642\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9287 - loss: 0.1715 - val_accuracy: 0.9323 - val_loss: 0.1621 - mcc: 0.8642\n",
      "Epoch 6/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9326 - loss: 0.1627\n",
      "Epoch 6 - MCC: 0.8681\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9326 - loss: 0.1627 - val_accuracy: 0.9339 - val_loss: 0.1595 - mcc: 0.8681\n",
      "Epoch 7/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9344 - loss: 0.1594\n",
      "Epoch 7 - MCC: 0.8722\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9344 - loss: 0.1594 - val_accuracy: 0.9363 - val_loss: 0.1540 - mcc: 0.8722\n",
      "Epoch 8/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9364 - loss: 0.1545\n",
      "Epoch 8 - MCC: 0.8732\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9364 - loss: 0.1546 - val_accuracy: 0.9368 - val_loss: 0.1530 - mcc: 0.8732\n",
      "Epoch 9/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9363 - loss: 0.1532\n",
      "Epoch 9 - MCC: 0.8740\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9363 - loss: 0.1532 - val_accuracy: 0.9368 - val_loss: 0.1535 - mcc: 0.8740\n",
      "Epoch 10/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9368 - loss: 0.1534\n",
      "Epoch 10 - MCC: 0.8762\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.9368 - loss: 0.1533 - val_accuracy: 0.9383 - val_loss: 0.1492 - mcc: 0.8762\n",
      "Epoch 11/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9353 - loss: 0.1565\n",
      "Epoch 11 - MCC: 0.8780\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.9354 - loss: 0.1564 - val_accuracy: 0.9391 - val_loss: 0.1472 - mcc: 0.8780\n",
      "Epoch 12/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9399 - loss: 0.1461\n",
      "Epoch 12 - MCC: 0.8804\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.9399 - loss: 0.1462 - val_accuracy: 0.9403 - val_loss: 0.1452 - mcc: 0.8804\n",
      "Epoch 13/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9393 - loss: 0.1469\n",
      "Epoch 13 - MCC: 0.8798\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9393 - loss: 0.1470 - val_accuracy: 0.9400 - val_loss: 0.1446 - mcc: 0.8798\n",
      "Epoch 14/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9401 - loss: 0.1458\n",
      "Epoch 14 - MCC: 0.8780\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9400 - loss: 0.1458 - val_accuracy: 0.9392 - val_loss: 0.1470 - mcc: 0.8780\n",
      "Epoch 15/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9407 - loss: 0.1438\n",
      "Epoch 15 - MCC: 0.8807\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9406 - loss: 0.1439 - val_accuracy: 0.9405 - val_loss: 0.1439 - mcc: 0.8807\n",
      "Epoch 16/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9396 - loss: 0.1459\n",
      "Epoch 16 - MCC: 0.8817\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9396 - loss: 0.1459 - val_accuracy: 0.9410 - val_loss: 0.1425 - mcc: 0.8817\n",
      "Epoch 17/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9410 - loss: 0.1435\n",
      "Epoch 17 - MCC: 0.8819\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9410 - loss: 0.1435 - val_accuracy: 0.9411 - val_loss: 0.1421 - mcc: 0.8819\n",
      "Epoch 18/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9409 - loss: 0.1423\n",
      "Epoch 18 - MCC: 0.8835\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9409 - loss: 0.1424 - val_accuracy: 0.9418 - val_loss: 0.1410 - mcc: 0.8835\n",
      "Epoch 19/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9414 - loss: 0.1421\n",
      "Epoch 19 - MCC: 0.8841\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9414 - loss: 0.1421 - val_accuracy: 0.9420 - val_loss: 0.1404 - mcc: 0.8841\n",
      "Epoch 20/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9410 - loss: 0.1418\n",
      "Epoch 20 - MCC: 0.8841\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - accuracy: 0.9410 - loss: 0.1418 - val_accuracy: 0.9422 - val_loss: 0.1403 - mcc: 0.8841\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: TCN, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6885 - loss: 0.7255\n",
      "Epoch 1 - MCC: 0.8002\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 45ms/step - accuracy: 0.6891 - loss: 0.7240 - val_accuracy: 0.8998 - val_loss: 0.2348 - mcc: 0.8002\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9089 - loss: 0.2172\n",
      "Epoch 2 - MCC: 0.8339\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9090 - loss: 0.2170 - val_accuracy: 0.9169 - val_loss: 0.1974 - mcc: 0.8339\n",
      "Epoch 3/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9205 - loss: 0.1910\n",
      "Epoch 3 - MCC: 0.8510\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9206 - loss: 0.1908 - val_accuracy: 0.9257 - val_loss: 0.1794 - mcc: 0.8510\n",
      "Epoch 4/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9269 - loss: 0.1777\n",
      "Epoch 4 - MCC: 0.8574\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9269 - loss: 0.1777 - val_accuracy: 0.9287 - val_loss: 0.1716 - mcc: 0.8574\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9283 - loss: 0.1727\n",
      "Epoch 5 - MCC: 0.8576\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9283 - loss: 0.1727 - val_accuracy: 0.9289 - val_loss: 0.1704 - mcc: 0.8576\n",
      "Epoch 6/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9306 - loss: 0.1680\n",
      "Epoch 6 - MCC: 0.8629\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9306 - loss: 0.1680 - val_accuracy: 0.9316 - val_loss: 0.1645 - mcc: 0.8629\n",
      "Epoch 7/20\n",
      "\u001B[1m176/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9321 - loss: 0.1637\n",
      "Epoch 7 - MCC: 0.8667\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9322 - loss: 0.1636 - val_accuracy: 0.9335 - val_loss: 0.1599 - mcc: 0.8667\n",
      "Epoch 8/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9346 - loss: 0.1592\n",
      "Epoch 8 - MCC: 0.8681\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9346 - loss: 0.1592 - val_accuracy: 0.9340 - val_loss: 0.1586 - mcc: 0.8681\n",
      "Epoch 9/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9333 - loss: 0.1602\n",
      "Epoch 9 - MCC: 0.8671\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.9334 - loss: 0.1601 - val_accuracy: 0.9333 - val_loss: 0.1612 - mcc: 0.8671\n",
      "Epoch 10/20\n",
      "\u001B[1m176/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9369 - loss: 0.1535\n",
      "Epoch 10 - MCC: 0.8709\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - accuracy: 0.9368 - loss: 0.1536 - val_accuracy: 0.9356 - val_loss: 0.1568 - mcc: 0.8709\n",
      "Epoch 11/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9322 - loss: 0.1623\n",
      "Epoch 11 - MCC: 0.8690\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9323 - loss: 0.1622 - val_accuracy: 0.9341 - val_loss: 0.1590 - mcc: 0.8690\n",
      "Epoch 12/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9383 - loss: 0.1510\n",
      "Epoch 12 - MCC: 0.8735\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9383 - loss: 0.1511 - val_accuracy: 0.9369 - val_loss: 0.1521 - mcc: 0.8735\n",
      "Epoch 13/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9366 - loss: 0.1528\n",
      "Epoch 13 - MCC: 0.8734\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9366 - loss: 0.1528 - val_accuracy: 0.9369 - val_loss: 0.1513 - mcc: 0.8734\n",
      "Epoch 14/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9385 - loss: 0.1482\n",
      "Epoch 14 - MCC: 0.8750\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9385 - loss: 0.1483 - val_accuracy: 0.9377 - val_loss: 0.1508 - mcc: 0.8750\n",
      "Epoch 15/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9399 - loss: 0.1458\n",
      "Epoch 15 - MCC: 0.8746\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9398 - loss: 0.1461 - val_accuracy: 0.9375 - val_loss: 0.1510 - mcc: 0.8746\n",
      "Epoch 16/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9394 - loss: 0.1467\n",
      "Epoch 16 - MCC: 0.8721\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9394 - loss: 0.1468 - val_accuracy: 0.9361 - val_loss: 0.1533 - mcc: 0.8721\n",
      "Epoch 17/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9390 - loss: 0.1466\n",
      "Epoch 17 - MCC: 0.8761\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9390 - loss: 0.1465 - val_accuracy: 0.9382 - val_loss: 0.1474 - mcc: 0.8761\n",
      "Epoch 18/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9403 - loss: 0.1441\n",
      "Epoch 18 - MCC: 0.8770\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.9403 - loss: 0.1442 - val_accuracy: 0.9386 - val_loss: 0.1473 - mcc: 0.8770\n",
      "Epoch 19/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9407 - loss: 0.1436\n",
      "Epoch 19 - MCC: 0.8716\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.9407 - loss: 0.1437 - val_accuracy: 0.9351 - val_loss: 0.1571 - mcc: 0.8716\n",
      "Epoch 20/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9386 - loss: 0.1471\n",
      "Epoch 20 - MCC: 0.8755\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9386 - loss: 0.1471 - val_accuracy: 0.9379 - val_loss: 0.1493 - mcc: 0.8755\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.9423893333333333),\n",
      "              'mean': np.float64(0.9402053333333333),\n",
      "              'min': np.float64(0.9369306666666667),\n",
      "              'std': np.float64(0.002305523570326967)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.0002888358434041341),\n",
      "                               'mean': np.float64(0.0002551554361979167),\n",
      "                               'min': np.float64(0.00020377763112386068),\n",
      "                               'std': np.float64(2.8918384434876504e-05)},\n",
      " 'MCC': {'max': np.float64(0.8846726948075004),\n",
      "         'mean': np.float64(0.8804672296232885),\n",
      "         'min': np.float64(0.8746714388302239),\n",
      "         'std': np.float64(0.004414073747261431)},\n",
      " 'Parameters': 5296,\n",
      " 'Train Time (s)': {'max': np.float64(49.47858786582947),\n",
      "                    'mean': np.float64(43.10222978591919),\n",
      "                    'min': np.float64(38.18172264099121),\n",
      "                    'std': np.float64(4.92234082288637)},\n",
      " 'Training Accuracy': [[0.8455908298492432,\n",
      "                        0.9183980226516724,\n",
      "                        0.9256350994110107,\n",
      "                        0.9289165139198303,\n",
      "                        0.9310701489448547,\n",
      "                        0.9337215423583984,\n",
      "                        0.9345810413360596,\n",
      "                        0.9351168870925903,\n",
      "                        0.9364261627197266,\n",
      "                        0.9372211694717407,\n",
      "                        0.9372246265411377,\n",
      "                        0.9384166598320007,\n",
      "                        0.9386235475540161,\n",
      "                        0.9395654201507568,\n",
      "                        0.9396324157714844,\n",
      "                        0.9397720694541931,\n",
      "                        0.9401468634605408,\n",
      "                        0.9406317472457886,\n",
      "                        0.9408425092697144,\n",
      "                        0.9407337307929993],\n",
      "                       [0.8106205463409424,\n",
      "                        0.9152753949165344,\n",
      "                        0.9225724935531616,\n",
      "                        0.9263361096382141,\n",
      "                        0.9296281933784485,\n",
      "                        0.9312383532524109,\n",
      "                        0.9329841136932373,\n",
      "                        0.9345115423202515,\n",
      "                        0.9358322620391846,\n",
      "                        0.9366551041603088,\n",
      "                        0.9374805688858032,\n",
      "                        0.9380493760108948,\n",
      "                        0.9387051463127136,\n",
      "                        0.9393332600593567,\n",
      "                        0.9402626752853394,\n",
      "                        0.9405080676078796,\n",
      "                        0.9407364726066589,\n",
      "                        0.9407060742378235,\n",
      "                        0.9416434168815613,\n",
      "                        0.941986083984375],\n",
      "                       [0.8419666886329651,\n",
      "                        0.9151245355606079,\n",
      "                        0.9234369397163391,\n",
      "                        0.9282219409942627,\n",
      "                        0.9304450750350952,\n",
      "                        0.9320619106292725,\n",
      "                        0.9341526627540588,\n",
      "                        0.935240626335144,\n",
      "                        0.9363888502120972,\n",
      "                        0.9376040101051331,\n",
      "                        0.9379687309265137,\n",
      "                        0.9391515254974365,\n",
      "                        0.9394029974937439,\n",
      "                        0.9401034116744995,\n",
      "                        0.9406355023384094,\n",
      "                        0.9403330683708191,\n",
      "                        0.940563976764679,\n",
      "                        0.9412791132926941,\n",
      "                        0.941686749458313,\n",
      "                        0.9418525099754333],\n",
      "                       [0.8029097318649292,\n",
      "                        0.9083108901977539,\n",
      "                        0.9203385710716248,\n",
      "                        0.9262953400611877,\n",
      "                        0.9296255707740784,\n",
      "                        0.9320929646492004,\n",
      "                        0.9334465861320496,\n",
      "                        0.934955894947052,\n",
      "                        0.9357514381408691,\n",
      "                        0.9365602135658264,\n",
      "                        0.9375699162483215,\n",
      "                        0.938045084476471,\n",
      "                        0.9388664364814758,\n",
      "                        0.9392261505126953,\n",
      "                        0.939655601978302,\n",
      "                        0.9398727416992188,\n",
      "                        0.9404778480529785,\n",
      "                        0.9403839707374573,\n",
      "                        0.9410838484764099,\n",
      "                        0.9407573938369751],\n",
      "                       [0.8008942008018494,\n",
      "                        0.9131450057029724,\n",
      "                        0.9225691556930542,\n",
      "                        0.9271294474601746,\n",
      "                        0.9295141696929932,\n",
      "                        0.9311075210571289,\n",
      "                        0.9333574771881104,\n",
      "                        0.934273898601532,\n",
      "                        0.9349108338356018,\n",
      "                        0.9361209273338318,\n",
      "                        0.9361492395401001,\n",
      "                        0.9373672604560852,\n",
      "                        0.9377359747886658,\n",
      "                        0.9380391240119934,\n",
      "                        0.9380459785461426,\n",
      "                        0.9388139843940735,\n",
      "                        0.9391844272613525,\n",
      "                        0.9401113390922546,\n",
      "                        0.9402539730072021,\n",
      "                        0.9400501251220703]],\n",
      " 'Training Loss': [[0.32666075229644775,\n",
      "                    0.19338259100914001,\n",
      "                    0.17703849077224731,\n",
      "                    0.16915884613990784,\n",
      "                    0.16433216631412506,\n",
      "                    0.1584291309118271,\n",
      "                    0.1563323587179184,\n",
      "                    0.15476329624652863,\n",
      "                    0.15226787328720093,\n",
      "                    0.15011830627918243,\n",
      "                    0.1503315269947052,\n",
      "                    0.14752846956253052,\n",
      "                    0.14674043655395508,\n",
      "                    0.14513884484767914,\n",
      "                    0.14523515105247498,\n",
      "                    0.1444416642189026,\n",
      "                    0.14302542805671692,\n",
      "                    0.14226147532463074,\n",
      "                    0.14189977943897247,\n",
      "                    0.14221863448619843],\n",
      "                   [0.39412426948547363,\n",
      "                    0.20347177982330322,\n",
      "                    0.18629689514636993,\n",
      "                    0.1768525391817093,\n",
      "                    0.16925324499607086,\n",
      "                    0.1651279777288437,\n",
      "                    0.1611417680978775,\n",
      "                    0.15723131597042084,\n",
      "                    0.15381968021392822,\n",
      "                    0.15233726799488068,\n",
      "                    0.15020586550235748,\n",
      "                    0.14860863983631134,\n",
      "                    0.14696790277957916,\n",
      "                    0.14567242562770844,\n",
      "                    0.1441468447446823,\n",
      "                    0.14302986860275269,\n",
      "                    0.14265191555023193,\n",
      "                    0.14242984354496002,\n",
      "                    0.14083504676818848,\n",
      "                    0.1397048681974411],\n",
      "                   [0.33731088042259216,\n",
      "                    0.20257668197155,\n",
      "                    0.18303819000720978,\n",
      "                    0.17198960483074188,\n",
      "                    0.16689170897006989,\n",
      "                    0.16288354992866516,\n",
      "                    0.15852494537830353,\n",
      "                    0.15561741590499878,\n",
      "                    0.15254218876361847,\n",
      "                    0.1507067233324051,\n",
      "                    0.1494171917438507,\n",
      "                    0.14662544429302216,\n",
      "                    0.14625807106494904,\n",
      "                    0.14463892579078674,\n",
      "                    0.14305542409420013,\n",
      "                    0.14371280372142792,\n",
      "                    0.14287981390953064,\n",
      "                    0.1414785385131836,\n",
      "                    0.14061345160007477,\n",
      "                    0.1398504674434662],\n",
      "                   [0.43661054968833923,\n",
      "                    0.218277245759964,\n",
      "                    0.19138343632221222,\n",
      "                    0.17754621803760529,\n",
      "                    0.16958366334438324,\n",
      "                    0.16371238231658936,\n",
      "                    0.16110719740390778,\n",
      "                    0.1574234813451767,\n",
      "                    0.15490376949310303,\n",
      "                    0.1533178687095642,\n",
      "                    0.15108640491962433,\n",
      "                    0.15018653869628906,\n",
      "                    0.14812643826007843,\n",
      "                    0.14724946022033691,\n",
      "                    0.14596876502037048,\n",
      "                    0.14533570408821106,\n",
      "                    0.1441357582807541,\n",
      "                    0.14416302740573883,\n",
      "                    0.14254723489284515,\n",
      "                    0.14229731261730194],\n",
      "                   [0.44091618061065674,\n",
      "                    0.20691296458244324,\n",
      "                    0.18622373044490814,\n",
      "                    0.17647162079811096,\n",
      "                    0.170340895652771,\n",
      "                    0.1662486493587494,\n",
      "                    0.16151286661624908,\n",
      "                    0.15941928327083588,\n",
      "                    0.1572098731994629,\n",
      "                    0.15496765077114105,\n",
      "                    0.15430891513824463,\n",
      "                    0.15204009413719177,\n",
      "                    0.15078695118427277,\n",
      "                    0.14965347945690155,\n",
      "                    0.14975617825984955,\n",
      "                    0.14781206846237183,\n",
      "                    0.1465039700269699,\n",
      "                    0.14506696164608002,\n",
      "                    0.14449840784072876,\n",
      "                    0.1445033699274063]],\n",
      " 'Validation Accuracy': [[0.9154907464981079,\n",
      "                          0.9257280230522156,\n",
      "                          0.9261839389801025,\n",
      "                          0.9327946901321411,\n",
      "                          0.934136152267456,\n",
      "                          0.9342132806777954,\n",
      "                          0.9362055659294128,\n",
      "                          0.9364054203033447,\n",
      "                          0.9380000233650208,\n",
      "                          0.9381919503211975,\n",
      "                          0.9389679431915283,\n",
      "                          0.9355999231338501,\n",
      "                          0.940000057220459,\n",
      "                          0.940237283706665,\n",
      "                          0.9402400851249695,\n",
      "                          0.9387839436531067,\n",
      "                          0.9398826360702515,\n",
      "                          0.9399707317352295,\n",
      "                          0.9415013194084167,\n",
      "                          0.9423893094062805],\n",
      "                         [0.9113920331001282,\n",
      "                          0.9192079305648804,\n",
      "                          0.9271707534790039,\n",
      "                          0.931325376033783,\n",
      "                          0.9325761198997498,\n",
      "                          0.9332319498062134,\n",
      "                          0.9357067346572876,\n",
      "                          0.9341495037078857,\n",
      "                          0.9375013709068298,\n",
      "                          0.9380374550819397,\n",
      "                          0.9395546913146973,\n",
      "                          0.9404186010360718,\n",
      "                          0.9405602216720581,\n",
      "                          0.9408668875694275,\n",
      "                          0.9402453899383545,\n",
      "                          0.9411708116531372,\n",
      "                          0.9420907497406006,\n",
      "                          0.9424239993095398,\n",
      "                          0.9423308372497559,\n",
      "                          0.9415706992149353],\n",
      "                         [0.9049439430236816,\n",
      "                          0.9178293347358704,\n",
      "                          0.9220747351646423,\n",
      "                          0.928762674331665,\n",
      "                          0.9300107359886169,\n",
      "                          0.9295548796653748,\n",
      "                          0.9313227534294128,\n",
      "                          0.932834804058075,\n",
      "                          0.9318587779998779,\n",
      "                          0.9358959794044495,\n",
      "                          0.9339200258255005,\n",
      "                          0.9374534487724304,\n",
      "                          0.9373705983161926,\n",
      "                          0.9366561770439148,\n",
      "                          0.9366587996482849,\n",
      "                          0.9324561357498169,\n",
      "                          0.9375360608100891,\n",
      "                          0.9384881258010864,\n",
      "                          0.9391146898269653,\n",
      "                          0.9369307160377502],\n",
      "                         [0.8994853496551514,\n",
      "                          0.9186800122261047,\n",
      "                          0.925608217716217,\n",
      "                          0.9270693063735962,\n",
      "                          0.9322934746742249,\n",
      "                          0.933861494064331,\n",
      "                          0.9362614154815674,\n",
      "                          0.9367548227310181,\n",
      "                          0.9367865920066833,\n",
      "                          0.9382588863372803,\n",
      "                          0.9391361474990845,\n",
      "                          0.9402586817741394,\n",
      "                          0.9400345087051392,\n",
      "                          0.9391706585884094,\n",
      "                          0.9405013918876648,\n",
      "                          0.9410267472267151,\n",
      "                          0.9411119818687439,\n",
      "                          0.9417839646339417,\n",
      "                          0.9419894218444824,\n",
      "                          0.9422106146812439],\n",
      "                         [0.8997682332992554,\n",
      "                          0.9168931245803833,\n",
      "                          0.9256613850593567,\n",
      "                          0.9287173748016357,\n",
      "                          0.9289172291755676,\n",
      "                          0.9316401481628418,\n",
      "                          0.9335466027259827,\n",
      "                          0.9340294003486633,\n",
      "                          0.9333413243293762,\n",
      "                          0.9355547428131104,\n",
      "                          0.9341040253639221,\n",
      "                          0.9369440078735352,\n",
      "                          0.9369174838066101,\n",
      "                          0.9376559853553772,\n",
      "                          0.9375093579292297,\n",
      "                          0.9361093640327454,\n",
      "                          0.9382215142250061,\n",
      "                          0.9385840892791748,\n",
      "                          0.9351094365119934,\n",
      "                          0.9379252791404724]],\n",
      " 'Validation Loss': [0.2347681224346161,\n",
      "                     0.19736509025096893,\n",
      "                     0.17943648993968964,\n",
      "                     0.171615332365036,\n",
      "                     0.17042337357997894,\n",
      "                     0.16447962820529938,\n",
      "                     0.15993750095367432,\n",
      "                     0.15862126648426056,\n",
      "                     0.16118013858795166,\n",
      "                     0.15683288872241974,\n",
      "                     0.1589559018611908,\n",
      "                     0.1520681232213974,\n",
      "                     0.1513436734676361,\n",
      "                     0.15084563195705414,\n",
      "                     0.151042178273201,\n",
      "                     0.15325042605400085,\n",
      "                     0.14740613102912903,\n",
      "                     0.14728575944900513,\n",
      "                     0.15713131427764893,\n",
      "                     0.14929284155368805],\n",
      " 'Validation MCC': [[np.float64(0.8314759761531288),\n",
      "                     np.float64(0.8510948420727572),\n",
      "                     np.float64(0.8524367854699714),\n",
      "                     np.float64(0.8652189097567755),\n",
      "                     np.float64(0.8680427258201519),\n",
      "                     np.float64(0.8682333302967806),\n",
      "                     np.float64(0.8721419299384928),\n",
      "                     np.float64(0.872819975686691),\n",
      "                     np.float64(0.8756646158082025),\n",
      "                     np.float64(0.8760663345108896),\n",
      "                     np.float64(0.8776016370544586),\n",
      "                     np.float64(0.8709394438110062),\n",
      "                     np.float64(0.8800855691728227),\n",
      "                     np.float64(0.880146933516436),\n",
      "                     np.float64(0.8801524454537125),\n",
      "                     np.float64(0.8773301354805261),\n",
      "                     np.float64(0.8794993239834157),\n",
      "                     np.float64(0.8796649705471082),\n",
      "                     np.float64(0.8830891295165625),\n",
      "                     np.float64(0.8846726948075004)],\n",
      "                    [np.float64(0.8224674141682178),\n",
      "                     np.float64(0.838503868689381),\n",
      "                     np.float64(0.853925132868788),\n",
      "                     np.float64(0.8625075258454534),\n",
      "                     np.float64(0.8647546562160844),\n",
      "                     np.float64(0.8660707541591558),\n",
      "                     np.float64(0.8713440527497511),\n",
      "                     np.float64(0.8681548588241091),\n",
      "                     np.float64(0.8747860011405404),\n",
      "                     np.float64(0.8759504219727855),\n",
      "                     np.float64(0.87881115658998),\n",
      "                     np.float64(0.8806609182345934),\n",
      "                     np.float64(0.8809464577906336),\n",
      "                     np.float64(0.8813882970717921),\n",
      "                     np.float64(0.8812006128653348),\n",
      "                     np.float64(0.8822705922626871),\n",
      "                     np.float64(0.884105928354607),\n",
      "                     np.float64(0.8845861761033069),\n",
      "                     np.float64(0.8848258408234192),\n",
      "                     np.float64(0.8833848086608662)],\n",
      "                    [np.float64(0.8092856667421368),\n",
      "                     np.float64(0.8357966358614886),\n",
      "                     np.float64(0.8438031257672522),\n",
      "                     np.float64(0.857226393928213),\n",
      "                     np.float64(0.8595746851036407),\n",
      "                     np.float64(0.8588244669781013),\n",
      "                     np.float64(0.8627877073946507),\n",
      "                     np.float64(0.8662255495436235),\n",
      "                     np.float64(0.8633555167891684),\n",
      "                     np.float64(0.8716212451949719),\n",
      "                     np.float64(0.8687574849706227),\n",
      "                     np.float64(0.8745995265395036),\n",
      "                     np.float64(0.8744786201518506),\n",
      "                     np.float64(0.8736113058168911),\n",
      "                     np.float64(0.8729096843679086),\n",
      "                     np.float64(0.866407324385478),\n",
      "                     np.float64(0.8747134419531237),\n",
      "                     np.float64(0.8766135781156347),\n",
      "                     np.float64(0.8778770640413137),\n",
      "                     np.float64(0.8746714388302239)],\n",
      "                    [np.float64(0.7983958584667227),\n",
      "                     np.float64(0.8369780307303784),\n",
      "                     np.float64(0.8507824871704807),\n",
      "                     np.float64(0.8550536644605453),\n",
      "                     np.float64(0.8641945046948702),\n",
      "                     np.float64(0.8680862353414606),\n",
      "                     np.float64(0.872199886816319),\n",
      "                     np.float64(0.8731575483274295),\n",
      "                     np.float64(0.8740267365445821),\n",
      "                     np.float64(0.8762024925847339),\n",
      "                     np.float64(0.8779926989301691),\n",
      "                     np.float64(0.8804170501800402),\n",
      "                     np.float64(0.8797536889307694),\n",
      "                     np.float64(0.8780094215867404),\n",
      "                     np.float64(0.8806885153710411),\n",
      "                     np.float64(0.8817479366415519),\n",
      "                     np.float64(0.8819115119695419),\n",
      "                     np.float64(0.8835049466793553),\n",
      "                     np.float64(0.8841471186885163),\n",
      "                     np.float64(0.8840902122115203)],\n",
      "                    [np.float64(0.800227098886213),\n",
      "                     np.float64(0.833897327396297),\n",
      "                     np.float64(0.8510488257537996),\n",
      "                     np.float64(0.8574234081810979),\n",
      "                     np.float64(0.8575649196743025),\n",
      "                     np.float64(0.8629049810031272),\n",
      "                     np.float64(0.866714875580014),\n",
      "                     np.float64(0.868139152003617),\n",
      "                     np.float64(0.8670561183218879),\n",
      "                     np.float64(0.870939859473202),\n",
      "                     np.float64(0.8689618734616678),\n",
      "                     np.float64(0.8735372639619914),\n",
      "                     np.float64(0.8733968073805487),\n",
      "                     np.float64(0.8749642792393586),\n",
      "                     np.float64(0.8746091428877245),\n",
      "                     np.float64(0.8720808067891853),\n",
      "                     np.float64(0.8760532752051963),\n",
      "                     np.float64(0.8770125813550457),\n",
      "                     np.float64(0.8716361736698812),\n",
      "                     np.float64(0.8755169936063315)]]}\n",
      "Training Model: MLP, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7249 - loss: 0.5012\n",
      "Epoch 1 - MCC: 0.7744\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 15ms/step - accuracy: 0.7254 - loss: 0.5006 - val_accuracy: 0.8874 - val_loss: 0.2669 - mcc: 0.7744\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8819 - loss: 0.2703\n",
      "Epoch 2 - MCC: 0.7861\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.8819 - loss: 0.2702 - val_accuracy: 0.8930 - val_loss: 0.2492 - mcc: 0.7861\n",
      "Epoch 3/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8927 - loss: 0.2449\n",
      "Epoch 3 - MCC: 0.7945\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8928 - loss: 0.2446 - val_accuracy: 0.8968 - val_loss: 0.2386 - mcc: 0.7945\n",
      "Epoch 4/20\n",
      "\u001B[1m176/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9007 - loss: 0.2257\n",
      "Epoch 4 - MCC: 0.8041\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9006 - loss: 0.2258 - val_accuracy: 0.9014 - val_loss: 0.2262 - mcc: 0.8041\n",
      "Epoch 5/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9056 - loss: 0.2179\n",
      "Epoch 5 - MCC: 0.8089\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9057 - loss: 0.2177 - val_accuracy: 0.9015 - val_loss: 0.2297 - mcc: 0.8089\n",
      "Epoch 6/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9106 - loss: 0.2082\n",
      "Epoch 6 - MCC: 0.8286\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9106 - loss: 0.2081 - val_accuracy: 0.9143 - val_loss: 0.2026 - mcc: 0.8286\n",
      "Epoch 7/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9123 - loss: 0.2039\n",
      "Epoch 7 - MCC: 0.8323\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9123 - loss: 0.2038 - val_accuracy: 0.9161 - val_loss: 0.1991 - mcc: 0.8323\n",
      "Epoch 8/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9142 - loss: 0.2003\n",
      "Epoch 8 - MCC: 0.8345\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9142 - loss: 0.2002 - val_accuracy: 0.9170 - val_loss: 0.1967 - mcc: 0.8345\n",
      "Epoch 9/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9143 - loss: 0.1999\n",
      "Epoch 9 - MCC: 0.8321\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9144 - loss: 0.1998 - val_accuracy: 0.9160 - val_loss: 0.1967 - mcc: 0.8321\n",
      "Epoch 10/20\n",
      "\u001B[1m171/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9142 - loss: 0.1999\n",
      "Epoch 10 - MCC: 0.8401\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9144 - loss: 0.1995 - val_accuracy: 0.9200 - val_loss: 0.1907 - mcc: 0.8401\n",
      "Epoch 11/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9161 - loss: 0.1974\n",
      "Epoch 11 - MCC: 0.8405\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9161 - loss: 0.1973 - val_accuracy: 0.9204 - val_loss: 0.1897 - mcc: 0.8405\n",
      "Epoch 12/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9155 - loss: 0.1971\n",
      "Epoch 12 - MCC: 0.8385\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9155 - loss: 0.1971 - val_accuracy: 0.9194 - val_loss: 0.1899 - mcc: 0.8385\n",
      "Epoch 13/20\n",
      "\u001B[1m175/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9197 - loss: 0.1880\n",
      "Epoch 13 - MCC: 0.8405\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9196 - loss: 0.1883 - val_accuracy: 0.9205 - val_loss: 0.1886 - mcc: 0.8405\n",
      "Epoch 14/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9191 - loss: 0.1910\n",
      "Epoch 14 - MCC: 0.8440\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - accuracy: 0.9190 - loss: 0.1910 - val_accuracy: 0.9221 - val_loss: 0.1858 - mcc: 0.8440\n",
      "Epoch 15/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9197 - loss: 0.1885\n",
      "Epoch 15 - MCC: 0.8435\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9197 - loss: 0.1885 - val_accuracy: 0.9220 - val_loss: 0.1860 - mcc: 0.8435\n",
      "Epoch 16/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9201 - loss: 0.1886\n",
      "Epoch 16 - MCC: 0.8446\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9200 - loss: 0.1886 - val_accuracy: 0.9219 - val_loss: 0.1879 - mcc: 0.8446\n",
      "Epoch 17/20\n",
      "\u001B[1m173/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9205 - loss: 0.1880\n",
      "Epoch 17 - MCC: 0.8422\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9204 - loss: 0.1883 - val_accuracy: 0.9213 - val_loss: 0.1865 - mcc: 0.8422\n",
      "Epoch 18/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9207 - loss: 0.1861\n",
      "Epoch 18 - MCC: 0.8403\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9206 - loss: 0.1862 - val_accuracy: 0.9202 - val_loss: 0.1889 - mcc: 0.8403\n",
      "Epoch 19/20\n",
      "\u001B[1m174/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9205 - loss: 0.1864\n",
      "Epoch 19 - MCC: 0.8457\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9205 - loss: 0.1865 - val_accuracy: 0.9231 - val_loss: 0.1835 - mcc: 0.8457\n",
      "Epoch 20/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9237 - loss: 0.1809\n",
      "Epoch 20 - MCC: 0.8464\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9235 - loss: 0.1812 - val_accuracy: 0.9231 - val_loss: 0.1852 - mcc: 0.8464\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: MLP, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7311 - loss: 0.5376\n",
      "Epoch 1 - MCC: 0.7754\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 21ms/step - accuracy: 0.7316 - loss: 0.5369 - val_accuracy: 0.8881 - val_loss: 0.2606 - mcc: 0.7754\n",
      "Epoch 2/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8851 - loss: 0.2640\n",
      "Epoch 2 - MCC: 0.7816\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8852 - loss: 0.2639 - val_accuracy: 0.8895 - val_loss: 0.2545 - mcc: 0.7816\n",
      "Epoch 3/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8909 - loss: 0.2481\n",
      "Epoch 3 - MCC: 0.7981\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8910 - loss: 0.2478 - val_accuracy: 0.8991 - val_loss: 0.2299 - mcc: 0.7981\n",
      "Epoch 4/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8997 - loss: 0.2303\n",
      "Epoch 4 - MCC: 0.8142\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8998 - loss: 0.2302 - val_accuracy: 0.9074 - val_loss: 0.2142 - mcc: 0.8142\n",
      "Epoch 5/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9043 - loss: 0.2211\n",
      "Epoch 5 - MCC: 0.8205\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9044 - loss: 0.2209 - val_accuracy: 0.9103 - val_loss: 0.2090 - mcc: 0.8205\n",
      "Epoch 6/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9075 - loss: 0.2140\n",
      "Epoch 6 - MCC: 0.8259\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9075 - loss: 0.2140 - val_accuracy: 0.9132 - val_loss: 0.2011 - mcc: 0.8259\n",
      "Epoch 7/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9117 - loss: 0.2069\n",
      "Epoch 7 - MCC: 0.8259\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9116 - loss: 0.2069 - val_accuracy: 0.9132 - val_loss: 0.1998 - mcc: 0.8259\n",
      "Epoch 8/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9112 - loss: 0.2073\n",
      "Epoch 8 - MCC: 0.8277\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9112 - loss: 0.2073 - val_accuracy: 0.9139 - val_loss: 0.1988 - mcc: 0.8277\n",
      "Epoch 9/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9121 - loss: 0.2062\n",
      "Epoch 9 - MCC: 0.8338\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9121 - loss: 0.2061 - val_accuracy: 0.9162 - val_loss: 0.1984 - mcc: 0.8338\n",
      "Epoch 10/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9146 - loss: 0.2009\n",
      "Epoch 10 - MCC: 0.8271\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.9146 - loss: 0.2008 - val_accuracy: 0.9132 - val_loss: 0.1988 - mcc: 0.8271\n",
      "Epoch 11/20\n",
      "\u001B[1m175/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9131 - loss: 0.2055\n",
      "Epoch 11 - MCC: 0.8399\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.9133 - loss: 0.2049 - val_accuracy: 0.9201 - val_loss: 0.1876 - mcc: 0.8399\n",
      "Epoch 12/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9171 - loss: 0.1951\n",
      "Epoch 12 - MCC: 0.8425\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9172 - loss: 0.1951 - val_accuracy: 0.9214 - val_loss: 0.1854 - mcc: 0.8425\n",
      "Epoch 13/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9183 - loss: 0.1926\n",
      "Epoch 13 - MCC: 0.8389\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9183 - loss: 0.1926 - val_accuracy: 0.9196 - val_loss: 0.1871 - mcc: 0.8389\n",
      "Epoch 14/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9165 - loss: 0.1966\n",
      "Epoch 14 - MCC: 0.8442\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9166 - loss: 0.1965 - val_accuracy: 0.9223 - val_loss: 0.1832 - mcc: 0.8442\n",
      "Epoch 15/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9182 - loss: 0.1933\n",
      "Epoch 15 - MCC: 0.8453\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9182 - loss: 0.1933 - val_accuracy: 0.9227 - val_loss: 0.1832 - mcc: 0.8453\n",
      "Epoch 16/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9196 - loss: 0.1909\n",
      "Epoch 16 - MCC: 0.8459\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9196 - loss: 0.1909 - val_accuracy: 0.9227 - val_loss: 0.1837 - mcc: 0.8459\n",
      "Epoch 17/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9170 - loss: 0.1948\n",
      "Epoch 17 - MCC: 0.8461\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9170 - loss: 0.1947 - val_accuracy: 0.9230 - val_loss: 0.1831 - mcc: 0.8461\n",
      "Epoch 18/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9193 - loss: 0.1911\n",
      "Epoch 18 - MCC: 0.8395\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9193 - loss: 0.1911 - val_accuracy: 0.9198 - val_loss: 0.1869 - mcc: 0.8395\n",
      "Epoch 19/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9216 - loss: 0.1863\n",
      "Epoch 19 - MCC: 0.8474\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9216 - loss: 0.1864 - val_accuracy: 0.9237 - val_loss: 0.1811 - mcc: 0.8474\n",
      "Epoch 20/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9208 - loss: 0.1876\n",
      "Epoch 20 - MCC: 0.8448\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9208 - loss: 0.1876 - val_accuracy: 0.9226 - val_loss: 0.1814 - mcc: 0.8448\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: MLP, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.6992 - loss: 0.5171\n",
      "Epoch 1 - MCC: 0.7716\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 14ms/step - accuracy: 0.6998 - loss: 0.5164 - val_accuracy: 0.8862 - val_loss: 0.2640 - mcc: 0.7716\n",
      "Epoch 2/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8900 - loss: 0.2521\n",
      "Epoch 2 - MCC: 0.7850\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8901 - loss: 0.2520 - val_accuracy: 0.8924 - val_loss: 0.2550 - mcc: 0.7850\n",
      "Epoch 3/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8937 - loss: 0.2437\n",
      "Epoch 3 - MCC: 0.7960\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8939 - loss: 0.2433 - val_accuracy: 0.8982 - val_loss: 0.2338 - mcc: 0.7960\n",
      "Epoch 4/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9010 - loss: 0.2273\n",
      "Epoch 4 - MCC: 0.8084\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9011 - loss: 0.2272 - val_accuracy: 0.9045 - val_loss: 0.2216 - mcc: 0.8084\n",
      "Epoch 5/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9066 - loss: 0.2154\n",
      "Epoch 5 - MCC: 0.8045\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9066 - loss: 0.2154 - val_accuracy: 0.9020 - val_loss: 0.2247 - mcc: 0.8045\n",
      "Epoch 6/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9099 - loss: 0.2095\n",
      "Epoch 6 - MCC: 0.8178\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9099 - loss: 0.2095 - val_accuracy: 0.9092 - val_loss: 0.2106 - mcc: 0.8178\n",
      "Epoch 7/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9132 - loss: 0.2033\n",
      "Epoch 7 - MCC: 0.8226\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9132 - loss: 0.2033 - val_accuracy: 0.9114 - val_loss: 0.2072 - mcc: 0.8226\n",
      "Epoch 8/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9145 - loss: 0.1993\n",
      "Epoch 8 - MCC: 0.8239\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9145 - loss: 0.1994 - val_accuracy: 0.9120 - val_loss: 0.2052 - mcc: 0.8239\n",
      "Epoch 9/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9149 - loss: 0.1991\n",
      "Epoch 9 - MCC: 0.8211\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9149 - loss: 0.1991 - val_accuracy: 0.9096 - val_loss: 0.2116 - mcc: 0.8211\n",
      "Epoch 10/20\n",
      "\u001B[1m181/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9162 - loss: 0.1976\n",
      "Epoch 10 - MCC: 0.8279\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9162 - loss: 0.1975 - val_accuracy: 0.9138 - val_loss: 0.2035 - mcc: 0.8279\n",
      "Epoch 11/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9180 - loss: 0.1915\n",
      "Epoch 11 - MCC: 0.8302\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9180 - loss: 0.1916 - val_accuracy: 0.9153 - val_loss: 0.1991 - mcc: 0.8302\n",
      "Epoch 12/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9165 - loss: 0.1975\n",
      "Epoch 12 - MCC: 0.8309\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9165 - loss: 0.1975 - val_accuracy: 0.9158 - val_loss: 0.1977 - mcc: 0.8309\n",
      "Epoch 13/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9191 - loss: 0.1913\n",
      "Epoch 13 - MCC: 0.8326\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9191 - loss: 0.1913 - val_accuracy: 0.9166 - val_loss: 0.1954 - mcc: 0.8326\n",
      "Epoch 14/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9199 - loss: 0.1895\n",
      "Epoch 14 - MCC: 0.8334\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9199 - loss: 0.1896 - val_accuracy: 0.9161 - val_loss: 0.1983 - mcc: 0.8334\n",
      "Epoch 15/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9194 - loss: 0.1899\n",
      "Epoch 15 - MCC: 0.8341\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9194 - loss: 0.1899 - val_accuracy: 0.9174 - val_loss: 0.1952 - mcc: 0.8341\n",
      "Epoch 16/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9212 - loss: 0.1873\n",
      "Epoch 16 - MCC: 0.8346\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9212 - loss: 0.1873 - val_accuracy: 0.9168 - val_loss: 0.1960 - mcc: 0.8346\n",
      "Epoch 17/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9187 - loss: 0.1916\n",
      "Epoch 17 - MCC: 0.8334\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9188 - loss: 0.1914 - val_accuracy: 0.9160 - val_loss: 0.1984 - mcc: 0.8334\n",
      "Epoch 18/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9180 - loss: 0.1932\n",
      "Epoch 18 - MCC: 0.8380\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9181 - loss: 0.1930 - val_accuracy: 0.9191 - val_loss: 0.1913 - mcc: 0.8380\n",
      "Epoch 19/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9208 - loss: 0.1882\n",
      "Epoch 19 - MCC: 0.8346\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9208 - loss: 0.1881 - val_accuracy: 0.9166 - val_loss: 0.1966 - mcc: 0.8346\n",
      "Epoch 20/20\n",
      "\u001B[1m176/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9220 - loss: 0.1843\n",
      "Epoch 20 - MCC: 0.8389\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9220 - loss: 0.1844 - val_accuracy: 0.9193 - val_loss: 0.1911 - mcc: 0.8389\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: MLP, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.7130 - loss: 0.5171\n",
      "Epoch 1 - MCC: 0.7718\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 17ms/step - accuracy: 0.7135 - loss: 0.5164 - val_accuracy: 0.8855 - val_loss: 0.2594 - mcc: 0.7718\n",
      "Epoch 2/20\n",
      "\u001B[1m180/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8886 - loss: 0.2558\n",
      "Epoch 2 - MCC: 0.7959\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.8887 - loss: 0.2556 - val_accuracy: 0.8980 - val_loss: 0.2373 - mcc: 0.7959\n",
      "Epoch 3/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8984 - loss: 0.2328\n",
      "Epoch 3 - MCC: 0.8171\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8985 - loss: 0.2326 - val_accuracy: 0.9088 - val_loss: 0.2123 - mcc: 0.8171\n",
      "Epoch 4/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9098 - loss: 0.2108\n",
      "Epoch 4 - MCC: 0.8205\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9098 - loss: 0.2108 - val_accuracy: 0.9101 - val_loss: 0.2083 - mcc: 0.8205\n",
      "Epoch 5/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9121 - loss: 0.2062\n",
      "Epoch 5 - MCC: 0.8328\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9121 - loss: 0.2062 - val_accuracy: 0.9167 - val_loss: 0.1961 - mcc: 0.8328\n",
      "Epoch 6/20\n",
      "\u001B[1m169/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9152 - loss: 0.2006\n",
      "Epoch 6 - MCC: 0.8314\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9153 - loss: 0.2002 - val_accuracy: 0.9159 - val_loss: 0.1971 - mcc: 0.8314\n",
      "Epoch 7/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9177 - loss: 0.1934\n",
      "Epoch 7 - MCC: 0.8353\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9177 - loss: 0.1934 - val_accuracy: 0.9179 - val_loss: 0.1930 - mcc: 0.8353\n",
      "Epoch 8/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9172 - loss: 0.1950\n",
      "Epoch 8 - MCC: 0.8371\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9172 - loss: 0.1950 - val_accuracy: 0.9188 - val_loss: 0.1909 - mcc: 0.8371\n",
      "Epoch 9/20\n",
      "\u001B[1m177/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9191 - loss: 0.1917\n",
      "Epoch 9 - MCC: 0.8331\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.9191 - loss: 0.1917 - val_accuracy: 0.9165 - val_loss: 0.1954 - mcc: 0.8331\n",
      "Epoch 10/20\n",
      "\u001B[1m178/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9168 - loss: 0.1977\n",
      "Epoch 10 - MCC: 0.8396\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9169 - loss: 0.1974 - val_accuracy: 0.9197 - val_loss: 0.1901 - mcc: 0.8396\n",
      "Epoch 11/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9209 - loss: 0.1870\n",
      "Epoch 11 - MCC: 0.8405\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9209 - loss: 0.1871 - val_accuracy: 0.9204 - val_loss: 0.1883 - mcc: 0.8405\n",
      "Epoch 12/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9203 - loss: 0.1878\n",
      "Epoch 12 - MCC: 0.8391\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9203 - loss: 0.1879 - val_accuracy: 0.9197 - val_loss: 0.1892 - mcc: 0.8391\n",
      "Epoch 13/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9217 - loss: 0.1852\n",
      "Epoch 13 - MCC: 0.8412\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9217 - loss: 0.1853 - val_accuracy: 0.9204 - val_loss: 0.1885 - mcc: 0.8412\n",
      "Epoch 14/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9190 - loss: 0.1911\n",
      "Epoch 14 - MCC: 0.8408\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9190 - loss: 0.1911 - val_accuracy: 0.9200 - val_loss: 0.1895 - mcc: 0.8408\n",
      "Epoch 15/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9226 - loss: 0.1845\n",
      "Epoch 15 - MCC: 0.8436\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9225 - loss: 0.1846 - val_accuracy: 0.9219 - val_loss: 0.1853 - mcc: 0.8436\n",
      "Epoch 16/20\n",
      "\u001B[1m179/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9226 - loss: 0.1840\n",
      "Epoch 16 - MCC: 0.8408\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9226 - loss: 0.1841 - val_accuracy: 0.9206 - val_loss: 0.1886 - mcc: 0.8408\n",
      "Epoch 17/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9190 - loss: 0.1909\n",
      "Epoch 17 - MCC: 0.8429\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9191 - loss: 0.1908 - val_accuracy: 0.9213 - val_loss: 0.1861 - mcc: 0.8429\n",
      "Epoch 18/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9225 - loss: 0.1832\n",
      "Epoch 18 - MCC: 0.8434\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9225 - loss: 0.1833 - val_accuracy: 0.9219 - val_loss: 0.1852 - mcc: 0.8434\n",
      "Epoch 19/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9221 - loss: 0.1859\n",
      "Epoch 19 - MCC: 0.8438\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9221 - loss: 0.1859 - val_accuracy: 0.9221 - val_loss: 0.1844 - mcc: 0.8438\n",
      "Epoch 20/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9228 - loss: 0.1840\n",
      "Epoch 20 - MCC: 0.8434\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9228 - loss: 0.1840 - val_accuracy: 0.9217 - val_loss: 0.1846 - mcc: 0.8434\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: MLP, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.7262 - loss: 0.4832\n",
      "Epoch 1 - MCC: 0.7729\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 12ms/step - accuracy: 0.7268 - loss: 0.4825 - val_accuracy: 0.8868 - val_loss: 0.2594 - mcc: 0.7729\n",
      "Epoch 2/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8924 - loss: 0.2477\n",
      "Epoch 2 - MCC: 0.7851\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 4ms/step - accuracy: 0.8924 - loss: 0.2477 - val_accuracy: 0.8929 - val_loss: 0.2435 - mcc: 0.7851\n",
      "Epoch 3/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8977 - loss: 0.2343\n",
      "Epoch 3 - MCC: 0.8001\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8977 - loss: 0.2343 - val_accuracy: 0.9004 - val_loss: 0.2287 - mcc: 0.8001\n",
      "Epoch 4/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9047 - loss: 0.2203\n",
      "Epoch 4 - MCC: 0.8070\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9047 - loss: 0.2203 - val_accuracy: 0.9025 - val_loss: 0.2255 - mcc: 0.8070\n",
      "Epoch 5/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9115 - loss: 0.2073\n",
      "Epoch 5 - MCC: 0.8152\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9115 - loss: 0.2073 - val_accuracy: 0.9077 - val_loss: 0.2145 - mcc: 0.8152\n",
      "Epoch 6/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9102 - loss: 0.2099\n",
      "Epoch 6 - MCC: 0.8246\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9102 - loss: 0.2099 - val_accuracy: 0.9118 - val_loss: 0.2070 - mcc: 0.8246\n",
      "Epoch 7/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9139 - loss: 0.2020\n",
      "Epoch 7 - MCC: 0.8267\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - accuracy: 0.9139 - loss: 0.2019 - val_accuracy: 0.9135 - val_loss: 0.2014 - mcc: 0.8267\n",
      "Epoch 8/20\n",
      "\u001B[1m169/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9154 - loss: 0.1988\n",
      "Epoch 8 - MCC: 0.8173\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9157 - loss: 0.1981 - val_accuracy: 0.9071 - val_loss: 0.2175 - mcc: 0.8173\n",
      "Epoch 9/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9153 - loss: 0.1986\n",
      "Epoch 9 - MCC: 0.8327\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9154 - loss: 0.1984 - val_accuracy: 0.9165 - val_loss: 0.1953 - mcc: 0.8327\n",
      "Epoch 10/20\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9190 - loss: 0.1905\n",
      "Epoch 10 - MCC: 0.8331\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9190 - loss: 0.1905 - val_accuracy: 0.9162 - val_loss: 0.1980 - mcc: 0.8331\n",
      "Epoch 11/20\n",
      "\u001B[1m182/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9174 - loss: 0.1950\n",
      "Epoch 11 - MCC: 0.8335\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9175 - loss: 0.1948 - val_accuracy: 0.9170 - val_loss: 0.1941 - mcc: 0.8335\n",
      "Epoch 12/20\n",
      "\u001B[1m184/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9201 - loss: 0.1880\n",
      "Epoch 12 - MCC: 0.8327\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9201 - loss: 0.1880 - val_accuracy: 0.9166 - val_loss: 0.1942 - mcc: 0.8327\n",
      "Epoch 13/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9214 - loss: 0.1860\n",
      "Epoch 13 - MCC: 0.8354\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9214 - loss: 0.1860 - val_accuracy: 0.9180 - val_loss: 0.1918 - mcc: 0.8354\n",
      "Epoch 14/20\n",
      "\u001B[1m186/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9227 - loss: 0.1836\n",
      "Epoch 14 - MCC: 0.8350\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9227 - loss: 0.1837 - val_accuracy: 0.9178 - val_loss: 0.1918 - mcc: 0.8350\n",
      "Epoch 15/20\n",
      "\u001B[1m187/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9204 - loss: 0.1877\n",
      "Epoch 15 - MCC: 0.8321\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9204 - loss: 0.1876 - val_accuracy: 0.9153 - val_loss: 0.1979 - mcc: 0.8321\n",
      "Epoch 16/20\n",
      "\u001B[1m183/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9195 - loss: 0.1906\n",
      "Epoch 16 - MCC: 0.8371\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9195 - loss: 0.1905 - val_accuracy: 0.9188 - val_loss: 0.1905 - mcc: 0.8371\n",
      "Epoch 17/20\n",
      "\u001B[1m172/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9205 - loss: 0.1870\n",
      "Epoch 17 - MCC: 0.8374\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9205 - loss: 0.1870 - val_accuracy: 0.9190 - val_loss: 0.1905 - mcc: 0.8374\n",
      "Epoch 18/20\n",
      "\u001B[1m173/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9196 - loss: 0.1880\n",
      "Epoch 18 - MCC: 0.8361\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9197 - loss: 0.1879 - val_accuracy: 0.9176 - val_loss: 0.1934 - mcc: 0.8361\n",
      "Epoch 19/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9202 - loss: 0.1882\n",
      "Epoch 19 - MCC: 0.8371\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9202 - loss: 0.1882 - val_accuracy: 0.9183 - val_loss: 0.1919 - mcc: 0.8371\n",
      "Epoch 20/20\n",
      "\u001B[1m185/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9219 - loss: 0.1860\n",
      "Epoch 20 - MCC: 0.8362\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9219 - loss: 0.1860 - val_accuracy: 0.9184 - val_loss: 0.1914 - mcc: 0.8362\n",
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.9230506666666667),\n",
      "              'mean': np.float64(0.9210074666666666),\n",
      "              'min': np.float64(0.918368),\n",
      "              'std': np.float64(0.0018559849807821612)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.00028715960184733075),\n",
      "                               'mean': np.float64(0.0002304522196451823),\n",
      "                               'min': np.float64(0.00017362403869628906),\n",
      "                               'std': np.float64(4.659520243726116e-05)},\n",
      " 'MCC': {'max': np.float64(0.8463657037253322),\n",
      "         'mean': np.float64(0.8419326058943973),\n",
      "         'min': np.float64(0.8361843377902796),\n",
      "         'std': np.float64(0.0037963567423610826)},\n",
      " 'Parameters': 5033,\n",
      " 'Train Time (s)': {'max': np.float64(29.38823437690735),\n",
      "                    'mean': np.float64(27.78469309806824),\n",
      "                    'min': np.float64(25.886887311935425),\n",
      "                    'std': np.float64(1.2216314259244963)},\n",
      " 'Training Accuracy': [[0.8235800862312317,\n",
      "                        0.8865846395492554,\n",
      "                        0.8938895463943481,\n",
      "                        0.9001861214637756,\n",
      "                        0.9073585867881775,\n",
      "                        0.91054368019104,\n",
      "                        0.9126372933387756,\n",
      "                        0.9145336151123047,\n",
      "                        0.9151465892791748,\n",
      "                        0.9168038964271545,\n",
      "                        0.916904866695404,\n",
      "                        0.9172978401184082,\n",
      "                        0.9178421497344971,\n",
      "                        0.9186612367630005,\n",
      "                        0.9192469120025635,\n",
      "                        0.9193913340568542,\n",
      "                        0.9190096259117126,\n",
      "                        0.9197422862052917,\n",
      "                        0.9203512072563171,\n",
      "                        0.9200330376625061],\n",
      "                       [0.824411928653717,\n",
      "                        0.8880888819694519,\n",
      "                        0.8941473960876465,\n",
      "                        0.9012495875358582,\n",
      "                        0.9061453342437744,\n",
      "                        0.9079123735427856,\n",
      "                        0.910662829875946,\n",
      "                        0.911763608455658,\n",
      "                        0.9131724238395691,\n",
      "                        0.9150114059448242,\n",
      "                        0.9161089658737183,\n",
      "                        0.9172840714454651,\n",
      "                        0.9183093309402466,\n",
      "                        0.917945384979248,\n",
      "                        0.9185699820518494,\n",
      "                        0.9194934964179993,\n",
      "                        0.9195046424865723,\n",
      "                        0.9191278219223022,\n",
      "                        0.9197314381599426,\n",
      "                        0.9201032519340515],\n",
      "                       [0.813082754611969,\n",
      "                        0.8911513090133667,\n",
      "                        0.8969536423683167,\n",
      "                        0.9030781984329224,\n",
      "                        0.9077897071838379,\n",
      "                        0.9106385707855225,\n",
      "                        0.9127553701400757,\n",
      "                        0.9143739938735962,\n",
      "                        0.9153798818588257,\n",
      "                        0.9166558980941772,\n",
      "                        0.9175515174865723,\n",
      "                        0.9185886383056641,\n",
      "                        0.9188145995140076,\n",
      "                        0.9195244908332825,\n",
      "                        0.9200860261917114,\n",
      "                        0.9206554293632507,\n",
      "                        0.9210866093635559,\n",
      "                        0.9213125705718994,\n",
      "                        0.9211356043815613,\n",
      "                        0.921680748462677],\n",
      "                       [0.8181962966918945,\n",
      "                        0.8906672596931458,\n",
      "                        0.9001434445381165,\n",
      "                        0.9097648859024048,\n",
      "                        0.9135891795158386,\n",
      "                        0.9161181449890137,\n",
      "                        0.9173949360847473,\n",
      "                        0.9177725315093994,\n",
      "                        0.9185546636581421,\n",
      "                        0.9184053540229797,\n",
      "                        0.9195746779441833,\n",
      "                        0.919878363609314,\n",
      "                        0.9203118681907654,\n",
      "                        0.9201622009277344,\n",
      "                        0.9209603667259216,\n",
      "                        0.9211809039115906,\n",
      "                        0.921055018901825,\n",
      "                        0.921262800693512,\n",
      "                        0.9212535619735718,\n",
      "                        0.9218763709068298],\n",
      "                       [0.8300567269325256,\n",
      "                        0.8913782835006714,\n",
      "                        0.8980588912963867,\n",
      "                        0.9053542613983154,\n",
      "                        0.911357581615448,\n",
      "                        0.9142324328422546,\n",
      "                        0.9165328741073608,\n",
      "                        0.9180981516838074,\n",
      "                        0.9184573292732239,\n",
      "                        0.9194045662879944,\n",
      "                        0.919725239276886,\n",
      "                        0.9189985990524292,\n",
      "                        0.9204753637313843,\n",
      "                        0.9207652807235718,\n",
      "                        0.9208062291145325,\n",
      "                        0.9209094047546387,\n",
      "                        0.9209395051002502,\n",
      "                        0.9210892915725708,\n",
      "                        0.9215201735496521,\n",
      "                        0.9216753840446472]],\n",
      " 'Training Loss': [[0.37592747807502747,\n",
      "                    0.25906991958618164,\n",
      "                    0.24075931310653687,\n",
      "                    0.22716131806373596,\n",
      "                    0.21349813044071198,\n",
      "                    0.2070857286453247,\n",
      "                    0.20348109304904938,\n",
      "                    0.19915771484375,\n",
      "                    0.19856475293636322,\n",
      "                    0.19530914723873138,\n",
      "                    0.19483843445777893,\n",
      "                    0.19376429915428162,\n",
      "                    0.19279760122299194,\n",
      "                    0.19132006168365479,\n",
      "                    0.18985730409622192,\n",
      "                    0.1895206719636917,\n",
      "                    0.19026467204093933,\n",
      "                    0.18891187012195587,\n",
      "                    0.18754126131534576,\n",
      "                    0.18848051130771637],\n",
      "                   [0.3968157172203064,\n",
      "                    0.256940096616745,\n",
      "                    0.24166196584701538,\n",
      "                    0.22726519405841827,\n",
      "                    0.2169458270072937,\n",
      "                    0.2132774442434311,\n",
      "                    0.20832891762256622,\n",
      "                    0.20581796765327454,\n",
      "                    0.2036372870206833,\n",
      "                    0.1998666375875473,\n",
      "                    0.1974104642868042,\n",
      "                    0.1951306164264679,\n",
      "                    0.19321942329406738,\n",
      "                    0.19359058141708374,\n",
      "                    0.19233408570289612,\n",
      "                    0.190551295876503,\n",
      "                    0.1902914047241211,\n",
      "                    0.19085581600666046,\n",
      "                    0.18993473052978516,\n",
      "                    0.1891496181488037],\n",
      "                   [0.3832331597805023,\n",
      "                    0.2500152885913849,\n",
      "                    0.23636901378631592,\n",
      "                    0.2233932763338089,\n",
      "                    0.21390092372894287,\n",
      "                    0.2082473486661911,\n",
      "                    0.20367993414402008,\n",
      "                    0.20019608736038208,\n",
      "                    0.1983855962753296,\n",
      "                    0.1959473043680191,\n",
      "                    0.1937762051820755,\n",
      "                    0.1921355426311493,\n",
      "                    0.19148406386375427,\n",
      "                    0.1900506317615509,\n",
      "                    0.18851137161254883,\n",
      "                    0.18750761449337006,\n",
      "                    0.18624623119831085,\n",
      "                    0.18554966151714325,\n",
      "                    0.186290442943573,\n",
      "                    0.18505799770355225],\n",
      "                   [0.38248953223228455,\n",
      "                    0.2509826719760895,\n",
      "                    0.22965389490127563,\n",
      "                    0.21049551665782928,\n",
      "                    0.20310816168785095,\n",
      "                    0.19772037863731384,\n",
      "                    0.19501160085201263,\n",
      "                    0.1941412091255188,\n",
      "                    0.19245293736457825,\n",
      "                    0.19232070446014404,\n",
      "                    0.1905023157596588,\n",
      "                    0.1896628886461258,\n",
      "                    0.18841275572776794,\n",
      "                    0.18864384293556213,\n",
      "                    0.18697598576545715,\n",
      "                    0.18681029975414276,\n",
      "                    0.18672585487365723,\n",
      "                    0.18611614406108856,\n",
      "                    0.18615415692329407,\n",
      "                    0.18480940163135529],\n",
      "                   [0.3604326844215393,\n",
      "                    0.24950288236141205,\n",
      "                    0.23354323208332062,\n",
      "                    0.21904069185256958,\n",
      "                    0.20748962461948395,\n",
      "                    0.2015838772058487,\n",
      "                    0.19673413038253784,\n",
      "                    0.1931910663843155,\n",
      "                    0.19258564710617065,\n",
      "                    0.19048909842967987,\n",
      "                    0.1896062195301056,\n",
      "                    0.19052106142044067,\n",
      "                    0.18766836822032928,\n",
      "                    0.1873902529478073,\n",
      "                    0.1871565580368042,\n",
      "                    0.18700432777404785,\n",
      "                    0.18675152957439423,\n",
      "                    0.18607012927532196,\n",
      "                    0.18563659489154816,\n",
      "                    0.18502672016620636]],\n",
      " 'Validation Accuracy': [[0.8874026536941528,\n",
      "                          0.8930453062057495,\n",
      "                          0.8967519402503967,\n",
      "                          0.90142422914505,\n",
      "                          0.9015493988990784,\n",
      "                          0.9143387675285339,\n",
      "                          0.9160985350608826,\n",
      "                          0.9169518947601318,\n",
      "                          0.916032075881958,\n",
      "                          0.9199868440628052,\n",
      "                          0.920394778251648,\n",
      "                          0.9194374084472656,\n",
      "                          0.9204720258712769,\n",
      "                          0.9221494197845459,\n",
      "                          0.921984076499939,\n",
      "                          0.9218641519546509,\n",
      "                          0.9212827086448669,\n",
      "                          0.9201787710189819,\n",
      "                          0.9230639934539795,\n",
      "                          0.9230508804321289],\n",
      "                         [0.8880721926689148,\n",
      "                          0.8894535303115845,\n",
      "                          0.8990934491157532,\n",
      "                          0.907357394695282,\n",
      "                          0.9102932810783386,\n",
      "                          0.9132001399993896,\n",
      "                          0.9132186770439148,\n",
      "                          0.9139014482498169,\n",
      "                          0.9162399768829346,\n",
      "                          0.9131760001182556,\n",
      "                          0.9201065301895142,\n",
      "                          0.9213598370552063,\n",
      "                          0.919610857963562,\n",
      "                          0.9223441481590271,\n",
      "                          0.9227199554443359,\n",
      "                          0.9227119088172913,\n",
      "                          0.9230319857597351,\n",
      "                          0.9198183417320251,\n",
      "                          0.9237145781517029,\n",
      "                          0.9226078987121582],\n",
      "                         [0.8861544728279114,\n",
      "                          0.8924161195755005,\n",
      "                          0.8981894254684448,\n",
      "                          0.904514491558075,\n",
      "                          0.9019680023193359,\n",
      "                          0.9091894626617432,\n",
      "                          0.9114428162574768,\n",
      "                          0.9120427370071411,\n",
      "                          0.9096373915672302,\n",
      "                          0.9137921333312988,\n",
      "                          0.915327787399292,\n",
      "                          0.9157708287239075,\n",
      "                          0.916597306728363,\n",
      "                          0.9160987138748169,\n",
      "                          0.9173575043678284,\n",
      "                          0.9167518615722656,\n",
      "                          0.9160080552101135,\n",
      "                          0.9190669059753418,\n",
      "                          0.9165707230567932,\n",
      "                          0.9192774891853333],\n",
      "                         [0.8854986429214478,\n",
      "                          0.8979868292808533,\n",
      "                          0.9087840914726257,\n",
      "                          0.9100613594055176,\n",
      "                          0.9166614413261414,\n",
      "                          0.9158694744110107,\n",
      "                          0.9178799390792847,\n",
      "                          0.9187732934951782,\n",
      "                          0.91648268699646,\n",
      "                          0.9197067022323608,\n",
      "                          0.9203948378562927,\n",
      "                          0.919709324836731,\n",
      "                          0.9204240441322327,\n",
      "                          0.9200053811073303,\n",
      "                          0.9219094514846802,\n",
      "                          0.9205681085586548,\n",
      "                          0.9213148355484009,\n",
      "                          0.9219199419021606,\n",
      "                          0.9221041798591614,\n",
      "                          0.9217333793640137],\n",
      "                         [0.8867999911308289,\n",
      "                          0.8929122090339661,\n",
      "                          0.9004214406013489,\n",
      "                          0.9024561643600464,\n",
      "                          0.9076959490776062,\n",
      "                          0.9118267297744751,\n",
      "                          0.9134960770606995,\n",
      "                          0.907050609588623,\n",
      "                          0.9165121912956238,\n",
      "                          0.9161866307258606,\n",
      "                          0.9170293807983398,\n",
      "                          0.916576087474823,\n",
      "                          0.9179626703262329,\n",
      "                          0.9177999496459961,\n",
      "                          0.9152533411979675,\n",
      "                          0.9187813401222229,\n",
      "                          0.9189521670341492,\n",
      "                          0.9175654053688049,\n",
      "                          0.9182961583137512,\n",
      "                          0.9183681011199951]],\n",
      " 'Validation Loss': [0.2593735456466675,\n",
      "                     0.24350972473621368,\n",
      "                     0.22869142889976501,\n",
      "                     0.22554254531860352,\n",
      "                     0.21448667347431183,\n",
      "                     0.2070314735174179,\n",
      "                     0.20137205719947815,\n",
      "                     0.2175081968307495,\n",
      "                     0.1953481286764145,\n",
      "                     0.19796542823314667,\n",
      "                     0.19408299028873444,\n",
      "                     0.19424544274806976,\n",
      "                     0.19178466498851776,\n",
      "                     0.1917884796857834,\n",
      "                     0.19789651036262512,\n",
      "                     0.19049596786499023,\n",
      "                     0.19048519432544708,\n",
      "                     0.19339413940906525,\n",
      "                     0.19191762804985046,\n",
      "                     0.19140049815177917],\n",
      " 'Validation MCC': [[np.float64(0.7744113309511859),\n",
      "                     np.float64(0.7860973024323503),\n",
      "                     np.float64(0.7944816104427191),\n",
      "                     np.float64(0.8040875544074635),\n",
      "                     np.float64(0.8088734092154231),\n",
      "                     np.float64(0.8286130573167207),\n",
      "                     np.float64(0.8322685308001966),\n",
      "                     np.float64(0.8344530010087379),\n",
      "                     np.float64(0.8321205314513253),\n",
      "                     np.float64(0.8400969061479241),\n",
      "                     np.float64(0.8405023657732295),\n",
      "                     np.float64(0.8384886290526301),\n",
      "                     np.float64(0.8405353694352359),\n",
      "                     np.float64(0.8440405643290283),\n",
      "                     np.float64(0.8435424685623455),\n",
      "                     np.float64(0.8446038389800054),\n",
      "                     np.float64(0.8421976092682756),\n",
      "                     np.float64(0.8402676242493927),\n",
      "                     np.float64(0.8457480107407137),\n",
      "                     np.float64(0.8463657037253322)],\n",
      "                    [np.float64(0.7754420236732993),\n",
      "                     np.float64(0.7815597081918885),\n",
      "                     np.float64(0.7981010916800947),\n",
      "                     np.float64(0.814179921700573),\n",
      "                     np.float64(0.8205136129140861),\n",
      "                     np.float64(0.825899035905251),\n",
      "                     np.float64(0.8259328599620135),\n",
      "                     np.float64(0.8276594386556829),\n",
      "                     np.float64(0.8337687956162999),\n",
      "                     np.float64(0.8270965675079107),\n",
      "                     np.float64(0.8399361542990751),\n",
      "                     np.float64(0.8425068050661905),\n",
      "                     np.float64(0.8388569542670463),\n",
      "                     np.float64(0.8442434623857824),\n",
      "                     np.float64(0.8452866837499002),\n",
      "                     np.float64(0.8459294810278928),\n",
      "                     np.float64(0.8460794667264294),\n",
      "                     np.float64(0.8395483486781588),\n",
      "                     np.float64(0.8473597453600479),\n",
      "                     np.float64(0.8447544958081246)],\n",
      "                    [np.float64(0.7715676547329698),\n",
      "                     np.float64(0.7850154828041687),\n",
      "                     np.float64(0.7959962963866736),\n",
      "                     np.float64(0.8083809926971027),\n",
      "                     np.float64(0.8044937717794084),\n",
      "                     np.float64(0.817764061371572),\n",
      "                     np.float64(0.8225930191043612),\n",
      "                     np.float64(0.8239204498995701),\n",
      "                     np.float64(0.8211056827055525),\n",
      "                     np.float64(0.8278952496476457),\n",
      "                     np.float64(0.8302212288799407),\n",
      "                     np.float64(0.8309364843681886),\n",
      "                     np.float64(0.8326076395666362),\n",
      "                     np.float64(0.833381414731874),\n",
      "                     np.float64(0.8341140573505135),\n",
      "                     np.float64(0.8346357323195774),\n",
      "                     np.float64(0.8333811681808548),\n",
      "                     np.float64(0.8379520361640429),\n",
      "                     np.float64(0.8345757697101182),\n",
      "                     np.float64(0.8389133560416987)],\n",
      "                    [np.float64(0.7718381431508824),\n",
      "                     np.float64(0.7959460711121982),\n",
      "                     np.float64(0.817118220575408),\n",
      "                     np.float64(0.8205254610433145),\n",
      "                     np.float64(0.8328438299835382),\n",
      "                     np.float64(0.8314023664168453),\n",
      "                     np.float64(0.8353248263303433),\n",
      "                     np.float64(0.8370812915633168),\n",
      "                     np.float64(0.8331002692434885),\n",
      "                     np.float64(0.8395565086605185),\n",
      "                     np.float64(0.8404708186824087),\n",
      "                     np.float64(0.8390855570747457),\n",
      "                     np.float64(0.8411845076810708),\n",
      "                     np.float64(0.8407776343003087),\n",
      "                     np.float64(0.843564830852167),\n",
      "                     np.float64(0.8408006950464064),\n",
      "                     np.float64(0.842873314650332),\n",
      "                     np.float64(0.8433859033195007),\n",
      "                     np.float64(0.8437503387635847),\n",
      "                     np.float64(0.8434451361065516)],\n",
      "                    [np.float64(0.772852112803335),\n",
      "                     np.float64(0.7850827535592367),\n",
      "                     np.float64(0.8001242255653628),\n",
      "                     np.float64(0.8069969093980103),\n",
      "                     np.float64(0.8152316752086508),\n",
      "                     np.float64(0.8246417888036611),\n",
      "                     np.float64(0.8267475108362455),\n",
      "                     np.float64(0.817335910061411),\n",
      "                     np.float64(0.8326564426589569),\n",
      "                     np.float64(0.833140473570567),\n",
      "                     np.float64(0.8334658426462219),\n",
      "                     np.float64(0.8326976994629536),\n",
      "                     np.float64(0.8353753810943643),\n",
      "                     np.float64(0.8350209896811419),\n",
      "                     np.float64(0.8321414430570451),\n",
      "                     np.float64(0.8371196504227901),\n",
      "                     np.float64(0.8374173666157546),\n",
      "                     np.float64(0.8360719365327338),\n",
      "                     np.float64(0.8370604582840451),\n",
      "                     np.float64(0.8361843377902796)]]}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi Models"
   ],
   "metadata": {
    "id": "Xg8M44vl8aN0",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Signal Multi\n",
    "\n",
    "model_results, trained_models = train_and_evaluate(simple_models_dict, X=signal_data_vec_multi, y=label_multi, epochs=20, basePath=basePath, dir_name='signal_multi')\n",
    "\n",
    "filePath = f\"{basePath}/Signal_Multi_Model_Results.json\"\n",
    "\n",
    "with open(filePath, 'w') as f:\n",
    "        json.dump(model_results, f, indent=4)  # indent=4 for pretty formatting"
   ],
   "metadata": {
    "id": "6zUENL6EbKQh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Hilbert Multi\n",
    "\n",
    "model_results, trained_models = train_and_evaluate(simple_models_dict, X=hilbert_data_vec_multi, y=label_multi, epochs=20, basePath=basePath, dir_name='hilbert_multi')\n",
    "\n",
    "filePath = f\"{basePath}/Hilbert_Multi_Model_Results.json\"\n",
    "\n",
    "with open(filePath, 'w') as f:\n",
    "        json.dump(model_results, f, indent=4)  # indent=4 for pretty formatting"
   ],
   "metadata": {
    "id": "FnIFQ0rbbLoP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# All Features Multi\n",
    "\n",
    "model_results, trained_models = train_and_evaluate(simple_models_dict, X=all_data_vec_multi, y=label_multi, epochs=20, batch_size=32, basePath=basePath, dir_name='allF_multi')\n",
    "\n",
    "filePath = f\"{basePath}/AllF_Multi_Model_Results.json\"\n",
    "\n",
    "with open(filePath, 'w') as f:\n",
    "        json.dump(model_results, f, indent=4)  # indent=4 for pretty formatting"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KgLlAmNO8wgl",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1744811040356,
     "user_tz": -120,
     "elapsed": 6415465,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     }
    },
    "outputId": "d878464e-042c-4ec0-a7d1-77a87fa37c9a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Binary: False\n",
      "Training Model: LSTM, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.6096 - loss: 1.0006\n",
      "Epoch 1 - MCC: 0.7467\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 25ms/step - accuracy: 0.6107 - loss: 0.9981 - val_accuracy: 0.8364 - val_loss: 0.4395 - mcc: 0.7467\n",
      "Epoch 2/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8435 - loss: 0.4336\n",
      "Epoch 2 - MCC: 0.7781\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.8435 - loss: 0.4336 - val_accuracy: 0.8555 - val_loss: 0.3975 - mcc: 0.7781\n",
      "Epoch 3/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8597 - loss: 0.3814\n",
      "Epoch 3 - MCC: 0.7984\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 19ms/step - accuracy: 0.8597 - loss: 0.3814 - val_accuracy: 0.8684 - val_loss: 0.3545 - mcc: 0.7984\n",
      "Epoch 4/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8671 - loss: 0.3587\n",
      "Epoch 4 - MCC: 0.7842\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 21ms/step - accuracy: 0.8671 - loss: 0.3588 - val_accuracy: 0.8600 - val_loss: 0.3877 - mcc: 0.7842\n",
      "Epoch 5/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8597 - loss: 0.3868\n",
      "Epoch 5 - MCC: 0.8067\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 27ms/step - accuracy: 0.8597 - loss: 0.3867 - val_accuracy: 0.8743 - val_loss: 0.3342 - mcc: 0.8067\n",
      "Epoch 6/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8672 - loss: 0.3548\n",
      "Epoch 6 - MCC: 0.7999\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.8672 - loss: 0.3549 - val_accuracy: 0.8692 - val_loss: 0.3534 - mcc: 0.7999\n",
      "Epoch 7/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8704 - loss: 0.3496\n",
      "Epoch 7 - MCC: 0.8126\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 21ms/step - accuracy: 0.8704 - loss: 0.3496 - val_accuracy: 0.8780 - val_loss: 0.3252 - mcc: 0.8126\n",
      "Epoch 8/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8741 - loss: 0.3331\n",
      "Epoch 8 - MCC: 0.8199\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.8741 - loss: 0.3331 - val_accuracy: 0.8825 - val_loss: 0.3074 - mcc: 0.8199\n",
      "Epoch 9/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8810 - loss: 0.3126\n",
      "Epoch 9 - MCC: 0.8132\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.8810 - loss: 0.3126 - val_accuracy: 0.8784 - val_loss: 0.3320 - mcc: 0.8132\n",
      "Epoch 10/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8801 - loss: 0.3249\n",
      "Epoch 10 - MCC: 0.8244\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.8801 - loss: 0.3249 - val_accuracy: 0.8856 - val_loss: 0.3038 - mcc: 0.8244\n",
      "Epoch 11/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8812 - loss: 0.3166\n",
      "Epoch 11 - MCC: 0.8112\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 22ms/step - accuracy: 0.8812 - loss: 0.3168 - val_accuracy: 0.8772 - val_loss: 0.3326 - mcc: 0.8112\n",
      "Epoch 12/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8770 - loss: 0.3284\n",
      "Epoch 12 - MCC: 0.8233\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.8770 - loss: 0.3283 - val_accuracy: 0.8844 - val_loss: 0.3014 - mcc: 0.8233\n",
      "Epoch 13/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8847 - loss: 0.3004\n",
      "Epoch 13 - MCC: 0.8319\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 22ms/step - accuracy: 0.8847 - loss: 0.3004 - val_accuracy: 0.8903 - val_loss: 0.2841 - mcc: 0.8319\n",
      "Epoch 14/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8830 - loss: 0.3106\n",
      "Epoch 14 - MCC: 0.8252\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.8830 - loss: 0.3108 - val_accuracy: 0.8857 - val_loss: 0.2995 - mcc: 0.8252\n",
      "Epoch 15/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8865 - loss: 0.2979\n",
      "Epoch 15 - MCC: 0.8271\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.8865 - loss: 0.2979 - val_accuracy: 0.8866 - val_loss: 0.2989 - mcc: 0.8271\n",
      "Epoch 16/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8900 - loss: 0.2863\n",
      "Epoch 16 - MCC: 0.8386\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 24ms/step - accuracy: 0.8900 - loss: 0.2863 - val_accuracy: 0.8945 - val_loss: 0.2725 - mcc: 0.8386\n",
      "Epoch 17/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8909 - loss: 0.2815\n",
      "Epoch 17 - MCC: 0.8405\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 23ms/step - accuracy: 0.8909 - loss: 0.2814 - val_accuracy: 0.8957 - val_loss: 0.2696 - mcc: 0.8405\n",
      "Epoch 18/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8932 - loss: 0.2733\n",
      "Epoch 18 - MCC: 0.8415\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.8932 - loss: 0.2732 - val_accuracy: 0.8964 - val_loss: 0.2657 - mcc: 0.8415\n",
      "Epoch 19/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8958 - loss: 0.2662\n",
      "Epoch 19 - MCC: 0.8441\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 22ms/step - accuracy: 0.8958 - loss: 0.2661 - val_accuracy: 0.8982 - val_loss: 0.2605 - mcc: 0.8441\n",
      "Epoch 20/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8962 - loss: 0.2648\n",
      "Epoch 20 - MCC: 0.8456\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 25ms/step - accuracy: 0.8963 - loss: 0.2648 - val_accuracy: 0.8991 - val_loss: 0.2562 - mcc: 0.8456\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.6647 - loss: 0.9030\n",
      "Epoch 1 - MCC: 0.7715\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 24ms/step - accuracy: 0.6652 - loss: 0.9015 - val_accuracy: 0.8516 - val_loss: 0.4129 - mcc: 0.7715\n",
      "Epoch 2/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8503 - loss: 0.4071\n",
      "Epoch 2 - MCC: 0.7947\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 23ms/step - accuracy: 0.8504 - loss: 0.4070 - val_accuracy: 0.8670 - val_loss: 0.3590 - mcc: 0.7947\n",
      "Epoch 3/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8686 - loss: 0.3514\n",
      "Epoch 3 - MCC: 0.8124\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 21ms/step - accuracy: 0.8686 - loss: 0.3513 - val_accuracy: 0.8783 - val_loss: 0.3222 - mcc: 0.8124\n",
      "Epoch 4/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8755 - loss: 0.3302\n",
      "Epoch 4 - MCC: 0.8176\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.8755 - loss: 0.3301 - val_accuracy: 0.8811 - val_loss: 0.3115 - mcc: 0.8176\n",
      "Epoch 5/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8786 - loss: 0.3168\n",
      "Epoch 5 - MCC: 0.8209\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 25ms/step - accuracy: 0.8787 - loss: 0.3167 - val_accuracy: 0.8833 - val_loss: 0.3081 - mcc: 0.8209\n",
      "Epoch 6/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8854 - loss: 0.2979\n",
      "Epoch 6 - MCC: 0.8286\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 21ms/step - accuracy: 0.8854 - loss: 0.2979 - val_accuracy: 0.8883 - val_loss: 0.2881 - mcc: 0.8286\n",
      "Epoch 7/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8863 - loss: 0.2912\n",
      "Epoch 7 - MCC: 0.8295\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 20ms/step - accuracy: 0.8863 - loss: 0.2912 - val_accuracy: 0.8894 - val_loss: 0.2832 - mcc: 0.8295\n",
      "Epoch 8/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8906 - loss: 0.2809\n",
      "Epoch 8 - MCC: 0.8386\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.8906 - loss: 0.2809 - val_accuracy: 0.8950 - val_loss: 0.2686 - mcc: 0.8386\n",
      "Epoch 9/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8926 - loss: 0.2727\n",
      "Epoch 9 - MCC: 0.8421\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 23ms/step - accuracy: 0.8927 - loss: 0.2726 - val_accuracy: 0.8972 - val_loss: 0.2642 - mcc: 0.8421\n",
      "Epoch 10/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8942 - loss: 0.2706\n",
      "Epoch 10 - MCC: 0.8442\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 21ms/step - accuracy: 0.8942 - loss: 0.2706 - val_accuracy: 0.8986 - val_loss: 0.2593 - mcc: 0.8442\n",
      "Epoch 11/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8968 - loss: 0.2633\n",
      "Epoch 11 - MCC: 0.8457\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 25ms/step - accuracy: 0.8968 - loss: 0.2633 - val_accuracy: 0.8996 - val_loss: 0.2579 - mcc: 0.8457\n",
      "Epoch 12/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8972 - loss: 0.2617\n",
      "Epoch 12 - MCC: 0.8494\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.8972 - loss: 0.2617 - val_accuracy: 0.9018 - val_loss: 0.2507 - mcc: 0.8494\n",
      "Epoch 13/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8997 - loss: 0.2539\n",
      "Epoch 13 - MCC: 0.8378\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.8997 - loss: 0.2539 - val_accuracy: 0.8941 - val_loss: 0.2791 - mcc: 0.8378\n",
      "Epoch 14/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8985 - loss: 0.2575\n",
      "Epoch 14 - MCC: 0.8474\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 23ms/step - accuracy: 0.8985 - loss: 0.2574 - val_accuracy: 0.9006 - val_loss: 0.2539 - mcc: 0.8474\n",
      "Epoch 15/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9018 - loss: 0.2487\n",
      "Epoch 15 - MCC: 0.8133\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 24ms/step - accuracy: 0.9018 - loss: 0.2487 - val_accuracy: 0.8793 - val_loss: 0.3251 - mcc: 0.8133\n",
      "Epoch 16/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8961 - loss: 0.2642\n",
      "Epoch 16 - MCC: 0.8548\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 23ms/step - accuracy: 0.8961 - loss: 0.2642 - val_accuracy: 0.9055 - val_loss: 0.2388 - mcc: 0.8548\n",
      "Epoch 17/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9028 - loss: 0.2450\n",
      "Epoch 17 - MCC: 0.8520\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 21ms/step - accuracy: 0.9028 - loss: 0.2450 - val_accuracy: 0.9038 - val_loss: 0.2442 - mcc: 0.8520\n",
      "Epoch 18/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9040 - loss: 0.2417\n",
      "Epoch 18 - MCC: 0.8530\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 23ms/step - accuracy: 0.9040 - loss: 0.2417 - val_accuracy: 0.9044 - val_loss: 0.2415 - mcc: 0.8530\n",
      "Epoch 19/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9049 - loss: 0.2388\n",
      "Epoch 19 - MCC: 0.8543\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.9049 - loss: 0.2388 - val_accuracy: 0.9048 - val_loss: 0.2396 - mcc: 0.8543\n",
      "Epoch 20/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9069 - loss: 0.2326\n",
      "Epoch 20 - MCC: 0.8597\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.9069 - loss: 0.2326 - val_accuracy: 0.9085 - val_loss: 0.2300 - mcc: 0.8597\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6675 - loss: 0.8877\n",
      "Epoch 1 - MCC: 0.7673\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 28ms/step - accuracy: 0.6678 - loss: 0.8870 - val_accuracy: 0.8485 - val_loss: 0.4138 - mcc: 0.7673\n",
      "Epoch 2/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8517 - loss: 0.4031\n",
      "Epoch 2 - MCC: 0.7896\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 20ms/step - accuracy: 0.8517 - loss: 0.4031 - val_accuracy: 0.8618 - val_loss: 0.3707 - mcc: 0.7896\n",
      "Epoch 3/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8656 - loss: 0.3593\n",
      "Epoch 3 - MCC: 0.8014\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 24ms/step - accuracy: 0.8656 - loss: 0.3592 - val_accuracy: 0.8709 - val_loss: 0.3365 - mcc: 0.8014\n",
      "Epoch 4/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8739 - loss: 0.3293\n",
      "Epoch 4 - MCC: 0.8107\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 24ms/step - accuracy: 0.8739 - loss: 0.3293 - val_accuracy: 0.8751 - val_loss: 0.3200 - mcc: 0.8107\n",
      "Epoch 5/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8764 - loss: 0.3189\n",
      "Epoch 5 - MCC: 0.8198\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 23ms/step - accuracy: 0.8764 - loss: 0.3189 - val_accuracy: 0.8819 - val_loss: 0.3036 - mcc: 0.8198\n",
      "Epoch 6/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8829 - loss: 0.2995\n",
      "Epoch 6 - MCC: 0.8209\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.8829 - loss: 0.2995 - val_accuracy: 0.8833 - val_loss: 0.2982 - mcc: 0.8209\n",
      "Epoch 7/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8799 - loss: 0.3125\n",
      "Epoch 7 - MCC: 0.8193\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 25ms/step - accuracy: 0.8799 - loss: 0.3126 - val_accuracy: 0.8821 - val_loss: 0.3140 - mcc: 0.8193\n",
      "Epoch 8/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8798 - loss: 0.3234\n",
      "Epoch 8 - MCC: 0.8262\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 22ms/step - accuracy: 0.8798 - loss: 0.3234 - val_accuracy: 0.8861 - val_loss: 0.2940 - mcc: 0.8262\n",
      "Epoch 9/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8885 - loss: 0.2893\n",
      "Epoch 9 - MCC: 0.8331\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 19ms/step - accuracy: 0.8885 - loss: 0.2893 - val_accuracy: 0.8909 - val_loss: 0.2800 - mcc: 0.8331\n",
      "Epoch 10/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8911 - loss: 0.2804\n",
      "Epoch 10 - MCC: 0.8339\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.8911 - loss: 0.2804 - val_accuracy: 0.8916 - val_loss: 0.2775 - mcc: 0.8339\n",
      "Epoch 11/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8935 - loss: 0.2733\n",
      "Epoch 11 - MCC: 0.8388\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 21ms/step - accuracy: 0.8935 - loss: 0.2733 - val_accuracy: 0.8945 - val_loss: 0.2694 - mcc: 0.8388\n",
      "Epoch 12/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8947 - loss: 0.2686\n",
      "Epoch 12 - MCC: 0.8417\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.8947 - loss: 0.2686 - val_accuracy: 0.8964 - val_loss: 0.2642 - mcc: 0.8417\n",
      "Epoch 13/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8968 - loss: 0.2644\n",
      "Epoch 13 - MCC: 0.8421\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 25ms/step - accuracy: 0.8968 - loss: 0.2644 - val_accuracy: 0.8967 - val_loss: 0.2620 - mcc: 0.8421\n",
      "Epoch 14/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8970 - loss: 0.2614\n",
      "Epoch 14 - MCC: 0.8458\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.8970 - loss: 0.2613 - val_accuracy: 0.8993 - val_loss: 0.2562 - mcc: 0.8458\n",
      "Epoch 15/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8985 - loss: 0.2595\n",
      "Epoch 15 - MCC: 0.8445\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.8985 - loss: 0.2594 - val_accuracy: 0.8984 - val_loss: 0.2574 - mcc: 0.8445\n",
      "Epoch 16/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9011 - loss: 0.2514\n",
      "Epoch 16 - MCC: 0.8491\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 22ms/step - accuracy: 0.9011 - loss: 0.2515 - val_accuracy: 0.9014 - val_loss: 0.2492 - mcc: 0.8491\n",
      "Epoch 17/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9016 - loss: 0.2486\n",
      "Epoch 17 - MCC: 0.8483\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.9016 - loss: 0.2486 - val_accuracy: 0.9006 - val_loss: 0.2523 - mcc: 0.8483\n",
      "Epoch 18/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9021 - loss: 0.2482\n",
      "Epoch 18 - MCC: 0.8511\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 21ms/step - accuracy: 0.9021 - loss: 0.2482 - val_accuracy: 0.9026 - val_loss: 0.2472 - mcc: 0.8511\n",
      "Epoch 19/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9025 - loss: 0.2476\n",
      "Epoch 19 - MCC: 0.8529\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 20ms/step - accuracy: 0.9025 - loss: 0.2476 - val_accuracy: 0.9033 - val_loss: 0.2433 - mcc: 0.8529\n",
      "Epoch 20/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9061 - loss: 0.2392\n",
      "Epoch 20 - MCC: 0.8549\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 26ms/step - accuracy: 0.9061 - loss: 0.2392 - val_accuracy: 0.9050 - val_loss: 0.2382 - mcc: 0.8549\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.6502 - loss: 0.9320\n",
      "Epoch 1 - MCC: 0.7571\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 24ms/step - accuracy: 0.6514 - loss: 0.9290 - val_accuracy: 0.8440 - val_loss: 0.4262 - mcc: 0.7571\n",
      "Epoch 2/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8521 - loss: 0.4062\n",
      "Epoch 2 - MCC: 0.7892\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 24ms/step - accuracy: 0.8521 - loss: 0.4061 - val_accuracy: 0.8623 - val_loss: 0.3710 - mcc: 0.7892\n",
      "Epoch 3/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8683 - loss: 0.3508\n",
      "Epoch 3 - MCC: 0.8050\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 24ms/step - accuracy: 0.8683 - loss: 0.3508 - val_accuracy: 0.8723 - val_loss: 0.3365 - mcc: 0.8050\n",
      "Epoch 4/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8775 - loss: 0.3219\n",
      "Epoch 4 - MCC: 0.8187\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 23ms/step - accuracy: 0.8775 - loss: 0.3219 - val_accuracy: 0.8811 - val_loss: 0.3079 - mcc: 0.8187\n",
      "Epoch 5/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8824 - loss: 0.3048\n",
      "Epoch 5 - MCC: 0.8267\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.8824 - loss: 0.3048 - val_accuracy: 0.8869 - val_loss: 0.2931 - mcc: 0.8267\n",
      "Epoch 6/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8890 - loss: 0.2874\n",
      "Epoch 6 - MCC: 0.8318\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 25ms/step - accuracy: 0.8890 - loss: 0.2873 - val_accuracy: 0.8903 - val_loss: 0.2838 - mcc: 0.8318\n",
      "Epoch 7/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8918 - loss: 0.2781\n",
      "Epoch 7 - MCC: 0.8265\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.8918 - loss: 0.2781 - val_accuracy: 0.8875 - val_loss: 0.2947 - mcc: 0.8265\n",
      "Epoch 8/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8918 - loss: 0.2795\n",
      "Epoch 8 - MCC: 0.8392\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 20ms/step - accuracy: 0.8918 - loss: 0.2795 - val_accuracy: 0.8953 - val_loss: 0.2716 - mcc: 0.8392\n",
      "Epoch 9/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8945 - loss: 0.2699\n",
      "Epoch 9 - MCC: 0.8355\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.8945 - loss: 0.2699 - val_accuracy: 0.8913 - val_loss: 0.2782 - mcc: 0.8355\n",
      "Epoch 10/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8903 - loss: 0.2838\n",
      "Epoch 10 - MCC: 0.8376\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.8903 - loss: 0.2838 - val_accuracy: 0.8946 - val_loss: 0.2744 - mcc: 0.8376\n",
      "Epoch 11/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8962 - loss: 0.2666\n",
      "Epoch 11 - MCC: 0.8410\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.8962 - loss: 0.2666 - val_accuracy: 0.8965 - val_loss: 0.2668 - mcc: 0.8410\n",
      "Epoch 12/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8964 - loss: 0.2652\n",
      "Epoch 12 - MCC: 0.8440\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 25ms/step - accuracy: 0.8964 - loss: 0.2651 - val_accuracy: 0.8977 - val_loss: 0.2629 - mcc: 0.8440\n",
      "Epoch 13/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8985 - loss: 0.2581\n",
      "Epoch 13 - MCC: 0.8432\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 24ms/step - accuracy: 0.8985 - loss: 0.2581 - val_accuracy: 0.8980 - val_loss: 0.2617 - mcc: 0.8432\n",
      "Epoch 14/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9000 - loss: 0.2535\n",
      "Epoch 14 - MCC: 0.8409\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 21ms/step - accuracy: 0.9000 - loss: 0.2535 - val_accuracy: 0.8960 - val_loss: 0.2676 - mcc: 0.8409\n",
      "Epoch 15/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9014 - loss: 0.2499\n",
      "Epoch 15 - MCC: 0.8473\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 22ms/step - accuracy: 0.9014 - loss: 0.2499 - val_accuracy: 0.9008 - val_loss: 0.2530 - mcc: 0.8473\n",
      "Epoch 16/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9002 - loss: 0.2538\n",
      "Epoch 16 - MCC: 0.8442\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 24ms/step - accuracy: 0.9002 - loss: 0.2537 - val_accuracy: 0.8989 - val_loss: 0.2608 - mcc: 0.8442\n",
      "Epoch 17/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9010 - loss: 0.2540\n",
      "Epoch 17 - MCC: 0.8480\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 24ms/step - accuracy: 0.9010 - loss: 0.2540 - val_accuracy: 0.9000 - val_loss: 0.2528 - mcc: 0.8480\n",
      "Epoch 18/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9024 - loss: 0.2455\n",
      "Epoch 18 - MCC: 0.8490\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.9024 - loss: 0.2455 - val_accuracy: 0.9015 - val_loss: 0.2521 - mcc: 0.8490\n",
      "Epoch 19/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9056 - loss: 0.2378\n",
      "Epoch 19 - MCC: 0.8519\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 22ms/step - accuracy: 0.9056 - loss: 0.2378 - val_accuracy: 0.9034 - val_loss: 0.2466 - mcc: 0.8519\n",
      "Epoch 20/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9051 - loss: 0.2392\n",
      "Epoch 20 - MCC: 0.8512\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 25ms/step - accuracy: 0.9051 - loss: 0.2392 - val_accuracy: 0.9031 - val_loss: 0.2471 - mcc: 0.8512\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.6477 - loss: 0.9196\n",
      "Epoch 1 - MCC: 0.7563\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 24ms/step - accuracy: 0.6490 - loss: 0.9166 - val_accuracy: 0.8422 - val_loss: 0.4285 - mcc: 0.7563\n",
      "Epoch 2/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8500 - loss: 0.4062\n",
      "Epoch 2 - MCC: 0.7872\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.8500 - loss: 0.4060 - val_accuracy: 0.8607 - val_loss: 0.3723 - mcc: 0.7872\n",
      "Epoch 3/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8670 - loss: 0.3565\n",
      "Epoch 3 - MCC: 0.8003\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 23ms/step - accuracy: 0.8670 - loss: 0.3565 - val_accuracy: 0.8703 - val_loss: 0.3454 - mcc: 0.8003\n",
      "Epoch 4/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8744 - loss: 0.3350\n",
      "Epoch 4 - MCC: 0.8106\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 21ms/step - accuracy: 0.8744 - loss: 0.3349 - val_accuracy: 0.8767 - val_loss: 0.3238 - mcc: 0.8106\n",
      "Epoch 5/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8818 - loss: 0.3108\n",
      "Epoch 5 - MCC: 0.8172\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 21ms/step - accuracy: 0.8818 - loss: 0.3108 - val_accuracy: 0.8808 - val_loss: 0.3114 - mcc: 0.8172\n",
      "Epoch 6/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8848 - loss: 0.3022\n",
      "Epoch 6 - MCC: 0.8228\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.8848 - loss: 0.3022 - val_accuracy: 0.8843 - val_loss: 0.2990 - mcc: 0.8228\n",
      "Epoch 7/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8874 - loss: 0.2937\n",
      "Epoch 7 - MCC: 0.8138\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 22ms/step - accuracy: 0.8874 - loss: 0.2938 - val_accuracy: 0.8784 - val_loss: 0.3251 - mcc: 0.8138\n",
      "Epoch 8/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8867 - loss: 0.3003\n",
      "Epoch 8 - MCC: 0.8292\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 20ms/step - accuracy: 0.8867 - loss: 0.3002 - val_accuracy: 0.8883 - val_loss: 0.2874 - mcc: 0.8292\n",
      "Epoch 9/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8934 - loss: 0.2734\n",
      "Epoch 9 - MCC: 0.8345\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.8934 - loss: 0.2734 - val_accuracy: 0.8918 - val_loss: 0.2790 - mcc: 0.8345\n",
      "Epoch 10/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8942 - loss: 0.2734\n",
      "Epoch 10 - MCC: 0.8377\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.8942 - loss: 0.2734 - val_accuracy: 0.8938 - val_loss: 0.2706 - mcc: 0.8377\n",
      "Epoch 11/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8952 - loss: 0.2695\n",
      "Epoch 11 - MCC: 0.8392\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 23ms/step - accuracy: 0.8952 - loss: 0.2695 - val_accuracy: 0.8941 - val_loss: 0.2679 - mcc: 0.8392\n",
      "Epoch 12/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8999 - loss: 0.2575\n",
      "Epoch 12 - MCC: 0.8417\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.8999 - loss: 0.2575 - val_accuracy: 0.8964 - val_loss: 0.2621 - mcc: 0.8417\n",
      "Epoch 13/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9002 - loss: 0.2525\n",
      "Epoch 13 - MCC: 0.8414\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 25ms/step - accuracy: 0.9002 - loss: 0.2524 - val_accuracy: 0.8957 - val_loss: 0.2614 - mcc: 0.8414\n",
      "Epoch 14/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9032 - loss: 0.2454\n",
      "Epoch 14 - MCC: 0.8444\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 22ms/step - accuracy: 0.9032 - loss: 0.2454 - val_accuracy: 0.8985 - val_loss: 0.2546 - mcc: 0.8444\n",
      "Epoch 15/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9017 - loss: 0.2476\n",
      "Epoch 15 - MCC: 0.8479\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 22ms/step - accuracy: 0.9017 - loss: 0.2475 - val_accuracy: 0.9006 - val_loss: 0.2493 - mcc: 0.8479\n",
      "Epoch 16/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9046 - loss: 0.2410\n",
      "Epoch 16 - MCC: 0.8470\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.9046 - loss: 0.2410 - val_accuracy: 0.9002 - val_loss: 0.2499 - mcc: 0.8470\n",
      "Epoch 17/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9057 - loss: 0.2389\n",
      "Epoch 17 - MCC: 0.8492\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 26ms/step - accuracy: 0.9057 - loss: 0.2389 - val_accuracy: 0.9012 - val_loss: 0.2475 - mcc: 0.8492\n",
      "Epoch 18/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9063 - loss: 0.2363\n",
      "Epoch 18 - MCC: 0.8501\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 22ms/step - accuracy: 0.9062 - loss: 0.2363 - val_accuracy: 0.9016 - val_loss: 0.2468 - mcc: 0.8501\n",
      "Epoch 19/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9068 - loss: 0.2351\n",
      "Epoch 19 - MCC: 0.8532\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.9068 - loss: 0.2351 - val_accuracy: 0.9040 - val_loss: 0.2410 - mcc: 0.8532\n",
      "Epoch 20/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9057 - loss: 0.2380\n",
      "Epoch 20 - MCC: 0.8517\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 23ms/step - accuracy: 0.9057 - loss: 0.2380 - val_accuracy: 0.9026 - val_loss: 0.2424 - mcc: 0.8517\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.9084666666666666),\n",
      "              'mean': np.float64(0.9036439999999999),\n",
      "              'min': np.float64(0.8990846666666666),\n",
      "              'std': np.float64(0.003079688526819269)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.0005574920177459717),\n",
      "                               'mean': np.float64(0.00046562064488728846),\n",
      "                               'min': np.float64(0.0003677686850229899),\n",
      "                               'std': np.float64(7.874628188519644e-05)},\n",
      " 'MCC': {'max': np.float64(0.859671690724848),\n",
      "         'mean': np.float64(0.8526011931412715),\n",
      "         'min': np.float64(0.8455805258645844),\n",
      "         'std': np.float64(0.004630467464291094)},\n",
      " 'Parameters': 7589,\n",
      " 'Train Time (s)': {'max': np.float64(198.69395470619202),\n",
      "                    'mean': np.float64(192.6044086456299),\n",
      "                    'min': np.float64(186.740642786026),\n",
      "                    'std': np.float64(3.8465122418402267)},\n",
      " 'Training Accuracy': [[0.7462956309318542,\n",
      "                        0.8466732501983643,\n",
      "                        0.863034188747406,\n",
      "                        0.8626267313957214,\n",
      "                        0.8651708960533142,\n",
      "                        0.8645397424697876,\n",
      "                        0.8719282746315002,\n",
      "                        0.8759914636611938,\n",
      "                        0.8790651559829712,\n",
      "                        0.8801520466804504,\n",
      "                        0.8767532706260681,\n",
      "                        0.8795436024665833,\n",
      "                        0.8854790329933167,\n",
      "                        0.8790440559387207,\n",
      "                        0.8871526718139648,\n",
      "                        0.8902146816253662,\n",
      "                        0.8927656412124634,\n",
      "                        0.8942278623580933,\n",
      "                        0.8959806561470032,\n",
      "                        0.8971893191337585],\n",
      "                       [0.7705568671226501,\n",
      "                        0.8556790947914124,\n",
      "                        0.8708906173706055,\n",
      "                        0.8766443133354187,\n",
      "                        0.8813300728797913,\n",
      "                        0.8852896094322205,\n",
      "                        0.8885223865509033,\n",
      "                        0.8892381191253662,\n",
      "                        0.8933067917823792,\n",
      "                        0.8940404653549194,\n",
      "                        0.8966164588928223,\n",
      "                        0.8983237147331238,\n",
      "                        0.899245023727417,\n",
      "                        0.8996025919914246,\n",
      "                        0.9013547897338867,\n",
      "                        0.9000166654586792,\n",
      "                        0.9017134308815002,\n",
      "                        0.9036254286766052,\n",
      "                        0.9049484729766846,\n",
      "                        0.9053351283073425],\n",
      "                       [0.7713965773582458,\n",
      "                        0.8551399111747742,\n",
      "                        0.8670856952667236,\n",
      "                        0.873927891254425,\n",
      "                        0.877919614315033,\n",
      "                        0.8840398788452148,\n",
      "                        0.875627875328064,\n",
      "                        0.8821176886558533,\n",
      "                        0.889211893081665,\n",
      "                        0.8914180397987366,\n",
      "                        0.8931193947792053,\n",
      "                        0.8954132199287415,\n",
      "                        0.8965001702308655,\n",
      "                        0.8984334468841553,\n",
      "                        0.8998444080352783,\n",
      "                        0.9009964466094971,\n",
      "                        0.9022354483604431,\n",
      "                        0.9031459093093872,\n",
      "                        0.9033428430557251,\n",
      "                        0.9048144817352295],\n",
      "                       [0.7627387642860413,\n",
      "                        0.8565779328346252,\n",
      "                        0.869292140007019,\n",
      "                        0.8789334893226624,\n",
      "                        0.8842505812644958,\n",
      "                        0.8891035914421082,\n",
      "                        0.891671359539032,\n",
      "                        0.8930455446243286,\n",
      "                        0.8948695659637451,\n",
      "                        0.8908002972602844,\n",
      "                        0.8964137434959412,\n",
      "                        0.8980737328529358,\n",
      "                        0.8992452621459961,\n",
      "                        0.8995397686958313,\n",
      "                        0.9012176990509033,\n",
      "                        0.9020178914070129,\n",
      "                        0.9019157886505127,\n",
      "                        0.9035248756408691,\n",
      "                        0.9039230942726135,\n",
      "                        0.9045926928520203],\n",
      "                       [0.7648735642433167,\n",
      "                        0.855830729007721,\n",
      "                        0.8695158958435059,\n",
      "                        0.8771204948425293,\n",
      "                        0.8827429413795471,\n",
      "                        0.8850197792053223,\n",
      "                        0.8852993249893188,\n",
      "                        0.8884558081626892,\n",
      "                        0.8933579921722412,\n",
      "                        0.8948889970779419,\n",
      "                        0.8947943449020386,\n",
      "                        0.8988146185874939,\n",
      "                        0.9007180333137512,\n",
      "                        0.9024357199668884,\n",
      "                        0.9030423164367676,\n",
      "                        0.9044126272201538,\n",
      "                        0.905106782913208,\n",
      "                        0.9059323668479919,\n",
      "                        0.906319797039032,\n",
      "                        0.9070104360580444]],\n",
      " 'Training Loss': [[0.687537431716919,\n",
      "                    0.42224064469337463,\n",
      "                    0.3710913360118866,\n",
      "                    0.37415438890457153,\n",
      "                    0.3661823868751526,\n",
      "                    0.36766231060028076,\n",
      "                    0.3439878821372986,\n",
      "                    0.32809969782829285,\n",
      "                    0.32013002038002014,\n",
      "                    0.3228170573711395,\n",
      "                    0.33059412240982056,\n",
      "                    0.31953009963035583,\n",
      "                    0.2975234389305115,\n",
      "                    0.3248973488807678,\n",
      "                    0.2943088710308075,\n",
      "                    0.2848820090293884,\n",
      "                    0.2761954665184021,\n",
      "                    0.27104464173316956,\n",
      "                    0.2649793326854706,\n",
      "                    0.2617904543876648],\n",
      "                   [0.6322451829910278,\n",
      "                    0.3905431032180786,\n",
      "                    0.3444836139678955,\n",
      "                    0.3255617320537567,\n",
      "                    0.3095453083515167,\n",
      "                    0.2973809838294983,\n",
      "                    0.28627464175224304,\n",
      "                    0.2851772606372833,\n",
      "                    0.27183398604393005,\n",
      "                    0.270591139793396,\n",
      "                    0.262764036655426,\n",
      "                    0.2576617896556854,\n",
      "                    0.25484123826026917,\n",
      "                    0.25418928265571594,\n",
      "                    0.2490590214729309,\n",
      "                    0.2528597414493561,\n",
      "                    0.24840281903743744,\n",
      "                    0.2426517754793167,\n",
      "                    0.2382083684206009,\n",
      "                    0.23650425672531128],\n",
      "                   [0.6243064403533936,\n",
      "                    0.3912043571472168,\n",
      "                    0.35206785798072815,\n",
      "                    0.32719123363494873,\n",
      "                    0.31585612893104553,\n",
      "                    0.29724669456481934,\n",
      "                    0.3293771743774414,\n",
      "                    0.31402355432510376,\n",
      "                    0.28716427087783813,\n",
      "                    0.28036201000213623,\n",
      "                    0.27416154742240906,\n",
      "                    0.267805814743042,\n",
      "                    0.26493677496910095,\n",
      "                    0.2596735954284668,\n",
      "                    0.25613969564437866,\n",
      "                    0.25235211849212646,\n",
      "                    0.24806886911392212,\n",
      "                    0.24563731253147125,\n",
      "                    0.24516725540161133,\n",
      "                    0.2410687506198883],\n",
      "                   [0.6487300395965576,\n",
      "                    0.3903787136077881,\n",
      "                    0.3472040295600891,\n",
      "                    0.31731852889060974,\n",
      "                    0.30037063360214233,\n",
      "                    0.2866639196872711,\n",
      "                    0.27846935391426086,\n",
      "                    0.2746566832065582,\n",
      "                    0.2687632739543915,\n",
      "                    0.2838000953197479,\n",
      "                    0.2659848928451538,\n",
      "                    0.25996479392051697,\n",
      "                    0.2567494809627533,\n",
      "                    0.2552701532840729,\n",
      "                    0.2504939138889313,\n",
      "                    0.24819384515285492,\n",
      "                    0.24945397675037384,\n",
      "                    0.2430385798215866,\n",
      "                    0.24091936647891998,\n",
      "                    0.2401675432920456],\n",
      "                   [0.6346379518508911,\n",
      "                    0.3900948166847229,\n",
      "                    0.3491707742214203,\n",
      "                    0.3265214264392853,\n",
      "                    0.30860936641693115,\n",
      "                    0.3018229305744171,\n",
      "                    0.3019576072692871,\n",
      "                    0.2922998368740082,\n",
      "                    0.2745590806007385,\n",
      "                    0.27001476287841797,\n",
      "                    0.27179476618766785,\n",
      "                    0.2590372860431671,\n",
      "                    0.2519665062427521,\n",
      "                    0.24706600606441498,\n",
      "                    0.2447439730167389,\n",
      "                    0.2411917746067047,\n",
      "                    0.23955678939819336,\n",
      "                    0.23762674629688263,\n",
      "                    0.23612374067306519,\n",
      "                    0.2343652993440628]],\n",
      " 'Validation Accuracy': [[0.8363633751869202,\n",
      "                          0.8554605841636658,\n",
      "                          0.8684192895889282,\n",
      "                          0.8600319623947144,\n",
      "                          0.8743432760238647,\n",
      "                          0.8691932559013367,\n",
      "                          0.8780470490455627,\n",
      "                          0.8824750781059265,\n",
      "                          0.8783948421478271,\n",
      "                          0.8855524659156799,\n",
      "                          0.8771973252296448,\n",
      "                          0.8844059109687805,\n",
      "                          0.8903260231018066,\n",
      "                          0.8856922388076782,\n",
      "                          0.8865544199943542,\n",
      "                          0.8945419788360596,\n",
      "                          0.8956565856933594,\n",
      "                          0.8964128494262695,\n",
      "                          0.8982481360435486,\n",
      "                          0.8990849852561951],\n",
      "                         [0.8516313433647156,\n",
      "                          0.8669759631156921,\n",
      "                          0.8783426284790039,\n",
      "                          0.8810704946517944,\n",
      "                          0.883286714553833,\n",
      "                          0.8883008360862732,\n",
      "                          0.8894280791282654,\n",
      "                          0.8949939608573914,\n",
      "                          0.8971887230873108,\n",
      "                          0.8985734581947327,\n",
      "                          0.8995900750160217,\n",
      "                          0.9018355011940002,\n",
      "                          0.8941019177436829,\n",
      "                          0.9005666375160217,\n",
      "                          0.8792805075645447,\n",
      "                          0.9054917693138123,\n",
      "                          0.9037967324256897,\n",
      "                          0.9044381380081177,\n",
      "                          0.9048300981521606,\n",
      "                          0.9084668159484863],\n",
      "                         [0.8484786748886108,\n",
      "                          0.8618480563163757,\n",
      "                          0.8709405064582825,\n",
      "                          0.8751429319381714,\n",
      "                          0.8819137215614319,\n",
      "                          0.8833207488059998,\n",
      "                          0.8821178674697876,\n",
      "                          0.8861221671104431,\n",
      "                          0.8909059166908264,\n",
      "                          0.8915772438049316,\n",
      "                          0.8945268392562866,\n",
      "                          0.8964028358459473,\n",
      "                          0.8967060446739197,\n",
      "                          0.8993233442306519,\n",
      "                          0.8984334468841553,\n",
      "                          0.9013534188270569,\n",
      "                          0.9006459712982178,\n",
      "                          0.9025838375091553,\n",
      "                          0.9033275842666626,\n",
      "                          0.9050258994102478],\n",
      "                         [0.8440033197402954,\n",
      "                          0.8622992634773254,\n",
      "                          0.8722599148750305,\n",
      "                          0.8811289668083191,\n",
      "                          0.8869013786315918,\n",
      "                          0.890275239944458,\n",
      "                          0.8874533772468567,\n",
      "                          0.8953485488891602,\n",
      "                          0.8912853002548218,\n",
      "                          0.8945800065994263,\n",
      "                          0.8965253233909607,\n",
      "                          0.8977493643760681,\n",
      "                          0.8979699015617371,\n",
      "                          0.896030843257904,\n",
      "                          0.9007745981216431,\n",
      "                          0.898884117603302,\n",
      "                          0.9000393152236938,\n",
      "                          0.9015275835990906,\n",
      "                          0.9033775925636292,\n",
      "                          0.9030590057373047],\n",
      "                         [0.8422349691390991,\n",
      "                          0.8607195019721985,\n",
      "                          0.8702946901321411,\n",
      "                          0.876653254032135,\n",
      "                          0.8808279037475586,\n",
      "                          0.8842666745185852,\n",
      "                          0.8784254789352417,\n",
      "                          0.8883051872253418,\n",
      "                          0.8918054103851318,\n",
      "                          0.8937906622886658,\n",
      "                          0.8940820097923279,\n",
      "                          0.8964435458183289,\n",
      "                          0.8956958651542664,\n",
      "                          0.8985148072242737,\n",
      "                          0.9005820155143738,\n",
      "                          0.9002200365066528,\n",
      "                          0.9012250900268555,\n",
      "                          0.9016239643096924,\n",
      "                          0.9039924144744873,\n",
      "                          0.9025834202766418]],\n",
      " 'Validation Loss': [0.4285254180431366,\n",
      "                     0.3722502589225769,\n",
      "                     0.34538111090660095,\n",
      "                     0.323783278465271,\n",
      "                     0.31135958433151245,\n",
      "                     0.29896992444992065,\n",
      "                     0.3251054584980011,\n",
      "                     0.2874000668525696,\n",
      "                     0.27900391817092896,\n",
      "                     0.27057182788848877,\n",
      "                     0.26785868406295776,\n",
      "                     0.26211750507354736,\n",
      "                     0.2613699436187744,\n",
      "                     0.2545759677886963,\n",
      "                     0.24934186041355133,\n",
      "                     0.24986635148525238,\n",
      "                     0.2475050836801529,\n",
      "                     0.24680857360363007,\n",
      "                     0.24103595316410065,\n",
      "                     0.24242928624153137],\n",
      " 'Validation MCC': [[np.float64(0.7466864464063128),\n",
      "                     np.float64(0.7780567485632842),\n",
      "                     np.float64(0.7983818875208816),\n",
      "                     np.float64(0.7841531139692361),\n",
      "                     np.float64(0.806706648885439),\n",
      "                     np.float64(0.7998727985490951),\n",
      "                     np.float64(0.8126431313160954),\n",
      "                     np.float64(0.8199418505637357),\n",
      "                     np.float64(0.8131976931198224),\n",
      "                     np.float64(0.824363478629573),\n",
      "                     np.float64(0.8111668647847695),\n",
      "                     np.float64(0.823280101564157),\n",
      "                     np.float64(0.8318903893578016),\n",
      "                     np.float64(0.8252179064515046),\n",
      "                     np.float64(0.827109712198493),\n",
      "                     np.float64(0.8385806537976777),\n",
      "                     np.float64(0.8404632565508648),\n",
      "                     np.float64(0.8415021191674327),\n",
      "                     np.float64(0.8441172612514048),\n",
      "                     np.float64(0.8455805258645844)],\n",
      "                    [np.float64(0.771488125214252),\n",
      "                     np.float64(0.7947042456098585),\n",
      "                     np.float64(0.8124392408246124),\n",
      "                     np.float64(0.8175759840790207),\n",
      "                     np.float64(0.8208616561146581),\n",
      "                     np.float64(0.8285577144134965),\n",
      "                     np.float64(0.8294982705538613),\n",
      "                     np.float64(0.8385923114149224),\n",
      "                     np.float64(0.842104478648412),\n",
      "                     np.float64(0.8441686174842993),\n",
      "                     np.float64(0.8456856621766486),\n",
      "                     np.float64(0.8493714513178054),\n",
      "                     np.float64(0.8378075592488753),\n",
      "                     np.float64(0.8473644594882033),\n",
      "                     np.float64(0.8133300231043957),\n",
      "                     np.float64(0.8547997925986994),\n",
      "                     np.float64(0.8519909475937496),\n",
      "                     np.float64(0.8529914225082046),\n",
      "                     np.float64(0.8543303693915316),\n",
      "                     np.float64(0.859671690724848)],\n",
      "                    [np.float64(0.7672858969028049),\n",
      "                     np.float64(0.7895897147612476),\n",
      "                     np.float64(0.8013798828741553),\n",
      "                     np.float64(0.810694502512962),\n",
      "                     np.float64(0.819772833973824),\n",
      "                     np.float64(0.8209110689304143),\n",
      "                     np.float64(0.8193482811921352),\n",
      "                     np.float64(0.8262360534600103),\n",
      "                     np.float64(0.8330530340864861),\n",
      "                     np.float64(0.8338659044024688),\n",
      "                     np.float64(0.8388422053637423),\n",
      "                     np.float64(0.8416706924709193),\n",
      "                     np.float64(0.8420537635784259),\n",
      "                     np.float64(0.8457706734203861),\n",
      "                     np.float64(0.8444577319263278),\n",
      "                     np.float64(0.8490627141266683),\n",
      "                     np.float64(0.8483425907189861),\n",
      "                     np.float64(0.851056385909414),\n",
      "                     np.float64(0.852915493310681),\n",
      "                     np.float64(0.8548677052733898)],\n",
      "                    [np.float64(0.7571139131885641),\n",
      "                     np.float64(0.7892168995789105),\n",
      "                     np.float64(0.8050353473648371),\n",
      "                     np.float64(0.8186928019504905),\n",
      "                     np.float64(0.8267008418360678),\n",
      "                     np.float64(0.8318314650529699),\n",
      "                     np.float64(0.8264832641851346),\n",
      "                     np.float64(0.8392494022971949),\n",
      "                     np.float64(0.8355377352401073),\n",
      "                     np.float64(0.8375741059484594),\n",
      "                     np.float64(0.84099110285108),\n",
      "                     np.float64(0.8439853779307908),\n",
      "                     np.float64(0.8432064700838567),\n",
      "                     np.float64(0.8408614274301185),\n",
      "                     np.float64(0.8472816457029864),\n",
      "                     np.float64(0.844245758582386),\n",
      "                     np.float64(0.8479860944210831),\n",
      "                     np.float64(0.8489618742755084),\n",
      "                     np.float64(0.8518545035732107),\n",
      "                     np.float64(0.8512142849466489)],\n",
      "                    [np.float64(0.7563065581660955),\n",
      "                     np.float64(0.7871696245701618),\n",
      "                     np.float64(0.8002976758676524),\n",
      "                     np.float64(0.8105811596373292),\n",
      "                     np.float64(0.8172492228853655),\n",
      "                     np.float64(0.8228439780449793),\n",
      "                     np.float64(0.8138466608722543),\n",
      "                     np.float64(0.8292032001473173),\n",
      "                     np.float64(0.8344634904753849),\n",
      "                     np.float64(0.8376833993365249),\n",
      "                     np.float64(0.8391658376805927),\n",
      "                     np.float64(0.8417046732529392),\n",
      "                     np.float64(0.8413749400624253),\n",
      "                     np.float64(0.8443635776691947),\n",
      "                     np.float64(0.8479054973631698),\n",
      "                     np.float64(0.8470222574614631),\n",
      "                     np.float64(0.8492370306669159),\n",
      "                     np.float64(0.8500753231768262),\n",
      "                     np.float64(0.8532436946666487),\n",
      "                     np.float64(0.8516717588968863)]]}\n",
      "Training Model: BiLSTM, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.6805 - loss: 0.8730\n",
      "Epoch 1 - MCC: 0.7932\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 42ms/step - accuracy: 0.6811 - loss: 0.8715 - val_accuracy: 0.8660 - val_loss: 0.3595 - mcc: 0.7932\n",
      "Epoch 2/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8706 - loss: 0.3477\n",
      "Epoch 2 - MCC: 0.8234\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 40ms/step - accuracy: 0.8706 - loss: 0.3477 - val_accuracy: 0.8847 - val_loss: 0.3049 - mcc: 0.8234\n",
      "Epoch 3/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.8860 - loss: 0.3016\n",
      "Epoch 3 - MCC: 0.8387\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 37ms/step - accuracy: 0.8860 - loss: 0.3015 - val_accuracy: 0.8945 - val_loss: 0.2781 - mcc: 0.8387\n",
      "Epoch 4/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.8919 - loss: 0.2841\n",
      "Epoch 4 - MCC: 0.8487\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.8919 - loss: 0.2841 - val_accuracy: 0.9013 - val_loss: 0.2613 - mcc: 0.8487\n",
      "Epoch 5/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8989 - loss: 0.2684\n",
      "Epoch 5 - MCC: 0.8538\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 38ms/step - accuracy: 0.8989 - loss: 0.2684 - val_accuracy: 0.9046 - val_loss: 0.2507 - mcc: 0.8538\n",
      "Epoch 6/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9006 - loss: 0.2629\n",
      "Epoch 6 - MCC: 0.8343\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 42ms/step - accuracy: 0.9006 - loss: 0.2629 - val_accuracy: 0.8917 - val_loss: 0.2826 - mcc: 0.8343\n",
      "Epoch 7/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9025 - loss: 0.2584\n",
      "Epoch 7 - MCC: 0.8594\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 40ms/step - accuracy: 0.9025 - loss: 0.2584 - val_accuracy: 0.9081 - val_loss: 0.2417 - mcc: 0.8594\n",
      "Epoch 8/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9072 - loss: 0.2421\n",
      "Epoch 8 - MCC: 0.8654\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.9072 - loss: 0.2420 - val_accuracy: 0.9120 - val_loss: 0.2294 - mcc: 0.8654\n",
      "Epoch 9/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9102 - loss: 0.2333\n",
      "Epoch 9 - MCC: 0.8700\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 39ms/step - accuracy: 0.9102 - loss: 0.2333 - val_accuracy: 0.9147 - val_loss: 0.2203 - mcc: 0.8700\n",
      "Epoch 10/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9136 - loss: 0.2246\n",
      "Epoch 10 - MCC: 0.8651\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.9135 - loss: 0.2247 - val_accuracy: 0.9117 - val_loss: 0.2320 - mcc: 0.8651\n",
      "Epoch 11/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9116 - loss: 0.2313\n",
      "Epoch 11 - MCC: 0.8752\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 38ms/step - accuracy: 0.9116 - loss: 0.2313 - val_accuracy: 0.9181 - val_loss: 0.2091 - mcc: 0.8752\n",
      "Epoch 12/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9188 - loss: 0.2081\n",
      "Epoch 12 - MCC: 0.8787\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 40ms/step - accuracy: 0.9188 - loss: 0.2081 - val_accuracy: 0.9200 - val_loss: 0.2023 - mcc: 0.8787\n",
      "Epoch 13/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9191 - loss: 0.2071\n",
      "Epoch 13 - MCC: 0.8815\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 38ms/step - accuracy: 0.9191 - loss: 0.2071 - val_accuracy: 0.9224 - val_loss: 0.1963 - mcc: 0.8815\n",
      "Epoch 14/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9219 - loss: 0.2001\n",
      "Epoch 14 - MCC: 0.8840\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 38ms/step - accuracy: 0.9219 - loss: 0.2001 - val_accuracy: 0.9236 - val_loss: 0.1936 - mcc: 0.8840\n",
      "Epoch 15/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9225 - loss: 0.1970\n",
      "Epoch 15 - MCC: 0.8734\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.9225 - loss: 0.1970 - val_accuracy: 0.9173 - val_loss: 0.2101 - mcc: 0.8734\n",
      "Epoch 16/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9207 - loss: 0.2009\n",
      "Epoch 16 - MCC: 0.8857\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 37ms/step - accuracy: 0.9208 - loss: 0.2008 - val_accuracy: 0.9251 - val_loss: 0.1882 - mcc: 0.8857\n",
      "Epoch 17/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9235 - loss: 0.1932\n",
      "Epoch 17 - MCC: 0.8878\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 37ms/step - accuracy: 0.9235 - loss: 0.1932 - val_accuracy: 0.9265 - val_loss: 0.1840 - mcc: 0.8878\n",
      "Epoch 18/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9254 - loss: 0.1884\n",
      "Epoch 18 - MCC: 0.8899\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.9254 - loss: 0.1884 - val_accuracy: 0.9275 - val_loss: 0.1810 - mcc: 0.8899\n",
      "Epoch 19/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9250 - loss: 0.1889\n",
      "Epoch 19 - MCC: 0.8892\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 37ms/step - accuracy: 0.9250 - loss: 0.1889 - val_accuracy: 0.9274 - val_loss: 0.1809 - mcc: 0.8892\n",
      "Epoch 20/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9256 - loss: 0.1871\n",
      "Epoch 20 - MCC: 0.8875\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.9256 - loss: 0.1871 - val_accuracy: 0.9258 - val_loss: 0.1864 - mcc: 0.8875\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 17ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.6912 - loss: 0.8347\n",
      "Epoch 1 - MCC: 0.8126\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 40ms/step - accuracy: 0.6915 - loss: 0.8340 - val_accuracy: 0.8782 - val_loss: 0.3327 - mcc: 0.8126\n",
      "Epoch 2/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.8783 - loss: 0.3293\n",
      "Epoch 2 - MCC: 0.8331\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.8784 - loss: 0.3292 - val_accuracy: 0.8917 - val_loss: 0.2917 - mcc: 0.8331\n",
      "Epoch 3/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8932 - loss: 0.2874\n",
      "Epoch 3 - MCC: 0.8473\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 38ms/step - accuracy: 0.8932 - loss: 0.2874 - val_accuracy: 0.9007 - val_loss: 0.2625 - mcc: 0.8473\n",
      "Epoch 4/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8993 - loss: 0.2672\n",
      "Epoch 4 - MCC: 0.8534\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 38ms/step - accuracy: 0.8993 - loss: 0.2672 - val_accuracy: 0.9042 - val_loss: 0.2498 - mcc: 0.8534\n",
      "Epoch 5/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9037 - loss: 0.2512\n",
      "Epoch 5 - MCC: 0.8526\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 37ms/step - accuracy: 0.9037 - loss: 0.2512 - val_accuracy: 0.9040 - val_loss: 0.2539 - mcc: 0.8526\n",
      "Epoch 6/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9065 - loss: 0.2434\n",
      "Epoch 6 - MCC: 0.8653\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 40ms/step - accuracy: 0.9065 - loss: 0.2433 - val_accuracy: 0.9122 - val_loss: 0.2266 - mcc: 0.8653\n",
      "Epoch 7/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9115 - loss: 0.2280\n",
      "Epoch 7 - MCC: 0.8708\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 37ms/step - accuracy: 0.9115 - loss: 0.2280 - val_accuracy: 0.9156 - val_loss: 0.2172 - mcc: 0.8708\n",
      "Epoch 8/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9144 - loss: 0.2195\n",
      "Epoch 8 - MCC: 0.8719\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 37ms/step - accuracy: 0.9144 - loss: 0.2195 - val_accuracy: 0.9164 - val_loss: 0.2152 - mcc: 0.8719\n",
      "Epoch 9/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9159 - loss: 0.2140\n",
      "Epoch 9 - MCC: 0.8757\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 37ms/step - accuracy: 0.9159 - loss: 0.2140 - val_accuracy: 0.9188 - val_loss: 0.2095 - mcc: 0.8757\n",
      "Epoch 10/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9154 - loss: 0.2169\n",
      "Epoch 10 - MCC: 0.8802\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.9154 - loss: 0.2169 - val_accuracy: 0.9219 - val_loss: 0.1995 - mcc: 0.8802\n",
      "Epoch 11/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9205 - loss: 0.2030\n",
      "Epoch 11 - MCC: 0.8857\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 37ms/step - accuracy: 0.9205 - loss: 0.2030 - val_accuracy: 0.9252 - val_loss: 0.1900 - mcc: 0.8857\n",
      "Epoch 12/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9140 - loss: 0.2193\n",
      "Epoch 12 - MCC: 0.8727\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 39ms/step - accuracy: 0.9140 - loss: 0.2193 - val_accuracy: 0.9169 - val_loss: 0.2129 - mcc: 0.8727\n",
      "Epoch 13/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9171 - loss: 0.2119\n",
      "Epoch 13 - MCC: 0.8805\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 38ms/step - accuracy: 0.9171 - loss: 0.2119 - val_accuracy: 0.9220 - val_loss: 0.1982 - mcc: 0.8805\n",
      "Epoch 14/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9193 - loss: 0.2052\n",
      "Epoch 14 - MCC: 0.8825\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.9193 - loss: 0.2052 - val_accuracy: 0.9234 - val_loss: 0.1954 - mcc: 0.8825\n",
      "Epoch 15/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9236 - loss: 0.1936\n",
      "Epoch 15 - MCC: 0.8679\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 37ms/step - accuracy: 0.9236 - loss: 0.1937 - val_accuracy: 0.9140 - val_loss: 0.2206 - mcc: 0.8679\n",
      "Epoch 16/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9221 - loss: 0.1994\n",
      "Epoch 16 - MCC: 0.8864\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.9221 - loss: 0.1994 - val_accuracy: 0.9260 - val_loss: 0.1867 - mcc: 0.8864\n",
      "Epoch 17/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9244 - loss: 0.1908\n",
      "Epoch 17 - MCC: 0.8882\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 40ms/step - accuracy: 0.9244 - loss: 0.1908 - val_accuracy: 0.9266 - val_loss: 0.1850 - mcc: 0.8882\n",
      "Epoch 18/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9230 - loss: 0.1936\n",
      "Epoch 18 - MCC: 0.8891\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.9230 - loss: 0.1936 - val_accuracy: 0.9273 - val_loss: 0.1834 - mcc: 0.8891\n",
      "Epoch 19/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9266 - loss: 0.1856\n",
      "Epoch 19 - MCC: 0.8896\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.9266 - loss: 0.1856 - val_accuracy: 0.9278 - val_loss: 0.1813 - mcc: 0.8896\n",
      "Epoch 20/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9258 - loss: 0.1873\n",
      "Epoch 20 - MCC: 0.8876\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 40ms/step - accuracy: 0.9258 - loss: 0.1873 - val_accuracy: 0.9267 - val_loss: 0.1852 - mcc: 0.8876\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 13ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.6821 - loss: 0.8501\n",
      "Epoch 1 - MCC: 0.7868\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 41ms/step - accuracy: 0.6824 - loss: 0.8493 - val_accuracy: 0.8619 - val_loss: 0.3602 - mcc: 0.7868\n",
      "Epoch 2/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.8607 - loss: 0.3755\n",
      "Epoch 2 - MCC: 0.8084\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 36ms/step - accuracy: 0.8607 - loss: 0.3754 - val_accuracy: 0.8755 - val_loss: 0.3246 - mcc: 0.8084\n",
      "Epoch 3/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.8797 - loss: 0.3142\n",
      "Epoch 3 - MCC: 0.8241\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 37ms/step - accuracy: 0.8798 - loss: 0.3142 - val_accuracy: 0.8853 - val_loss: 0.2957 - mcc: 0.8241\n",
      "Epoch 4/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.8857 - loss: 0.2950\n",
      "Epoch 4 - MCC: 0.8197\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 40ms/step - accuracy: 0.8857 - loss: 0.2951 - val_accuracy: 0.8827 - val_loss: 0.3072 - mcc: 0.8197\n",
      "Epoch 5/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8890 - loss: 0.2870\n",
      "Epoch 5 - MCC: 0.8370\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8891 - loss: 0.2870 - val_accuracy: 0.8935 - val_loss: 0.2794 - mcc: 0.8370\n",
      "Epoch 6/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.8954 - loss: 0.2696\n",
      "Epoch 6 - MCC: 0.8271\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 37ms/step - accuracy: 0.8953 - loss: 0.2696 - val_accuracy: 0.8871 - val_loss: 0.2966 - mcc: 0.8271\n",
      "Epoch 7/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.8933 - loss: 0.2769\n",
      "Epoch 7 - MCC: 0.8430\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 37ms/step - accuracy: 0.8933 - loss: 0.2768 - val_accuracy: 0.8975 - val_loss: 0.2675 - mcc: 0.8430\n",
      "Epoch 8/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9006 - loss: 0.2579\n",
      "Epoch 8 - MCC: 0.8507\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.9006 - loss: 0.2579 - val_accuracy: 0.9022 - val_loss: 0.2541 - mcc: 0.8507\n",
      "Epoch 9/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.8994 - loss: 0.2614\n",
      "Epoch 9 - MCC: 0.8543\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 40ms/step - accuracy: 0.8994 - loss: 0.2614 - val_accuracy: 0.9048 - val_loss: 0.2465 - mcc: 0.8543\n",
      "Epoch 10/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9070 - loss: 0.2395\n",
      "Epoch 10 - MCC: 0.8599\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 37ms/step - accuracy: 0.9070 - loss: 0.2396 - val_accuracy: 0.9079 - val_loss: 0.2382 - mcc: 0.8599\n",
      "Epoch 11/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9101 - loss: 0.2322\n",
      "Epoch 11 - MCC: 0.8607\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 37ms/step - accuracy: 0.9101 - loss: 0.2322 - val_accuracy: 0.9088 - val_loss: 0.2352 - mcc: 0.8607\n",
      "Epoch 12/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9118 - loss: 0.2275\n",
      "Epoch 12 - MCC: 0.8639\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.9118 - loss: 0.2275 - val_accuracy: 0.9107 - val_loss: 0.2297 - mcc: 0.8639\n",
      "Epoch 13/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9143 - loss: 0.2230\n",
      "Epoch 13 - MCC: 0.8647\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 36ms/step - accuracy: 0.9143 - loss: 0.2230 - val_accuracy: 0.9109 - val_loss: 0.2283 - mcc: 0.8647\n",
      "Epoch 14/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9141 - loss: 0.2212\n",
      "Epoch 14 - MCC: 0.8702\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 37ms/step - accuracy: 0.9141 - loss: 0.2212 - val_accuracy: 0.9149 - val_loss: 0.2192 - mcc: 0.8702\n",
      "Epoch 15/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9162 - loss: 0.2172\n",
      "Epoch 15 - MCC: 0.8365\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 38ms/step - accuracy: 0.9162 - loss: 0.2172 - val_accuracy: 0.8931 - val_loss: 0.3025 - mcc: 0.8365\n",
      "Epoch 16/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9167 - loss: 0.2160\n",
      "Epoch 16 - MCC: 0.8716\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 37ms/step - accuracy: 0.9167 - loss: 0.2159 - val_accuracy: 0.9157 - val_loss: 0.2181 - mcc: 0.8716\n",
      "Epoch 17/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9191 - loss: 0.2079\n",
      "Epoch 17 - MCC: 0.8764\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 36ms/step - accuracy: 0.9191 - loss: 0.2079 - val_accuracy: 0.9186 - val_loss: 0.2093 - mcc: 0.8764\n",
      "Epoch 18/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9212 - loss: 0.2029\n",
      "Epoch 18 - MCC: 0.8769\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 37ms/step - accuracy: 0.9212 - loss: 0.2029 - val_accuracy: 0.9190 - val_loss: 0.2096 - mcc: 0.8769\n",
      "Epoch 19/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9213 - loss: 0.2028\n",
      "Epoch 19 - MCC: 0.8808\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 36ms/step - accuracy: 0.9213 - loss: 0.2028 - val_accuracy: 0.9217 - val_loss: 0.1997 - mcc: 0.8808\n",
      "Epoch 20/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9236 - loss: 0.1967\n",
      "Epoch 20 - MCC: 0.8816\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 40ms/step - accuracy: 0.9236 - loss: 0.1967 - val_accuracy: 0.9224 - val_loss: 0.1985 - mcc: 0.8816\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 13ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.6999 - loss: 0.8534\n",
      "Epoch 1 - MCC: 0.7917\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 47ms/step - accuracy: 0.7001 - loss: 0.8526 - val_accuracy: 0.8637 - val_loss: 0.3640 - mcc: 0.7917\n",
      "Epoch 2/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8780 - loss: 0.3246\n",
      "Epoch 2 - MCC: 0.8191\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 38ms/step - accuracy: 0.8780 - loss: 0.3246 - val_accuracy: 0.8810 - val_loss: 0.3159 - mcc: 0.8191\n",
      "Epoch 3/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.8901 - loss: 0.2916\n",
      "Epoch 3 - MCC: 0.8431\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 36ms/step - accuracy: 0.8901 - loss: 0.2915 - val_accuracy: 0.8976 - val_loss: 0.2707 - mcc: 0.8431\n",
      "Epoch 4/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8966 - loss: 0.2770\n",
      "Epoch 4 - MCC: 0.8502\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 38ms/step - accuracy: 0.8966 - loss: 0.2769 - val_accuracy: 0.9022 - val_loss: 0.2586 - mcc: 0.8502\n",
      "Epoch 5/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9031 - loss: 0.2567\n",
      "Epoch 5 - MCC: 0.8521\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.9031 - loss: 0.2567 - val_accuracy: 0.9040 - val_loss: 0.2574 - mcc: 0.8521\n",
      "Epoch 6/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9065 - loss: 0.2471\n",
      "Epoch 6 - MCC: 0.8526\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.9065 - loss: 0.2471 - val_accuracy: 0.9043 - val_loss: 0.2562 - mcc: 0.8526\n",
      "Epoch 7/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9053 - loss: 0.2518\n",
      "Epoch 7 - MCC: 0.8544\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.9053 - loss: 0.2518 - val_accuracy: 0.9049 - val_loss: 0.2531 - mcc: 0.8544\n",
      "Epoch 8/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9104 - loss: 0.2348\n",
      "Epoch 8 - MCC: 0.8666\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 38ms/step - accuracy: 0.9104 - loss: 0.2348 - val_accuracy: 0.9130 - val_loss: 0.2279 - mcc: 0.8666\n",
      "Epoch 9/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9123 - loss: 0.2272\n",
      "Epoch 9 - MCC: 0.8687\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 42ms/step - accuracy: 0.9124 - loss: 0.2271 - val_accuracy: 0.9142 - val_loss: 0.2201 - mcc: 0.8687\n",
      "Epoch 10/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.9147 - loss: 0.2201\n",
      "Epoch 10 - MCC: 0.8727\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 41ms/step - accuracy: 0.9147 - loss: 0.2201 - val_accuracy: 0.9166 - val_loss: 0.2166 - mcc: 0.8727\n",
      "Epoch 11/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9110 - loss: 0.2339\n",
      "Epoch 11 - MCC: 0.8675\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 42ms/step - accuracy: 0.9110 - loss: 0.2339 - val_accuracy: 0.9130 - val_loss: 0.2295 - mcc: 0.8675\n",
      "Epoch 12/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9155 - loss: 0.2192\n",
      "Epoch 12 - MCC: 0.8584\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 39ms/step - accuracy: 0.9155 - loss: 0.2192 - val_accuracy: 0.9076 - val_loss: 0.2403 - mcc: 0.8584\n",
      "Epoch 13/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9196 - loss: 0.2068\n",
      "Epoch 13 - MCC: 0.8788\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 40ms/step - accuracy: 0.9196 - loss: 0.2068 - val_accuracy: 0.9210 - val_loss: 0.2038 - mcc: 0.8788\n",
      "Epoch 14/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9161 - loss: 0.2146\n",
      "Epoch 14 - MCC: 0.8699\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 39ms/step - accuracy: 0.9161 - loss: 0.2145 - val_accuracy: 0.9151 - val_loss: 0.2186 - mcc: 0.8699\n",
      "Epoch 15/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9199 - loss: 0.2063\n",
      "Epoch 15 - MCC: 0.8829\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 39ms/step - accuracy: 0.9199 - loss: 0.2063 - val_accuracy: 0.9234 - val_loss: 0.1962 - mcc: 0.8829\n",
      "Epoch 16/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9226 - loss: 0.1962\n",
      "Epoch 16 - MCC: 0.8816\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 39ms/step - accuracy: 0.9226 - loss: 0.1962 - val_accuracy: 0.9227 - val_loss: 0.1976 - mcc: 0.8816\n",
      "Epoch 17/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9251 - loss: 0.1905\n",
      "Epoch 17 - MCC: 0.8514\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.9251 - loss: 0.1905 - val_accuracy: 0.9032 - val_loss: 0.2420 - mcc: 0.8514\n",
      "Epoch 18/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9179 - loss: 0.2076\n",
      "Epoch 18 - MCC: 0.8824\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.9179 - loss: 0.2075 - val_accuracy: 0.9228 - val_loss: 0.1982 - mcc: 0.8824\n",
      "Epoch 19/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9258 - loss: 0.1886\n",
      "Epoch 19 - MCC: 0.8826\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 42ms/step - accuracy: 0.9258 - loss: 0.1886 - val_accuracy: 0.9235 - val_loss: 0.1959 - mcc: 0.8826\n",
      "Epoch 20/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9248 - loss: 0.1905\n",
      "Epoch 20 - MCC: 0.8846\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 42ms/step - accuracy: 0.9248 - loss: 0.1905 - val_accuracy: 0.9247 - val_loss: 0.1931 - mcc: 0.8846\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.6590 - loss: 0.9230\n",
      "Epoch 1 - MCC: 0.7986\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 42ms/step - accuracy: 0.6593 - loss: 0.9221 - val_accuracy: 0.8686 - val_loss: 0.3481 - mcc: 0.7986\n",
      "Epoch 2/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8727 - loss: 0.3348\n",
      "Epoch 2 - MCC: 0.8200\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 42ms/step - accuracy: 0.8727 - loss: 0.3348 - val_accuracy: 0.8820 - val_loss: 0.3113 - mcc: 0.8200\n",
      "Epoch 3/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8871 - loss: 0.2975\n",
      "Epoch 3 - MCC: 0.8352\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 42ms/step - accuracy: 0.8871 - loss: 0.2975 - val_accuracy: 0.8923 - val_loss: 0.2847 - mcc: 0.8352\n",
      "Epoch 4/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.8969 - loss: 0.2728\n",
      "Epoch 4 - MCC: 0.8457\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 40ms/step - accuracy: 0.8969 - loss: 0.2728 - val_accuracy: 0.8990 - val_loss: 0.2641 - mcc: 0.8457\n",
      "Epoch 5/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9060 - loss: 0.2477\n",
      "Epoch 5 - MCC: 0.8505\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 39ms/step - accuracy: 0.9060 - loss: 0.2477 - val_accuracy: 0.9025 - val_loss: 0.2568 - mcc: 0.8505\n",
      "Epoch 6/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9075 - loss: 0.2411\n",
      "Epoch 6 - MCC: 0.8559\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 39ms/step - accuracy: 0.9075 - loss: 0.2411 - val_accuracy: 0.9060 - val_loss: 0.2449 - mcc: 0.8559\n",
      "Epoch 7/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9108 - loss: 0.2318\n",
      "Epoch 7 - MCC: 0.8646\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 38ms/step - accuracy: 0.9108 - loss: 0.2318 - val_accuracy: 0.9112 - val_loss: 0.2276 - mcc: 0.8646\n",
      "Epoch 8/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9151 - loss: 0.2196\n",
      "Epoch 8 - MCC: 0.8641\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 40ms/step - accuracy: 0.9151 - loss: 0.2196 - val_accuracy: 0.9112 - val_loss: 0.2291 - mcc: 0.8641\n",
      "Epoch 9/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9115 - loss: 0.2308\n",
      "Epoch 9 - MCC: 0.8657\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 39ms/step - accuracy: 0.9115 - loss: 0.2308 - val_accuracy: 0.9122 - val_loss: 0.2255 - mcc: 0.8657\n",
      "Epoch 10/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9172 - loss: 0.2130\n",
      "Epoch 10 - MCC: 0.8724\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 39ms/step - accuracy: 0.9172 - loss: 0.2130 - val_accuracy: 0.9162 - val_loss: 0.2122 - mcc: 0.8724\n",
      "Epoch 11/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8778 - loss: 0.3211\n",
      "Epoch 11 - MCC: 0.8279\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 43ms/step - accuracy: 0.8778 - loss: 0.3210 - val_accuracy: 0.8877 - val_loss: 0.2874 - mcc: 0.8279\n",
      "Epoch 12/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.8918 - loss: 0.2800\n",
      "Epoch 12 - MCC: 0.8362\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 42ms/step - accuracy: 0.8918 - loss: 0.2800 - val_accuracy: 0.8927 - val_loss: 0.2739 - mcc: 0.8362\n",
      "Epoch 13/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8965 - loss: 0.2659\n",
      "Epoch 13 - MCC: 0.8392\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8965 - loss: 0.2659 - val_accuracy: 0.8952 - val_loss: 0.2695 - mcc: 0.8392\n",
      "Epoch 14/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9002 - loss: 0.2558\n",
      "Epoch 14 - MCC: 0.8445\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 42ms/step - accuracy: 0.9003 - loss: 0.2558 - val_accuracy: 0.8984 - val_loss: 0.2619 - mcc: 0.8445\n",
      "Epoch 15/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9021 - loss: 0.2498\n",
      "Epoch 15 - MCC: 0.8485\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 40ms/step - accuracy: 0.9021 - loss: 0.2498 - val_accuracy: 0.9005 - val_loss: 0.2535 - mcc: 0.8485\n",
      "Epoch 16/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9047 - loss: 0.2443\n",
      "Epoch 16 - MCC: 0.8517\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.9047 - loss: 0.2443 - val_accuracy: 0.9030 - val_loss: 0.2475 - mcc: 0.8517\n",
      "Epoch 17/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9067 - loss: 0.2383\n",
      "Epoch 17 - MCC: 0.8523\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.9067 - loss: 0.2383 - val_accuracy: 0.9035 - val_loss: 0.2471 - mcc: 0.8523\n",
      "Epoch 18/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9087 - loss: 0.2340\n",
      "Epoch 18 - MCC: 0.8560\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 40ms/step - accuracy: 0.9087 - loss: 0.2340 - val_accuracy: 0.9058 - val_loss: 0.2396 - mcc: 0.8560\n",
      "Epoch 19/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9095 - loss: 0.2302\n",
      "Epoch 19 - MCC: 0.8582\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 39ms/step - accuracy: 0.9096 - loss: 0.2302 - val_accuracy: 0.9074 - val_loss: 0.2347 - mcc: 0.8582\n",
      "Epoch 20/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9122 - loss: 0.2227\n",
      "Epoch 20 - MCC: 0.8620\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 39ms/step - accuracy: 0.9122 - loss: 0.2227 - val_accuracy: 0.9098 - val_loss: 0.2305 - mcc: 0.8620\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 13ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.9267093333333334),\n",
      "              'mean': np.float64(0.9218853333333333),\n",
      "              'min': np.float64(0.9097966666666667),\n",
      "              'std': np.float64(0.006211793557419622)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.0010071662267049154),\n",
      "                               'mean': np.float64(0.0008173705418904623),\n",
      "                               'min': np.float64(0.0005566634337107341),\n",
      "                               'std': np.float64(0.00020835912239646566)},\n",
      " 'MCC': {'max': np.float64(0.8875845475024206),\n",
      "         'mean': np.float64(0.8806659872426813),\n",
      "         'min': np.float64(0.8620413581459542),\n",
      "         'std': np.float64(0.00956545006060142)},\n",
      " 'Parameters': 8673,\n",
      " 'Train Time (s)': {'max': np.float64(376.18914794921875),\n",
      "                    'mean': np.float64(368.48126745224),\n",
      "                    'min': np.float64(364.73014307022095),\n",
      "                    'std': np.float64(4.253444792665158)},\n",
      " 'Training Accuracy': [[0.7893857359886169,\n",
      "                        0.8748706579208374,\n",
      "                        0.8872677683830261,\n",
      "                        0.8944360613822937,\n",
      "                        0.8979843854904175,\n",
      "                        0.9029845595359802,\n",
      "                        0.9037923216819763,\n",
      "                        0.9091162085533142,\n",
      "                        0.9120022058486938,\n",
      "                        0.911024272441864,\n",
      "                        0.9147316217422485,\n",
      "                        0.9180896878242493,\n",
      "                        0.919416069984436,\n",
      "                        0.9215742945671082,\n",
      "                        0.9215718507766724,\n",
      "                        0.9227759838104248,\n",
      "                        0.9233428835868835,\n",
      "                        0.9250678420066833,\n",
      "                        0.9262405633926392,\n",
      "                        0.926485538482666],\n",
      "                       [0.8002355098724365,\n",
      "                        0.882901668548584,\n",
      "                        0.8943399786949158,\n",
      "                        0.9003133177757263,\n",
      "                        0.9043747782707214,\n",
      "                        0.9082675576210022,\n",
      "                        0.9120873808860779,\n",
      "                        0.9156277775764465,\n",
      "                        0.914683997631073,\n",
      "                        0.9166117310523987,\n",
      "                        0.920401930809021,\n",
      "                        0.9121881723403931,\n",
      "                        0.917448878288269,\n",
      "                        0.9212490320205688,\n",
      "                        0.921846866607666,\n",
      "                        0.9226952195167542,\n",
      "                        0.9236499667167664,\n",
      "                        0.9243860840797424,\n",
      "                        0.9265291094779968,\n",
      "                        0.925692081451416],\n",
      "                       [0.7947085499763489,\n",
      "                        0.868883490562439,\n",
      "                        0.8825752139091492,\n",
      "                        0.883128821849823,\n",
      "                        0.8914077877998352,\n",
      "                        0.8922517895698547,\n",
      "                        0.8943784832954407,\n",
      "                        0.9002863764762878,\n",
      "                        0.9007639288902283,\n",
      "                        0.9064784049987793,\n",
      "                        0.9096719622612,\n",
      "                        0.9116227030754089,\n",
      "                        0.9135844707489014,\n",
      "                        0.9158146977424622,\n",
      "                        0.917081892490387,\n",
      "                        0.9179999828338623,\n",
      "                        0.9195781350135803,\n",
      "                        0.9210009574890137,\n",
      "                        0.9210138320922852,\n",
      "                        0.923393726348877],\n",
      "                       [0.7982875108718872,\n",
      "                        0.8808850049972534,\n",
      "                        0.8943210244178772,\n",
      "                        0.8991382718086243,\n",
      "                        0.9029850363731384,\n",
      "                        0.907072126865387,\n",
      "                        0.9046201109886169,\n",
      "                        0.911148190498352,\n",
      "                        0.9147664308547974,\n",
      "                        0.9136512279510498,\n",
      "                        0.9112105965614319,\n",
      "                        0.9177435040473938,\n",
      "                        0.9196498990058899,\n",
      "                        0.9180157780647278,\n",
      "                        0.9218634963035583,\n",
      "                        0.9229806065559387,\n",
      "                        0.9231241345405579,\n",
      "                        0.9213359355926514,\n",
      "                        0.9250412583351135,\n",
      "                        0.9261311888694763],\n",
      "                       [0.7832706570625305,\n",
      "                        0.877644956111908,\n",
      "                        0.8896255493164062,\n",
      "                        0.898738443851471,\n",
      "                        0.9047695994377136,\n",
      "                        0.9083772897720337,\n",
      "                        0.911106526851654,\n",
      "                        0.9149411916732788,\n",
      "                        0.9123432636260986,\n",
      "                        0.9185094237327576,\n",
      "                        0.8809528946876526,\n",
      "                        0.8926901817321777,\n",
      "                        0.8982658982276917,\n",
      "                        0.9011622071266174,\n",
      "                        0.9031299352645874,\n",
      "                        0.9052175283432007,\n",
      "                        0.9070122838020325,\n",
      "                        0.9087522625923157,\n",
      "                        0.9108466506004333,\n",
      "                        0.9124922752380371]],\n",
      " 'Training Loss': [[0.5823744535446167,\n",
      "                    0.33404678106307983,\n",
      "                    0.29744216799736023,\n",
      "                    0.27742207050323486,\n",
      "                    0.27131569385528564,\n",
      "                    0.25605064630508423,\n",
      "                    0.25372380018234253,\n",
      "                    0.23645883798599243,\n",
      "                    0.22805559635162354,\n",
      "                    0.23166286945343018,\n",
      "                    0.22051949799060822,\n",
      "                    0.21049250662326813,\n",
      "                    0.2058442234992981,\n",
      "                    0.19961729645729065,\n",
      "                    0.19863958656787872,\n",
      "                    0.1958695650100708,\n",
      "                    0.1940702348947525,\n",
      "                    0.18881836533546448,\n",
      "                    0.18512068688869476,\n",
      "                    0.1844893991947174],\n",
      "                   [0.5500215888023376,\n",
      "                    0.31541579961776733,\n",
      "                    0.28194230794906616,\n",
      "                    0.2627588212490082,\n",
      "                    0.250606894493103,\n",
      "                    0.2381906509399414,\n",
      "                    0.2263948768377304,\n",
      "                    0.21603792905807495,\n",
      "                    0.2189195603132248,\n",
      "                    0.21377786993980408,\n",
      "                    0.20250296592712402,\n",
      "                    0.22479701042175293,\n",
      "                    0.2106686383485794,\n",
      "                    0.20029011368751526,\n",
      "                    0.19835388660430908,\n",
      "                    0.19624924659729004,\n",
      "                    0.19347204267978668,\n",
      "                    0.19083437323570251,\n",
      "                    0.18543510138988495,\n",
      "                    0.18865583837032318],\n",
      "                   [0.5589054226875305,\n",
      "                    0.34941399097442627,\n",
      "                    0.30537694692611694,\n",
      "                    0.30226027965545654,\n",
      "                    0.281476765871048,\n",
      "                    0.27786341309547424,\n",
      "                    0.273800790309906,\n",
      "                    0.25788187980651855,\n",
      "                    0.25776657462120056,\n",
      "                    0.24181827902793884,\n",
      "                    0.23376819491386414,\n",
      "                    0.22833570837974548,\n",
      "                    0.22417807579040527,\n",
      "                    0.21757039427757263,\n",
      "                    0.2150764763355255,\n",
      "                    0.21188338100910187,\n",
      "                    0.2076563984155655,\n",
      "                    0.2034798562526703,\n",
      "                    0.20357611775398254,\n",
      "                    0.19711507856845856],\n",
      "                   [0.5602930784225464,\n",
      "                    0.3163769841194153,\n",
      "                    0.28119462728500366,\n",
      "                    0.2701881527900696,\n",
      "                    0.2560540437698364,\n",
      "                    0.24538879096508026,\n",
      "                    0.25320494174957275,\n",
      "                    0.23231318593025208,\n",
      "                    0.219890296459198,\n",
      "                    0.2236575186252594,\n",
      "                    0.23325476050376892,\n",
      "                    0.21183516085147858,\n",
      "                    0.2058836817741394,\n",
      "                    0.21069501340389252,\n",
      "                    0.20040036737918854,\n",
      "                    0.19539083540439606,\n",
      "                    0.19523490965366364,\n",
      "                    0.19982469081878662,\n",
      "                    0.19017450511455536,\n",
      "                    0.18696169555187225],\n",
      "                   [0.5919234752655029,\n",
      "                    0.32204630970954895,\n",
      "                    0.2922382354736328,\n",
      "                    0.2677595913410187,\n",
      "                    0.2504364848136902,\n",
      "                    0.23874707520008087,\n",
      "                    0.23108725249767303,\n",
      "                    0.22027339041233063,\n",
      "                    0.2277117669582367,\n",
      "                    0.209171324968338,\n",
      "                    0.30863022804260254,\n",
      "                    0.27768248319625854,\n",
      "                    0.2615794241428375,\n",
      "                    0.25280681252479553,\n",
      "                    0.24779005348682404,\n",
      "                    0.24220310151576996,\n",
      "                    0.23733292520046234,\n",
      "                    0.23313578963279724,\n",
      "                    0.22799068689346313,\n",
      "                    0.22354374825954437]],\n",
      " 'Validation Accuracy': [[0.8659787774085999,\n",
      "                          0.8846713304519653,\n",
      "                          0.8944973945617676,\n",
      "                          0.9013451933860779,\n",
      "                          0.9045960307121277,\n",
      "                          0.8917375206947327,\n",
      "                          0.9081471562385559,\n",
      "                          0.9120327830314636,\n",
      "                          0.9147038459777832,\n",
      "                          0.911677896976471,\n",
      "                          0.918089747428894,\n",
      "                          0.9200207591056824,\n",
      "                          0.9223779439926147,\n",
      "                          0.9235807061195374,\n",
      "                          0.917252779006958,\n",
      "                          0.925055980682373,\n",
      "                          0.9265313148498535,\n",
      "                          0.9274628162384033,\n",
      "                          0.9274024963378906,\n",
      "                          0.9257834553718567],\n",
      "                         [0.8782406449317932,\n",
      "                          0.8916719555854797,\n",
      "                          0.9006898403167725,\n",
      "                          0.9041948318481445,\n",
      "                          0.9040312767028809,\n",
      "                          0.912203311920166,\n",
      "                          0.9155579209327698,\n",
      "                          0.9164407849311829,\n",
      "                          0.9188332557678223,\n",
      "                          0.9218634366989136,\n",
      "                          0.9252215027809143,\n",
      "                          0.9168853163719177,\n",
      "                          0.9219686388969421,\n",
      "                          0.923408031463623,\n",
      "                          0.913994550704956,\n",
      "                          0.925971269607544,\n",
      "                          0.9265608191490173,\n",
      "                          0.9272887110710144,\n",
      "                          0.9278061389923096,\n",
      "                          0.9267094731330872],\n",
      "                         [0.8619227409362793,\n",
      "                          0.8754740357398987,\n",
      "                          0.8853405714035034,\n",
      "                          0.8827164769172668,\n",
      "                          0.8935399651527405,\n",
      "                          0.8871086239814758,\n",
      "                          0.8975431323051453,\n",
      "                          0.9022220969200134,\n",
      "                          0.9048488140106201,\n",
      "                          0.9079445004463196,\n",
      "                          0.908767819404602,\n",
      "                          0.9107025265693665,\n",
      "                          0.9108932018280029,\n",
      "                          0.9149488806724548,\n",
      "                          0.8930608630180359,\n",
      "                          0.9156756401062012,\n",
      "                          0.9185945391654968,\n",
      "                          0.9190332293510437,\n",
      "                          0.921716570854187,\n",
      "                          0.9224147796630859],\n",
      "                         [0.8636751174926758,\n",
      "                          0.881010115146637,\n",
      "                          0.8976137638092041,\n",
      "                          0.902224600315094,\n",
      "                          0.9039526581764221,\n",
      "                          0.904317319393158,\n",
      "                          0.9048715233802795,\n",
      "                          0.9129713773727417,\n",
      "                          0.9142404794692993,\n",
      "                          0.9166460633277893,\n",
      "                          0.9130054712295532,\n",
      "                          0.9076215028762817,\n",
      "                          0.9210447072982788,\n",
      "                          0.915105938911438,\n",
      "                          0.9234106540679932,\n",
      "                          0.9226944446563721,\n",
      "                          0.9032299518585205,\n",
      "                          0.9228085875511169,\n",
      "                          0.9235236048698425,\n",
      "                          0.9247227311134338],\n",
      "                         [0.8686233162879944,\n",
      "                          0.8820417523384094,\n",
      "                          0.892347514629364,\n",
      "                          0.8990168571472168,\n",
      "                          0.902497410774231,\n",
      "                          0.905977189540863,\n",
      "                          0.9111745357513428,\n",
      "                          0.9112119674682617,\n",
      "                          0.9122154712677002,\n",
      "                          0.916197657585144,\n",
      "                          0.8876765966415405,\n",
      "                          0.8927473425865173,\n",
      "                          0.8951854109764099,\n",
      "                          0.8984361290931702,\n",
      "                          0.9004805684089661,\n",
      "                          0.9029867053031921,\n",
      "                          0.9034653306007385,\n",
      "                          0.9057686924934387,\n",
      "                          0.907412052154541,\n",
      "                          0.9097966551780701]],\n",
      " 'Validation Loss': [0.3481064736843109,\n",
      "                     0.31127530336380005,\n",
      "                     0.2846806049346924,\n",
      "                     0.2640593945980072,\n",
      "                     0.2568080723285675,\n",
      "                     0.24486030638217926,\n",
      "                     0.2275509387254715,\n",
      "                     0.22909224033355713,\n",
      "                     0.22548381984233856,\n",
      "                     0.21218465268611908,\n",
      "                     0.2873550057411194,\n",
      "                     0.2738579213619232,\n",
      "                     0.26948538422584534,\n",
      "                     0.26194897294044495,\n",
      "                     0.253454327583313,\n",
      "                     0.24753591418266296,\n",
      "                     0.24710626900196075,\n",
      "                     0.23957166075706482,\n",
      "                     0.2347124218940735,\n",
      "                     0.2304939329624176],\n",
      " 'Validation MCC': [[np.float64(0.7932367833885889),\n",
      "                     np.float64(0.823420833731203),\n",
      "                     np.float64(0.8386868947495544),\n",
      "                     np.float64(0.8487370186615097),\n",
      "                     np.float64(0.8538177810200784),\n",
      "                     np.float64(0.8342572047215088),\n",
      "                     np.float64(0.859378554873007),\n",
      "                     np.float64(0.8653869884070379),\n",
      "                     np.float64(0.8700142386393275),\n",
      "                     np.float64(0.8651448256650845),\n",
      "                     np.float64(0.875158464834445),\n",
      "                     np.float64(0.8787067852236444),\n",
      "                     np.float64(0.881542996849807),\n",
      "                     np.float64(0.8840194839513208),\n",
      "                     np.float64(0.8733550462779821),\n",
      "                     np.float64(0.885689462146742),\n",
      "                     np.float64(0.8878211080189696),\n",
      "                     np.float64(0.8898627339581813),\n",
      "                     np.float64(0.8892335011594774),\n",
      "                     np.float64(0.8874859432361952)],\n",
      "                    [np.float64(0.8125900296811603),\n",
      "                     np.float64(0.8331011813974696),\n",
      "                     np.float64(0.8472803394831532),\n",
      "                     np.float64(0.8534219471449112),\n",
      "                     np.float64(0.8526418869369571),\n",
      "                     np.float64(0.8653270203098483),\n",
      "                     np.float64(0.8707799679993075),\n",
      "                     np.float64(0.8719136155438924),\n",
      "                     np.float64(0.875670659232863),\n",
      "                     np.float64(0.8802226298564321),\n",
      "                     np.float64(0.8856826111933093),\n",
      "                     np.float64(0.8726622531305757),\n",
      "                     np.float64(0.8805268063173268),\n",
      "                     np.float64(0.8824521030803153),\n",
      "                     np.float64(0.8678673604473172),\n",
      "                     np.float64(0.8863771537325608),\n",
      "                     np.float64(0.8882052358380711),\n",
      "                     np.float64(0.8891251205140588),\n",
      "                     np.float64(0.8896095710670722),\n",
      "                     np.float64(0.8875845475024206)],\n",
      "                    [np.float64(0.7868035083198028),\n",
      "                     np.float64(0.8083769764324378),\n",
      "                     np.float64(0.8241196656235809),\n",
      "                     np.float64(0.8196646388857258),\n",
      "                     np.float64(0.8370349207567266),\n",
      "                     np.float64(0.8270744101437126),\n",
      "                     np.float64(0.842975493604779),\n",
      "                     np.float64(0.8507496504927144),\n",
      "                     np.float64(0.8543499643019669),\n",
      "                     np.float64(0.8598751599864628),\n",
      "                     np.float64(0.8607329943715439),\n",
      "                     np.float64(0.8638663638809969),\n",
      "                     np.float64(0.864713370163739),\n",
      "                     np.float64(0.8701535637071113),\n",
      "                     np.float64(0.8364774678629566),\n",
      "                     np.float64(0.8716277105177908),\n",
      "                     np.float64(0.8763820165817049),\n",
      "                     np.float64(0.8769169536034175),\n",
      "                     np.float64(0.8808313543580863),\n",
      "                     np.float64(0.8816432605737197)],\n",
      "                    [np.float64(0.7916721778380533),\n",
      "                     np.float64(0.8191496977945671),\n",
      "                     np.float64(0.8430937080951147),\n",
      "                     np.float64(0.8501862679276134),\n",
      "                     np.float64(0.8520931552698151),\n",
      "                     np.float64(0.8525856481637608),\n",
      "                     np.float64(0.8544076090444243),\n",
      "                     np.float64(0.8666026701313275),\n",
      "                     np.float64(0.8686948747072143),\n",
      "                     np.float64(0.8727393999605733),\n",
      "                     np.float64(0.8674517947694788),\n",
      "                     np.float64(0.858385546024589),\n",
      "                     np.float64(0.8788487694625096),\n",
      "                     np.float64(0.8699416934946652),\n",
      "                     np.float64(0.8829027654784629),\n",
      "                     np.float64(0.8816213647295845),\n",
      "                     np.float64(0.8514149134840628),\n",
      "                     np.float64(0.8823608458130185),\n",
      "                     np.float64(0.8825932170287871),\n",
      "                     np.float64(0.8845748267551166)],\n",
      "                    [np.float64(0.7985767701426102),\n",
      "                     np.float64(0.819957828711173),\n",
      "                     np.float64(0.835156292666987),\n",
      "                     np.float64(0.8457407533083705),\n",
      "                     np.float64(0.85046789020011),\n",
      "                     np.float64(0.8559436653875923),\n",
      "                     np.float64(0.864625151732179),\n",
      "                     np.float64(0.8641453263689829),\n",
      "                     np.float64(0.8656660555482809),\n",
      "                     np.float64(0.8724293551181317),\n",
      "                     np.float64(0.82789520229631),\n",
      "                     np.float64(0.8361716971857079),\n",
      "                     np.float64(0.8392019073814525),\n",
      "                     np.float64(0.8444553987439476),\n",
      "                     np.float64(0.848459376345112),\n",
      "                     np.float64(0.8517010587344852),\n",
      "                     np.float64(0.8522631242632235),\n",
      "                     np.float64(0.856001402469082),\n",
      "                     np.float64(0.8581998710956172),\n",
      "                     np.float64(0.8620413581459542)]]}\n",
      "Training Model: RNN, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.7468 - loss: 0.6885\n",
      "Epoch 1 - MCC: 0.7669\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 45ms/step - accuracy: 0.7469 - loss: 0.6880 - val_accuracy: 0.8492 - val_loss: 0.4002 - mcc: 0.7669\n",
      "Epoch 2/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8474 - loss: 0.4032\n",
      "Epoch 2 - MCC: 0.7829\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8474 - loss: 0.4032 - val_accuracy: 0.8595 - val_loss: 0.3725 - mcc: 0.7829\n",
      "Epoch 3/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8605 - loss: 0.3708\n",
      "Epoch 3 - MCC: 0.7942\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 40ms/step - accuracy: 0.8605 - loss: 0.3708 - val_accuracy: 0.8662 - val_loss: 0.3541 - mcc: 0.7942\n",
      "Epoch 4/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8659 - loss: 0.3562\n",
      "Epoch 4 - MCC: 0.8060\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 40ms/step - accuracy: 0.8659 - loss: 0.3562 - val_accuracy: 0.8737 - val_loss: 0.3365 - mcc: 0.8060\n",
      "Epoch 5/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8701 - loss: 0.3460\n",
      "Epoch 5 - MCC: 0.8099\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 41ms/step - accuracy: 0.8701 - loss: 0.3460 - val_accuracy: 0.8755 - val_loss: 0.3275 - mcc: 0.8099\n",
      "Epoch 6/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8724 - loss: 0.3388\n",
      "Epoch 6 - MCC: 0.8117\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 40ms/step - accuracy: 0.8724 - loss: 0.3388 - val_accuracy: 0.8775 - val_loss: 0.3247 - mcc: 0.8117\n",
      "Epoch 7/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8752 - loss: 0.3313\n",
      "Epoch 7 - MCC: 0.8131\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 40ms/step - accuracy: 0.8752 - loss: 0.3313 - val_accuracy: 0.8770 - val_loss: 0.3268 - mcc: 0.8131\n",
      "Epoch 8/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8755 - loss: 0.3290\n",
      "Epoch 8 - MCC: 0.8103\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 40ms/step - accuracy: 0.8755 - loss: 0.3289 - val_accuracy: 0.8767 - val_loss: 0.3310 - mcc: 0.8103\n",
      "Epoch 9/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8751 - loss: 0.3336\n",
      "Epoch 9 - MCC: 0.8152\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 39ms/step - accuracy: 0.8751 - loss: 0.3336 - val_accuracy: 0.8799 - val_loss: 0.3238 - mcc: 0.8152\n",
      "Epoch 10/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8761 - loss: 0.3316\n",
      "Epoch 10 - MCC: 0.8024\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 41ms/step - accuracy: 0.8761 - loss: 0.3316 - val_accuracy: 0.8717 - val_loss: 0.3356 - mcc: 0.8024\n",
      "Epoch 11/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8736 - loss: 0.3328\n",
      "Epoch 11 - MCC: 0.8159\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 40ms/step - accuracy: 0.8736 - loss: 0.3328 - val_accuracy: 0.8799 - val_loss: 0.3149 - mcc: 0.8159\n",
      "Epoch 12/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8711 - loss: 0.3467\n",
      "Epoch 12 - MCC: 0.8097\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 40ms/step - accuracy: 0.8711 - loss: 0.3467 - val_accuracy: 0.8751 - val_loss: 0.3326 - mcc: 0.8097\n",
      "Epoch 13/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8783 - loss: 0.3231\n",
      "Epoch 13 - MCC: 0.8195\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 41ms/step - accuracy: 0.8783 - loss: 0.3231 - val_accuracy: 0.8827 - val_loss: 0.3119 - mcc: 0.8195\n",
      "Epoch 14/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8782 - loss: 0.3245\n",
      "Epoch 14 - MCC: 0.8138\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 40ms/step - accuracy: 0.8782 - loss: 0.3245 - val_accuracy: 0.8789 - val_loss: 0.3195 - mcc: 0.8138\n",
      "Epoch 15/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8793 - loss: 0.3228\n",
      "Epoch 15 - MCC: 0.8205\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 39ms/step - accuracy: 0.8793 - loss: 0.3228 - val_accuracy: 0.8834 - val_loss: 0.3114 - mcc: 0.8205\n",
      "Epoch 16/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8817 - loss: 0.3147\n",
      "Epoch 16 - MCC: 0.8193\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8816 - loss: 0.3147 - val_accuracy: 0.8820 - val_loss: 0.3129 - mcc: 0.8193\n",
      "Epoch 17/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8801 - loss: 0.3184\n",
      "Epoch 17 - MCC: 0.8249\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 41ms/step - accuracy: 0.8802 - loss: 0.3184 - val_accuracy: 0.8861 - val_loss: 0.3025 - mcc: 0.8249\n",
      "Epoch 18/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8852 - loss: 0.3076\n",
      "Epoch 18 - MCC: 0.8207\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 40ms/step - accuracy: 0.8852 - loss: 0.3076 - val_accuracy: 0.8835 - val_loss: 0.3145 - mcc: 0.8207\n",
      "Epoch 19/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8831 - loss: 0.3103\n",
      "Epoch 19 - MCC: 0.8283\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 40ms/step - accuracy: 0.8831 - loss: 0.3103 - val_accuracy: 0.8884 - val_loss: 0.2946 - mcc: 0.8283\n",
      "Epoch 20/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8768 - loss: 0.3295\n",
      "Epoch 20 - MCC: 0.8193\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 40ms/step - accuracy: 0.8768 - loss: 0.3295 - val_accuracy: 0.8816 - val_loss: 0.3137 - mcc: 0.8193\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.7120 - loss: 0.7565\n",
      "Epoch 1 - MCC: 0.7615\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 50ms/step - accuracy: 0.7122 - loss: 0.7560 - val_accuracy: 0.8440 - val_loss: 0.4082 - mcc: 0.7615\n",
      "Epoch 2/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8423 - loss: 0.4148\n",
      "Epoch 2 - MCC: 0.7760\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 40ms/step - accuracy: 0.8423 - loss: 0.4148 - val_accuracy: 0.8553 - val_loss: 0.3796 - mcc: 0.7760\n",
      "Epoch 3/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8551 - loss: 0.3842\n",
      "Epoch 3 - MCC: 0.7942\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8551 - loss: 0.3842 - val_accuracy: 0.8662 - val_loss: 0.3566 - mcc: 0.7942\n",
      "Epoch 4/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8631 - loss: 0.3631\n",
      "Epoch 4 - MCC: 0.7989\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8631 - loss: 0.3631 - val_accuracy: 0.8698 - val_loss: 0.3454 - mcc: 0.7989\n",
      "Epoch 5/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8688 - loss: 0.3498\n",
      "Epoch 5 - MCC: 0.7992\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8688 - loss: 0.3498 - val_accuracy: 0.8690 - val_loss: 0.3483 - mcc: 0.7992\n",
      "Epoch 6/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8713 - loss: 0.3423\n",
      "Epoch 6 - MCC: 0.8092\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8713 - loss: 0.3423 - val_accuracy: 0.8765 - val_loss: 0.3336 - mcc: 0.8092\n",
      "Epoch 7/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8738 - loss: 0.3358\n",
      "Epoch 7 - MCC: 0.8108\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 39ms/step - accuracy: 0.8738 - loss: 0.3358 - val_accuracy: 0.8767 - val_loss: 0.3304 - mcc: 0.8108\n",
      "Epoch 8/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8747 - loss: 0.3342\n",
      "Epoch 8 - MCC: 0.8130\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 39ms/step - accuracy: 0.8747 - loss: 0.3342 - val_accuracy: 0.8790 - val_loss: 0.3200 - mcc: 0.8130\n",
      "Epoch 9/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8766 - loss: 0.3282\n",
      "Epoch 9 - MCC: 0.8145\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8766 - loss: 0.3282 - val_accuracy: 0.8799 - val_loss: 0.3212 - mcc: 0.8145\n",
      "Epoch 10/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8784 - loss: 0.3227\n",
      "Epoch 10 - MCC: 0.8159\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 38ms/step - accuracy: 0.8784 - loss: 0.3227 - val_accuracy: 0.8809 - val_loss: 0.3155 - mcc: 0.8159\n",
      "Epoch 11/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8788 - loss: 0.3214\n",
      "Epoch 11 - MCC: 0.8194\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8788 - loss: 0.3214 - val_accuracy: 0.8831 - val_loss: 0.3085 - mcc: 0.8194\n",
      "Epoch 12/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8795 - loss: 0.3196\n",
      "Epoch 12 - MCC: 0.8180\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8795 - loss: 0.3196 - val_accuracy: 0.8808 - val_loss: 0.3135 - mcc: 0.8180\n",
      "Epoch 13/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8797 - loss: 0.3175\n",
      "Epoch 13 - MCC: 0.8183\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 39ms/step - accuracy: 0.8797 - loss: 0.3175 - val_accuracy: 0.8826 - val_loss: 0.3126 - mcc: 0.8183\n",
      "Epoch 14/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8803 - loss: 0.3168\n",
      "Epoch 14 - MCC: 0.8192\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8803 - loss: 0.3168 - val_accuracy: 0.8830 - val_loss: 0.3102 - mcc: 0.8192\n",
      "Epoch 15/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8814 - loss: 0.3128\n",
      "Epoch 15 - MCC: 0.8200\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 39ms/step - accuracy: 0.8814 - loss: 0.3128 - val_accuracy: 0.8834 - val_loss: 0.3098 - mcc: 0.8200\n",
      "Epoch 16/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8844 - loss: 0.3058\n",
      "Epoch 16 - MCC: 0.8194\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 38ms/step - accuracy: 0.8844 - loss: 0.3059 - val_accuracy: 0.8826 - val_loss: 0.3109 - mcc: 0.8194\n",
      "Epoch 17/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8792 - loss: 0.3179\n",
      "Epoch 17 - MCC: 0.8130\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8792 - loss: 0.3179 - val_accuracy: 0.8787 - val_loss: 0.3215 - mcc: 0.8130\n",
      "Epoch 18/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8770 - loss: 0.3265\n",
      "Epoch 18 - MCC: 0.8208\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8770 - loss: 0.3265 - val_accuracy: 0.8839 - val_loss: 0.3075 - mcc: 0.8208\n",
      "Epoch 19/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8798 - loss: 0.3179\n",
      "Epoch 19 - MCC: 0.8216\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8798 - loss: 0.3179 - val_accuracy: 0.8845 - val_loss: 0.3053 - mcc: 0.8216\n",
      "Epoch 20/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8814 - loss: 0.3132\n",
      "Epoch 20 - MCC: 0.8264\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 40ms/step - accuracy: 0.8814 - loss: 0.3132 - val_accuracy: 0.8874 - val_loss: 0.2998 - mcc: 0.8264\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.7299 - loss: 0.7115\n",
      "Epoch 1 - MCC: 0.7547\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 42ms/step - accuracy: 0.7300 - loss: 0.7110 - val_accuracy: 0.8414 - val_loss: 0.4182 - mcc: 0.7547\n",
      "Epoch 2/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8426 - loss: 0.4141\n",
      "Epoch 2 - MCC: 0.7721\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 39ms/step - accuracy: 0.8427 - loss: 0.4140 - val_accuracy: 0.8525 - val_loss: 0.3884 - mcc: 0.7721\n",
      "Epoch 3/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8527 - loss: 0.3877\n",
      "Epoch 3 - MCC: 0.7835\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8527 - loss: 0.3877 - val_accuracy: 0.8585 - val_loss: 0.3722 - mcc: 0.7835\n",
      "Epoch 4/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8615 - loss: 0.3676\n",
      "Epoch 4 - MCC: 0.7883\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 40ms/step - accuracy: 0.8615 - loss: 0.3676 - val_accuracy: 0.8627 - val_loss: 0.3641 - mcc: 0.7883\n",
      "Epoch 5/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8648 - loss: 0.3581\n",
      "Epoch 5 - MCC: 0.7904\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 39ms/step - accuracy: 0.8648 - loss: 0.3581 - val_accuracy: 0.8639 - val_loss: 0.3620 - mcc: 0.7904\n",
      "Epoch 6/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8663 - loss: 0.3542\n",
      "Epoch 6 - MCC: 0.8009\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8663 - loss: 0.3542 - val_accuracy: 0.8708 - val_loss: 0.3438 - mcc: 0.8009\n",
      "Epoch 7/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8710 - loss: 0.3416\n",
      "Epoch 7 - MCC: 0.8095\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 38ms/step - accuracy: 0.8710 - loss: 0.3416 - val_accuracy: 0.8760 - val_loss: 0.3279 - mcc: 0.8095\n",
      "Epoch 8/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8752 - loss: 0.3299\n",
      "Epoch 8 - MCC: 0.8096\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8752 - loss: 0.3299 - val_accuracy: 0.8762 - val_loss: 0.3295 - mcc: 0.8096\n",
      "Epoch 9/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8757 - loss: 0.3318\n",
      "Epoch 9 - MCC: 0.8082\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8757 - loss: 0.3319 - val_accuracy: 0.8744 - val_loss: 0.3339 - mcc: 0.8082\n",
      "Epoch 10/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8757 - loss: 0.3332\n",
      "Epoch 10 - MCC: 0.8121\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 40ms/step - accuracy: 0.8757 - loss: 0.3332 - val_accuracy: 0.8776 - val_loss: 0.3249 - mcc: 0.8121\n",
      "Epoch 11/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8784 - loss: 0.3237\n",
      "Epoch 11 - MCC: 0.8164\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 40ms/step - accuracy: 0.8784 - loss: 0.3237 - val_accuracy: 0.8799 - val_loss: 0.3191 - mcc: 0.8164\n",
      "Epoch 12/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8801 - loss: 0.3200\n",
      "Epoch 12 - MCC: 0.8082\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 40ms/step - accuracy: 0.8801 - loss: 0.3200 - val_accuracy: 0.8751 - val_loss: 0.3273 - mcc: 0.8082\n",
      "Epoch 13/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8762 - loss: 0.3273\n",
      "Epoch 13 - MCC: 0.8165\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 40ms/step - accuracy: 0.8762 - loss: 0.3273 - val_accuracy: 0.8792 - val_loss: 0.3159 - mcc: 0.8165\n",
      "Epoch 14/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8836 - loss: 0.3090\n",
      "Epoch 14 - MCC: 0.8200\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8836 - loss: 0.3090 - val_accuracy: 0.8830 - val_loss: 0.3104 - mcc: 0.8200\n",
      "Epoch 15/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8832 - loss: 0.3086\n",
      "Epoch 15 - MCC: 0.8230\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8832 - loss: 0.3086 - val_accuracy: 0.8847 - val_loss: 0.3054 - mcc: 0.8230\n",
      "Epoch 16/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8836 - loss: 0.3079\n",
      "Epoch 16 - MCC: 0.8219\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8836 - loss: 0.3079 - val_accuracy: 0.8841 - val_loss: 0.3096 - mcc: 0.8219\n",
      "Epoch 17/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8861 - loss: 0.3022\n",
      "Epoch 17 - MCC: 0.8232\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 40ms/step - accuracy: 0.8861 - loss: 0.3022 - val_accuracy: 0.8843 - val_loss: 0.3045 - mcc: 0.8232\n",
      "Epoch 18/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8847 - loss: 0.3063\n",
      "Epoch 18 - MCC: 0.8205\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8847 - loss: 0.3063 - val_accuracy: 0.8831 - val_loss: 0.3058 - mcc: 0.8205\n",
      "Epoch 19/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8838 - loss: 0.3084\n",
      "Epoch 19 - MCC: 0.8238\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 40ms/step - accuracy: 0.8838 - loss: 0.3084 - val_accuracy: 0.8854 - val_loss: 0.3025 - mcc: 0.8238\n",
      "Epoch 20/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8854 - loss: 0.3045\n",
      "Epoch 20 - MCC: 0.8283\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 40ms/step - accuracy: 0.8854 - loss: 0.3044 - val_accuracy: 0.8881 - val_loss: 0.2950 - mcc: 0.8283\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.7259 - loss: 0.7272\n",
      "Epoch 1 - MCC: 0.7604\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 46ms/step - accuracy: 0.7263 - loss: 0.7261 - val_accuracy: 0.8452 - val_loss: 0.4125 - mcc: 0.7604\n",
      "Epoch 2/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8474 - loss: 0.4059\n",
      "Epoch 2 - MCC: 0.7782\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 40ms/step - accuracy: 0.8474 - loss: 0.4058 - val_accuracy: 0.8568 - val_loss: 0.3811 - mcc: 0.7782\n",
      "Epoch 3/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8560 - loss: 0.3796\n",
      "Epoch 3 - MCC: 0.7882\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8560 - loss: 0.3796 - val_accuracy: 0.8624 - val_loss: 0.3638 - mcc: 0.7882\n",
      "Epoch 4/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8631 - loss: 0.3634\n",
      "Epoch 4 - MCC: 0.7831\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8632 - loss: 0.3633 - val_accuracy: 0.8603 - val_loss: 0.3708 - mcc: 0.7831\n",
      "Epoch 5/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8678 - loss: 0.3496\n",
      "Epoch 5 - MCC: 0.7982\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 39ms/step - accuracy: 0.8678 - loss: 0.3495 - val_accuracy: 0.8691 - val_loss: 0.3508 - mcc: 0.7982\n",
      "Epoch 6/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8706 - loss: 0.3440\n",
      "Epoch 6 - MCC: 0.8059\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 39ms/step - accuracy: 0.8706 - loss: 0.3440 - val_accuracy: 0.8746 - val_loss: 0.3373 - mcc: 0.8059\n",
      "Epoch 7/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8763 - loss: 0.3281\n",
      "Epoch 7 - MCC: 0.8073\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8763 - loss: 0.3281 - val_accuracy: 0.8754 - val_loss: 0.3349 - mcc: 0.8073\n",
      "Epoch 8/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8774 - loss: 0.3246\n",
      "Epoch 8 - MCC: 0.8069\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.8774 - loss: 0.3246 - val_accuracy: 0.8740 - val_loss: 0.3354 - mcc: 0.8069\n",
      "Epoch 9/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8751 - loss: 0.3305\n",
      "Epoch 9 - MCC: 0.8059\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.8751 - loss: 0.3305 - val_accuracy: 0.8744 - val_loss: 0.3353 - mcc: 0.8059\n",
      "Epoch 10/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8783 - loss: 0.3224\n",
      "Epoch 10 - MCC: 0.8059\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8783 - loss: 0.3224 - val_accuracy: 0.8743 - val_loss: 0.3404 - mcc: 0.8059\n",
      "Epoch 11/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8775 - loss: 0.3272\n",
      "Epoch 11 - MCC: 0.7993\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8775 - loss: 0.3272 - val_accuracy: 0.8687 - val_loss: 0.3439 - mcc: 0.7993\n",
      "Epoch 12/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8758 - loss: 0.3267\n",
      "Epoch 12 - MCC: 0.8153\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 39ms/step - accuracy: 0.8758 - loss: 0.3267 - val_accuracy: 0.8797 - val_loss: 0.3157 - mcc: 0.8153\n",
      "Epoch 13/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8757 - loss: 0.3323\n",
      "Epoch 13 - MCC: 0.7987\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 40ms/step - accuracy: 0.8757 - loss: 0.3324 - val_accuracy: 0.8699 - val_loss: 0.3476 - mcc: 0.7987\n",
      "Epoch 14/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8702 - loss: 0.3453\n",
      "Epoch 14 - MCC: 0.8093\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 39ms/step - accuracy: 0.8702 - loss: 0.3452 - val_accuracy: 0.8767 - val_loss: 0.3297 - mcc: 0.8093\n",
      "Epoch 15/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8771 - loss: 0.3255\n",
      "Epoch 15 - MCC: 0.8119\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8771 - loss: 0.3255 - val_accuracy: 0.8783 - val_loss: 0.3252 - mcc: 0.8119\n",
      "Epoch 16/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8803 - loss: 0.3167\n",
      "Epoch 16 - MCC: 0.8128\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 38ms/step - accuracy: 0.8803 - loss: 0.3167 - val_accuracy: 0.8773 - val_loss: 0.3248 - mcc: 0.8128\n",
      "Epoch 17/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8787 - loss: 0.3216\n",
      "Epoch 17 - MCC: 0.8144\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8787 - loss: 0.3216 - val_accuracy: 0.8793 - val_loss: 0.3224 - mcc: 0.8144\n",
      "Epoch 18/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8802 - loss: 0.3173\n",
      "Epoch 18 - MCC: 0.8151\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.8802 - loss: 0.3173 - val_accuracy: 0.8800 - val_loss: 0.3214 - mcc: 0.8151\n",
      "Epoch 19/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8813 - loss: 0.3148\n",
      "Epoch 19 - MCC: 0.8213\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8813 - loss: 0.3148 - val_accuracy: 0.8843 - val_loss: 0.3098 - mcc: 0.8213\n",
      "Epoch 20/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8851 - loss: 0.3055\n",
      "Epoch 20 - MCC: 0.8213\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8851 - loss: 0.3055 - val_accuracy: 0.8843 - val_loss: 0.3085 - mcc: 0.8213\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.7178 - loss: 0.7658\n",
      "Epoch 1 - MCC: 0.7595\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 48ms/step - accuracy: 0.7180 - loss: 0.7652 - val_accuracy: 0.8431 - val_loss: 0.4208 - mcc: 0.7595\n",
      "Epoch 2/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8482 - loss: 0.4025\n",
      "Epoch 2 - MCC: 0.7741\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8482 - loss: 0.4025 - val_accuracy: 0.8537 - val_loss: 0.3891 - mcc: 0.7741\n",
      "Epoch 3/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8605 - loss: 0.3689\n",
      "Epoch 3 - MCC: 0.7869\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8605 - loss: 0.3689 - val_accuracy: 0.8604 - val_loss: 0.3706 - mcc: 0.7869\n",
      "Epoch 4/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8637 - loss: 0.3616\n",
      "Epoch 4 - MCC: 0.7938\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 39ms/step - accuracy: 0.8637 - loss: 0.3616 - val_accuracy: 0.8660 - val_loss: 0.3571 - mcc: 0.7938\n",
      "Epoch 5/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8685 - loss: 0.3489\n",
      "Epoch 5 - MCC: 0.7950\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 38ms/step - accuracy: 0.8685 - loss: 0.3489 - val_accuracy: 0.8663 - val_loss: 0.3540 - mcc: 0.7950\n",
      "Epoch 6/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8741 - loss: 0.3358\n",
      "Epoch 6 - MCC: 0.8027\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 37ms/step - accuracy: 0.8741 - loss: 0.3359 - val_accuracy: 0.8717 - val_loss: 0.3403 - mcc: 0.8027\n",
      "Epoch 7/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8742 - loss: 0.3350\n",
      "Epoch 7 - MCC: 0.8072\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 38ms/step - accuracy: 0.8742 - loss: 0.3350 - val_accuracy: 0.8741 - val_loss: 0.3349 - mcc: 0.8072\n",
      "Epoch 8/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8774 - loss: 0.3265\n",
      "Epoch 8 - MCC: 0.8085\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 39ms/step - accuracy: 0.8774 - loss: 0.3265 - val_accuracy: 0.8756 - val_loss: 0.3311 - mcc: 0.8085\n",
      "Epoch 9/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8790 - loss: 0.3227\n",
      "Epoch 9 - MCC: 0.8039\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 39ms/step - accuracy: 0.8790 - loss: 0.3227 - val_accuracy: 0.8704 - val_loss: 0.3391 - mcc: 0.8039\n",
      "Epoch 10/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8807 - loss: 0.3175\n",
      "Epoch 10 - MCC: 0.8135\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 38ms/step - accuracy: 0.8807 - loss: 0.3175 - val_accuracy: 0.8786 - val_loss: 0.3213 - mcc: 0.8135\n",
      "Epoch 11/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8805 - loss: 0.3176\n",
      "Epoch 11 - MCC: 0.8141\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8805 - loss: 0.3176 - val_accuracy: 0.8788 - val_loss: 0.3238 - mcc: 0.8141\n",
      "Epoch 12/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8815 - loss: 0.3157\n",
      "Epoch 12 - MCC: 0.8164\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8815 - loss: 0.3157 - val_accuracy: 0.8803 - val_loss: 0.3172 - mcc: 0.8164\n",
      "Epoch 13/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8821 - loss: 0.3138\n",
      "Epoch 13 - MCC: 0.8169\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 39ms/step - accuracy: 0.8821 - loss: 0.3138 - val_accuracy: 0.8809 - val_loss: 0.3154 - mcc: 0.8169\n",
      "Epoch 14/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8813 - loss: 0.3137\n",
      "Epoch 14 - MCC: 0.7991\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 39ms/step - accuracy: 0.8813 - loss: 0.3137 - val_accuracy: 0.8689 - val_loss: 0.3481 - mcc: 0.7991\n",
      "Epoch 15/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8827 - loss: 0.3142\n",
      "Epoch 15 - MCC: 0.8184\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8827 - loss: 0.3142 - val_accuracy: 0.8815 - val_loss: 0.3151 - mcc: 0.8184\n",
      "Epoch 16/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8850 - loss: 0.3049\n",
      "Epoch 16 - MCC: 0.8154\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8850 - loss: 0.3049 - val_accuracy: 0.8800 - val_loss: 0.3196 - mcc: 0.8154\n",
      "Epoch 17/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8846 - loss: 0.3062\n",
      "Epoch 17 - MCC: 0.8186\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 38ms/step - accuracy: 0.8846 - loss: 0.3062 - val_accuracy: 0.8818 - val_loss: 0.3139 - mcc: 0.8186\n",
      "Epoch 18/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8865 - loss: 0.3009\n",
      "Epoch 18 - MCC: 0.8179\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8865 - loss: 0.3009 - val_accuracy: 0.8815 - val_loss: 0.3200 - mcc: 0.8179\n",
      "Epoch 19/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8873 - loss: 0.3000\n",
      "Epoch 19 - MCC: 0.8213\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 38ms/step - accuracy: 0.8873 - loss: 0.3000 - val_accuracy: 0.8837 - val_loss: 0.3059 - mcc: 0.8213\n",
      "Epoch 20/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8837 - loss: 0.3105\n",
      "Epoch 20 - MCC: 0.8196\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 39ms/step - accuracy: 0.8837 - loss: 0.3105 - val_accuracy: 0.8828 - val_loss: 0.3120 - mcc: 0.8196\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.8881006666666666),\n",
      "              'mean': np.float64(0.8848364),\n",
      "              'min': np.float64(0.8816186666666667),\n",
      "              'std': np.float64(0.002540691370473804)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.0005498362382253011),\n",
      "                               'mean': np.float64(0.0005268498897552491),\n",
      "                               'min': np.float64(0.0004771549701690674),\n",
      "                               'std': np.float64(2.77378075006709e-05)},\n",
      " 'MCC': {'max': np.float64(0.8283456684761119),\n",
      "         'mean': np.float64(0.8229736943926863),\n",
      "         'min': np.float64(0.8192743116754063),\n",
      "         'std': np.float64(0.003710519441095741)},\n",
      " 'Parameters': 6571,\n",
      " 'Train Time (s)': {'max': np.float64(376.99316239356995),\n",
      "                    'mean': np.float64(351.69678287506105),\n",
      "                    'min': np.float64(340.28177857398987),\n",
      "                    'std': np.float64(13.68001349867073)},\n",
      " 'Training Accuracy': [[0.8084667325019836,\n",
      "                        0.8500637412071228,\n",
      "                        0.8619034290313721,\n",
      "                        0.867506742477417,\n",
      "                        0.8714080452919006,\n",
      "                        0.8733795285224915,\n",
      "                        0.8757800459861755,\n",
      "                        0.8770201802253723,\n",
      "                        0.8765310049057007,\n",
      "                        0.873029351234436,\n",
      "                        0.873602032661438,\n",
      "                        0.8748024702072144,\n",
      "                        0.8785974383354187,\n",
      "                        0.8783353567123413,\n",
      "                        0.8805422186851501,\n",
      "                        0.8809812664985657,\n",
      "                        0.8822944164276123,\n",
      "                        0.8833584189414978,\n",
      "                        0.8831924796104431,\n",
      "                        0.875662624835968],\n",
      "                       [0.7931336164474487,\n",
      "                        0.8459417223930359,\n",
      "                        0.8567535281181335,\n",
      "                        0.8638160824775696,\n",
      "                        0.8689196705818176,\n",
      "                        0.8717318773269653,\n",
      "                        0.8735371828079224,\n",
      "                        0.8755824565887451,\n",
      "                        0.8769751191139221,\n",
      "                        0.877001166343689,\n",
      "                        0.8791649341583252,\n",
      "                        0.8804363012313843,\n",
      "                        0.8787510395050049,\n",
      "                        0.8817607164382935,\n",
      "                        0.8813507556915283,\n",
      "                        0.8829639554023743,\n",
      "                        0.8755621910095215,\n",
      "                        0.8777020573616028,\n",
      "                        0.8810908198356628,\n",
      "                        0.881990373134613],\n",
      "                       [0.8001049757003784,\n",
      "                        0.8470391631126404,\n",
      "                        0.8559957146644592,\n",
      "                        0.8611726760864258,\n",
      "                        0.865507185459137,\n",
      "                        0.8688664436340332,\n",
      "                        0.8727142810821533,\n",
      "                        0.8746300339698792,\n",
      "                        0.8718560338020325,\n",
      "                        0.8770458698272705,\n",
      "                        0.8785995244979858,\n",
      "                        0.8797273635864258,\n",
      "                        0.8801214098930359,\n",
      "                        0.882566511631012,\n",
      "                        0.8828661441802979,\n",
      "                        0.8833271265029907,\n",
      "                        0.8844853639602661,\n",
      "                        0.8849865198135376,\n",
      "                        0.8852457404136658,\n",
      "                        0.8860706090927124],\n",
      "                       [0.8005931973457336,\n",
      "                        0.8498243689537048,\n",
      "                        0.8592837452888489,\n",
      "                        0.8659839630126953,\n",
      "                        0.8691197037696838,\n",
      "                        0.8720000982284546,\n",
      "                        0.8746328353881836,\n",
      "                        0.8763843774795532,\n",
      "                        0.876305103302002,\n",
      "                        0.8769752383232117,\n",
      "                        0.8763487935066223,\n",
      "                        0.8782644867897034,\n",
      "                        0.8678533434867859,\n",
      "                        0.8737295866012573,\n",
      "                        0.8772538304328918,\n",
      "                        0.8796591758728027,\n",
      "                        0.8806154131889343,\n",
      "                        0.8818994760513306,\n",
      "                        0.8813583254814148,\n",
      "                        0.8836740851402283],\n",
      "                       [0.7947296500205994,\n",
      "                        0.8499366044998169,\n",
      "                        0.8599695563316345,\n",
      "                        0.8662393689155579,\n",
      "                        0.8692558407783508,\n",
      "                        0.8728447556495667,\n",
      "                        0.8747590184211731,\n",
      "                        0.8773264288902283,\n",
      "                        0.8773131370544434,\n",
      "                        0.8804764151573181,\n",
      "                        0.8811340928077698,\n",
      "                        0.8825267553329468,\n",
      "                        0.8828554153442383,\n",
      "                        0.883033037185669,\n",
      "                        0.8843247294425964,\n",
      "                        0.8856085538864136,\n",
      "                        0.885628342628479,\n",
      "                        0.8856984972953796,\n",
      "                        0.8864045143127441,\n",
      "                        0.8831201791763306]],\n",
      " 'Training Loss': [[0.5156686902046204,\n",
      "                    0.396382600069046,\n",
      "                    0.36727574467658997,\n",
      "                    0.35223424434661865,\n",
      "                    0.34225326776504517,\n",
      "                    0.3362763822078705,\n",
      "                    0.32937705516815186,\n",
      "                    0.32669204473495483,\n",
      "                    0.33032190799713135,\n",
      "                    0.3361937999725342,\n",
      "                    0.33357906341552734,\n",
      "                    0.3346531391143799,\n",
      "                    0.32294806838035583,\n",
      "                    0.3261944651603699,\n",
      "                    0.31956204771995544,\n",
      "                    0.31642910838127136,\n",
      "                    0.3130834698677063,\n",
      "                    0.3102773427963257,\n",
      "                    0.30995798110961914,\n",
      "                    0.33056098222732544],\n",
      "                   [0.5506664514541626,\n",
      "                    0.4050484299659729,\n",
      "                    0.3796795606613159,\n",
      "                    0.36234891414642334,\n",
      "                    0.3490763008594513,\n",
      "                    0.3412739038467407,\n",
      "                    0.33648043870925903,\n",
      "                    0.33151617646217346,\n",
      "                    0.32650893926620483,\n",
      "                    0.32592642307281494,\n",
      "                    0.3199045956134796,\n",
      "                    0.31638622283935547,\n",
      "                    0.32122838497161865,\n",
      "                    0.31275081634521484,\n",
      "                    0.3131328225135803,\n",
      "                    0.30952271819114685,\n",
      "                    0.3295539617538452,\n",
      "                    0.32466915249824524,\n",
      "                    0.3144640624523163,\n",
      "                    0.3125663101673126],\n",
      "                   [0.5360414385795593,\n",
      "                    0.4026731848716736,\n",
      "                    0.3801538050174713,\n",
      "                    0.3671704828739166,\n",
      "                    0.3562222421169281,\n",
      "                    0.34784239530563354,\n",
      "                    0.33752718567848206,\n",
      "                    0.33232831954956055,\n",
      "                    0.340829074382782,\n",
      "                    0.32885050773620605,\n",
      "                    0.3234143853187561,\n",
      "                    0.32005253434181213,\n",
      "                    0.31769126653671265,\n",
      "                    0.31253528594970703,\n",
      "                    0.3104182183742523,\n",
      "                    0.30897068977355957,\n",
      "                    0.30644991993904114,\n",
      "                    0.30475035309791565,\n",
      "                    0.304009348154068,\n",
      "                    0.301453173160553],\n",
      "                   [0.5365082025527954,\n",
      "                    0.3981136381626129,\n",
      "                    0.37268877029418945,\n",
      "                    0.35629284381866455,\n",
      "                    0.3465995788574219,\n",
      "                    0.33882150053977966,\n",
      "                    0.33205902576446533,\n",
      "                    0.3268609046936035,\n",
      "                    0.32784998416900635,\n",
      "                    0.3266855776309967,\n",
      "                    0.32816827297210693,\n",
      "                    0.32119041681289673,\n",
      "                    0.3523164391517639,\n",
      "                    0.3361976742744446,\n",
      "                    0.3260713517665863,\n",
      "                    0.3189621865749359,\n",
      "                    0.3159925639629364,\n",
      "                    0.3125719130039215,\n",
      "                    0.31524577736854553,\n",
      "                    0.30890190601348877],\n",
      "                   [0.5551114678382874,\n",
      "                    0.3970394432544708,\n",
      "                    0.37070995569229126,\n",
      "                    0.3557099997997284,\n",
      "                    0.34786397218704224,\n",
      "                    0.33884477615356445,\n",
      "                    0.3336288332939148,\n",
      "                    0.3266783356666565,\n",
      "                    0.3260091245174408,\n",
      "                    0.3184717297554016,\n",
      "                    0.3163427412509918,\n",
      "                    0.3132767081260681,\n",
      "                    0.3121757507324219,\n",
      "                    0.3103512227535248,\n",
      "                    0.3083951771259308,\n",
      "                    0.304279088973999,\n",
      "                    0.30374425649642944,\n",
      "                    0.30337560176849365,\n",
      "                    0.3026749789714813,\n",
      "                    0.3115629553794861]],\n",
      " 'Validation Accuracy': [[0.8492133617401123,\n",
      "                          0.8595001101493835,\n",
      "                          0.8661668300628662,\n",
      "                          0.8737446069717407,\n",
      "                          0.8754932284355164,\n",
      "                          0.877515971660614,\n",
      "                          0.8769758939743042,\n",
      "                          0.8766942024230957,\n",
      "                          0.8799088001251221,\n",
      "                          0.8716719746589661,\n",
      "                          0.8798714280128479,\n",
      "                          0.8751213550567627,\n",
      "                          0.8827105164527893,\n",
      "                          0.8789048790931702,\n",
      "                          0.8834166526794434,\n",
      "                          0.8820070624351501,\n",
      "                          0.8860908150672913,\n",
      "                          0.8834751844406128,\n",
      "                          0.8883829116821289,\n",
      "                          0.8816185593605042],\n",
      "                         [0.8440093398094177,\n",
      "                          0.8552929162979126,\n",
      "                          0.866237461566925,\n",
      "                          0.8698334097862244,\n",
      "                          0.8689962029457092,\n",
      "                          0.8765401244163513,\n",
      "                          0.8766545653343201,\n",
      "                          0.8789782524108887,\n",
      "                          0.8799440860748291,\n",
      "                          0.8808867931365967,\n",
      "                          0.8830989003181458,\n",
      "                          0.8807553648948669,\n",
      "                          0.8825511336326599,\n",
      "                          0.882998526096344,\n",
      "                          0.8833578824996948,\n",
      "                          0.882638692855835,\n",
      "                          0.8787412643432617,\n",
      "                          0.8838778734207153,\n",
      "                          0.8845124244689941,\n",
      "                          0.8874182105064392],\n",
      "                         [0.8414332866668701,\n",
      "                          0.8524751663208008,\n",
      "                          0.8584615588188171,\n",
      "                          0.8627058863639832,\n",
      "                          0.8638781905174255,\n",
      "                          0.8708146810531616,\n",
      "                          0.8759647011756897,\n",
      "                          0.8761813044548035,\n",
      "                          0.8743704557418823,\n",
      "                          0.8775859475135803,\n",
      "                          0.8799009323120117,\n",
      "                          0.8750880360603333,\n",
      "                          0.8791621327400208,\n",
      "                          0.8830062747001648,\n",
      "                          0.8846574425697327,\n",
      "                          0.8840657472610474,\n",
      "                          0.8843472599983215,\n",
      "                          0.8831029534339905,\n",
      "                          0.8853799104690552,\n",
      "                          0.8881005048751831],\n",
      "                         [0.8452151417732239,\n",
      "                          0.8568460941314697,\n",
      "                          0.8624014258384705,\n",
      "                          0.8603100776672363,\n",
      "                          0.8691281676292419,\n",
      "                          0.8745841383934021,\n",
      "                          0.8754474520683289,\n",
      "                          0.8740260601043701,\n",
      "                          0.8743820190429688,\n",
      "                          0.8743125796318054,\n",
      "                          0.8687300086021423,\n",
      "                          0.8797205686569214,\n",
      "                          0.8699480891227722,\n",
      "                          0.8766693472862244,\n",
      "                          0.8783375024795532,\n",
      "                          0.8772865533828735,\n",
      "                          0.8793247938156128,\n",
      "                          0.8799827694892883,\n",
      "                          0.8842846155166626,\n",
      "                          0.8842802047729492],\n",
      "                         [0.8430966138839722,\n",
      "                          0.8536953330039978,\n",
      "                          0.8603966236114502,\n",
      "                          0.8659774661064148,\n",
      "                          0.8662994503974915,\n",
      "                          0.871660053730011,\n",
      "                          0.8740559816360474,\n",
      "                          0.8755598068237305,\n",
      "                          0.8704174160957336,\n",
      "                          0.8786320686340332,\n",
      "                          0.8787786364555359,\n",
      "                          0.8802592754364014,\n",
      "                          0.8809031844139099,\n",
      "                          0.8689225316047668,\n",
      "                          0.8815298676490784,\n",
      "                          0.8800285458564758,\n",
      "                          0.8817948698997498,\n",
      "                          0.8815321326255798,\n",
      "                          0.8836948871612549,\n",
      "                          0.8827647566795349]],\n",
      " 'Validation Loss': [0.42082205414772034,\n",
      "                     0.38909468054771423,\n",
      "                     0.3705592751502991,\n",
      "                     0.35708874464035034,\n",
      "                     0.3540266156196594,\n",
      "                     0.3403027057647705,\n",
      "                     0.3349398672580719,\n",
      "                     0.331054151058197,\n",
      "                     0.3391088545322418,\n",
      "                     0.3213244378566742,\n",
      "                     0.3238382339477539,\n",
      "                     0.3171589970588684,\n",
      "                     0.3153827488422394,\n",
      "                     0.34807828068733215,\n",
      "                     0.3151128590106964,\n",
      "                     0.31956538558006287,\n",
      "                     0.313932329416275,\n",
      "                     0.3199703097343445,\n",
      "                     0.30594706535339355,\n",
      "                     0.3119578957557678],\n",
      " 'Validation MCC': [[np.float64(0.76688772837797),\n",
      "                     np.float64(0.7829413319757594),\n",
      "                     np.float64(0.7942398445566671),\n",
      "                     np.float64(0.8059514583635181),\n",
      "                     np.float64(0.8099223660200466),\n",
      "                     np.float64(0.811669387372758),\n",
      "                     np.float64(0.8131424426263556),\n",
      "                     np.float64(0.8103054173916974),\n",
      "                     np.float64(0.8151635805192294),\n",
      "                     np.float64(0.802436802493399),\n",
      "                     np.float64(0.8159134559722991),\n",
      "                     np.float64(0.8096943907396099),\n",
      "                     np.float64(0.8194893238629397),\n",
      "                     np.float64(0.8138463080094854),\n",
      "                     np.float64(0.8205422045547561),\n",
      "                     np.float64(0.8193227405918878),\n",
      "                     np.float64(0.8248636778150238),\n",
      "                     np.float64(0.8206774314657883),\n",
      "                     np.float64(0.8283274729884829),\n",
      "                     np.float64(0.8192743116754063)],\n",
      "                    [np.float64(0.7615435513172859),\n",
      "                     np.float64(0.775970308597584),\n",
      "                     np.float64(0.7941522574856187),\n",
      "                     np.float64(0.7988875060910796),\n",
      "                     np.float64(0.7992198679818566),\n",
      "                     np.float64(0.8092061235292921),\n",
      "                     np.float64(0.8108294598174121),\n",
      "                     np.float64(0.813003239702613),\n",
      "                     np.float64(0.8144504999716532),\n",
      "                     np.float64(0.8158644417590234),\n",
      "                     np.float64(0.8193627800285612),\n",
      "                     np.float64(0.81801791304123),\n",
      "                     np.float64(0.8183368798273446),\n",
      "                     np.float64(0.8192161165023926),\n",
      "                     np.float64(0.8199920082082386),\n",
      "                     np.float64(0.8194357636645795),\n",
      "                     np.float64(0.8129644873623563),\n",
      "                     np.float64(0.8207915145748849),\n",
      "                     np.float64(0.8216094693595313),\n",
      "                     np.float64(0.8264136700723302)],\n",
      "                    [np.float64(0.7547258943674343),\n",
      "                     np.float64(0.7721336056742002),\n",
      "                     np.float64(0.78345196650008),\n",
      "                     np.float64(0.7882877048060384),\n",
      "                     np.float64(0.7903695618239421),\n",
      "                     np.float64(0.8009145838449444),\n",
      "                     np.float64(0.8095046199870732),\n",
      "                     np.float64(0.8096139984859867),\n",
      "                     np.float64(0.808231995078053),\n",
      "                     np.float64(0.8121357857815705),\n",
      "                     np.float64(0.8163587224102854),\n",
      "                     np.float64(0.8081775842874608),\n",
      "                     np.float64(0.8165396432219022),\n",
      "                     np.float64(0.8199833321388241),\n",
      "                     np.float64(0.8230431719123315),\n",
      "                     np.float64(0.8218780359061251),\n",
      "                     np.float64(0.8231573594118259),\n",
      "                     np.float64(0.8205185400573816),\n",
      "                     np.float64(0.8237966014484492),\n",
      "                     np.float64(0.8283456684761119)],\n",
      "                    [np.float64(0.7603991915728348),\n",
      "                     np.float64(0.778203823219719),\n",
      "                     np.float64(0.7881584506849522),\n",
      "                     np.float64(0.7831187946489495),\n",
      "                     np.float64(0.7981864176978961),\n",
      "                     np.float64(0.8058956841479757),\n",
      "                     np.float64(0.8073109347021742),\n",
      "                     np.float64(0.8068803875418786),\n",
      "                     np.float64(0.8059227294291547),\n",
      "                     np.float64(0.805935694195554),\n",
      "                     np.float64(0.799277915178612),\n",
      "                     np.float64(0.8153413622386431),\n",
      "                     np.float64(0.798738293041352),\n",
      "                     np.float64(0.8093219456099279),\n",
      "                     np.float64(0.8119317962453447),\n",
      "                     np.float64(0.8127716567515381),\n",
      "                     np.float64(0.8144360608977399),\n",
      "                     np.float64(0.8150978419582529),\n",
      "                     np.float64(0.8213366213764491),\n",
      "                     np.float64(0.8212521656231326)],\n",
      "                    [np.float64(0.7595037707587848),\n",
      "                     np.float64(0.7740875315293407),\n",
      "                     np.float64(0.7869145699599298),\n",
      "                     np.float64(0.7937770267053457),\n",
      "                     np.float64(0.7950480667884186),\n",
      "                     np.float64(0.8027016219551224),\n",
      "                     np.float64(0.8072057217429465),\n",
      "                     np.float64(0.8084622457743612),\n",
      "                     np.float64(0.803856230971166),\n",
      "                     np.float64(0.8134981339268202),\n",
      "                     np.float64(0.8140503888057983),\n",
      "                     np.float64(0.8163872745503421),\n",
      "                     np.float64(0.816928442948628),\n",
      "                     np.float64(0.7991391819870465),\n",
      "                     np.float64(0.8183788836468593),\n",
      "                     np.float64(0.8154336253966878),\n",
      "                     np.float64(0.8185822792183878),\n",
      "                     np.float64(0.8179353450008562),\n",
      "                     np.float64(0.8212625119886233),\n",
      "                     np.float64(0.8195826561164502)]]}\n",
      "Training Model: GRU, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.6533 - loss: 0.9431\n",
      "Epoch 1 - MCC: 0.7683\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 26ms/step - accuracy: 0.6539 - loss: 0.9415 - val_accuracy: 0.8488 - val_loss: 0.4013 - mcc: 0.7683\n",
      "Epoch 2/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8520 - loss: 0.3923\n",
      "Epoch 2 - MCC: 0.8009\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 21ms/step - accuracy: 0.8520 - loss: 0.3921 - val_accuracy: 0.8694 - val_loss: 0.3405 - mcc: 0.8009\n",
      "Epoch 3/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8687 - loss: 0.3399\n",
      "Epoch 3 - MCC: 0.8080\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 22ms/step - accuracy: 0.8687 - loss: 0.3399 - val_accuracy: 0.8747 - val_loss: 0.3232 - mcc: 0.8080\n",
      "Epoch 4/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8761 - loss: 0.3206\n",
      "Epoch 4 - MCC: 0.8220\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 21ms/step - accuracy: 0.8761 - loss: 0.3206 - val_accuracy: 0.8838 - val_loss: 0.2964 - mcc: 0.8220\n",
      "Epoch 5/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8838 - loss: 0.2957\n",
      "Epoch 5 - MCC: 0.8292\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 23ms/step - accuracy: 0.8838 - loss: 0.2957 - val_accuracy: 0.8884 - val_loss: 0.2823 - mcc: 0.8292\n",
      "Epoch 6/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8888 - loss: 0.2801\n",
      "Epoch 6 - MCC: 0.8357\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.8888 - loss: 0.2801 - val_accuracy: 0.8924 - val_loss: 0.2690 - mcc: 0.8357\n",
      "Epoch 7/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8920 - loss: 0.2720\n",
      "Epoch 7 - MCC: 0.8361\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 20ms/step - accuracy: 0.8920 - loss: 0.2720 - val_accuracy: 0.8927 - val_loss: 0.2674 - mcc: 0.8361\n",
      "Epoch 8/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8933 - loss: 0.2667\n",
      "Epoch 8 - MCC: 0.8414\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 26ms/step - accuracy: 0.8933 - loss: 0.2667 - val_accuracy: 0.8963 - val_loss: 0.2586 - mcc: 0.8414\n",
      "Epoch 9/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8939 - loss: 0.2642\n",
      "Epoch 9 - MCC: 0.8436\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 25ms/step - accuracy: 0.8939 - loss: 0.2642 - val_accuracy: 0.8980 - val_loss: 0.2556 - mcc: 0.8436\n",
      "Epoch 10/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8970 - loss: 0.2567\n",
      "Epoch 10 - MCC: 0.8443\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 23ms/step - accuracy: 0.8970 - loss: 0.2567 - val_accuracy: 0.8977 - val_loss: 0.2533 - mcc: 0.8443\n",
      "Epoch 11/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8972 - loss: 0.2556\n",
      "Epoch 11 - MCC: 0.8481\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.8972 - loss: 0.2556 - val_accuracy: 0.9002 - val_loss: 0.2482 - mcc: 0.8481\n",
      "Epoch 12/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8986 - loss: 0.2517\n",
      "Epoch 12 - MCC: 0.8506\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 26ms/step - accuracy: 0.8986 - loss: 0.2517 - val_accuracy: 0.9023 - val_loss: 0.2432 - mcc: 0.8506\n",
      "Epoch 13/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9016 - loss: 0.2443\n",
      "Epoch 13 - MCC: 0.8515\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 25ms/step - accuracy: 0.9016 - loss: 0.2443 - val_accuracy: 0.9030 - val_loss: 0.2428 - mcc: 0.8515\n",
      "Epoch 14/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9013 - loss: 0.2452\n",
      "Epoch 14 - MCC: 0.8531\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 23ms/step - accuracy: 0.9013 - loss: 0.2452 - val_accuracy: 0.9039 - val_loss: 0.2382 - mcc: 0.8531\n",
      "Epoch 15/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9017 - loss: 0.2436\n",
      "Epoch 15 - MCC: 0.8533\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.9017 - loss: 0.2435 - val_accuracy: 0.9042 - val_loss: 0.2378 - mcc: 0.8533\n",
      "Epoch 16/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9044 - loss: 0.2371\n",
      "Epoch 16 - MCC: 0.8564\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 24ms/step - accuracy: 0.9044 - loss: 0.2371 - val_accuracy: 0.9060 - val_loss: 0.2331 - mcc: 0.8564\n",
      "Epoch 17/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9038 - loss: 0.2389\n",
      "Epoch 17 - MCC: 0.8517\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.9038 - loss: 0.2389 - val_accuracy: 0.9016 - val_loss: 0.2415 - mcc: 0.8517\n",
      "Epoch 18/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9056 - loss: 0.2347\n",
      "Epoch 18 - MCC: 0.8553\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.9056 - loss: 0.2347 - val_accuracy: 0.9051 - val_loss: 0.2340 - mcc: 0.8553\n",
      "Epoch 19/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9048 - loss: 0.2356\n",
      "Epoch 19 - MCC: 0.8584\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 24ms/step - accuracy: 0.9048 - loss: 0.2356 - val_accuracy: 0.9075 - val_loss: 0.2295 - mcc: 0.8584\n",
      "Epoch 20/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9059 - loss: 0.2330\n",
      "Epoch 20 - MCC: 0.8601\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 25ms/step - accuracy: 0.9059 - loss: 0.2329 - val_accuracy: 0.9084 - val_loss: 0.2266 - mcc: 0.8601\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.6737 - loss: 0.9263\n",
      "Epoch 1 - MCC: 0.7626\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 27ms/step - accuracy: 0.6742 - loss: 0.9248 - val_accuracy: 0.8458 - val_loss: 0.4116 - mcc: 0.7626\n",
      "Epoch 2/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8485 - loss: 0.4045\n",
      "Epoch 2 - MCC: 0.7956\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 23ms/step - accuracy: 0.8486 - loss: 0.4044 - val_accuracy: 0.8666 - val_loss: 0.3559 - mcc: 0.7956\n",
      "Epoch 3/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8649 - loss: 0.3611\n",
      "Epoch 3 - MCC: 0.8106\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 22ms/step - accuracy: 0.8649 - loss: 0.3610 - val_accuracy: 0.8762 - val_loss: 0.3238 - mcc: 0.8106\n",
      "Epoch 4/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8756 - loss: 0.3225\n",
      "Epoch 4 - MCC: 0.8277\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 25ms/step - accuracy: 0.8756 - loss: 0.3224 - val_accuracy: 0.8880 - val_loss: 0.2861 - mcc: 0.8277\n",
      "Epoch 5/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8868 - loss: 0.2862\n",
      "Epoch 5 - MCC: 0.8340\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 25ms/step - accuracy: 0.8868 - loss: 0.2862 - val_accuracy: 0.8920 - val_loss: 0.2749 - mcc: 0.8340\n",
      "Epoch 6/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8889 - loss: 0.2793\n",
      "Epoch 6 - MCC: 0.8405\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.8889 - loss: 0.2793 - val_accuracy: 0.8959 - val_loss: 0.2616 - mcc: 0.8405\n",
      "Epoch 7/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8959 - loss: 0.2612\n",
      "Epoch 7 - MCC: 0.8438\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.8959 - loss: 0.2613 - val_accuracy: 0.8981 - val_loss: 0.2557 - mcc: 0.8438\n",
      "Epoch 8/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8953 - loss: 0.2629\n",
      "Epoch 8 - MCC: 0.8477\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 26ms/step - accuracy: 0.8953 - loss: 0.2629 - val_accuracy: 0.9006 - val_loss: 0.2488 - mcc: 0.8477\n",
      "Epoch 9/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8982 - loss: 0.2536\n",
      "Epoch 9 - MCC: 0.8491\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.8982 - loss: 0.2536 - val_accuracy: 0.9014 - val_loss: 0.2468 - mcc: 0.8491\n",
      "Epoch 10/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8989 - loss: 0.2510\n",
      "Epoch 10 - MCC: 0.8492\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.8989 - loss: 0.2510 - val_accuracy: 0.9019 - val_loss: 0.2448 - mcc: 0.8492\n",
      "Epoch 11/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8987 - loss: 0.2506\n",
      "Epoch 11 - MCC: 0.8509\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.8987 - loss: 0.2506 - val_accuracy: 0.9030 - val_loss: 0.2425 - mcc: 0.8509\n",
      "Epoch 12/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9034 - loss: 0.2414\n",
      "Epoch 12 - MCC: 0.8532\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.9034 - loss: 0.2414 - val_accuracy: 0.9044 - val_loss: 0.2385 - mcc: 0.8532\n",
      "Epoch 13/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9004 - loss: 0.2469\n",
      "Epoch 13 - MCC: 0.8546\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 22ms/step - accuracy: 0.9004 - loss: 0.2469 - val_accuracy: 0.9055 - val_loss: 0.2368 - mcc: 0.8546\n",
      "Epoch 14/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9037 - loss: 0.2392\n",
      "Epoch 14 - MCC: 0.8553\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 23ms/step - accuracy: 0.9037 - loss: 0.2392 - val_accuracy: 0.9057 - val_loss: 0.2366 - mcc: 0.8553\n",
      "Epoch 15/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9040 - loss: 0.2379\n",
      "Epoch 15 - MCC: 0.8574\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 23ms/step - accuracy: 0.9040 - loss: 0.2379 - val_accuracy: 0.9068 - val_loss: 0.2354 - mcc: 0.8574\n",
      "Epoch 16/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9054 - loss: 0.2334\n",
      "Epoch 16 - MCC: 0.8596\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 20ms/step - accuracy: 0.9054 - loss: 0.2334 - val_accuracy: 0.9083 - val_loss: 0.2294 - mcc: 0.8596\n",
      "Epoch 17/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9059 - loss: 0.2335\n",
      "Epoch 17 - MCC: 0.8585\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 22ms/step - accuracy: 0.9059 - loss: 0.2335 - val_accuracy: 0.9079 - val_loss: 0.2307 - mcc: 0.8585\n",
      "Epoch 18/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9068 - loss: 0.2313\n",
      "Epoch 18 - MCC: 0.8614\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 23ms/step - accuracy: 0.9068 - loss: 0.2313 - val_accuracy: 0.9093 - val_loss: 0.2269 - mcc: 0.8614\n",
      "Epoch 19/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9068 - loss: 0.2318\n",
      "Epoch 19 - MCC: 0.8601\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 26ms/step - accuracy: 0.9068 - loss: 0.2318 - val_accuracy: 0.9091 - val_loss: 0.2268 - mcc: 0.8601\n",
      "Epoch 20/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9069 - loss: 0.2303\n",
      "Epoch 20 - MCC: 0.8619\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 22ms/step - accuracy: 0.9069 - loss: 0.2303 - val_accuracy: 0.9097 - val_loss: 0.2250 - mcc: 0.8619\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6497 - loss: 0.9358\n",
      "Epoch 1 - MCC: 0.7591\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 25ms/step - accuracy: 0.6508 - loss: 0.9327 - val_accuracy: 0.8415 - val_loss: 0.4203 - mcc: 0.7591\n",
      "Epoch 2/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8487 - loss: 0.4032\n",
      "Epoch 2 - MCC: 0.7838\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 20ms/step - accuracy: 0.8488 - loss: 0.4030 - val_accuracy: 0.8589 - val_loss: 0.3740 - mcc: 0.7838\n",
      "Epoch 3/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8660 - loss: 0.3542\n",
      "Epoch 3 - MCC: 0.8109\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.8660 - loss: 0.3541 - val_accuracy: 0.8767 - val_loss: 0.3235 - mcc: 0.8109\n",
      "Epoch 4/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8783 - loss: 0.3190\n",
      "Epoch 4 - MCC: 0.8162\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 23ms/step - accuracy: 0.8783 - loss: 0.3190 - val_accuracy: 0.8796 - val_loss: 0.3130 - mcc: 0.8162\n",
      "Epoch 5/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8816 - loss: 0.3077\n",
      "Epoch 5 - MCC: 0.8193\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 20ms/step - accuracy: 0.8816 - loss: 0.3077 - val_accuracy: 0.8816 - val_loss: 0.3071 - mcc: 0.8193\n",
      "Epoch 6/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8848 - loss: 0.2991\n",
      "Epoch 6 - MCC: 0.8223\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.8848 - loss: 0.2991 - val_accuracy: 0.8837 - val_loss: 0.3024 - mcc: 0.8223\n",
      "Epoch 7/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8840 - loss: 0.2995\n",
      "Epoch 7 - MCC: 0.8238\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.8841 - loss: 0.2995 - val_accuracy: 0.8853 - val_loss: 0.2984 - mcc: 0.8238\n",
      "Epoch 8/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8864 - loss: 0.2923\n",
      "Epoch 8 - MCC: 0.8283\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.8864 - loss: 0.2922 - val_accuracy: 0.8878 - val_loss: 0.2859 - mcc: 0.8283\n",
      "Epoch 9/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8906 - loss: 0.2798\n",
      "Epoch 9 - MCC: 0.8333\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.8906 - loss: 0.2798 - val_accuracy: 0.8912 - val_loss: 0.2762 - mcc: 0.8333\n",
      "Epoch 10/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8936 - loss: 0.2704\n",
      "Epoch 10 - MCC: 0.8376\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.8936 - loss: 0.2703 - val_accuracy: 0.8936 - val_loss: 0.2666 - mcc: 0.8376\n",
      "Epoch 11/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8947 - loss: 0.2644\n",
      "Epoch 11 - MCC: 0.8424\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 22ms/step - accuracy: 0.8947 - loss: 0.2643 - val_accuracy: 0.8971 - val_loss: 0.2569 - mcc: 0.8424\n",
      "Epoch 12/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8998 - loss: 0.2513\n",
      "Epoch 12 - MCC: 0.8455\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 20ms/step - accuracy: 0.8998 - loss: 0.2513 - val_accuracy: 0.8990 - val_loss: 0.2520 - mcc: 0.8455\n",
      "Epoch 13/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8986 - loss: 0.2534\n",
      "Epoch 13 - MCC: 0.8473\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 26ms/step - accuracy: 0.8986 - loss: 0.2533 - val_accuracy: 0.8995 - val_loss: 0.2496 - mcc: 0.8473\n",
      "Epoch 14/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9011 - loss: 0.2462\n",
      "Epoch 14 - MCC: 0.8476\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.9011 - loss: 0.2462 - val_accuracy: 0.8998 - val_loss: 0.2493 - mcc: 0.8476\n",
      "Epoch 15/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9019 - loss: 0.2439\n",
      "Epoch 15 - MCC: 0.8481\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 22ms/step - accuracy: 0.9019 - loss: 0.2439 - val_accuracy: 0.9007 - val_loss: 0.2477 - mcc: 0.8481\n",
      "Epoch 16/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9032 - loss: 0.2417\n",
      "Epoch 16 - MCC: 0.8500\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 23ms/step - accuracy: 0.9032 - loss: 0.2417 - val_accuracy: 0.9020 - val_loss: 0.2440 - mcc: 0.8500\n",
      "Epoch 17/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9032 - loss: 0.2410\n",
      "Epoch 17 - MCC: 0.8490\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 25ms/step - accuracy: 0.9032 - loss: 0.2410 - val_accuracy: 0.9014 - val_loss: 0.2461 - mcc: 0.8490\n",
      "Epoch 18/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9057 - loss: 0.2341\n",
      "Epoch 18 - MCC: 0.8446\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.9057 - loss: 0.2342 - val_accuracy: 0.8983 - val_loss: 0.2566 - mcc: 0.8446\n",
      "Epoch 19/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9051 - loss: 0.2358\n",
      "Epoch 19 - MCC: 0.8532\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 24ms/step - accuracy: 0.9051 - loss: 0.2358 - val_accuracy: 0.9039 - val_loss: 0.2381 - mcc: 0.8532\n",
      "Epoch 20/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9045 - loss: 0.2370\n",
      "Epoch 20 - MCC: 0.8548\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 20ms/step - accuracy: 0.9045 - loss: 0.2370 - val_accuracy: 0.9051 - val_loss: 0.2371 - mcc: 0.8548\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6592 - loss: 0.9128\n",
      "Epoch 1 - MCC: 0.7641\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 25ms/step - accuracy: 0.6595 - loss: 0.9120 - val_accuracy: 0.8452 - val_loss: 0.4158 - mcc: 0.7641\n",
      "Epoch 2/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8506 - loss: 0.4000\n",
      "Epoch 2 - MCC: 0.7891\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 20ms/step - accuracy: 0.8506 - loss: 0.4000 - val_accuracy: 0.8631 - val_loss: 0.3730 - mcc: 0.7891\n",
      "Epoch 3/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8648 - loss: 0.3614\n",
      "Epoch 3 - MCC: 0.8023\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.8648 - loss: 0.3614 - val_accuracy: 0.8713 - val_loss: 0.3465 - mcc: 0.8023\n",
      "Epoch 4/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8743 - loss: 0.3359\n",
      "Epoch 4 - MCC: 0.8145\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 24ms/step - accuracy: 0.8743 - loss: 0.3359 - val_accuracy: 0.8794 - val_loss: 0.3182 - mcc: 0.8145\n",
      "Epoch 5/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8807 - loss: 0.3116\n",
      "Epoch 5 - MCC: 0.8237\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 23ms/step - accuracy: 0.8807 - loss: 0.3116 - val_accuracy: 0.8853 - val_loss: 0.2952 - mcc: 0.8237\n",
      "Epoch 6/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8874 - loss: 0.2884\n",
      "Epoch 6 - MCC: 0.8290\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.8874 - loss: 0.2884 - val_accuracy: 0.8890 - val_loss: 0.2837 - mcc: 0.8290\n",
      "Epoch 7/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8889 - loss: 0.2820\n",
      "Epoch 7 - MCC: 0.8329\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 24ms/step - accuracy: 0.8890 - loss: 0.2819 - val_accuracy: 0.8914 - val_loss: 0.2764 - mcc: 0.8329\n",
      "Epoch 8/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8927 - loss: 0.2714\n",
      "Epoch 8 - MCC: 0.8379\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 22ms/step - accuracy: 0.8927 - loss: 0.2714 - val_accuracy: 0.8943 - val_loss: 0.2664 - mcc: 0.8379\n",
      "Epoch 9/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8940 - loss: 0.2662\n",
      "Epoch 9 - MCC: 0.8401\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.8940 - loss: 0.2662 - val_accuracy: 0.8958 - val_loss: 0.2615 - mcc: 0.8401\n",
      "Epoch 10/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8974 - loss: 0.2566\n",
      "Epoch 10 - MCC: 0.8437\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 25ms/step - accuracy: 0.8974 - loss: 0.2566 - val_accuracy: 0.8983 - val_loss: 0.2541 - mcc: 0.8437\n",
      "Epoch 11/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9001 - loss: 0.2503\n",
      "Epoch 11 - MCC: 0.8460\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.9001 - loss: 0.2503 - val_accuracy: 0.8996 - val_loss: 0.2513 - mcc: 0.8460\n",
      "Epoch 12/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9007 - loss: 0.2474\n",
      "Epoch 12 - MCC: 0.8453\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.9007 - loss: 0.2474 - val_accuracy: 0.8994 - val_loss: 0.2516 - mcc: 0.8453\n",
      "Epoch 13/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9013 - loss: 0.2456\n",
      "Epoch 13 - MCC: 0.8498\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 22ms/step - accuracy: 0.9013 - loss: 0.2456 - val_accuracy: 0.9021 - val_loss: 0.2452 - mcc: 0.8498\n",
      "Epoch 14/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9017 - loss: 0.2447\n",
      "Epoch 14 - MCC: 0.8502\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 26ms/step - accuracy: 0.9017 - loss: 0.2447 - val_accuracy: 0.9025 - val_loss: 0.2439 - mcc: 0.8502\n",
      "Epoch 15/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9031 - loss: 0.2400\n",
      "Epoch 15 - MCC: 0.8511\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.9031 - loss: 0.2400 - val_accuracy: 0.9028 - val_loss: 0.2427 - mcc: 0.8511\n",
      "Epoch 16/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9045 - loss: 0.2358\n",
      "Epoch 16 - MCC: 0.8412\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 23ms/step - accuracy: 0.9044 - loss: 0.2358 - val_accuracy: 0.8963 - val_loss: 0.2636 - mcc: 0.8412\n",
      "Epoch 17/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9043 - loss: 0.2385\n",
      "Epoch 17 - MCC: 0.8543\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.9043 - loss: 0.2385 - val_accuracy: 0.9050 - val_loss: 0.2380 - mcc: 0.8543\n",
      "Epoch 18/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9072 - loss: 0.2309\n",
      "Epoch 18 - MCC: 0.8559\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.9072 - loss: 0.2309 - val_accuracy: 0.9060 - val_loss: 0.2350 - mcc: 0.8559\n",
      "Epoch 19/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9059 - loss: 0.2333\n",
      "Epoch 19 - MCC: 0.8553\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 23ms/step - accuracy: 0.9059 - loss: 0.2333 - val_accuracy: 0.9049 - val_loss: 0.2366 - mcc: 0.8553\n",
      "Epoch 20/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9082 - loss: 0.2274\n",
      "Epoch 20 - MCC: 0.8581\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.9081 - loss: 0.2274 - val_accuracy: 0.9072 - val_loss: 0.2318 - mcc: 0.8581\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6338 - loss: 0.9448\n",
      "Epoch 1 - MCC: 0.7574\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 25ms/step - accuracy: 0.6345 - loss: 0.9431 - val_accuracy: 0.8415 - val_loss: 0.4258 - mcc: 0.7574\n",
      "Epoch 2/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8497 - loss: 0.4056\n",
      "Epoch 2 - MCC: 0.7834\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.8497 - loss: 0.4056 - val_accuracy: 0.8591 - val_loss: 0.3810 - mcc: 0.7834\n",
      "Epoch 3/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8659 - loss: 0.3604\n",
      "Epoch 3 - MCC: 0.7974\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.8659 - loss: 0.3604 - val_accuracy: 0.8680 - val_loss: 0.3496 - mcc: 0.7974\n",
      "Epoch 4/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8749 - loss: 0.3291\n",
      "Epoch 4 - MCC: 0.8097\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 23ms/step - accuracy: 0.8749 - loss: 0.3291 - val_accuracy: 0.8763 - val_loss: 0.3182 - mcc: 0.8097\n",
      "Epoch 5/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8810 - loss: 0.3041\n",
      "Epoch 5 - MCC: 0.8215\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.8810 - loss: 0.3041 - val_accuracy: 0.8835 - val_loss: 0.2957 - mcc: 0.8215\n",
      "Epoch 6/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8874 - loss: 0.2855\n",
      "Epoch 6 - MCC: 0.8232\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.8874 - loss: 0.2854 - val_accuracy: 0.8842 - val_loss: 0.2901 - mcc: 0.8232\n",
      "Epoch 7/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8890 - loss: 0.2812\n",
      "Epoch 7 - MCC: 0.8291\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.8890 - loss: 0.2811 - val_accuracy: 0.8886 - val_loss: 0.2809 - mcc: 0.8291\n",
      "Epoch 8/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8924 - loss: 0.2708\n",
      "Epoch 8 - MCC: 0.8309\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 23ms/step - accuracy: 0.8924 - loss: 0.2708 - val_accuracy: 0.8893 - val_loss: 0.2775 - mcc: 0.8309\n",
      "Epoch 9/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8952 - loss: 0.2642\n",
      "Epoch 9 - MCC: 0.8305\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 20ms/step - accuracy: 0.8952 - loss: 0.2642 - val_accuracy: 0.8885 - val_loss: 0.2781 - mcc: 0.8305\n",
      "Epoch 10/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8966 - loss: 0.2605\n",
      "Epoch 10 - MCC: 0.8393\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 25ms/step - accuracy: 0.8966 - loss: 0.2605 - val_accuracy: 0.8948 - val_loss: 0.2643 - mcc: 0.8393\n",
      "Epoch 11/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9000 - loss: 0.2515\n",
      "Epoch 11 - MCC: 0.8393\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 24ms/step - accuracy: 0.9000 - loss: 0.2515 - val_accuracy: 0.8938 - val_loss: 0.2644 - mcc: 0.8393\n",
      "Epoch 12/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9001 - loss: 0.2502\n",
      "Epoch 12 - MCC: 0.8428\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 24ms/step - accuracy: 0.9001 - loss: 0.2502 - val_accuracy: 0.8972 - val_loss: 0.2585 - mcc: 0.8428\n",
      "Epoch 13/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9000 - loss: 0.2507\n",
      "Epoch 13 - MCC: 0.8434\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.9000 - loss: 0.2506 - val_accuracy: 0.8978 - val_loss: 0.2557 - mcc: 0.8434\n",
      "Epoch 14/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9034 - loss: 0.2421\n",
      "Epoch 14 - MCC: 0.8457\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 23ms/step - accuracy: 0.9034 - loss: 0.2421 - val_accuracy: 0.8992 - val_loss: 0.2531 - mcc: 0.8457\n",
      "Epoch 15/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9047 - loss: 0.2385\n",
      "Epoch 15 - MCC: 0.8479\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 26ms/step - accuracy: 0.9047 - loss: 0.2385 - val_accuracy: 0.9005 - val_loss: 0.2487 - mcc: 0.8479\n",
      "Epoch 16/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9030 - loss: 0.2423\n",
      "Epoch 16 - MCC: 0.8483\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 22ms/step - accuracy: 0.9030 - loss: 0.2423 - val_accuracy: 0.9010 - val_loss: 0.2474 - mcc: 0.8483\n",
      "Epoch 17/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9055 - loss: 0.2355\n",
      "Epoch 17 - MCC: 0.8494\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - accuracy: 0.9055 - loss: 0.2355 - val_accuracy: 0.9011 - val_loss: 0.2449 - mcc: 0.8494\n",
      "Epoch 18/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9078 - loss: 0.2301\n",
      "Epoch 18 - MCC: 0.8508\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 26ms/step - accuracy: 0.9078 - loss: 0.2301 - val_accuracy: 0.9021 - val_loss: 0.2437 - mcc: 0.8508\n",
      "Epoch 19/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9075 - loss: 0.2295\n",
      "Epoch 19 - MCC: 0.8495\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 23ms/step - accuracy: 0.9075 - loss: 0.2295 - val_accuracy: 0.9016 - val_loss: 0.2463 - mcc: 0.8495\n",
      "Epoch 20/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9068 - loss: 0.2310\n",
      "Epoch 20 - MCC: 0.8511\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 22ms/step - accuracy: 0.9068 - loss: 0.2310 - val_accuracy: 0.9025 - val_loss: 0.2428 - mcc: 0.8511\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.90974),\n",
      "              'mean': np.float64(0.9065702666666666),\n",
      "              'min': np.float64(0.9024926666666667),\n",
      "              'std': np.float64(0.0025551114991978837)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.0005484193166097006),\n",
      "                               'mean': np.float64(0.0005038740634918214),\n",
      "                               'min': np.float64(0.0004125247001647949),\n",
      "                               'std': np.float64(4.778957671051945e-05)},\n",
      " 'MCC': {'max': np.float64(0.8618655703833864),\n",
      "         'mean': np.float64(0.8571964981052063),\n",
      "         'min': np.float64(0.8510529999256433),\n",
      "         'std': np.float64(0.0038684200243306833)},\n",
      " 'Parameters': 7294,\n",
      " 'Train Time (s)': {'max': np.float64(200.1817433834076),\n",
      "                    'mean': np.float64(194.68739190101624),\n",
      "                    'min': np.float64(191.2974817752838),\n",
      "                    'std': np.float64(3.36486462370086)},\n",
      " 'Training Accuracy': [[0.7633221745491028,\n",
      "                        0.8576648831367493,\n",
      "                        0.8706586360931396,\n",
      "                        0.8772712349891663,\n",
      "                        0.8837066292762756,\n",
      "                        0.8883348703384399,\n",
      "                        0.8908747434616089,\n",
      "                        0.8934021592140198,\n",
      "                        0.8945642113685608,\n",
      "                        0.8968351483345032,\n",
      "                        0.8977712392807007,\n",
      "                        0.899385929107666,\n",
      "                        0.9009897708892822,\n",
      "                        0.9016757607460022,\n",
      "                        0.9027721881866455,\n",
      "                        0.9033342003822327,\n",
      "                        0.904477596282959,\n",
      "                        0.9053491353988647,\n",
      "                        0.9061346650123596,\n",
      "                        0.906803548336029],\n",
      "                       [0.7691671252250671,\n",
      "                        0.8533098697662354,\n",
      "                        0.8694642782211304,\n",
      "                        0.8797896504402161,\n",
      "                        0.8876155018806458,\n",
      "                        0.8917548060417175,\n",
      "                        0.8948525190353394,\n",
      "                        0.8962898850440979,\n",
      "                        0.8983330130577087,\n",
      "                        0.8994272351264954,\n",
      "                        0.9000482559204102,\n",
      "                        0.9018018245697021,\n",
      "                        0.9019833207130432,\n",
      "                        0.9031703472137451,\n",
      "                        0.9044336676597595,\n",
      "                        0.9049711227416992,\n",
      "                        0.9058573246002197,\n",
      "                        0.9061967134475708,\n",
      "                        0.9068267941474915,\n",
      "                        0.9076678156852722],\n",
      "                       [0.7602601647377014,\n",
      "                        0.8541218042373657,\n",
      "                        0.8708482980728149,\n",
      "                        0.8783035278320312,\n",
      "                        0.8815918564796448,\n",
      "                        0.8836790323257446,\n",
      "                        0.885698139667511,\n",
      "                        0.8876053094863892,\n",
      "                        0.8912707567214966,\n",
      "                        0.8943486213684082,\n",
      "                        0.8964126110076904,\n",
      "                        0.8985977172851562,\n",
      "                        0.9000278115272522,\n",
      "                        0.9013466238975525,\n",
      "                        0.9024004936218262,\n",
      "                        0.9032851457595825,\n",
      "                        0.9042358994483948,\n",
      "                        0.9047932028770447,\n",
      "                        0.9055126905441284,\n",
      "                        0.9061373472213745],\n",
      "                       [0.7692193984985352,\n",
      "                        0.8550055623054504,\n",
      "                        0.8675064444541931,\n",
      "                        0.8758593797683716,\n",
      "                        0.8826760053634644,\n",
      "                        0.886875569820404,\n",
      "                        0.8905773758888245,\n",
      "                        0.8932352662086487,\n",
      "                        0.8956202268600464,\n",
      "                        0.8979217410087585,\n",
      "                        0.8991954922676086,\n",
      "                        0.9004468321800232,\n",
      "                        0.9015986323356628,\n",
      "                        0.9027247428894043,\n",
      "                        0.9034500122070312,\n",
      "                        0.903263509273529,\n",
      "                        0.9051295518875122,\n",
      "                        0.9061084985733032,\n",
      "                        0.9066479206085205,\n",
      "                        0.9071723818778992],\n",
      "                       [0.7585052847862244,\n",
      "                        0.8537655472755432,\n",
      "                        0.8676584362983704,\n",
      "                        0.8764259219169617,\n",
      "                        0.8841516375541687,\n",
      "                        0.888781726360321,\n",
      "                        0.8909914493560791,\n",
      "                        0.8934074640274048,\n",
      "                        0.8954554200172424,\n",
      "                        0.8976670503616333,\n",
      "                        0.8989659547805786,\n",
      "                        0.9005921483039856,\n",
      "                        0.9019442796707153,\n",
      "                        0.9031744003295898,\n",
      "                        0.9037477970123291,\n",
      "                        0.9044274091720581,\n",
      "                        0.9054449796676636,\n",
      "                        0.9064357876777649,\n",
      "                        0.9071403741836548,\n",
      "                        0.907724142074585]],\n",
      " 'Training Loss': [[0.6475849747657776,\n",
      "                    0.3753199875354767,\n",
      "                    0.33522120118141174,\n",
      "                    0.3146781623363495,\n",
      "                    0.29472246766090393,\n",
      "                    0.28082266449928284,\n",
      "                    0.2731468081474304,\n",
      "                    0.2659192383289337,\n",
      "                    0.2624819576740265,\n",
      "                    0.25631073117256165,\n",
      "                    0.2540704011917114,\n",
      "                    0.25001227855682373,\n",
      "                    0.2457340508699417,\n",
      "                    0.24372199177742004,\n",
      "                    0.2408520132303238,\n",
      "                    0.2390909641981125,\n",
      "                    0.236643448472023,\n",
      "                    0.23454700410366058,\n",
      "                    0.2328004688024521,\n",
      "                    0.23047581315040588],\n",
      "                   [0.6398709416389465,\n",
      "                    0.3919079601764679,\n",
      "                    0.3475044369697571,\n",
      "                    0.3094523251056671,\n",
      "                    0.2840770184993744,\n",
      "                    0.27166274189949036,\n",
      "                    0.2631913423538208,\n",
      "                    0.2603844106197357,\n",
      "                    0.2537415325641632,\n",
      "                    0.250421404838562,\n",
      "                    0.2483983188867569,\n",
      "                    0.24444036185741425,\n",
      "                    0.24374856054782867,\n",
      "                    0.24055548012256622,\n",
      "                    0.23737184703350067,\n",
      "                    0.23587219417095184,\n",
      "                    0.23358099162578583,\n",
      "                    0.23325268924236298,\n",
      "                    0.23177951574325562,\n",
      "                    0.2295147031545639],\n",
      "                   [0.6407150030136108,\n",
      "                    0.3884695768356323,\n",
      "                    0.3415813446044922,\n",
      "                    0.31773051619529724,\n",
      "                    0.3076739013195038,\n",
      "                    0.30129244923591614,\n",
      "                    0.2952278256416321,\n",
      "                    0.2888675332069397,\n",
      "                    0.27678239345550537,\n",
      "                    0.26692309975624084,\n",
      "                    0.25973886251449585,\n",
      "                    0.2537713348865509,\n",
      "                    0.24960815906524658,\n",
      "                    0.24571138620376587,\n",
      "                    0.24298790097236633,\n",
      "                    0.2415848970413208,\n",
      "                    0.238301619887352,\n",
      "                    0.23678238689899445,\n",
      "                    0.23443490266799927,\n",
      "                    0.23317024111747742],\n",
      "                   [0.6211706399917603,\n",
      "                    0.38860806822776794,\n",
      "                    0.35487228631973267,\n",
      "                    0.33005690574645996,\n",
      "                    0.3040967285633087,\n",
      "                    0.28865042328834534,\n",
      "                    0.27703872323036194,\n",
      "                    0.2695811688899994,\n",
      "                    0.262265145778656,\n",
      "                    0.2549743354320526,\n",
      "                    0.25161251425743103,\n",
      "                    0.24810366332530975,\n",
      "                    0.24497853219509125,\n",
      "                    0.24216952919960022,\n",
      "                    0.2398880422115326,\n",
      "                    0.240822896361351,\n",
      "                    0.23555399477481842,\n",
      "                    0.2327246516942978,\n",
      "                    0.2314823418855667,\n",
      "                    0.2301376610994339],\n",
      "                   [0.6413063406944275,\n",
      "                    0.3932763338088989,\n",
      "                    0.3542296290397644,\n",
      "                    0.3224601745605469,\n",
      "                    0.2950022220611572,\n",
      "                    0.2814558744430542,\n",
      "                    0.2753412127494812,\n",
      "                    0.26823189854621887,\n",
      "                    0.2630405128002167,\n",
      "                    0.25786063075065613,\n",
      "                    0.25346699357032776,\n",
      "                    0.2489510476589203,\n",
      "                    0.24615482985973358,\n",
      "                    0.24229134619235992,\n",
      "                    0.24065181612968445,\n",
      "                    0.2385758012533188,\n",
      "                    0.23572111129760742,\n",
      "                    0.23344768583774567,\n",
      "                    0.2308758795261383,\n",
      "                    0.22979509830474854]],\n",
      " 'Validation Accuracy': [[0.8487521409988403,\n",
      "                          0.8694334030151367,\n",
      "                          0.874718427658081,\n",
      "                          0.8837527632713318,\n",
      "                          0.8883998394012451,\n",
      "                          0.8924208879470825,\n",
      "                          0.8926999568939209,\n",
      "                          0.8963282108306885,\n",
      "                          0.8980241417884827,\n",
      "                          0.8977000117301941,\n",
      "                          0.9001625776290894,\n",
      "                          0.9023372530937195,\n",
      "                          0.9029906392097473,\n",
      "                          0.9039126634597778,\n",
      "                          0.9042041301727295,\n",
      "                          0.9060191512107849,\n",
      "                          0.9016208648681641,\n",
      "                          0.9050625562667847,\n",
      "                          0.9075116515159607,\n",
      "                          0.9083907008171082],\n",
      "                         [0.8457741141319275,\n",
      "                          0.8666425943374634,\n",
      "                          0.8761599063873291,\n",
      "                          0.8880087733268738,\n",
      "                          0.8920450806617737,\n",
      "                          0.89589923620224,\n",
      "                          0.8980832695960999,\n",
      "                          0.9006140232086182,\n",
      "                          0.9013720154762268,\n",
      "                          0.901944100856781,\n",
      "                          0.9029601216316223,\n",
      "                          0.9044144153594971,\n",
      "                          0.9054833054542542,\n",
      "                          0.9057040214538574,\n",
      "                          0.9067612290382385,\n",
      "                          0.9082799553871155,\n",
      "                          0.9079426527023315,\n",
      "                          0.9093233346939087,\n",
      "                          0.9090520143508911,\n",
      "                          0.9097399711608887],\n",
      "                         [0.8415079116821289,\n",
      "                          0.8589085340499878,\n",
      "                          0.8767259120941162,\n",
      "                          0.8796346783638,\n",
      "                          0.8816013932228088,\n",
      "                          0.883653461933136,\n",
      "                          0.8853114247322083,\n",
      "                          0.8877750635147095,\n",
      "                          0.8912460207939148,\n",
      "                          0.893597424030304,\n",
      "                          0.8970521092414856,\n",
      "                          0.8989927768707275,\n",
      "                          0.8995214700698853,\n",
      "                          0.8997551798820496,\n",
      "                          0.9006528258323669,\n",
      "                          0.9020499587059021,\n",
      "                          0.9013939499855042,\n",
      "                          0.8983325958251953,\n",
      "                          0.9038647413253784,\n",
      "                          0.9050559997558594],\n",
      "                         [0.8451535701751709,\n",
      "                          0.8630765080451965,\n",
      "                          0.8713152408599854,\n",
      "                          0.8793806433677673,\n",
      "                          0.8853179812431335,\n",
      "                          0.8889982104301453,\n",
      "                          0.8914467692375183,\n",
      "                          0.8942521214485168,\n",
      "                          0.8958436846733093,\n",
      "                          0.898272693157196,\n",
      "                          0.899630606174469,\n",
      "                          0.8994293808937073,\n",
      "                          0.9020871520042419,\n",
      "                          0.9025201201438904,\n",
      "                          0.9027565121650696,\n",
      "                          0.8963152766227722,\n",
      "                          0.9050337076187134,\n",
      "                          0.9060401320457458,\n",
      "                          0.9048600196838379,\n",
      "                          0.9071719646453857],\n",
      "                         [0.8414854407310486,\n",
      "                          0.8590802550315857,\n",
      "                          0.867987871170044,\n",
      "                          0.8763179779052734,\n",
      "                          0.8835460543632507,\n",
      "                          0.8842125535011292,\n",
      "                          0.888590395450592,\n",
      "                          0.8893346190452576,\n",
      "                          0.8884894847869873,\n",
      "                          0.8948091864585876,\n",
      "                          0.8938097953796387,\n",
      "                          0.897158682346344,\n",
      "                          0.89778733253479,\n",
      "                          0.8991668820381165,\n",
      "                          0.9005332589149475,\n",
      "                          0.900998592376709,\n",
      "                          0.9011266231536865,\n",
      "                          0.9020711183547974,\n",
      "                          0.9015761613845825,\n",
      "                          0.9024927616119385]],\n",
      " 'Validation Loss': [0.42578673362731934,\n",
      "                     0.3809545934200287,\n",
      "                     0.34961405396461487,\n",
      "                     0.3182388246059418,\n",
      "                     0.29573434591293335,\n",
      "                     0.2901078462600708,\n",
      "                     0.28094395995140076,\n",
      "                     0.27749770879745483,\n",
      "                     0.2781226634979248,\n",
      "                     0.2642960846424103,\n",
      "                     0.26439765095710754,\n",
      "                     0.2585320472717285,\n",
      "                     0.25573956966400146,\n",
      "                     0.25311219692230225,\n",
      "                     0.24874459207057953,\n",
      "                     0.24740009009838104,\n",
      "                     0.24486838281154633,\n",
      "                     0.24367283284664154,\n",
      "                     0.2462511956691742,\n",
      "                     0.2427975833415985],\n",
      " 'Validation MCC': [[np.float64(0.7682819476692284),\n",
      "                     np.float64(0.8008531819610738),\n",
      "                     np.float64(0.807984816141868),\n",
      "                     np.float64(0.82201159249505),\n",
      "                     np.float64(0.8291774351374633),\n",
      "                     np.float64(0.8356998711677586),\n",
      "                     np.float64(0.8361465093646284),\n",
      "                     np.float64(0.8414089971312434),\n",
      "                     np.float64(0.8436244897796701),\n",
      "                     np.float64(0.8442669331556151),\n",
      "                     np.float64(0.8480599908509852),\n",
      "                     np.float64(0.850642754125148),\n",
      "                     np.float64(0.8514553563264622),\n",
      "                     np.float64(0.8530751053242643),\n",
      "                     np.float64(0.8533162332607651),\n",
      "                     np.float64(0.8563871149492271),\n",
      "                     np.float64(0.8516883798910649),\n",
      "                     np.float64(0.8553237156107351),\n",
      "                     np.float64(0.85843204802866),\n",
      "                     np.float64(0.8601388247135687)],\n",
      "                    [np.float64(0.7626487622408817),\n",
      "                     np.float64(0.7956066306242531),\n",
      "                     np.float64(0.8106463066980023),\n",
      "                     np.float64(0.8277046701871266),\n",
      "                     np.float64(0.8339892350814844),\n",
      "                     np.float64(0.8404670442707658),\n",
      "                     np.float64(0.8437899840168284),\n",
      "                     np.float64(0.8477484735498486),\n",
      "                     np.float64(0.8490992064305947),\n",
      "                     np.float64(0.8491846587284521),\n",
      "                     np.float64(0.8508626774707083),\n",
      "                     np.float64(0.8531804825138811),\n",
      "                     np.float64(0.8545687363996162),\n",
      "                     np.float64(0.8553102292152522),\n",
      "                     np.float64(0.8573934763514265),\n",
      "                     np.float64(0.8596207454731115),\n",
      "                     np.float64(0.8584841123490993),\n",
      "                     np.float64(0.8614268127571759),\n",
      "                     np.float64(0.8600544991258272),\n",
      "                     np.float64(0.8618655703833864)],\n",
      "                    [np.float64(0.7590529369716703),\n",
      "                     np.float64(0.7838440563602842),\n",
      "                     np.float64(0.8109285663496845),\n",
      "                     np.float64(0.8161841777746248),\n",
      "                     np.float64(0.8192579782131064),\n",
      "                     np.float64(0.8222691978509774),\n",
      "                     np.float64(0.8237848126489014),\n",
      "                     np.float64(0.8283213189284905),\n",
      "                     np.float64(0.8333204505732104),\n",
      "                     np.float64(0.8376203017632147),\n",
      "                     np.float64(0.8424237933948321),\n",
      "                     np.float64(0.8454606842716851),\n",
      "                     np.float64(0.8473139683577735),\n",
      "                     np.float64(0.8475919085794485),\n",
      "                     np.float64(0.8480946106423473),\n",
      "                     np.float64(0.8499931938409087),\n",
      "                     np.float64(0.8490355632613058),\n",
      "                     np.float64(0.8446100477504025),\n",
      "                     np.float64(0.8531836277149021),\n",
      "                     np.float64(0.854797328623644)],\n",
      "                    [np.float64(0.764073016031406),\n",
      "                     np.float64(0.7891380542144258),\n",
      "                     np.float64(0.8022693951500206),\n",
      "                     np.float64(0.8144922718875218),\n",
      "                     np.float64(0.823677236252964),\n",
      "                     np.float64(0.8289904775007312),\n",
      "                     np.float64(0.8328663110256325),\n",
      "                     np.float64(0.837902510002218),\n",
      "                     np.float64(0.8400865092509847),\n",
      "                     np.float64(0.8436641045295215),\n",
      "                     np.float64(0.8459807716641211),\n",
      "                     np.float64(0.8452819327503356),\n",
      "                     np.float64(0.849796792933107),\n",
      "                     np.float64(0.8502232773220908),\n",
      "                     np.float64(0.8511111050062254),\n",
      "                     np.float64(0.8412364842826394),\n",
      "                     np.float64(0.8542841676847852),\n",
      "                     np.float64(0.8559068834180223),\n",
      "                     np.float64(0.8552794633100409),\n",
      "                     np.float64(0.8581277668797885)],\n",
      "                    [np.float64(0.7574028295483465),\n",
      "                     np.float64(0.7834012735552088),\n",
      "                     np.float64(0.7973788771765993),\n",
      "                     np.float64(0.8097073801746101),\n",
      "                     np.float64(0.8214835437858459),\n",
      "                     np.float64(0.8232374916213883),\n",
      "                     np.float64(0.8290979191876053),\n",
      "                     np.float64(0.8309394851907206),\n",
      "                     np.float64(0.8305324257620686),\n",
      "                     np.float64(0.8393372452540262),\n",
      "                     np.float64(0.8393073591344108),\n",
      "                     np.float64(0.842824391265252),\n",
      "                     np.float64(0.8433883503900674),\n",
      "                     np.float64(0.845666396625241),\n",
      "                     np.float64(0.8478788953752772),\n",
      "                     np.float64(0.8483253962561823),\n",
      "                     np.float64(0.849443961384594),\n",
      "                     np.float64(0.8508182813400617),\n",
      "                     np.float64(0.8494874704077016),\n",
      "                     np.float64(0.8510529999256433)]]}\n",
      "Training Model: TCN, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m369/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.5945 - loss: 1.0435\n",
      "Epoch 1 - MCC: 0.7732\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 27ms/step - accuracy: 0.5973 - loss: 1.0367 - val_accuracy: 0.8529 - val_loss: 0.3947 - mcc: 0.7732\n",
      "Epoch 2/20\n",
      "\u001B[1m364/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8567 - loss: 0.3845\n",
      "Epoch 2 - MCC: 0.8044\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.8568 - loss: 0.3841 - val_accuracy: 0.8730 - val_loss: 0.3386 - mcc: 0.8044\n",
      "Epoch 3/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8700 - loss: 0.3481\n",
      "Epoch 3 - MCC: 0.8094\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8701 - loss: 0.3478 - val_accuracy: 0.8764 - val_loss: 0.3261 - mcc: 0.8094\n",
      "Epoch 4/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8772 - loss: 0.3253\n",
      "Epoch 4 - MCC: 0.8267\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.8772 - loss: 0.3253 - val_accuracy: 0.8869 - val_loss: 0.3010 - mcc: 0.8267\n",
      "Epoch 5/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8856 - loss: 0.3054\n",
      "Epoch 5 - MCC: 0.8234\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.8856 - loss: 0.3054 - val_accuracy: 0.8833 - val_loss: 0.3069 - mcc: 0.8234\n",
      "Epoch 6/20\n",
      "\u001B[1m366/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8879 - loss: 0.2964\n",
      "Epoch 6 - MCC: 0.8306\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 10ms/step - accuracy: 0.8879 - loss: 0.2964 - val_accuracy: 0.8894 - val_loss: 0.2928 - mcc: 0.8306\n",
      "Epoch 7/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8910 - loss: 0.2893\n",
      "Epoch 7 - MCC: 0.8343\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.8910 - loss: 0.2893 - val_accuracy: 0.8914 - val_loss: 0.2875 - mcc: 0.8343\n",
      "Epoch 8/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8926 - loss: 0.2849\n",
      "Epoch 8 - MCC: 0.8424\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8925 - loss: 0.2849 - val_accuracy: 0.8973 - val_loss: 0.2732 - mcc: 0.8424\n",
      "Epoch 9/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8944 - loss: 0.2789\n",
      "Epoch 9 - MCC: 0.8407\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 10ms/step - accuracy: 0.8944 - loss: 0.2789 - val_accuracy: 0.8953 - val_loss: 0.2758 - mcc: 0.8407\n",
      "Epoch 10/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8954 - loss: 0.2783\n",
      "Epoch 10 - MCC: 0.8460\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.8954 - loss: 0.2783 - val_accuracy: 0.8993 - val_loss: 0.2659 - mcc: 0.8460\n",
      "Epoch 11/20\n",
      "\u001B[1m365/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8988 - loss: 0.2692\n",
      "Epoch 11 - MCC: 0.8466\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8988 - loss: 0.2693 - val_accuracy: 0.8999 - val_loss: 0.2638 - mcc: 0.8466\n",
      "Epoch 12/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8972 - loss: 0.2716\n",
      "Epoch 12 - MCC: 0.8469\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8972 - loss: 0.2716 - val_accuracy: 0.8994 - val_loss: 0.2641 - mcc: 0.8469\n",
      "Epoch 13/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8987 - loss: 0.2673\n",
      "Epoch 13 - MCC: 0.8498\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 10ms/step - accuracy: 0.8987 - loss: 0.2673 - val_accuracy: 0.9020 - val_loss: 0.2588 - mcc: 0.8498\n",
      "Epoch 14/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8989 - loss: 0.2681\n",
      "Epoch 14 - MCC: 0.8517\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.8989 - loss: 0.2681 - val_accuracy: 0.9030 - val_loss: 0.2547 - mcc: 0.8517\n",
      "Epoch 15/20\n",
      "\u001B[1m365/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9007 - loss: 0.2624\n",
      "Epoch 15 - MCC: 0.8511\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.9007 - loss: 0.2624 - val_accuracy: 0.9028 - val_loss: 0.2565 - mcc: 0.8511\n",
      "Epoch 16/20\n",
      "\u001B[1m369/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9017 - loss: 0.2608\n",
      "Epoch 16 - MCC: 0.8498\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 11ms/step - accuracy: 0.9017 - loss: 0.2608 - val_accuracy: 0.9020 - val_loss: 0.2577 - mcc: 0.8498\n",
      "Epoch 17/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9024 - loss: 0.2583\n",
      "Epoch 17 - MCC: 0.8536\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.9023 - loss: 0.2583 - val_accuracy: 0.9043 - val_loss: 0.2520 - mcc: 0.8536\n",
      "Epoch 18/20\n",
      "\u001B[1m365/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9027 - loss: 0.2575\n",
      "Epoch 18 - MCC: 0.8530\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.9027 - loss: 0.2575 - val_accuracy: 0.9037 - val_loss: 0.2528 - mcc: 0.8530\n",
      "Epoch 19/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9023 - loss: 0.2572\n",
      "Epoch 19 - MCC: 0.8525\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.9023 - loss: 0.2572 - val_accuracy: 0.9038 - val_loss: 0.2527 - mcc: 0.8525\n",
      "Epoch 20/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9022 - loss: 0.2578\n",
      "Epoch 20 - MCC: 0.8526\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 9ms/step - accuracy: 0.9022 - loss: 0.2578 - val_accuracy: 0.9035 - val_loss: 0.2534 - mcc: 0.8526\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: TCN, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m369/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6812 - loss: 0.9154\n",
      "Epoch 1 - MCC: 0.7803\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 21ms/step - accuracy: 0.6829 - loss: 0.9097 - val_accuracy: 0.8577 - val_loss: 0.3793 - mcc: 0.7803\n",
      "Epoch 2/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8604 - loss: 0.3681\n",
      "Epoch 2 - MCC: 0.8097\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.8604 - loss: 0.3680 - val_accuracy: 0.8764 - val_loss: 0.3286 - mcc: 0.8097\n",
      "Epoch 3/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8739 - loss: 0.3314\n",
      "Epoch 3 - MCC: 0.8156\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 11ms/step - accuracy: 0.8739 - loss: 0.3314 - val_accuracy: 0.8806 - val_loss: 0.3140 - mcc: 0.8156\n",
      "Epoch 4/20\n",
      "\u001B[1m364/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8786 - loss: 0.3174\n",
      "Epoch 4 - MCC: 0.8175\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.8786 - loss: 0.3173 - val_accuracy: 0.8807 - val_loss: 0.3119 - mcc: 0.8175\n",
      "Epoch 5/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8826 - loss: 0.3058\n",
      "Epoch 5 - MCC: 0.8299\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.8827 - loss: 0.3057 - val_accuracy: 0.8891 - val_loss: 0.2929 - mcc: 0.8299\n",
      "Epoch 6/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8861 - loss: 0.2974\n",
      "Epoch 6 - MCC: 0.8346\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.8861 - loss: 0.2974 - val_accuracy: 0.8926 - val_loss: 0.2824 - mcc: 0.8346\n",
      "Epoch 7/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8890 - loss: 0.2893\n",
      "Epoch 7 - MCC: 0.8358\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8890 - loss: 0.2893 - val_accuracy: 0.8935 - val_loss: 0.2801 - mcc: 0.8358\n",
      "Epoch 8/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8911 - loss: 0.2844\n",
      "Epoch 8 - MCC: 0.8391\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.8911 - loss: 0.2844 - val_accuracy: 0.8954 - val_loss: 0.2762 - mcc: 0.8391\n",
      "Epoch 9/20\n",
      "\u001B[1m369/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8924 - loss: 0.2817\n",
      "Epoch 9 - MCC: 0.8362\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - accuracy: 0.8924 - loss: 0.2817 - val_accuracy: 0.8927 - val_loss: 0.2829 - mcc: 0.8362\n",
      "Epoch 10/20\n",
      "\u001B[1m365/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8955 - loss: 0.2731\n",
      "Epoch 10 - MCC: 0.8429\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.8955 - loss: 0.2732 - val_accuracy: 0.8981 - val_loss: 0.2686 - mcc: 0.8429\n",
      "Epoch 11/20\n",
      "\u001B[1m364/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8968 - loss: 0.2714\n",
      "Epoch 11 - MCC: 0.8448\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8967 - loss: 0.2714 - val_accuracy: 0.8991 - val_loss: 0.2661 - mcc: 0.8448\n",
      "Epoch 12/20\n",
      "\u001B[1m368/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8948 - loss: 0.2751\n",
      "Epoch 12 - MCC: 0.8446\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 10ms/step - accuracy: 0.8948 - loss: 0.2750 - val_accuracy: 0.8990 - val_loss: 0.2683 - mcc: 0.8446\n",
      "Epoch 13/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8981 - loss: 0.2670\n",
      "Epoch 13 - MCC: 0.8466\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.8981 - loss: 0.2670 - val_accuracy: 0.9003 - val_loss: 0.2633 - mcc: 0.8466\n",
      "Epoch 14/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9003 - loss: 0.2615\n",
      "Epoch 14 - MCC: 0.8482\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.9003 - loss: 0.2616 - val_accuracy: 0.9014 - val_loss: 0.2614 - mcc: 0.8482\n",
      "Epoch 15/20\n",
      "\u001B[1m368/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9010 - loss: 0.2602\n",
      "Epoch 15 - MCC: 0.8519\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.9010 - loss: 0.2602 - val_accuracy: 0.9036 - val_loss: 0.2542 - mcc: 0.8519\n",
      "Epoch 16/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9022 - loss: 0.2577\n",
      "Epoch 16 - MCC: 0.8532\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.9022 - loss: 0.2577 - val_accuracy: 0.9046 - val_loss: 0.2530 - mcc: 0.8532\n",
      "Epoch 17/20\n",
      "\u001B[1m365/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9012 - loss: 0.2582\n",
      "Epoch 17 - MCC: 0.8490\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.9012 - loss: 0.2581 - val_accuracy: 0.9020 - val_loss: 0.2603 - mcc: 0.8490\n",
      "Epoch 18/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9026 - loss: 0.2554\n",
      "Epoch 18 - MCC: 0.8513\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - accuracy: 0.9026 - loss: 0.2554 - val_accuracy: 0.9025 - val_loss: 0.2574 - mcc: 0.8513\n",
      "Epoch 19/20\n",
      "\u001B[1m369/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9009 - loss: 0.2591\n",
      "Epoch 19 - MCC: 0.8573\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - accuracy: 0.9009 - loss: 0.2590 - val_accuracy: 0.9072 - val_loss: 0.2460 - mcc: 0.8573\n",
      "Epoch 20/20\n",
      "\u001B[1m365/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9059 - loss: 0.2487\n",
      "Epoch 20 - MCC: 0.8584\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.9059 - loss: 0.2488 - val_accuracy: 0.9079 - val_loss: 0.2448 - mcc: 0.8584\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: TCN, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.6287 - loss: 1.1520\n",
      "Epoch 1 - MCC: 0.7715\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 19ms/step - accuracy: 0.6298 - loss: 1.1483 - val_accuracy: 0.8524 - val_loss: 0.3900 - mcc: 0.7715\n",
      "Epoch 2/20\n",
      "\u001B[1m369/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8599 - loss: 0.3730\n",
      "Epoch 2 - MCC: 0.7957\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 10ms/step - accuracy: 0.8599 - loss: 0.3728 - val_accuracy: 0.8669 - val_loss: 0.3506 - mcc: 0.7957\n",
      "Epoch 3/20\n",
      "\u001B[1m366/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8687 - loss: 0.3469\n",
      "Epoch 3 - MCC: 0.8066\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.8688 - loss: 0.3467 - val_accuracy: 0.8726 - val_loss: 0.3338 - mcc: 0.8066\n",
      "Epoch 4/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8777 - loss: 0.3238\n",
      "Epoch 4 - MCC: 0.8177\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8777 - loss: 0.3238 - val_accuracy: 0.8805 - val_loss: 0.3143 - mcc: 0.8177\n",
      "Epoch 5/20\n",
      "\u001B[1m365/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8816 - loss: 0.3128\n",
      "Epoch 5 - MCC: 0.8229\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8816 - loss: 0.3128 - val_accuracy: 0.8844 - val_loss: 0.3041 - mcc: 0.8229\n",
      "Epoch 6/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8845 - loss: 0.3034\n",
      "Epoch 6 - MCC: 0.8266\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - accuracy: 0.8845 - loss: 0.3034 - val_accuracy: 0.8872 - val_loss: 0.2967 - mcc: 0.8266\n",
      "Epoch 7/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8885 - loss: 0.2956\n",
      "Epoch 7 - MCC: 0.8221\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.8885 - loss: 0.2956 - val_accuracy: 0.8840 - val_loss: 0.3052 - mcc: 0.8221\n",
      "Epoch 8/20\n",
      "\u001B[1m368/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8906 - loss: 0.2896\n",
      "Epoch 8 - MCC: 0.8332\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8906 - loss: 0.2896 - val_accuracy: 0.8910 - val_loss: 0.2857 - mcc: 0.8332\n",
      "Epoch 9/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8909 - loss: 0.2887\n",
      "Epoch 9 - MCC: 0.8356\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8909 - loss: 0.2886 - val_accuracy: 0.8925 - val_loss: 0.2831 - mcc: 0.8356\n",
      "Epoch 10/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8918 - loss: 0.2857\n",
      "Epoch 10 - MCC: 0.8357\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 9ms/step - accuracy: 0.8918 - loss: 0.2857 - val_accuracy: 0.8930 - val_loss: 0.2822 - mcc: 0.8357\n",
      "Epoch 11/20\n",
      "\u001B[1m369/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8945 - loss: 0.2799\n",
      "Epoch 11 - MCC: 0.8396\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.8946 - loss: 0.2799 - val_accuracy: 0.8953 - val_loss: 0.2755 - mcc: 0.8396\n",
      "Epoch 12/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8978 - loss: 0.2712\n",
      "Epoch 12 - MCC: 0.8397\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8977 - loss: 0.2713 - val_accuracy: 0.8952 - val_loss: 0.2768 - mcc: 0.8397\n",
      "Epoch 13/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8957 - loss: 0.2768\n",
      "Epoch 13 - MCC: 0.8420\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 10ms/step - accuracy: 0.8957 - loss: 0.2768 - val_accuracy: 0.8970 - val_loss: 0.2714 - mcc: 0.8420\n",
      "Epoch 14/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8973 - loss: 0.2722\n",
      "Epoch 14 - MCC: 0.8374\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8973 - loss: 0.2722 - val_accuracy: 0.8939 - val_loss: 0.2793 - mcc: 0.8374\n",
      "Epoch 15/20\n",
      "\u001B[1m368/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8962 - loss: 0.2749\n",
      "Epoch 15 - MCC: 0.8412\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8963 - loss: 0.2747 - val_accuracy: 0.8966 - val_loss: 0.2738 - mcc: 0.8412\n",
      "Epoch 16/20\n",
      "\u001B[1m368/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8993 - loss: 0.2660\n",
      "Epoch 16 - MCC: 0.8429\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8994 - loss: 0.2660 - val_accuracy: 0.8975 - val_loss: 0.2686 - mcc: 0.8429\n",
      "Epoch 17/20\n",
      "\u001B[1m365/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8989 - loss: 0.2680\n",
      "Epoch 17 - MCC: 0.8452\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.8990 - loss: 0.2679 - val_accuracy: 0.8986 - val_loss: 0.2666 - mcc: 0.8452\n",
      "Epoch 18/20\n",
      "\u001B[1m364/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8996 - loss: 0.2662\n",
      "Epoch 18 - MCC: 0.8469\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.8996 - loss: 0.2661 - val_accuracy: 0.9002 - val_loss: 0.2618 - mcc: 0.8469\n",
      "Epoch 19/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9025 - loss: 0.2567\n",
      "Epoch 19 - MCC: 0.8471\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.9025 - loss: 0.2567 - val_accuracy: 0.8999 - val_loss: 0.2626 - mcc: 0.8471\n",
      "Epoch 20/20\n",
      "\u001B[1m368/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9005 - loss: 0.2620\n",
      "Epoch 20 - MCC: 0.8476\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 8ms/step - accuracy: 0.9005 - loss: 0.2620 - val_accuracy: 0.9005 - val_loss: 0.2605 - mcc: 0.8476\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: TCN, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.6907 - loss: 0.8639\n",
      "Epoch 1 - MCC: 0.7729\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 19ms/step - accuracy: 0.6915 - loss: 0.8616 - val_accuracy: 0.8512 - val_loss: 0.3991 - mcc: 0.7729\n",
      "Epoch 2/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8582 - loss: 0.3745\n",
      "Epoch 2 - MCC: 0.7956\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 8ms/step - accuracy: 0.8582 - loss: 0.3744 - val_accuracy: 0.8664 - val_loss: 0.3523 - mcc: 0.7956\n",
      "Epoch 3/20\n",
      "\u001B[1m368/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8692 - loss: 0.3432\n",
      "Epoch 3 - MCC: 0.8045\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.8693 - loss: 0.3431 - val_accuracy: 0.8721 - val_loss: 0.3357 - mcc: 0.8045\n",
      "Epoch 4/20\n",
      "\u001B[1m370/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8779 - loss: 0.3199\n",
      "Epoch 4 - MCC: 0.8152\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8779 - loss: 0.3198 - val_accuracy: 0.8794 - val_loss: 0.3180 - mcc: 0.8152\n",
      "Epoch 5/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8805 - loss: 0.3131\n",
      "Epoch 5 - MCC: 0.8221\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 7ms/step - accuracy: 0.8805 - loss: 0.3131 - val_accuracy: 0.8843 - val_loss: 0.3052 - mcc: 0.8221\n",
      "Epoch 6/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8848 - loss: 0.3015\n",
      "Epoch 6 - MCC: 0.8276\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.8848 - loss: 0.3015 - val_accuracy: 0.8877 - val_loss: 0.2959 - mcc: 0.8276\n",
      "Epoch 7/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8890 - loss: 0.2924\n",
      "Epoch 7 - MCC: 0.8269\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 7ms/step - accuracy: 0.8890 - loss: 0.2923 - val_accuracy: 0.8879 - val_loss: 0.2943 - mcc: 0.8269\n",
      "Epoch 8/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8916 - loss: 0.2842\n",
      "Epoch 8 - MCC: 0.8332\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.8916 - loss: 0.2842 - val_accuracy: 0.8912 - val_loss: 0.2864 - mcc: 0.8332\n",
      "Epoch 9/20\n",
      "\u001B[1m369/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8922 - loss: 0.2828\n",
      "Epoch 9 - MCC: 0.8377\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.8922 - loss: 0.2827 - val_accuracy: 0.8946 - val_loss: 0.2794 - mcc: 0.8377\n",
      "Epoch 10/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8964 - loss: 0.2708\n",
      "Epoch 10 - MCC: 0.8375\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8964 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 0.2782 - mcc: 0.8375\n",
      "Epoch 11/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8975 - loss: 0.2685\n",
      "Epoch 11 - MCC: 0.8410\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 10ms/step - accuracy: 0.8975 - loss: 0.2685 - val_accuracy: 0.8966 - val_loss: 0.2744 - mcc: 0.8410\n",
      "Epoch 12/20\n",
      "\u001B[1m365/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8966 - loss: 0.2716\n",
      "Epoch 12 - MCC: 0.8407\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.8966 - loss: 0.2715 - val_accuracy: 0.8960 - val_loss: 0.2742 - mcc: 0.8407\n",
      "Epoch 13/20\n",
      "\u001B[1m368/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8979 - loss: 0.2671\n",
      "Epoch 13 - MCC: 0.8441\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.8979 - loss: 0.2671 - val_accuracy: 0.8988 - val_loss: 0.2674 - mcc: 0.8441\n",
      "Epoch 14/20\n",
      "\u001B[1m364/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9000 - loss: 0.2625\n",
      "Epoch 14 - MCC: 0.8412\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.8999 - loss: 0.2626 - val_accuracy: 0.8960 - val_loss: 0.2731 - mcc: 0.8412\n",
      "Epoch 15/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8971 - loss: 0.2698\n",
      "Epoch 15 - MCC: 0.8459\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.8971 - loss: 0.2696 - val_accuracy: 0.9000 - val_loss: 0.2644 - mcc: 0.8459\n",
      "Epoch 16/20\n",
      "\u001B[1m364/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9019 - loss: 0.2566\n",
      "Epoch 16 - MCC: 0.8455\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.9018 - loss: 0.2567 - val_accuracy: 0.8996 - val_loss: 0.2648 - mcc: 0.8455\n",
      "Epoch 17/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9009 - loss: 0.2612\n",
      "Epoch 17 - MCC: 0.8463\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 10ms/step - accuracy: 0.9009 - loss: 0.2611 - val_accuracy: 0.9001 - val_loss: 0.2640 - mcc: 0.8463\n",
      "Epoch 18/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9023 - loss: 0.2565\n",
      "Epoch 18 - MCC: 0.8475\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.9023 - loss: 0.2565 - val_accuracy: 0.9009 - val_loss: 0.2613 - mcc: 0.8475\n",
      "Epoch 19/20\n",
      "\u001B[1m366/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9025 - loss: 0.2568\n",
      "Epoch 19 - MCC: 0.8489\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.9025 - loss: 0.2567 - val_accuracy: 0.9018 - val_loss: 0.2593 - mcc: 0.8489\n",
      "Epoch 20/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9038 - loss: 0.2527\n",
      "Epoch 20 - MCC: 0.8494\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 9ms/step - accuracy: 0.9038 - loss: 0.2527 - val_accuracy: 0.9020 - val_loss: 0.2604 - mcc: 0.8494\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: TCN, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m364/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.5916 - loss: 1.2013\n",
      "Epoch 1 - MCC: 0.7675\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 21ms/step - accuracy: 0.5965 - loss: 1.1858 - val_accuracy: 0.8492 - val_loss: 0.4019 - mcc: 0.7675\n",
      "Epoch 2/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8559 - loss: 0.3820\n",
      "Epoch 2 - MCC: 0.7847\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 8ms/step - accuracy: 0.8560 - loss: 0.3817 - val_accuracy: 0.8608 - val_loss: 0.3645 - mcc: 0.7847\n",
      "Epoch 3/20\n",
      "\u001B[1m366/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8680 - loss: 0.3453\n",
      "Epoch 3 - MCC: 0.7992\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - accuracy: 0.8680 - loss: 0.3453 - val_accuracy: 0.8692 - val_loss: 0.3426 - mcc: 0.7992\n",
      "Epoch 4/20\n",
      "\u001B[1m369/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8730 - loss: 0.3326\n",
      "Epoch 4 - MCC: 0.8048\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - accuracy: 0.8731 - loss: 0.3325 - val_accuracy: 0.8727 - val_loss: 0.3311 - mcc: 0.8048\n",
      "Epoch 5/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8779 - loss: 0.3195\n",
      "Epoch 5 - MCC: 0.8109\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8779 - loss: 0.3195 - val_accuracy: 0.8771 - val_loss: 0.3222 - mcc: 0.8109\n",
      "Epoch 6/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8830 - loss: 0.3057\n",
      "Epoch 6 - MCC: 0.8119\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.8830 - loss: 0.3057 - val_accuracy: 0.8773 - val_loss: 0.3211 - mcc: 0.8119\n",
      "Epoch 7/20\n",
      "\u001B[1m364/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8834 - loss: 0.3042\n",
      "Epoch 7 - MCC: 0.8175\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.8834 - loss: 0.3041 - val_accuracy: 0.8793 - val_loss: 0.3106 - mcc: 0.8175\n",
      "Epoch 8/20\n",
      "\u001B[1m368/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8857 - loss: 0.2989\n",
      "Epoch 8 - MCC: 0.8255\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.8858 - loss: 0.2988 - val_accuracy: 0.8864 - val_loss: 0.2965 - mcc: 0.8255\n",
      "Epoch 9/20\n",
      "\u001B[1m369/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8900 - loss: 0.2879\n",
      "Epoch 9 - MCC: 0.8248\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 11ms/step - accuracy: 0.8900 - loss: 0.2880 - val_accuracy: 0.8846 - val_loss: 0.2986 - mcc: 0.8248\n",
      "Epoch 10/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8918 - loss: 0.2834\n",
      "Epoch 10 - MCC: 0.8278\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.8918 - loss: 0.2834 - val_accuracy: 0.8877 - val_loss: 0.2919 - mcc: 0.8278\n",
      "Epoch 11/20\n",
      "\u001B[1m368/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8937 - loss: 0.2790\n",
      "Epoch 11 - MCC: 0.8310\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8937 - loss: 0.2790 - val_accuracy: 0.8897 - val_loss: 0.2877 - mcc: 0.8310\n",
      "Epoch 12/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8937 - loss: 0.2776\n",
      "Epoch 12 - MCC: 0.8330\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 10ms/step - accuracy: 0.8937 - loss: 0.2776 - val_accuracy: 0.8911 - val_loss: 0.2837 - mcc: 0.8330\n",
      "Epoch 13/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8962 - loss: 0.2717\n",
      "Epoch 13 - MCC: 0.8381\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.8962 - loss: 0.2717 - val_accuracy: 0.8945 - val_loss: 0.2783 - mcc: 0.8381\n",
      "Epoch 14/20\n",
      "\u001B[1m364/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8967 - loss: 0.2714\n",
      "Epoch 14 - MCC: 0.8367\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.8967 - loss: 0.2713 - val_accuracy: 0.8937 - val_loss: 0.2796 - mcc: 0.8367\n",
      "Epoch 15/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8977 - loss: 0.2686\n",
      "Epoch 15 - MCC: 0.8404\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.8977 - loss: 0.2686 - val_accuracy: 0.8956 - val_loss: 0.2737 - mcc: 0.8404\n",
      "Epoch 16/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8985 - loss: 0.2671\n",
      "Epoch 16 - MCC: 0.8410\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.8985 - loss: 0.2671 - val_accuracy: 0.8963 - val_loss: 0.2749 - mcc: 0.8410\n",
      "Epoch 17/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8993 - loss: 0.2649\n",
      "Epoch 17 - MCC: 0.8391\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 11ms/step - accuracy: 0.8994 - loss: 0.2649 - val_accuracy: 0.8951 - val_loss: 0.2783 - mcc: 0.8391\n",
      "Epoch 18/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9004 - loss: 0.2616\n",
      "Epoch 18 - MCC: 0.8443\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 8ms/step - accuracy: 0.9004 - loss: 0.2616 - val_accuracy: 0.8984 - val_loss: 0.2689 - mcc: 0.8443\n",
      "Epoch 19/20\n",
      "\u001B[1m366/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8999 - loss: 0.2643\n",
      "Epoch 19 - MCC: 0.8438\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8999 - loss: 0.2641 - val_accuracy: 0.8979 - val_loss: 0.2695 - mcc: 0.8438\n",
      "Epoch 20/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9008 - loss: 0.2598\n",
      "Epoch 20 - MCC: 0.8436\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 10ms/step - accuracy: 0.9008 - loss: 0.2598 - val_accuracy: 0.8981 - val_loss: 0.2698 - mcc: 0.8436\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.9078573333333333),\n",
      "              'mean': np.float64(0.9023794666666667),\n",
      "              'min': np.float64(0.8980573333333334),\n",
      "              'std': np.float64(0.0032719220691615745)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.00033602007230122883),\n",
      "                               'mean': np.float64(0.0002570571581522624),\n",
      "                               'min': np.float64(0.00023031059900919596),\n",
      "                               'std': np.float64(3.9663911914067455e-05)},\n",
      " 'MCC': {'max': np.float64(0.8583917878073914),\n",
      "         'mean': np.float64(0.8503260300666591),\n",
      "         'min': np.float64(0.8436031333815485),\n",
      "         'std': np.float64(0.0049778341782764045)},\n",
      " 'Parameters': 6440,\n",
      " 'Train Time (s)': {'max': np.float64(111.74033713340759),\n",
      "                    'mean': np.float64(98.33367052078248),\n",
      "                    'min': np.float64(86.42872047424316),\n",
      "                    'std': np.float64(10.528359825880347)},\n",
      " 'Training Accuracy': [[0.7473539113998413,\n",
      "                        0.8613760471343994,\n",
      "                        0.8735738396644592,\n",
      "                        0.8797248601913452,\n",
      "                        0.8855107426643372,\n",
      "                        0.8877055644989014,\n",
      "                        0.8907713294029236,\n",
      "                        0.8922263383865356,\n",
      "                        0.8938571214675903,\n",
      "                        0.8950682878494263,\n",
      "                        0.8966884016990662,\n",
      "                        0.8974882960319519,\n",
      "                        0.8987533450126648,\n",
      "                        0.8993570804595947,\n",
      "                        0.9004833698272705,\n",
      "                        0.900865375995636,\n",
      "                        0.9018244743347168,\n",
      "                        0.9021185636520386,\n",
      "                        0.9024590849876404,\n",
      "                        0.9033185243606567],\n",
      "                       [0.7770656943321228,\n",
      "                        0.8639510869979858,\n",
      "                        0.8743090033531189,\n",
      "                        0.8803145885467529,\n",
      "                        0.8841367363929749,\n",
      "                        0.8859389424324036,\n",
      "                        0.888507068157196,\n",
      "                        0.8909860849380493,\n",
      "                        0.8927360773086548,\n",
      "                        0.894299328327179,\n",
      "                        0.8960613012313843,\n",
      "                        0.8970494270324707,\n",
      "                        0.8982639908790588,\n",
      "                        0.8991751074790955,\n",
      "                        0.8999996781349182,\n",
      "                        0.9016327857971191,\n",
      "                        0.902015209197998,\n",
      "                        0.902176022529602,\n",
      "                        0.9032421708106995,\n",
      "                        0.904076337814331],\n",
      "                       [0.7597426176071167,\n",
      "                        0.8622568249702454,\n",
      "                        0.8716480135917664,\n",
      "                        0.8776577115058899,\n",
      "                        0.8828547596931458,\n",
      "                        0.8855271935462952,\n",
      "                        0.8883972764015198,\n",
      "                        0.8905413150787354,\n",
      "                        0.892106294631958,\n",
      "                        0.8936964273452759,\n",
      "                        0.895001232624054,\n",
      "                        0.8962793946266174,\n",
      "                        0.8967365622520447,\n",
      "                        0.8982585668563843,\n",
      "                        0.8988077044487,\n",
      "                        0.8995478749275208,\n",
      "                        0.9001534581184387,\n",
      "                        0.9002137184143066,\n",
      "                        0.9014702439308167,\n",
      "                        0.9015652537345886],\n",
      "                       [0.7884998917579651,\n",
      "                        0.8617008328437805,\n",
      "                        0.8709521293640137,\n",
      "                        0.8780128359794617,\n",
      "                        0.8830565810203552,\n",
      "                        0.8859147429466248,\n",
      "                        0.8893312811851501,\n",
      "                        0.892349123954773,\n",
      "                        0.8937409520149231,\n",
      "                        0.8955618739128113,\n",
      "                        0.8965715169906616,\n",
      "                        0.8973144292831421,\n",
      "                        0.8988314867019653,\n",
      "                        0.8987565636634827,\n",
      "                        0.9003115892410278,\n",
      "                        0.9007227420806885,\n",
      "                        0.9016756415367126,\n",
      "                        0.9022585153579712,\n",
      "                        0.9030592441558838,\n",
      "                        0.9028363227844238],\n",
      "                       [0.7467390894889832,\n",
      "                        0.8601593971252441,\n",
      "                        0.869562566280365,\n",
      "                        0.875373363494873,\n",
      "                        0.8795585036277771,\n",
      "                        0.8821769952774048,\n",
      "                        0.884830892086029,\n",
      "                        0.8877362608909607,\n",
      "                        0.8895323276519775,\n",
      "                        0.891327977180481,\n",
      "                        0.8932771682739258,\n",
      "                        0.8943355083465576,\n",
      "                        0.8959012627601624,\n",
      "                        0.8970004916191101,\n",
      "                        0.8987556099891663,\n",
      "                        0.8993668556213379,\n",
      "                        0.9003915190696716,\n",
      "                        0.9010413289070129,\n",
      "                        0.9020224809646606,\n",
      "                        0.9024765491485596]],\n",
      " 'Training Loss': [[0.6794652342796326,\n",
      "                    0.3721214234828949,\n",
      "                    0.33793121576309204,\n",
      "                    0.3198094964027405,\n",
      "                    0.3049083352088928,\n",
      "                    0.29852357506752014,\n",
      "                    0.28998059034347534,\n",
      "                    0.28562214970588684,\n",
      "                    0.28093236684799194,\n",
      "                    0.2776721715927124,\n",
      "                    0.27340978384017944,\n",
      "                    0.27107131481170654,\n",
      "                    0.26728203892707825,\n",
      "                    0.2661839723587036,\n",
      "                    0.263420969247818,\n",
      "                    0.2621445059776306,\n",
      "                    0.2597516179084778,\n",
      "                    0.2583746016025543,\n",
      "                    0.2573184370994568,\n",
      "                    0.25559738278388977],\n",
      "                   [0.6093379855155945,\n",
      "                    0.35867878794670105,\n",
      "                    0.32959726452827454,\n",
      "                    0.31337371468544006,\n",
      "                    0.302970826625824,\n",
      "                    0.297242671251297,\n",
      "                    0.29081690311431885,\n",
      "                    0.2848893105983734,\n",
      "                    0.2800651490688324,\n",
      "                    0.2762772738933563,\n",
      "                    0.2719528079032898,\n",
      "                    0.26934123039245605,\n",
      "                    0.2662067115306854,\n",
      "                    0.2642557919025421,\n",
      "                    0.2622879147529602,\n",
      "                    0.2584441900253296,\n",
      "                    0.25674811005592346,\n",
      "                    0.25694888830184937,\n",
      "                    0.25374630093574524,\n",
      "                    0.2523135244846344],\n",
      "                   [0.6887294054031372,\n",
      "                    0.3651005029678345,\n",
      "                    0.3394359052181244,\n",
      "                    0.32334256172180176,\n",
      "                    0.3096849024295807,\n",
      "                    0.3025377690792084,\n",
      "                    0.2953609526157379,\n",
      "                    0.2895022928714752,\n",
      "                    0.2856661379337311,\n",
      "                    0.2811791002750397,\n",
      "                    0.27787911891937256,\n",
      "                    0.27478504180908203,\n",
      "                    0.273493230342865,\n",
      "                    0.26990923285484314,\n",
      "                    0.2680758535861969,\n",
      "                    0.2656910717487335,\n",
      "                    0.26393193006515503,\n",
      "                    0.2637304961681366,\n",
      "                    0.26025715470314026,\n",
      "                    0.2598668038845062],\n",
      "                   [0.5798826813697815,\n",
      "                    0.36472269892692566,\n",
      "                    0.33847615122795105,\n",
      "                    0.3195539116859436,\n",
      "                    0.30675774812698364,\n",
      "                    0.2988708019256592,\n",
      "                    0.2902320623397827,\n",
      "                    0.2825407385826111,\n",
      "                    0.279477596282959,\n",
      "                    0.2741841971874237,\n",
      "                    0.27135178446769714,\n",
      "                    0.27018964290618896,\n",
      "                    0.26555994153022766,\n",
      "                    0.2656906843185425,\n",
      "                    0.2618074119091034,\n",
      "                    0.2603718042373657,\n",
      "                    0.2587175965309143,\n",
      "                    0.2568136751651764,\n",
      "                    0.2549644708633423,\n",
      "                    0.2555542290210724],\n",
      "                   [0.7124156951904297,\n",
      "                    0.3700827360153198,\n",
      "                    0.3423556685447693,\n",
      "                    0.32623744010925293,\n",
      "                    0.3150671422481537,\n",
      "                    0.30795249342918396,\n",
      "                    0.30074790120124817,\n",
      "                    0.2935798168182373,\n",
      "                    0.2889844477176666,\n",
      "                    0.2841922342777252,\n",
      "                    0.2793031930923462,\n",
      "                    0.2763645350933075,\n",
      "                    0.2725575566291809,\n",
      "                    0.27027711272239685,\n",
      "                    0.2660662829875946,\n",
      "                    0.2644444704055786,\n",
      "                    0.26218315958976746,\n",
      "                    0.2611484229564667,\n",
      "                    0.2581924498081207,\n",
      "                    0.2564505934715271]],\n",
      " 'Validation Accuracy': [[0.8528753519058228,\n",
      "                          0.8729974627494812,\n",
      "                          0.8764046430587769,\n",
      "                          0.8869125843048096,\n",
      "                          0.883285403251648,\n",
      "                          0.8893893957138062,\n",
      "                          0.8914293050765991,\n",
      "                          0.8973446488380432,\n",
      "                          0.8953359127044678,\n",
      "                          0.8993071913719177,\n",
      "                          0.8999270796775818,\n",
      "                          0.8993929028511047,\n",
      "                          0.9019650220870972,\n",
      "                          0.9030300378799438,\n",
      "                          0.9028195738792419,\n",
      "                          0.9019508361816406,\n",
      "                          0.9042952656745911,\n",
      "                          0.9037225842475891,\n",
      "                          0.9038012623786926,\n",
      "                          0.9034925103187561],\n",
      "                         [0.8577041029930115,\n",
      "                          0.8764327168464661,\n",
      "                          0.8805811405181885,\n",
      "                          0.8806671500205994,\n",
      "                          0.8890608549118042,\n",
      "                          0.892647922039032,\n",
      "                          0.8934881091117859,\n",
      "                          0.8954205513000488,\n",
      "                          0.8927445411682129,\n",
      "                          0.8981281518936157,\n",
      "                          0.8990558981895447,\n",
      "                          0.8989525437355042,\n",
      "                          0.9003067016601562,\n",
      "                          0.9014268517494202,\n",
      "                          0.903627336025238,\n",
      "                          0.9046025276184082,\n",
      "                          0.901954174041748,\n",
      "                          0.9024761319160461,\n",
      "                          0.907187819480896,\n",
      "                          0.9078571200370789],\n",
      "                         [0.8523707389831543,\n",
      "                          0.8669154644012451,\n",
      "                          0.8726425766944885,\n",
      "                          0.8805180788040161,\n",
      "                          0.8844080567359924,\n",
      "                          0.8871555328369141,\n",
      "                          0.8840027451515198,\n",
      "                          0.8909815549850464,\n",
      "                          0.8924621343612671,\n",
      "                          0.8930131793022156,\n",
      "                          0.8953359127044678,\n",
      "                          0.8952109217643738,\n",
      "                          0.8969828486442566,\n",
      "                          0.8939206600189209,\n",
      "                          0.8965648412704468,\n",
      "                          0.8974625468254089,\n",
      "                          0.8985503911972046,\n",
      "                          0.9001738429069519,\n",
      "                          0.8998513221740723,\n",
      "                          0.9005284905433655],\n",
      "                         [0.8511899709701538,\n",
      "                          0.8664267659187317,\n",
      "                          0.8720879554748535,\n",
      "                          0.87939453125,\n",
      "                          0.8842687010765076,\n",
      "                          0.8876674175262451,\n",
      "                          0.887879490852356,\n",
      "                          0.8912321925163269,\n",
      "                          0.8946419358253479,\n",
      "                          0.8946908116340637,\n",
      "                          0.8965567946434021,\n",
      "                          0.8959831595420837,\n",
      "                          0.8988099694252014,\n",
      "                          0.8960373401641846,\n",
      "                          0.8999748826026917,\n",
      "                          0.8996031880378723,\n",
      "                          0.9001164436340332,\n",
      "                          0.9009190201759338,\n",
      "                          0.9018116593360901,\n",
      "                          0.9019613265991211],\n",
      "                         [0.8491767644882202,\n",
      "                          0.8607820868492126,\n",
      "                          0.8692272901535034,\n",
      "                          0.8727180361747742,\n",
      "                          0.8771308660507202,\n",
      "                          0.8772667646408081,\n",
      "                          0.8793214559555054,\n",
      "                          0.8863964676856995,\n",
      "                          0.8846493363380432,\n",
      "                          0.8876692652702332,\n",
      "                          0.8896828889846802,\n",
      "                          0.8911488652229309,\n",
      "                          0.8945392966270447,\n",
      "                          0.8936680555343628,\n",
      "                          0.895556628704071,\n",
      "                          0.8963253498077393,\n",
      "                          0.8950666785240173,\n",
      "                          0.8983694911003113,\n",
      "                          0.8978807926177979,\n",
      "                          0.8980574607849121]],\n",
      " 'Validation Loss': [0.40188711881637573,\n",
      "                     0.3645144999027252,\n",
      "                     0.3426286578178406,\n",
      "                     0.33111071586608887,\n",
      "                     0.3222486078739166,\n",
      "                     0.3211081326007843,\n",
      "                     0.3105545938014984,\n",
      "                     0.29649412631988525,\n",
      "                     0.2986046373844147,\n",
      "                     0.29193374514579773,\n",
      "                     0.28772085905075073,\n",
      "                     0.28373393416404724,\n",
      "                     0.2782912850379944,\n",
      "                     0.27961981296539307,\n",
      "                     0.2736557424068451,\n",
      "                     0.2749190330505371,\n",
      "                     0.27827852964401245,\n",
      "                     0.26887932419776917,\n",
      "                     0.269474595785141,\n",
      "                     0.26976558566093445],\n",
      " 'Validation MCC': [[np.float64(0.7732429277526268),\n",
      "                     np.float64(0.8044380487845447),\n",
      "                     np.float64(0.8093744836228662),\n",
      "                     np.float64(0.8267150313789527),\n",
      "                     np.float64(0.8233946262128503),\n",
      "                     np.float64(0.8306010517905982),\n",
      "                     np.float64(0.834276232504473),\n",
      "                     np.float64(0.8424344934891209),\n",
      "                     np.float64(0.8406760631363684),\n",
      "                     np.float64(0.845956751247433),\n",
      "                     np.float64(0.8466020211595209),\n",
      "                     np.float64(0.8469220900538654),\n",
      "                     np.float64(0.8497615408128332),\n",
      "                     np.float64(0.8516985652303869),\n",
      "                     np.float64(0.8511025942748579),\n",
      "                     np.float64(0.8497958964899329),\n",
      "                     np.float64(0.8536226969056593),\n",
      "                     np.float64(0.8530269339619855),\n",
      "                     np.float64(0.8524906002760163),\n",
      "                     np.float64(0.8526359890162531)],\n",
      "                    [np.float64(0.7803132221140877),\n",
      "                     np.float64(0.8096623410465705),\n",
      "                     np.float64(0.8156124878089933),\n",
      "                     np.float64(0.8175260540146296),\n",
      "                     np.float64(0.8299428015109874),\n",
      "                     np.float64(0.8345822469295973),\n",
      "                     np.float64(0.835844205848341),\n",
      "                     np.float64(0.8391063699350214),\n",
      "                     np.float64(0.8361559382478194),\n",
      "                     np.float64(0.8428533301368412),\n",
      "                     np.float64(0.844845239251688),\n",
      "                     np.float64(0.8445670138203311),\n",
      "                     np.float64(0.8465943350882075),\n",
      "                     np.float64(0.8481596361719049),\n",
      "                     np.float64(0.8519224435801199),\n",
      "                     np.float64(0.8531675400656408),\n",
      "                     np.float64(0.8490135856236765),\n",
      "                     np.float64(0.8512986877687372),\n",
      "                     np.float64(0.8573431675899484),\n",
      "                     np.float64(0.8583917878073914)],\n",
      "                    [np.float64(0.771546748015319),\n",
      "                     np.float64(0.7957273050472906),\n",
      "                     np.float64(0.8066055407634242),\n",
      "                     np.float64(0.8176842151842281),\n",
      "                     np.float64(0.8229166400116471),\n",
      "                     np.float64(0.8266320460614208),\n",
      "                     np.float64(0.822127635491758),\n",
      "                     np.float64(0.8332154169726378),\n",
      "                     np.float64(0.8355684520871025),\n",
      "                     np.float64(0.8356894989091528),\n",
      "                     np.float64(0.8395634995154452),\n",
      "                     np.float64(0.8396910977314204),\n",
      "                     np.float64(0.8420046754715919),\n",
      "                     np.float64(0.8373811380844572),\n",
      "                     np.float64(0.8412111364482573),\n",
      "                     np.float64(0.8428861447828223),\n",
      "                     np.float64(0.8452219262019877),\n",
      "                     np.float64(0.8468626712527431),\n",
      "                     np.float64(0.8471078986999169),\n",
      "                     np.float64(0.8475960381869734)],\n",
      "                    [np.float64(0.7729442229131701),\n",
      "                     np.float64(0.7956050599364287),\n",
      "                     np.float64(0.8044679056390838),\n",
      "                     np.float64(0.8151873550781553),\n",
      "                     np.float64(0.822054949555638),\n",
      "                     np.float64(0.8276321952977741),\n",
      "                     np.float64(0.8269402776028997),\n",
      "                     np.float64(0.8331513934980146),\n",
      "                     np.float64(0.8376763486776737),\n",
      "                     np.float64(0.8374661663769208),\n",
      "                     np.float64(0.8409931328428406),\n",
      "                     np.float64(0.8407304606678453),\n",
      "                     np.float64(0.8441164295621171),\n",
      "                     np.float64(0.8411726101051544),\n",
      "                     np.float64(0.845871381444611),\n",
      "                     np.float64(0.8454725298197341),\n",
      "                     np.float64(0.8463192478059954),\n",
      "                     np.float64(0.8474692906053753),\n",
      "                     np.float64(0.8489426915622701),\n",
      "                     np.float64(0.8494032019411294)],\n",
      "                    [np.float64(0.7674547226687185),\n",
      "                     np.float64(0.7847323457395584),\n",
      "                     np.float64(0.7992254977295105),\n",
      "                     np.float64(0.8047921359557675),\n",
      "                     np.float64(0.8108736314304379),\n",
      "                     np.float64(0.8118768205591667),\n",
      "                     np.float64(0.8174631551108077),\n",
      "                     np.float64(0.8254945525679802),\n",
      "                     np.float64(0.8247978099533263),\n",
      "                     np.float64(0.8278284565067007),\n",
      "                     np.float64(0.8309766949961994),\n",
      "                     np.float64(0.8330198859606238),\n",
      "                     np.float64(0.8380871484965883),\n",
      "                     np.float64(0.8367346865242278),\n",
      "                     np.float64(0.840353411067516),\n",
      "                     np.float64(0.8409667565775535),\n",
      "                     np.float64(0.8391118571472099),\n",
      "                     np.float64(0.8442777660068465),\n",
      "                     np.float64(0.8437916519502223),\n",
      "                     np.float64(0.8436031333815485)]]}\n",
      "Training Model: MLP, Fold: 1\n",
      "Epoch 1/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6882 - loss: 0.9023\n",
      "Epoch 1 - MCC: 0.7617\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 12ms/step - accuracy: 0.6892 - loss: 0.8991 - val_accuracy: 0.8457 - val_loss: 0.4054 - mcc: 0.7617\n",
      "Epoch 2/20\n",
      "\u001B[1m366/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8457 - loss: 0.4013\n",
      "Epoch 2 - MCC: 0.7745\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8458 - loss: 0.4011 - val_accuracy: 0.8539 - val_loss: 0.3766 - mcc: 0.7745\n",
      "Epoch 3/20\n",
      "\u001B[1m362/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8533 - loss: 0.3817\n",
      "Epoch 3 - MCC: 0.7839\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 6ms/step - accuracy: 0.8533 - loss: 0.3815 - val_accuracy: 0.8578 - val_loss: 0.3665 - mcc: 0.7839\n",
      "Epoch 4/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8592 - loss: 0.3659\n",
      "Epoch 4 - MCC: 0.7915\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.8593 - loss: 0.3658 - val_accuracy: 0.8642 - val_loss: 0.3497 - mcc: 0.7915\n",
      "Epoch 5/20\n",
      "\u001B[1m368/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8614 - loss: 0.3569\n",
      "Epoch 5 - MCC: 0.7900\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8614 - loss: 0.3569 - val_accuracy: 0.8640 - val_loss: 0.3521 - mcc: 0.7900\n",
      "Epoch 6/20\n",
      "\u001B[1m366/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8637 - loss: 0.3520\n",
      "Epoch 6 - MCC: 0.7980\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8637 - loss: 0.3519 - val_accuracy: 0.8680 - val_loss: 0.3392 - mcc: 0.7980\n",
      "Epoch 7/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8662 - loss: 0.3466\n",
      "Epoch 7 - MCC: 0.7993\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8663 - loss: 0.3466 - val_accuracy: 0.8689 - val_loss: 0.3357 - mcc: 0.7993\n",
      "Epoch 8/20\n",
      "\u001B[1m366/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8680 - loss: 0.3407\n",
      "Epoch 8 - MCC: 0.8007\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.8680 - loss: 0.3407 - val_accuracy: 0.8708 - val_loss: 0.3330 - mcc: 0.8007\n",
      "Epoch 9/20\n",
      "\u001B[1m363/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8683 - loss: 0.3397\n",
      "Epoch 9 - MCC: 0.8020\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8683 - loss: 0.3396 - val_accuracy: 0.8715 - val_loss: 0.3311 - mcc: 0.8020\n",
      "Epoch 10/20\n",
      "\u001B[1m365/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8682 - loss: 0.3399\n",
      "Epoch 10 - MCC: 0.8039\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8683 - loss: 0.3398 - val_accuracy: 0.8728 - val_loss: 0.3273 - mcc: 0.8039\n",
      "Epoch 11/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8705 - loss: 0.3350\n",
      "Epoch 11 - MCC: 0.8047\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.8705 - loss: 0.3350 - val_accuracy: 0.8731 - val_loss: 0.3267 - mcc: 0.8047\n",
      "Epoch 12/20\n",
      "\u001B[1m366/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8724 - loss: 0.3290\n",
      "Epoch 12 - MCC: 0.8062\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.8724 - loss: 0.3290 - val_accuracy: 0.8728 - val_loss: 0.3267 - mcc: 0.8062\n",
      "Epoch 13/20\n",
      "\u001B[1m362/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8716 - loss: 0.3310\n",
      "Epoch 13 - MCC: 0.8053\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8717 - loss: 0.3310 - val_accuracy: 0.8738 - val_loss: 0.3250 - mcc: 0.8053\n",
      "Epoch 14/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8728 - loss: 0.3282\n",
      "Epoch 14 - MCC: 0.8094\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.8728 - loss: 0.3282 - val_accuracy: 0.8762 - val_loss: 0.3179 - mcc: 0.8094\n",
      "Epoch 15/20\n",
      "\u001B[1m364/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8721 - loss: 0.3292\n",
      "Epoch 15 - MCC: 0.8094\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.8721 - loss: 0.3291 - val_accuracy: 0.8753 - val_loss: 0.3179 - mcc: 0.8094\n",
      "Epoch 16/20\n",
      "\u001B[1m370/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8740 - loss: 0.3245\n",
      "Epoch 16 - MCC: 0.8084\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.8740 - loss: 0.3245 - val_accuracy: 0.8757 - val_loss: 0.3192 - mcc: 0.8084\n",
      "Epoch 17/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8747 - loss: 0.3231\n",
      "Epoch 17 - MCC: 0.8126\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.8747 - loss: 0.3231 - val_accuracy: 0.8782 - val_loss: 0.3124 - mcc: 0.8126\n",
      "Epoch 18/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8743 - loss: 0.3239\n",
      "Epoch 18 - MCC: 0.8109\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8743 - loss: 0.3239 - val_accuracy: 0.8763 - val_loss: 0.3150 - mcc: 0.8109\n",
      "Epoch 19/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8764 - loss: 0.3179\n",
      "Epoch 19 - MCC: 0.8145\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 9ms/step - accuracy: 0.8764 - loss: 0.3179 - val_accuracy: 0.8793 - val_loss: 0.3100 - mcc: 0.8145\n",
      "Epoch 20/20\n",
      "\u001B[1m368/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8765 - loss: 0.3174\n",
      "Epoch 20 - MCC: 0.8134\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8765 - loss: 0.3174 - val_accuracy: 0.8788 - val_loss: 0.3104 - mcc: 0.8134\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: MLP, Fold: 2\n",
      "Epoch 1/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6813 - loss: 0.9222\n",
      "Epoch 1 - MCC: 0.7630\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 13ms/step - accuracy: 0.6836 - loss: 0.9150 - val_accuracy: 0.8471 - val_loss: 0.3982 - mcc: 0.7630\n",
      "Epoch 2/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8444 - loss: 0.4060\n",
      "Epoch 2 - MCC: 0.7807\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8444 - loss: 0.4059 - val_accuracy: 0.8582 - val_loss: 0.3669 - mcc: 0.7807\n",
      "Epoch 3/20\n",
      "\u001B[1m366/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8549 - loss: 0.3768\n",
      "Epoch 3 - MCC: 0.7869\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8550 - loss: 0.3766 - val_accuracy: 0.8621 - val_loss: 0.3574 - mcc: 0.7869\n",
      "Epoch 4/20\n",
      "\u001B[1m369/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8594 - loss: 0.3658\n",
      "Epoch 4 - MCC: 0.7921\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8594 - loss: 0.3657 - val_accuracy: 0.8652 - val_loss: 0.3494 - mcc: 0.7921\n",
      "Epoch 5/20\n",
      "\u001B[1m362/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8614 - loss: 0.3572\n",
      "Epoch 5 - MCC: 0.7969\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.8615 - loss: 0.3570 - val_accuracy: 0.8685 - val_loss: 0.3400 - mcc: 0.7969\n",
      "Epoch 6/20\n",
      "\u001B[1m368/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8677 - loss: 0.3419\n",
      "Epoch 6 - MCC: 0.8014\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - accuracy: 0.8677 - loss: 0.3420 - val_accuracy: 0.8709 - val_loss: 0.3343 - mcc: 0.8014\n",
      "Epoch 7/20\n",
      "\u001B[1m370/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8674 - loss: 0.3413\n",
      "Epoch 7 - MCC: 0.8023\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.8674 - loss: 0.3413 - val_accuracy: 0.8713 - val_loss: 0.3322 - mcc: 0.8023\n",
      "Epoch 8/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8705 - loss: 0.3342\n",
      "Epoch 8 - MCC: 0.8046\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8705 - loss: 0.3342 - val_accuracy: 0.8734 - val_loss: 0.3273 - mcc: 0.8046\n",
      "Epoch 9/20\n",
      "\u001B[1m370/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8690 - loss: 0.3375\n",
      "Epoch 9 - MCC: 0.8060\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.8691 - loss: 0.3374 - val_accuracy: 0.8739 - val_loss: 0.3269 - mcc: 0.8060\n",
      "Epoch 10/20\n",
      "\u001B[1m369/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8718 - loss: 0.3305\n",
      "Epoch 10 - MCC: 0.8061\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.8718 - loss: 0.3305 - val_accuracy: 0.8746 - val_loss: 0.3246 - mcc: 0.8061\n",
      "Epoch 11/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8718 - loss: 0.3305\n",
      "Epoch 11 - MCC: 0.8096\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 6ms/step - accuracy: 0.8719 - loss: 0.3304 - val_accuracy: 0.8765 - val_loss: 0.3202 - mcc: 0.8096\n",
      "Epoch 12/20\n",
      "\u001B[1m365/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8728 - loss: 0.3272\n",
      "Epoch 12 - MCC: 0.8058\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.8728 - loss: 0.3272 - val_accuracy: 0.8746 - val_loss: 0.3258 - mcc: 0.8058\n",
      "Epoch 13/20\n",
      "\u001B[1m360/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8732 - loss: 0.3261\n",
      "Epoch 13 - MCC: 0.8078\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.8732 - loss: 0.3260 - val_accuracy: 0.8758 - val_loss: 0.3223 - mcc: 0.8078\n",
      "Epoch 14/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8755 - loss: 0.3202\n",
      "Epoch 14 - MCC: 0.8127\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.8755 - loss: 0.3202 - val_accuracy: 0.8779 - val_loss: 0.3162 - mcc: 0.8127\n",
      "Epoch 15/20\n",
      "\u001B[1m364/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8759 - loss: 0.3198\n",
      "Epoch 15 - MCC: 0.8128\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8759 - loss: 0.3199 - val_accuracy: 0.8784 - val_loss: 0.3152 - mcc: 0.8128\n",
      "Epoch 16/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8759 - loss: 0.3194\n",
      "Epoch 16 - MCC: 0.8113\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8759 - loss: 0.3194 - val_accuracy: 0.8767 - val_loss: 0.3195 - mcc: 0.8113\n",
      "Epoch 17/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8761 - loss: 0.3186\n",
      "Epoch 17 - MCC: 0.8152\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8761 - loss: 0.3186 - val_accuracy: 0.8800 - val_loss: 0.3115 - mcc: 0.8152\n",
      "Epoch 18/20\n",
      "\u001B[1m368/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8775 - loss: 0.3156\n",
      "Epoch 18 - MCC: 0.8133\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.8775 - loss: 0.3156 - val_accuracy: 0.8777 - val_loss: 0.3160 - mcc: 0.8133\n",
      "Epoch 19/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8746 - loss: 0.3229\n",
      "Epoch 19 - MCC: 0.8115\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.8747 - loss: 0.3227 - val_accuracy: 0.8780 - val_loss: 0.3156 - mcc: 0.8115\n",
      "Epoch 20/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8782 - loss: 0.3148\n",
      "Epoch 20 - MCC: 0.8159\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8782 - loss: 0.3148 - val_accuracy: 0.8809 - val_loss: 0.3086 - mcc: 0.8159\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: MLP, Fold: 3\n",
      "Epoch 1/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6761 - loss: 0.9229\n",
      "Epoch 1 - MCC: 0.7592\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 14ms/step - accuracy: 0.6772 - loss: 0.9196 - val_accuracy: 0.8442 - val_loss: 0.4055 - mcc: 0.7592\n",
      "Epoch 2/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8480 - loss: 0.3953\n",
      "Epoch 2 - MCC: 0.7730\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8480 - loss: 0.3952 - val_accuracy: 0.8519 - val_loss: 0.3841 - mcc: 0.7730\n",
      "Epoch 3/20\n",
      "\u001B[1m370/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8562 - loss: 0.3726\n",
      "Epoch 3 - MCC: 0.7809\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.8562 - loss: 0.3726 - val_accuracy: 0.8580 - val_loss: 0.3677 - mcc: 0.7809\n",
      "Epoch 4/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8596 - loss: 0.3624\n",
      "Epoch 4 - MCC: 0.7911\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8597 - loss: 0.3623 - val_accuracy: 0.8636 - val_loss: 0.3521 - mcc: 0.7911\n",
      "Epoch 5/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8635 - loss: 0.3541\n",
      "Epoch 5 - MCC: 0.7939\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8635 - loss: 0.3541 - val_accuracy: 0.8651 - val_loss: 0.3465 - mcc: 0.7939\n",
      "Epoch 6/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8663 - loss: 0.3462\n",
      "Epoch 6 - MCC: 0.7933\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.8663 - loss: 0.3462 - val_accuracy: 0.8661 - val_loss: 0.3441 - mcc: 0.7933\n",
      "Epoch 7/20\n",
      "\u001B[1m364/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8694 - loss: 0.3379\n",
      "Epoch 7 - MCC: 0.7967\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.8694 - loss: 0.3379 - val_accuracy: 0.8671 - val_loss: 0.3400 - mcc: 0.7967\n",
      "Epoch 8/20\n",
      "\u001B[1m365/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8682 - loss: 0.3398\n",
      "Epoch 8 - MCC: 0.8001\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8682 - loss: 0.3397 - val_accuracy: 0.8700 - val_loss: 0.3340 - mcc: 0.8001\n",
      "Epoch 9/20\n",
      "\u001B[1m361/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8720 - loss: 0.3314\n",
      "Epoch 9 - MCC: 0.7988\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8720 - loss: 0.3314 - val_accuracy: 0.8686 - val_loss: 0.3369 - mcc: 0.7988\n",
      "Epoch 10/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8713 - loss: 0.3328\n",
      "Epoch 10 - MCC: 0.8020\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.8713 - loss: 0.3327 - val_accuracy: 0.8715 - val_loss: 0.3300 - mcc: 0.8020\n",
      "Epoch 11/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8741 - loss: 0.3253\n",
      "Epoch 11 - MCC: 0.8043\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.8741 - loss: 0.3253 - val_accuracy: 0.8727 - val_loss: 0.3270 - mcc: 0.8043\n",
      "Epoch 12/20\n",
      "\u001B[1m370/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8721 - loss: 0.3298\n",
      "Epoch 12 - MCC: 0.8044\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.8722 - loss: 0.3297 - val_accuracy: 0.8717 - val_loss: 0.3281 - mcc: 0.8044\n",
      "Epoch 13/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8743 - loss: 0.3250\n",
      "Epoch 13 - MCC: 0.8060\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8743 - loss: 0.3250 - val_accuracy: 0.8736 - val_loss: 0.3236 - mcc: 0.8060\n",
      "Epoch 14/20\n",
      "\u001B[1m364/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8755 - loss: 0.3217\n",
      "Epoch 14 - MCC: 0.8069\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - accuracy: 0.8754 - loss: 0.3217 - val_accuracy: 0.8745 - val_loss: 0.3221 - mcc: 0.8069\n",
      "Epoch 15/20\n",
      "\u001B[1m370/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8739 - loss: 0.3241\n",
      "Epoch 15 - MCC: 0.8061\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.8739 - loss: 0.3241 - val_accuracy: 0.8731 - val_loss: 0.3242 - mcc: 0.8061\n",
      "Epoch 16/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8742 - loss: 0.3239\n",
      "Epoch 16 - MCC: 0.8056\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8742 - loss: 0.3238 - val_accuracy: 0.8738 - val_loss: 0.3235 - mcc: 0.8056\n",
      "Epoch 17/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8763 - loss: 0.3183\n",
      "Epoch 17 - MCC: 0.8082\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.8763 - loss: 0.3183 - val_accuracy: 0.8754 - val_loss: 0.3203 - mcc: 0.8082\n",
      "Epoch 18/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8747 - loss: 0.3243\n",
      "Epoch 18 - MCC: 0.8089\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.8747 - loss: 0.3242 - val_accuracy: 0.8754 - val_loss: 0.3187 - mcc: 0.8089\n",
      "Epoch 19/20\n",
      "\u001B[1m369/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8758 - loss: 0.3203\n",
      "Epoch 19 - MCC: 0.8100\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8758 - loss: 0.3202 - val_accuracy: 0.8761 - val_loss: 0.3172 - mcc: 0.8100\n",
      "Epoch 20/20\n",
      "\u001B[1m369/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8782 - loss: 0.3140\n",
      "Epoch 20 - MCC: 0.8067\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8782 - loss: 0.3141 - val_accuracy: 0.8742 - val_loss: 0.3202 - mcc: 0.8067\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: MLP, Fold: 4\n",
      "Epoch 1/20\n",
      "\u001B[1m361/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6869 - loss: 0.8963\n",
      "Epoch 1 - MCC: 0.7542\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 12ms/step - accuracy: 0.6908 - loss: 0.8842 - val_accuracy: 0.8424 - val_loss: 0.4088 - mcc: 0.7542\n",
      "Epoch 2/20\n",
      "\u001B[1m361/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8485 - loss: 0.3910\n",
      "Epoch 2 - MCC: 0.7738\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8486 - loss: 0.3908 - val_accuracy: 0.8545 - val_loss: 0.3782 - mcc: 0.7738\n",
      "Epoch 3/20\n",
      "\u001B[1m361/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8572 - loss: 0.3687\n",
      "Epoch 3 - MCC: 0.7821\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8573 - loss: 0.3686 - val_accuracy: 0.8598 - val_loss: 0.3660 - mcc: 0.7821\n",
      "Epoch 4/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8622 - loss: 0.3569\n",
      "Epoch 4 - MCC: 0.7894\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8623 - loss: 0.3568 - val_accuracy: 0.8626 - val_loss: 0.3536 - mcc: 0.7894\n",
      "Epoch 5/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8650 - loss: 0.3480\n",
      "Epoch 5 - MCC: 0.7939\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8650 - loss: 0.3480 - val_accuracy: 0.8658 - val_loss: 0.3470 - mcc: 0.7939\n",
      "Epoch 6/20\n",
      "\u001B[1m370/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8667 - loss: 0.3433\n",
      "Epoch 6 - MCC: 0.7985\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - accuracy: 0.8668 - loss: 0.3432 - val_accuracy: 0.8691 - val_loss: 0.3385 - mcc: 0.7985\n",
      "Epoch 7/20\n",
      "\u001B[1m362/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8699 - loss: 0.3350\n",
      "Epoch 7 - MCC: 0.8002\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.8699 - loss: 0.3350 - val_accuracy: 0.8706 - val_loss: 0.3352 - mcc: 0.8002\n",
      "Epoch 8/20\n",
      "\u001B[1m365/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8728 - loss: 0.3272\n",
      "Epoch 8 - MCC: 0.8001\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.8727 - loss: 0.3274 - val_accuracy: 0.8701 - val_loss: 0.3362 - mcc: 0.8001\n",
      "Epoch 9/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8720 - loss: 0.3309\n",
      "Epoch 9 - MCC: 0.8024\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8720 - loss: 0.3309 - val_accuracy: 0.8724 - val_loss: 0.3321 - mcc: 0.8024\n",
      "Epoch 10/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8745 - loss: 0.3243\n",
      "Epoch 10 - MCC: 0.8031\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - accuracy: 0.8745 - loss: 0.3243 - val_accuracy: 0.8727 - val_loss: 0.3305 - mcc: 0.8031\n",
      "Epoch 11/20\n",
      "\u001B[1m365/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8767 - loss: 0.3174\n",
      "Epoch 11 - MCC: 0.8047\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.8766 - loss: 0.3176 - val_accuracy: 0.8738 - val_loss: 0.3275 - mcc: 0.8047\n",
      "Epoch 12/20\n",
      "\u001B[1m360/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8748 - loss: 0.3228\n",
      "Epoch 12 - MCC: 0.8054\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8748 - loss: 0.3228 - val_accuracy: 0.8741 - val_loss: 0.3266 - mcc: 0.8054\n",
      "Epoch 13/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8758 - loss: 0.3203\n",
      "Epoch 13 - MCC: 0.8081\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.8758 - loss: 0.3203 - val_accuracy: 0.8755 - val_loss: 0.3224 - mcc: 0.8081\n",
      "Epoch 14/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8778 - loss: 0.3146\n",
      "Epoch 14 - MCC: 0.8084\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.8778 - loss: 0.3146 - val_accuracy: 0.8752 - val_loss: 0.3231 - mcc: 0.8084\n",
      "Epoch 15/20\n",
      "\u001B[1m360/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8774 - loss: 0.3155\n",
      "Epoch 15 - MCC: 0.8075\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8774 - loss: 0.3156 - val_accuracy: 0.8756 - val_loss: 0.3229 - mcc: 0.8075\n",
      "Epoch 16/20\n",
      "\u001B[1m369/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8764 - loss: 0.3171\n",
      "Epoch 16 - MCC: 0.8087\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 6ms/step - accuracy: 0.8764 - loss: 0.3171 - val_accuracy: 0.8760 - val_loss: 0.3212 - mcc: 0.8087\n",
      "Epoch 17/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8782 - loss: 0.3139\n",
      "Epoch 17 - MCC: 0.8099\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8782 - loss: 0.3139 - val_accuracy: 0.8770 - val_loss: 0.3183 - mcc: 0.8099\n",
      "Epoch 18/20\n",
      "\u001B[1m368/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8774 - loss: 0.3148\n",
      "Epoch 18 - MCC: 0.8115\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.8774 - loss: 0.3148 - val_accuracy: 0.8777 - val_loss: 0.3166 - mcc: 0.8115\n",
      "Epoch 19/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8794 - loss: 0.3094\n",
      "Epoch 19 - MCC: 0.8123\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8794 - loss: 0.3094 - val_accuracy: 0.8784 - val_loss: 0.3155 - mcc: 0.8123\n",
      "Epoch 20/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8819 - loss: 0.3045\n",
      "Epoch 20 - MCC: 0.8120\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8819 - loss: 0.3046 - val_accuracy: 0.8782 - val_loss: 0.3159 - mcc: 0.8120\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: MLP, Fold: 5\n",
      "Epoch 1/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6828 - loss: 0.8931\n",
      "Epoch 1 - MCC: 0.7594\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 14ms/step - accuracy: 0.6851 - loss: 0.8861 - val_accuracy: 0.8436 - val_loss: 0.4117 - mcc: 0.7594\n",
      "Epoch 2/20\n",
      "\u001B[1m370/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8495 - loss: 0.3915\n",
      "Epoch 2 - MCC: 0.7688\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 6ms/step - accuracy: 0.8495 - loss: 0.3914 - val_accuracy: 0.8506 - val_loss: 0.3893 - mcc: 0.7688\n",
      "Epoch 3/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8584 - loss: 0.3678\n",
      "Epoch 3 - MCC: 0.7815\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8584 - loss: 0.3677 - val_accuracy: 0.8576 - val_loss: 0.3720 - mcc: 0.7815\n",
      "Epoch 4/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8607 - loss: 0.3598\n",
      "Epoch 4 - MCC: 0.7879\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - accuracy: 0.8607 - loss: 0.3598 - val_accuracy: 0.8613 - val_loss: 0.3605 - mcc: 0.7879\n",
      "Epoch 5/20\n",
      "\u001B[1m366/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8651 - loss: 0.3488\n",
      "Epoch 5 - MCC: 0.7876\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.8651 - loss: 0.3488 - val_accuracy: 0.8596 - val_loss: 0.3610 - mcc: 0.7876\n",
      "Epoch 6/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8662 - loss: 0.3461\n",
      "Epoch 6 - MCC: 0.7938\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8662 - loss: 0.3461 - val_accuracy: 0.8657 - val_loss: 0.3484 - mcc: 0.7938\n",
      "Epoch 7/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8682 - loss: 0.3382\n",
      "Epoch 7 - MCC: 0.7926\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8682 - loss: 0.3383 - val_accuracy: 0.8650 - val_loss: 0.3480 - mcc: 0.7926\n",
      "Epoch 8/20\n",
      "\u001B[1m371/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8706 - loss: 0.3340\n",
      "Epoch 8 - MCC: 0.7933\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.8706 - loss: 0.3340 - val_accuracy: 0.8657 - val_loss: 0.3473 - mcc: 0.7933\n",
      "Epoch 9/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8703 - loss: 0.3338\n",
      "Epoch 9 - MCC: 0.7987\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.8703 - loss: 0.3338 - val_accuracy: 0.8687 - val_loss: 0.3388 - mcc: 0.7987\n",
      "Epoch 10/20\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8714 - loss: 0.3309\n",
      "Epoch 10 - MCC: 0.7996\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8714 - loss: 0.3309 - val_accuracy: 0.8696 - val_loss: 0.3365 - mcc: 0.7996\n",
      "Epoch 11/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8715 - loss: 0.3296\n",
      "Epoch 11 - MCC: 0.8011\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.8715 - loss: 0.3296 - val_accuracy: 0.8704 - val_loss: 0.3341 - mcc: 0.8011\n",
      "Epoch 12/20\n",
      "\u001B[1m370/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8738 - loss: 0.3256\n",
      "Epoch 12 - MCC: 0.8004\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8738 - loss: 0.3256 - val_accuracy: 0.8702 - val_loss: 0.3342 - mcc: 0.8004\n",
      "Epoch 13/20\n",
      "\u001B[1m373/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8745 - loss: 0.3227\n",
      "Epoch 13 - MCC: 0.8008\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 9ms/step - accuracy: 0.8745 - loss: 0.3227 - val_accuracy: 0.8702 - val_loss: 0.3334 - mcc: 0.8008\n",
      "Epoch 14/20\n",
      "\u001B[1m368/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8761 - loss: 0.3187\n",
      "Epoch 14 - MCC: 0.8021\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8760 - loss: 0.3188 - val_accuracy: 0.8713 - val_loss: 0.3319 - mcc: 0.8021\n",
      "Epoch 15/20\n",
      "\u001B[1m360/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8735 - loss: 0.3256\n",
      "Epoch 15 - MCC: 0.8031\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8735 - loss: 0.3255 - val_accuracy: 0.8714 - val_loss: 0.3301 - mcc: 0.8031\n",
      "Epoch 16/20\n",
      "\u001B[1m374/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8750 - loss: 0.3229\n",
      "Epoch 16 - MCC: 0.8054\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8750 - loss: 0.3229 - val_accuracy: 0.8733 - val_loss: 0.3263 - mcc: 0.8054\n",
      "Epoch 17/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8766 - loss: 0.3180\n",
      "Epoch 17 - MCC: 0.8064\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.8766 - loss: 0.3180 - val_accuracy: 0.8743 - val_loss: 0.3248 - mcc: 0.8064\n",
      "Epoch 18/20\n",
      "\u001B[1m372/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8749 - loss: 0.3226\n",
      "Epoch 18 - MCC: 0.8077\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 9ms/step - accuracy: 0.8749 - loss: 0.3226 - val_accuracy: 0.8747 - val_loss: 0.3231 - mcc: 0.8077\n",
      "Epoch 19/20\n",
      "\u001B[1m367/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8758 - loss: 0.3181\n",
      "Epoch 19 - MCC: 0.8061\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.8758 - loss: 0.3180 - val_accuracy: 0.8726 - val_loss: 0.3265 - mcc: 0.8061\n",
      "Epoch 20/20\n",
      "\u001B[1m364/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8784 - loss: 0.3121\n",
      "Epoch 20 - MCC: 0.8059\n",
      "\u001B[1m375/375\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 6ms/step - accuracy: 0.8784 - loss: 0.3122 - val_accuracy: 0.8741 - val_loss: 0.3255 - mcc: 0.8059\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': np.float64(0.8808753333333333),\n",
      "              'mean': np.float64(0.8772389333333332),\n",
      "              'min': np.float64(0.874086),\n",
      "              'std': np.float64(0.002662741431098569)},\n",
      " 'Inference Time (s/sample)': {'max': np.float64(0.00022968300183614094),\n",
      "                               'mean': np.float64(0.00022425416310628256),\n",
      "                               'min': np.float64(0.00022078967094421386),\n",
      "                               'std': np.float64(3.206480511151273e-06)},\n",
      " 'MCC': {'max': np.float64(0.8159332627699284),\n",
      "         'mean': np.float64(0.8107765876573618),\n",
      "         'min': np.float64(0.8059232195126537),\n",
      "         'std': np.float64(0.0038812405385034296)},\n",
      " 'Parameters': 6301,\n",
      " 'Train Time (s)': {'max': np.float64(66.56008172035217),\n",
      "                    'mean': np.float64(64.39247941970825),\n",
      "                    'min': np.float64(63.14753985404968),\n",
      "                    'std': np.float64(1.2117840341047241)},\n",
      " 'Training Accuracy': [[0.7823675274848938,\n",
      "                        0.848409116268158,\n",
      "                        0.8555331826210022,\n",
      "                        0.8600082397460938,\n",
      "                        0.8633283972740173,\n",
      "                        0.8648817539215088,\n",
      "                        0.8667206168174744,\n",
      "                        0.8681455254554749,\n",
      "                        0.8685712218284607,\n",
      "                        0.8697779774665833,\n",
      "                        0.8706071972846985,\n",
      "                        0.8717793822288513,\n",
      "                        0.872144877910614,\n",
      "                        0.8728876709938049,\n",
      "                        0.8736494779586792,\n",
      "                        0.8739503026008606,\n",
      "                        0.8749163150787354,\n",
      "                        0.8753281831741333,\n",
      "                        0.8762808442115784,\n",
      "                        0.8758838176727295],\n",
      "                       [0.7766278386116028,\n",
      "                        0.848304271697998,\n",
      "                        0.8569473624229431,\n",
      "                        0.8610702157020569,\n",
      "                        0.8641172647476196,\n",
      "                        0.8665317296981812,\n",
      "                        0.8676639199256897,\n",
      "                        0.8692896366119385,\n",
      "                        0.8704279065132141,\n",
      "                        0.8712436556816101,\n",
      "                        0.8725715279579163,\n",
      "                        0.8731432557106018,\n",
      "                        0.8739321231842041,\n",
      "                        0.8745612502098083,\n",
      "                        0.8755189776420593,\n",
      "                        0.8760843873023987,\n",
      "                        0.8764747977256775,\n",
      "                        0.8766491413116455,\n",
      "                        0.8772059082984924,\n",
      "                        0.8780305981636047],\n",
      "                       [0.7760007977485657,\n",
      "                        0.849992573261261,\n",
      "                        0.8570531606674194,\n",
      "                        0.8615636229515076,\n",
      "                        0.8647581934928894,\n",
      "                        0.86712247133255,\n",
      "                        0.8691905736923218,\n",
      "                        0.8699267506599426,\n",
      "                        0.8714553117752075,\n",
      "                        0.8724924921989441,\n",
      "                        0.8729639649391174,\n",
      "                        0.8735179305076599,\n",
      "                        0.8739564418792725,\n",
      "                        0.8745035529136658,\n",
      "                        0.8750959634780884,\n",
      "                        0.875543475151062,\n",
      "                        0.875887930393219,\n",
      "                        0.8763111233711243,\n",
      "                        0.8762993812561035,\n",
      "                        0.8765680193901062],\n",
      "                       [0.7854536175727844,\n",
      "                        0.8512763381004333,\n",
      "                        0.8587769269943237,\n",
      "                        0.8638151288032532,\n",
      "                        0.8663260340690613,\n",
      "                        0.8680987358093262,\n",
      "                        0.869942307472229,\n",
      "                        0.8709454536437988,\n",
      "                        0.8720778226852417,\n",
      "                        0.8729649186134338,\n",
      "                        0.8740895986557007,\n",
      "                        0.8743564486503601,\n",
      "                        0.8755292892456055,\n",
      "                        0.8758571147918701,\n",
      "                        0.8766221404075623,\n",
      "                        0.8772177696228027,\n",
      "                        0.8775447010993958,\n",
      "                        0.8782076239585876,\n",
      "                        0.8786861896514893,\n",
      "                        0.8790227770805359],\n",
      "                       [0.7810405492782593,\n",
      "                        0.8518909215927124,\n",
      "                        0.8590967059135437,\n",
      "                        0.8628144264221191,\n",
      "                        0.8650891780853271,\n",
      "                        0.866728663444519,\n",
      "                        0.8678410053253174,\n",
      "                        0.8692259788513184,\n",
      "                        0.8700240850448608,\n",
      "                        0.8709096908569336,\n",
      "                        0.8720942139625549,\n",
      "                        0.8728715777397156,\n",
      "                        0.8737255334854126,\n",
      "                        0.8739945292472839,\n",
      "                        0.8745665550231934,\n",
      "                        0.8756141662597656,\n",
      "                        0.8760848045349121,\n",
      "                        0.876655101776123,\n",
      "                        0.8768918514251709,\n",
      "                        0.8777826428413391]],\n",
      " 'Training Loss': [[0.6018269062042236,\n",
      "                    0.3943112790584564,\n",
      "                    0.37461674213409424,\n",
      "                    0.3628515601158142,\n",
      "                    0.3536129891872406,\n",
      "                    0.34921643137931824,\n",
      "                    0.3447425663471222,\n",
      "                    0.34044134616851807,\n",
      "                    0.3391369879245758,\n",
      "                    0.3363158106803894,\n",
      "                    0.3341149389743805,\n",
      "                    0.3310735821723938,\n",
      "                    0.3301675319671631,\n",
      "                    0.32786697149276733,\n",
      "                    0.3255622088909149,\n",
      "                    0.3249867856502533,\n",
      "                    0.32252588868141174,\n",
      "                    0.32130274176597595,\n",
      "                    0.31888166069984436,\n",
      "                    0.3193799555301666],\n",
      "                   [0.6200917363166809,\n",
      "                    0.39425021409988403,\n",
      "                    0.37101826071739197,\n",
      "                    0.3601885437965393,\n",
      "                    0.3515261709690094,\n",
      "                    0.34520047903060913,\n",
      "                    0.34151211380958557,\n",
      "                    0.33732929825782776,\n",
      "                    0.3343815505504608,\n",
      "                    0.3320125639438629,\n",
      "                    0.3290480375289917,\n",
      "                    0.326947957277298,\n",
      "                    0.3251008987426758,\n",
      "                    0.32338085770606995,\n",
      "                    0.32074329257011414,\n",
      "                    0.31932348012924194,\n",
      "                    0.3188377618789673,\n",
      "                    0.3174133598804474,\n",
      "                    0.3161999583244324,\n",
      "                    0.314188152551651],\n",
      "                   [0.6163557171821594,\n",
      "                    0.38916152715682983,\n",
      "                    0.3703443109989166,\n",
      "                    0.3587343692779541,\n",
      "                    0.3501533269882202,\n",
      "                    0.3432177007198334,\n",
      "                    0.337666392326355,\n",
      "                    0.33511894941329956,\n",
      "                    0.3320590555667877,\n",
      "                    0.3293437361717224,\n",
      "                    0.3280053436756134,\n",
      "                    0.32636556029319763,\n",
      "                    0.3251156806945801,\n",
      "                    0.32346227765083313,\n",
      "                    0.32198214530944824,\n",
      "                    0.32080742716789246,\n",
      "                    0.31991246342658997,\n",
      "                    0.3190457224845886,\n",
      "                    0.31906527280807495,\n",
      "                    0.3179980516433716],\n",
      "                   [0.5893727540969849,\n",
      "                    0.3845052421092987,\n",
      "                    0.3644160032272339,\n",
      "                    0.3520110249519348,\n",
      "                    0.3450296223163605,\n",
      "                    0.33972543478012085,\n",
      "                    0.3353411853313446,\n",
      "                    0.33218276500701904,\n",
      "                    0.32931649684906006,\n",
      "                    0.32675835490226746,\n",
      "                    0.3241010010242462,\n",
      "                    0.3234615623950958,\n",
      "                    0.32041966915130615,\n",
      "                    0.3192451596260071,\n",
      "                    0.3176490366458893,\n",
      "                    0.31605827808380127,\n",
      "                    0.3151412904262543,\n",
      "                    0.3132874667644501,\n",
      "                    0.31218478083610535,\n",
      "                    0.3112586438655853],\n",
      "                   [0.6008428335189819,\n",
      "                    0.3858162462711334,\n",
      "                    0.3658287823200226,\n",
      "                    0.35512232780456543,\n",
      "                    0.3484870195388794,\n",
      "                    0.34370091557502747,\n",
      "                    0.3405326306819916,\n",
      "                    0.3365927040576935,\n",
      "                    0.3342607617378235,\n",
      "                    0.33200398087501526,\n",
      "                    0.32897958159446716,\n",
      "                    0.3268814980983734,\n",
      "                    0.3252805769443512,\n",
      "                    0.3240967094898224,\n",
      "                    0.3230415880680084,\n",
      "                    0.3203628957271576,\n",
      "                    0.31903278827667236,\n",
      "                    0.31741008162498474,\n",
      "                    0.3167596161365509,\n",
      "                    0.31494852900505066]],\n",
      " 'Validation Accuracy': [[0.8457029461860657,\n",
      "                          0.8539438247680664,\n",
      "                          0.8577688932418823,\n",
      "                          0.8642066121101379,\n",
      "                          0.8639865517616272,\n",
      "                          0.8679911494255066,\n",
      "                          0.8689323663711548,\n",
      "                          0.8707762956619263,\n",
      "                          0.8714641332626343,\n",
      "                          0.8728340864181519,\n",
      "                          0.8730646371841431,\n",
      "                          0.8727986812591553,\n",
      "                          0.8737578988075256,\n",
      "                          0.8762173652648926,\n",
      "                          0.875313937664032,\n",
      "                          0.8756647706031799,\n",
      "                          0.8782300353050232,\n",
      "                          0.8763372302055359,\n",
      "                          0.8793025612831116,\n",
      "                          0.878756046295166],\n",
      "                         [0.847098708152771,\n",
      "                          0.8582198619842529,\n",
      "                          0.8621326684951782,\n",
      "                          0.8651604652404785,\n",
      "                          0.8684714436531067,\n",
      "                          0.8708934187889099,\n",
      "                          0.8713347315788269,\n",
      "                          0.873439610004425,\n",
      "                          0.8739038705825806,\n",
      "                          0.8746492266654968,\n",
      "                          0.8764735460281372,\n",
      "                          0.8745988011360168,\n",
      "                          0.8758113384246826,\n",
      "                          0.8779453039169312,\n",
      "                          0.8784188628196716,\n",
      "                          0.8766617774963379,\n",
      "                          0.8799911141395569,\n",
      "                          0.8777134418487549,\n",
      "                          0.8780200481414795,\n",
      "                          0.8808757066726685],\n",
      "                         [0.844249427318573,\n",
      "                          0.8519140481948853,\n",
      "                          0.8579620122909546,\n",
      "                          0.8636059761047363,\n",
      "                          0.8650612235069275,\n",
      "                          0.866071343421936,\n",
      "                          0.8671213984489441,\n",
      "                          0.8699522018432617,\n",
      "                          0.8686459064483643,\n",
      "                          0.871483564376831,\n",
      "                          0.8726754784584045,\n",
      "                          0.8716977834701538,\n",
      "                          0.8735799193382263,\n",
      "                          0.8744553327560425,\n",
      "                          0.8730711340904236,\n",
      "                          0.8738011717796326,\n",
      "                          0.8753767013549805,\n",
      "                          0.8753970265388489,\n",
      "                          0.8760902285575867,\n",
      "                          0.8742404580116272],\n",
      "                         [0.8423662781715393,\n",
      "                          0.8544886708259583,\n",
      "                          0.859768807888031,\n",
      "                          0.8625873327255249,\n",
      "                          0.8658369779586792,\n",
      "                          0.8690729141235352,\n",
      "                          0.8706000447273254,\n",
      "                          0.8701307773590088,\n",
      "                          0.8724287748336792,\n",
      "                          0.8726601600646973,\n",
      "                          0.873754620552063,\n",
      "                          0.8741421103477478,\n",
      "                          0.875503420829773,\n",
      "                          0.8752452731132507,\n",
      "                          0.8756132125854492,\n",
      "                          0.8759514689445496,\n",
      "                          0.8769869208335876,\n",
      "                          0.8776559233665466,\n",
      "                          0.8784261345863342,\n",
      "                          0.8782369494438171],\n",
      "                         [0.8435887098312378,\n",
      "                          0.8506182432174683,\n",
      "                          0.8576300740242004,\n",
      "                          0.8612874150276184,\n",
      "                          0.8595507144927979,\n",
      "                          0.8656841516494751,\n",
      "                          0.8649879693984985,\n",
      "                          0.8656784892082214,\n",
      "                          0.868675947189331,\n",
      "                          0.8696420192718506,\n",
      "                          0.8703595399856567,\n",
      "                          0.8702301383018494,\n",
      "                          0.8701961040496826,\n",
      "                          0.871330738067627,\n",
      "                          0.871380627155304,\n",
      "                          0.8732925653457642,\n",
      "                          0.8742708563804626,\n",
      "                          0.8746801614761353,\n",
      "                          0.8726313710212708,\n",
      "                          0.8740862011909485]],\n",
      " 'Validation Loss': [0.41166743636131287,\n",
      "                     0.38928020000457764,\n",
      "                     0.37201058864593506,\n",
      "                     0.3605479598045349,\n",
      "                     0.36103612184524536,\n",
      "                     0.3484130799770355,\n",
      "                     0.3479894995689392,\n",
      "                     0.3472706973552704,\n",
      "                     0.33881866931915283,\n",
      "                     0.33650198578834534,\n",
      "                     0.3341164290904999,\n",
      "                     0.3341871500015259,\n",
      "                     0.3334163427352905,\n",
      "                     0.3319275379180908,\n",
      "                     0.3301096260547638,\n",
      "                     0.3262576162815094,\n",
      "                     0.32480406761169434,\n",
      "                     0.3230600357055664,\n",
      "                     0.3264661133289337,\n",
      "                     0.3254627585411072],\n",
      " 'Validation MCC': [[np.float64(0.7616604947161449),\n",
      "                     np.float64(0.7744762326852608),\n",
      "                     np.float64(0.7839253766406431),\n",
      "                     np.float64(0.7915028132286461),\n",
      "                     np.float64(0.7899718669607307),\n",
      "                     np.float64(0.7980256009594079),\n",
      "                     np.float64(0.7993147501020365),\n",
      "                     np.float64(0.800702100273079),\n",
      "                     np.float64(0.801951435677124),\n",
      "                     np.float64(0.8039308273953089),\n",
      "                     np.float64(0.8046706608339059),\n",
      "                     np.float64(0.8062267447008343),\n",
      "                     np.float64(0.8053455342568283),\n",
      "                     np.float64(0.8094254415589959),\n",
      "                     np.float64(0.8093897835480917),\n",
      "                     np.float64(0.8084170636963876),\n",
      "                     np.float64(0.812550331529622),\n",
      "                     np.float64(0.8109299910256149),\n",
      "                     np.float64(0.8145132495172558),\n",
      "                     np.float64(0.8133628472869987)],\n",
      "                    [np.float64(0.7630199734444041),\n",
      "                     np.float64(0.780697640105467),\n",
      "                     np.float64(0.7868981290368483),\n",
      "                     np.float64(0.7920718122270348),\n",
      "                     np.float64(0.7969498844439724),\n",
      "                     np.float64(0.801365577930074),\n",
      "                     np.float64(0.8023408741476425),\n",
      "                     np.float64(0.8046481839266795),\n",
      "                     np.float64(0.8059717386866212),\n",
      "                     np.float64(0.8061369047709099),\n",
      "                     np.float64(0.8096200306249396),\n",
      "                     np.float64(0.805778398991443),\n",
      "                     np.float64(0.8078457966996363),\n",
      "                     np.float64(0.8126722744509829),\n",
      "                     np.float64(0.8128456261523958),\n",
      "                     np.float64(0.8113007874800042),\n",
      "                     np.float64(0.8151872809686483),\n",
      "                     np.float64(0.8132673695966866),\n",
      "                     np.float64(0.8114588355993221),\n",
      "                     np.float64(0.8159332627699284)],\n",
      "                    [np.float64(0.7591721141439504),\n",
      "                     np.float64(0.7730306668571709),\n",
      "                     np.float64(0.7809128956188475),\n",
      "                     np.float64(0.7910861449404502),\n",
      "                     np.float64(0.7938808795097502),\n",
      "                     np.float64(0.7932968417845573),\n",
      "                     np.float64(0.7966744803759116),\n",
      "                     np.float64(0.8001076682082711),\n",
      "                     np.float64(0.7987677547986953),\n",
      "                     np.float64(0.8020477530238327),\n",
      "                     np.float64(0.8042657650169798),\n",
      "                     np.float64(0.8044093145845411),\n",
      "                     np.float64(0.8059520578478637),\n",
      "                     np.float64(0.8068715760058277),\n",
      "                     np.float64(0.806082265482853),\n",
      "                     np.float64(0.8056439077465302),\n",
      "                     np.float64(0.8082489064659495),\n",
      "                     np.float64(0.8088868349767511),\n",
      "                     np.float64(0.8099843782470064),\n",
      "                     np.float64(0.8066569096325164)],\n",
      "                    [np.float64(0.7541972838579156),\n",
      "                     np.float64(0.7737787977412046),\n",
      "                     np.float64(0.7820979935531603),\n",
      "                     np.float64(0.789443153312488),\n",
      "                     np.float64(0.7938811592241748),\n",
      "                     np.float64(0.7984728915956705),\n",
      "                     np.float64(0.8001677528689296),\n",
      "                     np.float64(0.8001479824792735),\n",
      "                     np.float64(0.8023788306098389),\n",
      "                     np.float64(0.8031348681532066),\n",
      "                     np.float64(0.8047109136497077),\n",
      "                     np.float64(0.8054102756622958),\n",
      "                     np.float64(0.8080738421633208),\n",
      "                     np.float64(0.8083934828331898),\n",
      "                     np.float64(0.8074547294634511),\n",
      "                     np.float64(0.8087478957043187),\n",
      "                     np.float64(0.8098801833051746),\n",
      "                     np.float64(0.81146625954408),\n",
      "                     np.float64(0.8123412350714136),\n",
      "                     np.float64(0.8120066990847116)],\n",
      "                    [np.float64(0.7594348102355112),\n",
      "                     np.float64(0.7687891681271547),\n",
      "                     np.float64(0.7814539741266068),\n",
      "                     np.float64(0.787878945892088),\n",
      "                     np.float64(0.7875513519708001),\n",
      "                     np.float64(0.7938465351459594),\n",
      "                     np.float64(0.7925946646045539),\n",
      "                     np.float64(0.7933326567326275),\n",
      "                     np.float64(0.7986847730904251),\n",
      "                     np.float64(0.7995500501604019),\n",
      "                     np.float64(0.8011472530681419),\n",
      "                     np.float64(0.8003749647946564),\n",
      "                     np.float64(0.8007619495749059),\n",
      "                     np.float64(0.8021301893617647),\n",
      "                     np.float64(0.8031388126971389),\n",
      "                     np.float64(0.8054343972866017),\n",
      "                     np.float64(0.8063771626325651),\n",
      "                     np.float64(0.8077277268385376),\n",
      "                     np.float64(0.8061404501253685),\n",
      "                     np.float64(0.8059232195126537)]]}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Current SetUp (Deprecated)"
   ],
   "metadata": {
    "id": "neW2rBtSL-xn",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "np.unique(label_binary)"
   ],
   "metadata": {
    "id": "9Mkr7UCVM9Pn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "## GOT HERE!!!!\n",
    "\n",
    "signal_model_results, trained_models = train_and_evaluate(simple_models_dict, X=signal_data_vec, y=label_multi, epochs=10,\n",
    "                                                           dir_name=\"signal_multi\")\n",
    "\n",
    "basePath = \"/content/drive/MyDrive/Colab Notebooks/Bachelor Thesis/Data/Model Comparisons/\"\n",
    "filePath = f\"{basePath}/Signal_Multi_Model_Results.json\"\n",
    "\n",
    "with open(filePath, 'w') as f:\n",
    "        json.dump(signal_model_results, f, indent=4)  # indent=4 for pretty formatting"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4vx9R9KHuZ4x",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738694622275,
     "user_tz": -60,
     "elapsed": 1141725,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     }
    },
    "outputId": "cdcad025-adaf-4697-ac2e-502b5e85ff26",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 1\n",
      "Epoch 1/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.4631 - loss: 1.4171\n",
      "Epoch 1 - MCC: 0.2942\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 30ms/step - accuracy: 0.4644 - loss: 1.4139 - val_accuracy: 0.5936 - val_loss: 1.0309 - mcc: 0.2942\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.6458 - loss: 0.9835\n",
      "Epoch 2 - MCC: 0.5506\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 17ms/step - accuracy: 0.6462 - loss: 0.9827 - val_accuracy: 0.7244 - val_loss: 0.8133 - mcc: 0.5506\n",
      "Epoch 3/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7194 - loss: 0.8193\n",
      "Epoch 3 - MCC: 0.5896\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.7195 - loss: 0.8188 - val_accuracy: 0.7436 - val_loss: 0.7645 - mcc: 0.5896\n",
      "Epoch 4/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.7352 - loss: 0.7733\n",
      "Epoch 4 - MCC: 0.6064\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.7353 - loss: 0.7732 - val_accuracy: 0.7541 - val_loss: 0.6971 - mcc: 0.6064\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7434 - loss: 0.7380\n",
      "Epoch 5 - MCC: 0.6213\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.7435 - loss: 0.7379 - val_accuracy: 0.7633 - val_loss: 0.6939 - mcc: 0.6213\n",
      "Epoch 6/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7635 - loss: 0.6808\n",
      "Epoch 6 - MCC: 0.6468\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.7636 - loss: 0.6805 - val_accuracy: 0.7775 - val_loss: 0.6316 - mcc: 0.6468\n",
      "Epoch 7/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.7726 - loss: 0.6531\n",
      "Epoch 7 - MCC: 0.6582\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 21ms/step - accuracy: 0.7727 - loss: 0.6528 - val_accuracy: 0.7844 - val_loss: 0.6210 - mcc: 0.6582\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7602 - loss: 0.6855\n",
      "Epoch 8 - MCC: 0.6623\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.7603 - loss: 0.6854 - val_accuracy: 0.7883 - val_loss: 0.6128 - mcc: 0.6623\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7823 - loss: 0.6208\n",
      "Epoch 9 - MCC: 0.6483\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 17ms/step - accuracy: 0.7822 - loss: 0.6210 - val_accuracy: 0.7782 - val_loss: 0.6098 - mcc: 0.6483\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.7702 - loss: 0.6364\n",
      "Epoch 10 - MCC: 0.6130\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 17ms/step - accuracy: 0.7701 - loss: 0.6366 - val_accuracy: 0.7583 - val_loss: 0.6950 - mcc: 0.6130\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 2\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.5011 - loss: 1.3907\n",
      "Epoch 1 - MCC: 0.2531\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 28ms/step - accuracy: 0.5016 - loss: 1.3890 - val_accuracy: 0.5779 - val_loss: 1.0559 - mcc: 0.2531\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6286 - loss: 0.9808\n",
      "Epoch 2 - MCC: 0.5454\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.6291 - loss: 0.9801 - val_accuracy: 0.7209 - val_loss: 0.8381 - mcc: 0.5454\n",
      "Epoch 3/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7217 - loss: 0.8015\n",
      "Epoch 3 - MCC: 0.5889\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.7219 - loss: 0.8010 - val_accuracy: 0.7427 - val_loss: 0.7309 - mcc: 0.5889\n",
      "Epoch 4/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.7335 - loss: 0.7622\n",
      "Epoch 4 - MCC: 0.6204\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.7336 - loss: 0.7622 - val_accuracy: 0.7642 - val_loss: 0.6856 - mcc: 0.6204\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7614 - loss: 0.6973\n",
      "Epoch 5 - MCC: 0.6348\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.7613 - loss: 0.6973 - val_accuracy: 0.7715 - val_loss: 0.6603 - mcc: 0.6348\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7640 - loss: 0.6744\n",
      "Epoch 6 - MCC: 0.6419\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 17ms/step - accuracy: 0.7640 - loss: 0.6743 - val_accuracy: 0.7757 - val_loss: 0.6391 - mcc: 0.6419\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7640 - loss: 0.6674\n",
      "Epoch 7 - MCC: 0.6332\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 21ms/step - accuracy: 0.7640 - loss: 0.6675 - val_accuracy: 0.7689 - val_loss: 0.6647 - mcc: 0.6332\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.7605 - loss: 0.6866\n",
      "Epoch 8 - MCC: 0.6576\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 25ms/step - accuracy: 0.7605 - loss: 0.6865 - val_accuracy: 0.7856 - val_loss: 0.6132 - mcc: 0.6576\n",
      "Epoch 9/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.7648 - loss: 0.6652\n",
      "Epoch 9 - MCC: 0.6615\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.7647 - loss: 0.6656 - val_accuracy: 0.7875 - val_loss: 0.6235 - mcc: 0.6615\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.7720 - loss: 0.6601\n",
      "Epoch 10 - MCC: 0.5664\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 25ms/step - accuracy: 0.7719 - loss: 0.6602 - val_accuracy: 0.7231 - val_loss: 0.7793 - mcc: 0.5664\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 3\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.4677 - loss: 1.3863\n",
      "Epoch 1 - MCC: 0.2289\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.4681 - loss: 1.3854 - val_accuracy: 0.5625 - val_loss: 1.0667 - mcc: 0.2289\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6068 - loss: 1.0210\n",
      "Epoch 2 - MCC: 0.4761\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 27ms/step - accuracy: 0.6073 - loss: 1.0202 - val_accuracy: 0.6780 - val_loss: 0.8697 - mcc: 0.4761\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.6978 - loss: 0.8358\n",
      "Epoch 3 - MCC: 0.5454\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.6979 - loss: 0.8356 - val_accuracy: 0.7188 - val_loss: 0.7709 - mcc: 0.5454\n",
      "Epoch 4/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6990 - loss: 0.8611\n",
      "Epoch 4 - MCC: 0.5797\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.6991 - loss: 0.8608 - val_accuracy: 0.7393 - val_loss: 0.7510 - mcc: 0.5797\n",
      "Epoch 5/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7489 - loss: 0.7295\n",
      "Epoch 5 - MCC: 0.6017\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 17ms/step - accuracy: 0.7488 - loss: 0.7295 - val_accuracy: 0.7519 - val_loss: 0.7021 - mcc: 0.6017\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7357 - loss: 0.7643\n",
      "Epoch 6 - MCC: 0.5951\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 25ms/step - accuracy: 0.7356 - loss: 0.7646 - val_accuracy: 0.7487 - val_loss: 0.7195 - mcc: 0.5951\n",
      "Epoch 7/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.7253 - loss: 0.7772\n",
      "Epoch 7 - MCC: 0.6038\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.7255 - loss: 0.7768 - val_accuracy: 0.7530 - val_loss: 0.7152 - mcc: 0.6038\n",
      "Epoch 8/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7589 - loss: 0.6977\n",
      "Epoch 8 - MCC: 0.6285\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.7590 - loss: 0.6975 - val_accuracy: 0.7675 - val_loss: 0.6722 - mcc: 0.6285\n",
      "Epoch 9/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.7718 - loss: 0.6623\n",
      "Epoch 9 - MCC: 0.6399\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 24ms/step - accuracy: 0.7719 - loss: 0.6622 - val_accuracy: 0.7744 - val_loss: 0.6521 - mcc: 0.6399\n",
      "Epoch 10/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.7760 - loss: 0.6423\n",
      "Epoch 10 - MCC: 0.6496\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 22ms/step - accuracy: 0.7761 - loss: 0.6421 - val_accuracy: 0.7796 - val_loss: 0.6278 - mcc: 0.6496\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 4\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.4734 - loss: 1.3931\n",
      "Epoch 1 - MCC: 0.2076\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.4741 - loss: 1.3913 - val_accuracy: 0.5543 - val_loss: 1.1194 - mcc: 0.2076\n",
      "Epoch 2/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.6248 - loss: 1.0125\n",
      "Epoch 2 - MCC: 0.4649\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 25ms/step - accuracy: 0.6254 - loss: 1.0111 - val_accuracy: 0.6635 - val_loss: 0.8860 - mcc: 0.4649\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6902 - loss: 0.8359\n",
      "Epoch 3 - MCC: 0.5262\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.6903 - loss: 0.8360 - val_accuracy: 0.7063 - val_loss: 0.8395 - mcc: 0.5262\n",
      "Epoch 4/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7227 - loss: 0.7906\n",
      "Epoch 4 - MCC: 0.5374\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 17ms/step - accuracy: 0.7228 - loss: 0.7904 - val_accuracy: 0.7079 - val_loss: 0.8223 - mcc: 0.5374\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7242 - loss: 0.8011\n",
      "Epoch 5 - MCC: 0.5844\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 21ms/step - accuracy: 0.7242 - loss: 0.8011 - val_accuracy: 0.7397 - val_loss: 0.7506 - mcc: 0.5844\n",
      "Epoch 6/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7523 - loss: 0.7107\n",
      "Epoch 6 - MCC: 0.6048\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.7523 - loss: 0.7105 - val_accuracy: 0.7504 - val_loss: 0.6902 - mcc: 0.6048\n",
      "Epoch 7/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7587 - loss: 0.6710\n",
      "Epoch 7 - MCC: 0.6291\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.7587 - loss: 0.6709 - val_accuracy: 0.7644 - val_loss: 0.6501 - mcc: 0.6291\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7721 - loss: 0.6344\n",
      "Epoch 8 - MCC: 0.6092\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.7721 - loss: 0.6344 - val_accuracy: 0.7532 - val_loss: 0.7122 - mcc: 0.6092\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.7658 - loss: 0.6645\n",
      "Epoch 9 - MCC: 0.6597\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.7660 - loss: 0.6641 - val_accuracy: 0.7844 - val_loss: 0.6124 - mcc: 0.6597\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7261 - loss: 0.7916\n",
      "Epoch 10 - MCC: 0.5722\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 17ms/step - accuracy: 0.7260 - loss: 0.7918 - val_accuracy: 0.7334 - val_loss: 0.7500 - mcc: 0.5722\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 5\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.4718 - loss: 1.4114\n",
      "Epoch 1 - MCC: 0.2117\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.4725 - loss: 1.4096 - val_accuracy: 0.5601 - val_loss: 1.1209 - mcc: 0.2117\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.5971 - loss: 1.0458\n",
      "Epoch 2 - MCC: 0.5285\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 25ms/step - accuracy: 0.5974 - loss: 1.0454 - val_accuracy: 0.7045 - val_loss: 0.8647 - mcc: 0.5285\n",
      "Epoch 3/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7295 - loss: 0.7867\n",
      "Epoch 3 - MCC: 0.4541\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.7296 - loss: 0.7865 - val_accuracy: 0.6547 - val_loss: 1.0092 - mcc: 0.4541\n",
      "Epoch 4/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7059 - loss: 0.8423\n",
      "Epoch 4 - MCC: 0.6070\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.7062 - loss: 0.8411 - val_accuracy: 0.7537 - val_loss: 0.7028 - mcc: 0.6070\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.7500 - loss: 0.7197\n",
      "Epoch 5 - MCC: 0.6156\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 25ms/step - accuracy: 0.7500 - loss: 0.7196 - val_accuracy: 0.7583 - val_loss: 0.6806 - mcc: 0.6156\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7663 - loss: 0.6567\n",
      "Epoch 6 - MCC: 0.6296\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.7663 - loss: 0.6568 - val_accuracy: 0.7664 - val_loss: 0.6506 - mcc: 0.6296\n",
      "Epoch 7/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7517 - loss: 0.7039\n",
      "Epoch 7 - MCC: 0.6191\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.7515 - loss: 0.7048 - val_accuracy: 0.7601 - val_loss: 0.6819 - mcc: 0.6191\n",
      "Epoch 8/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7682 - loss: 0.6500\n",
      "Epoch 8 - MCC: 0.6431\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 17ms/step - accuracy: 0.7682 - loss: 0.6501 - val_accuracy: 0.7746 - val_loss: 0.6360 - mcc: 0.6431\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.7830 - loss: 0.6110\n",
      "Epoch 9 - MCC: 0.6609\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 20ms/step - accuracy: 0.7830 - loss: 0.6110 - val_accuracy: 0.7854 - val_loss: 0.6081 - mcc: 0.6609\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7873 - loss: 0.5910\n",
      "Epoch 10 - MCC: 0.6627\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.7873 - loss: 0.5910 - val_accuracy: 0.7862 - val_loss: 0.6042 - mcc: 0.6627\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': 0.7861766666666666,\n",
      "              'mean': 0.7561133333333332,\n",
      "              'min': 0.7230666666666666,\n",
      "              'std': 0.024778238929440578},\n",
      " 'Inference Time (s/sample)': {'max': 0.0005929271380106608,\n",
      "                               'mean': 0.0005414422353108724,\n",
      "                               'min': 0.0003451772530873617,\n",
      "                               'std': 9.814385971129209e-05},\n",
      " 'MCC': {'max': 0.6627097946257398,\n",
      "         'mean': 0.6127771038357984,\n",
      "         'min': 0.5663790640066816,\n",
      "         'std': 0.03909940859892811},\n",
      " 'Parameters': 4517,\n",
      " 'Train Time (s)': {'max': 45.208189725875854,\n",
      "                    'mean': 42.44419560432434,\n",
      "                    'min': 40.08367991447449,\n",
      "                    'std': 1.8084549294040417},\n",
      " 'Training Accuracy': [[0.5278066992759705,\n",
      "                        0.6755423545837402,\n",
      "                        0.7258027195930481,\n",
      "                        0.740182638168335,\n",
      "                        0.7499157786369324,\n",
      "                        0.7696298360824585,\n",
      "                        0.7795016765594482,\n",
      "                        0.7664741277694702,\n",
      "                        0.7749173045158386,\n",
      "                        0.7672048807144165],\n",
      "                       [0.5332900881767273,\n",
      "                        0.6640207171440125,\n",
      "                        0.7295008897781372,\n",
      "                        0.7370158433914185,\n",
      "                        0.755852460861206,\n",
      "                        0.7657117247581482,\n",
      "                        0.7641825079917908,\n",
      "                        0.7630676031112671,\n",
      "                        0.7594117522239685,\n",
      "                        0.7612800598144531],\n",
      "                       [0.5295684337615967,\n",
      "                        0.6420749425888062,\n",
      "                        0.7068449854850769,\n",
      "                        0.708096444606781,\n",
      "                        0.7458834052085876,\n",
      "                        0.7277073860168457,\n",
      "                        0.7342633605003357,\n",
      "                        0.7640999555587769,\n",
      "                        0.7739001512527466,\n",
      "                        0.7808090448379517],\n",
      "                       [0.5265058279037476,\n",
      "                        0.6537133455276489,\n",
      "                        0.6920232176780701,\n",
      "                        0.7238268256187439,\n",
      "                        0.7262590527534485,\n",
      "                        0.7534958124160767,\n",
      "                        0.761798620223999,\n",
      "                        0.7709873914718628,\n",
      "                        0.7761015892028809,\n",
      "                        0.7176832556724548],\n",
      "                       [0.52656090259552,\n",
      "                        0.6402700543403625,\n",
      "                        0.7296916246414185,\n",
      "                        0.7256225347518921,\n",
      "                        0.7504615783691406,\n",
      "                        0.7626375555992126,\n",
      "                        0.7382791042327881,\n",
      "                        0.7667283415794373,\n",
      "                        0.7835047841072083,\n",
      "                        0.7882314920425415]],\n",
      " 'Training Loss': [[1.2557591199874878,\n",
      "                    0.9222363233566284,\n",
      "                    0.7965505719184875,\n",
      "                    0.7525506615638733,\n",
      "                    0.7215439081192017,\n",
      "                    0.6631454229354858,\n",
      "                    0.6399152278900146,\n",
      "                    0.6734832525253296,\n",
      "                    0.6366637945175171,\n",
      "                    0.6526037454605103],\n",
      "                   [1.257391095161438,\n",
      "                    0.9248665571212769,\n",
      "                    0.7824102640151978,\n",
      "                    0.7587100863456726,\n",
      "                    0.7026559710502625,\n",
      "                    0.6652012467384338,\n",
      "                    0.674807071685791,\n",
      "                    0.6788524985313416,\n",
      "                    0.6864769458770752,\n",
      "                    0.6833522319793701],\n",
      "                   [1.2415599822998047,\n",
      "                    0.9632151126861572,\n",
      "                    0.8219487071037292,\n",
      "                    0.826158881187439,\n",
      "                    0.7291925549507141,\n",
      "                    0.7884226441383362,\n",
      "                    0.7605195045471191,\n",
      "                    0.6853538751602173,\n",
      "                    0.6554137468338013,\n",
      "                    0.6331812739372253],\n",
      "                   [1.2624927759170532,\n",
      "                    0.9451624751091003,\n",
      "                    0.8485048413276672,\n",
      "                    0.7791293859481812,\n",
      "                    0.8004795908927917,\n",
      "                    0.7001847624778748,\n",
      "                    0.6644121408462524,\n",
      "                    0.6449185609817505,\n",
      "                    0.6344737410545349,\n",
      "                    0.8096890449523926],\n",
      "                   [1.2794402837753296,\n",
      "                    0.9772294163703918,\n",
      "                    0.7770807147026062,\n",
      "                    0.7826318740844727,\n",
      "                    0.7147406935691833,\n",
      "                    0.668057382106781,\n",
      "                    0.7472910284996033,\n",
      "                    0.6534196138381958,\n",
      "                    0.6087858080863953,\n",
      "                    0.5911426544189453]],\n",
      " 'Validation Accuracy': [[0.593603253364563,\n",
      "                          0.7244067192077637,\n",
      "                          0.7436167001724243,\n",
      "                          0.7540965676307678,\n",
      "                          0.763283371925354,\n",
      "                          0.7774566411972046,\n",
      "                          0.7843700647354126,\n",
      "                          0.7882532477378845,\n",
      "                          0.7781934142112732,\n",
      "                          0.7583165764808655],\n",
      "                         [0.5779466032981873,\n",
      "                          0.7208966612815857,\n",
      "                          0.7427399158477783,\n",
      "                          0.7642399668693542,\n",
      "                          0.7715067863464355,\n",
      "                          0.7757499814033508,\n",
      "                          0.7688600420951843,\n",
      "                          0.7855833172798157,\n",
      "                          0.7875466346740723,\n",
      "                          0.7230666875839233],\n",
      "                         [0.5624699592590332,\n",
      "                          0.6779998540878296,\n",
      "                          0.7188166379928589,\n",
      "                          0.7393332719802856,\n",
      "                          0.7519434690475464,\n",
      "                          0.7487465739250183,\n",
      "                          0.7530099749565125,\n",
      "                          0.7675066590309143,\n",
      "                          0.7743966579437256,\n",
      "                          0.7796199917793274],\n",
      "                         [0.5542833209037781,\n",
      "                          0.6635499596595764,\n",
      "                          0.7062765955924988,\n",
      "                          0.7079033851623535,\n",
      "                          0.7396834492683411,\n",
      "                          0.7503833174705505,\n",
      "                          0.764403223991394,\n",
      "                          0.7531799077987671,\n",
      "                          0.7844365239143372,\n",
      "                          0.7333866953849792],\n",
      "                         [0.560143232345581,\n",
      "                          0.704516589641571,\n",
      "                          0.6547265648841858,\n",
      "                          0.7537000179290771,\n",
      "                          0.7583099603652954,\n",
      "                          0.7663599252700806,\n",
      "                          0.7600732445716858,\n",
      "                          0.7746200561523438,\n",
      "                          0.7853533625602722,\n",
      "                          0.7861766815185547]],\n",
      " 'Validation Loss': [1.1209170818328857,\n",
      "                     0.8646952509880066,\n",
      "                     1.0092257261276245,\n",
      "                     0.7027963399887085,\n",
      "                     0.6806101202964783,\n",
      "                     0.6505881547927856,\n",
      "                     0.6819235682487488,\n",
      "                     0.6360336542129517,\n",
      "                     0.6081163287162781,\n",
      "                     0.6042394638061523],\n",
      " 'Validation MCC': [[0.294208951545592,\n",
      "                     0.5505916016860738,\n",
      "                     0.5896406998345424,\n",
      "                     0.6064038948637738,\n",
      "                     0.6212670034627327,\n",
      "                     0.6467918520919717,\n",
      "                     0.6582437087622215,\n",
      "                     0.6622756596345604,\n",
      "                     0.6483493792550066,\n",
      "                     0.6129854623170796],\n",
      "                    [0.253080467108933,\n",
      "                     0.5454419786953011,\n",
      "                     0.5888688829042672,\n",
      "                     0.620386854876455,\n",
      "                     0.6348114163859884,\n",
      "                     0.6418675170009384,\n",
      "                     0.6331573821130061,\n",
      "                     0.6575556133417956,\n",
      "                     0.6615480853318414,\n",
      "                     0.5663790640066816],\n",
      "                    [0.22893304360771544,\n",
      "                     0.4760997699319887,\n",
      "                     0.5453796167460976,\n",
      "                     0.5796639568915565,\n",
      "                     0.6017123743370347,\n",
      "                     0.5951000546569883,\n",
      "                     0.603759941602103,\n",
      "                     0.6284528887245037,\n",
      "                     0.6399016067534666,\n",
      "                     0.6495754748665687],\n",
      "                    [0.20758351998306232,\n",
      "                     0.46492935711638367,\n",
      "                     0.5262320516023876,\n",
      "                     0.5374070335656579,\n",
      "                     0.5844247083898706,\n",
      "                     0.6047605968666241,\n",
      "                     0.629149536845984,\n",
      "                     0.6092149664973084,\n",
      "                     0.6597422493932129,\n",
      "                     0.5722357233629223],\n",
      "                    [0.21174229780455064,\n",
      "                     0.5285132567488431,\n",
      "                     0.4541054087353223,\n",
      "                     0.6069933283273667,\n",
      "                     0.6155981725101931,\n",
      "                     0.6295583478622445,\n",
      "                     0.6190809240218261,\n",
      "                     0.6431346799222045,\n",
      "                     0.6609097502100876,\n",
      "                     0.6627097946257398]]}\n",
      "Training Model: BiLSTM, Fold: 1\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.4697 - loss: 1.3891\n",
      "Epoch 1 - MCC: 0.2741\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 44ms/step - accuracy: 0.4705 - loss: 1.3868 - val_accuracy: 0.5846 - val_loss: 0.9675 - mcc: 0.2741\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.6597 - loss: 0.8814\n",
      "Epoch 2 - MCC: 0.6123\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.6600 - loss: 0.8810 - val_accuracy: 0.7589 - val_loss: 0.6909 - mcc: 0.6123\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.6922 - loss: 0.8504\n",
      "Epoch 3 - MCC: 0.6194\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 41ms/step - accuracy: 0.6923 - loss: 0.8501 - val_accuracy: 0.7633 - val_loss: 0.6919 - mcc: 0.6194\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7674 - loss: 0.6750\n",
      "Epoch 4 - MCC: 0.6771\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 31ms/step - accuracy: 0.7675 - loss: 0.6748 - val_accuracy: 0.7969 - val_loss: 0.6061 - mcc: 0.6771\n",
      "Epoch 5/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.7927 - loss: 0.6036\n",
      "Epoch 5 - MCC: 0.7021\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 40ms/step - accuracy: 0.7928 - loss: 0.6033 - val_accuracy: 0.8114 - val_loss: 0.5438 - mcc: 0.7021\n",
      "Epoch 6/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8100 - loss: 0.5479\n",
      "Epoch 6 - MCC: 0.7231\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 35ms/step - accuracy: 0.8100 - loss: 0.5479 - val_accuracy: 0.8248 - val_loss: 0.5128 - mcc: 0.7231\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8187 - loss: 0.5233\n",
      "Epoch 7 - MCC: 0.7405\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.8187 - loss: 0.5233 - val_accuracy: 0.8353 - val_loss: 0.4841 - mcc: 0.7405\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8117 - loss: 0.5367\n",
      "Epoch 8 - MCC: 0.7289\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 42ms/step - accuracy: 0.8118 - loss: 0.5366 - val_accuracy: 0.8273 - val_loss: 0.4904 - mcc: 0.7289\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8313 - loss: 0.4814\n",
      "Epoch 9 - MCC: 0.7510\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 32ms/step - accuracy: 0.8313 - loss: 0.4814 - val_accuracy: 0.8420 - val_loss: 0.4593 - mcc: 0.7510\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.8336 - loss: 0.4718\n",
      "Epoch 10 - MCC: 0.7394\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.8335 - loss: 0.4720 - val_accuracy: 0.8342 - val_loss: 0.4784 - mcc: 0.7394\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 2\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.4939 - loss: 1.3977\n",
      "Epoch 1 - MCC: 0.2614\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.4942 - loss: 1.3967 - val_accuracy: 0.5804 - val_loss: 1.0003 - mcc: 0.2614\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.6429 - loss: 0.9111\n",
      "Epoch 2 - MCC: 0.6003\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.6432 - loss: 0.9105 - val_accuracy: 0.7500 - val_loss: 0.6818 - mcc: 0.6003\n",
      "Epoch 3/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.7611 - loss: 0.6481\n",
      "Epoch 3 - MCC: 0.6803\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 31ms/step - accuracy: 0.7613 - loss: 0.6479 - val_accuracy: 0.7995 - val_loss: 0.5637 - mcc: 0.6803\n",
      "Epoch 4/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.7963 - loss: 0.5702\n",
      "Epoch 4 - MCC: 0.7157\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 38ms/step - accuracy: 0.7964 - loss: 0.5701 - val_accuracy: 0.8186 - val_loss: 0.5000 - mcc: 0.7157\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8166 - loss: 0.5154\n",
      "Epoch 5 - MCC: 0.7300\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8166 - loss: 0.5152 - val_accuracy: 0.8291 - val_loss: 0.4650 - mcc: 0.7300\n",
      "Epoch 6/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8335 - loss: 0.4613\n",
      "Epoch 6 - MCC: 0.7380\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 31ms/step - accuracy: 0.8335 - loss: 0.4614 - val_accuracy: 0.8324 - val_loss: 0.4575 - mcc: 0.7380\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8378 - loss: 0.4521\n",
      "Epoch 7 - MCC: 0.7589\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 42ms/step - accuracy: 0.8379 - loss: 0.4520 - val_accuracy: 0.8467 - val_loss: 0.4200 - mcc: 0.7589\n",
      "Epoch 8/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8460 - loss: 0.4310\n",
      "Epoch 8 - MCC: 0.7757\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 32ms/step - accuracy: 0.8460 - loss: 0.4310 - val_accuracy: 0.8574 - val_loss: 0.4016 - mcc: 0.7757\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.8526 - loss: 0.4180\n",
      "Epoch 9 - MCC: 0.7762\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 41ms/step - accuracy: 0.8526 - loss: 0.4180 - val_accuracy: 0.8576 - val_loss: 0.3910 - mcc: 0.7762\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8574 - loss: 0.3993\n",
      "Epoch 10 - MCC: 0.7805\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 31ms/step - accuracy: 0.8574 - loss: 0.3993 - val_accuracy: 0.8599 - val_loss: 0.3860 - mcc: 0.7805\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 3\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.4747 - loss: 1.3921\n",
      "Epoch 1 - MCC: 0.3781\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 45ms/step - accuracy: 0.4755 - loss: 1.3897 - val_accuracy: 0.6294 - val_loss: 0.9252 - mcc: 0.3781\n",
      "Epoch 2/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.6952 - loss: 0.8322\n",
      "Epoch 2 - MCC: 0.6379\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 33ms/step - accuracy: 0.6959 - loss: 0.8309 - val_accuracy: 0.7738 - val_loss: 0.6508 - mcc: 0.6379\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.7904 - loss: 0.6131\n",
      "Epoch 3 - MCC: 0.6857\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.7904 - loss: 0.6130 - val_accuracy: 0.8009 - val_loss: 0.5610 - mcc: 0.6857\n",
      "Epoch 4/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8118 - loss: 0.5377\n",
      "Epoch 4 - MCC: 0.7111\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 31ms/step - accuracy: 0.8118 - loss: 0.5377 - val_accuracy: 0.8168 - val_loss: 0.5152 - mcc: 0.7111\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8241 - loss: 0.4947\n",
      "Epoch 5 - MCC: 0.7287\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 41ms/step - accuracy: 0.8241 - loss: 0.4947 - val_accuracy: 0.8273 - val_loss: 0.4833 - mcc: 0.7287\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8351 - loss: 0.4581\n",
      "Epoch 6 - MCC: 0.7533\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.8351 - loss: 0.4580 - val_accuracy: 0.8432 - val_loss: 0.4391 - mcc: 0.7533\n",
      "Epoch 7/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8438 - loss: 0.4383\n",
      "Epoch 7 - MCC: 0.7041\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.8437 - loss: 0.4387 - val_accuracy: 0.8133 - val_loss: 0.5043 - mcc: 0.7041\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.8361 - loss: 0.4537\n",
      "Epoch 8 - MCC: 0.7497\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.8361 - loss: 0.4536 - val_accuracy: 0.8402 - val_loss: 0.4402 - mcc: 0.7497\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8496 - loss: 0.4221\n",
      "Epoch 9 - MCC: 0.7683\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 34ms/step - accuracy: 0.8497 - loss: 0.4219 - val_accuracy: 0.8521 - val_loss: 0.4067 - mcc: 0.7683\n",
      "Epoch 10/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.8492 - loss: 0.4210\n",
      "Epoch 10 - MCC: 0.7769\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 47ms/step - accuracy: 0.8494 - loss: 0.4205 - val_accuracy: 0.8573 - val_loss: 0.3908 - mcc: 0.7769\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 4\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.4836 - loss: 1.3833\n",
      "Epoch 1 - MCC: 0.2762\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.4840 - loss: 1.3821 - val_accuracy: 0.5775 - val_loss: 0.9775 - mcc: 0.2762\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.6596 - loss: 0.8801\n",
      "Epoch 2 - MCC: 0.5996\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.6601 - loss: 0.8792 - val_accuracy: 0.7466 - val_loss: 0.7053 - mcc: 0.5996\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.7648 - loss: 0.6625\n",
      "Epoch 3 - MCC: 0.6748\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.7649 - loss: 0.6622 - val_accuracy: 0.7914 - val_loss: 0.5841 - mcc: 0.6748\n",
      "Epoch 4/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8020 - loss: 0.5565\n",
      "Epoch 4 - MCC: 0.7017\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.8020 - loss: 0.5565 - val_accuracy: 0.8098 - val_loss: 0.5431 - mcc: 0.7017\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8182 - loss: 0.5142\n",
      "Epoch 5 - MCC: 0.7252\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8182 - loss: 0.5142 - val_accuracy: 0.8236 - val_loss: 0.4968 - mcc: 0.7252\n",
      "Epoch 6/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8276 - loss: 0.4844\n",
      "Epoch 6 - MCC: 0.6988\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 41ms/step - accuracy: 0.8276 - loss: 0.4845 - val_accuracy: 0.8071 - val_loss: 0.5416 - mcc: 0.6988\n",
      "Epoch 7/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8334 - loss: 0.4682\n",
      "Epoch 7 - MCC: 0.7624\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.8335 - loss: 0.4679 - val_accuracy: 0.8470 - val_loss: 0.4387 - mcc: 0.7624\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8503 - loss: 0.4214\n",
      "Epoch 8 - MCC: 0.7631\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 31ms/step - accuracy: 0.8503 - loss: 0.4214 - val_accuracy: 0.8470 - val_loss: 0.4308 - mcc: 0.7631\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.8465 - loss: 0.4296\n",
      "Epoch 9 - MCC: 0.7687\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 41ms/step - accuracy: 0.8465 - loss: 0.4295 - val_accuracy: 0.8509 - val_loss: 0.4150 - mcc: 0.7687\n",
      "Epoch 10/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8495 - loss: 0.4189\n",
      "Epoch 10 - MCC: 0.7697\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.8496 - loss: 0.4188 - val_accuracy: 0.8510 - val_loss: 0.4129 - mcc: 0.7697\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 5\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.4921 - loss: 1.3810\n",
      "Epoch 1 - MCC: 0.4331\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 45ms/step - accuracy: 0.4928 - loss: 1.3786 - val_accuracy: 0.6582 - val_loss: 0.9527 - mcc: 0.4331\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.6847 - loss: 0.8905\n",
      "Epoch 2 - MCC: 0.6163\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 31ms/step - accuracy: 0.6848 - loss: 0.8902 - val_accuracy: 0.7577 - val_loss: 0.7409 - mcc: 0.6163\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.7753 - loss: 0.6567\n",
      "Epoch 3 - MCC: 0.6886\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.7753 - loss: 0.6564 - val_accuracy: 0.8025 - val_loss: 0.5577 - mcc: 0.6886\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8148 - loss: 0.5292\n",
      "Epoch 4 - MCC: 0.7289\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 33ms/step - accuracy: 0.8149 - loss: 0.5289 - val_accuracy: 0.8273 - val_loss: 0.4897 - mcc: 0.7289\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8310 - loss: 0.4774\n",
      "Epoch 5 - MCC: 0.7487\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 40ms/step - accuracy: 0.8311 - loss: 0.4774 - val_accuracy: 0.8395 - val_loss: 0.4598 - mcc: 0.7487\n",
      "Epoch 6/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8341 - loss: 0.4664\n",
      "Epoch 6 - MCC: 0.7550\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 31ms/step - accuracy: 0.8341 - loss: 0.4664 - val_accuracy: 0.8430 - val_loss: 0.4486 - mcc: 0.7550\n",
      "Epoch 7/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.8490 - loss: 0.4278\n",
      "Epoch 7 - MCC: 0.7616\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 52ms/step - accuracy: 0.8490 - loss: 0.4278 - val_accuracy: 0.8472 - val_loss: 0.4332 - mcc: 0.7616\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 53ms/step - accuracy: 0.8540 - loss: 0.4056\n",
      "Epoch 8 - MCC: 0.7645\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 59ms/step - accuracy: 0.8540 - loss: 0.4057 - val_accuracy: 0.8484 - val_loss: 0.4274 - mcc: 0.7645\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8557 - loss: 0.4075\n",
      "Epoch 9 - MCC: 0.7705\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8557 - loss: 0.4075 - val_accuracy: 0.8525 - val_loss: 0.4147 - mcc: 0.7705\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.8311 - loss: 0.4627\n",
      "Epoch 10 - MCC: 0.7650\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.8311 - loss: 0.4626 - val_accuracy: 0.8486 - val_loss: 0.4316 - mcc: 0.7650\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': 0.85989,\n",
      "              'mean': 0.8501966666666668,\n",
      "              'min': 0.8342166666666667,\n",
      "              'std': 0.008981513111819056},\n",
      " 'Inference Time (s/sample)': {'max': 0.0005978775024414062,\n",
      "                               'mean': 0.0005124111970265706,\n",
      "                               'min': 0.0004850129286448161,\n",
      "                               'std': 4.2922010578771725e-05},\n",
      " 'MCC': {'max': 0.7804957953972158,\n",
      "         'mean': 0.7662996137190139,\n",
      "         'min': 0.7394226366710502,\n",
      "         'std': 0.014493577319163942},\n",
      " 'Parameters': 4449,\n",
      " 'Train Time (s)': {'max': 75.00558543205261,\n",
      "                    'mean': 68.41048188209534,\n",
      "                    'min': 60.234431743621826,\n",
      "                    'std': 5.367305369596405},\n",
      " 'Training Accuracy': [[0.5294843316078186,\n",
      "                        0.698073148727417,\n",
      "                        0.7041475176811218,\n",
      "                        0.7714266777038574,\n",
      "                        0.796740710735321,\n",
      "                        0.8096017241477966,\n",
      "                        0.8173841834068298,\n",
      "                        0.8177741169929504,\n",
      "                        0.8319200873374939,\n",
      "                        0.8308326005935669],\n",
      "                       [0.5368192195892334,\n",
      "                        0.6848423480987549,\n",
      "                        0.769710898399353,\n",
      "                        0.8072559833526611,\n",
      "                        0.8234899640083313,\n",
      "                        0.8322818279266357,\n",
      "                        0.840273380279541,\n",
      "                        0.8466118574142456,\n",
      "                        0.8531558513641357,\n",
      "                        0.8577916622161865],\n",
      "                       [0.5384608507156372,\n",
      "                        0.7287085652351379,\n",
      "                        0.7927050590515137,\n",
      "                        0.8136758208274841,\n",
      "                        0.8276167511940002,\n",
      "                        0.8365357518196106,\n",
      "                        0.8374666571617126,\n",
      "                        0.8385050892829895,\n",
      "                        0.8526182770729065,\n",
      "                        0.8575791716575623],\n",
      "                       [0.5413722991943359,\n",
      "                        0.6987324357032776,\n",
      "                        0.7765493988990784,\n",
      "                        0.8000367283821106,\n",
      "                        0.8175257444381714,\n",
      "                        0.8258065581321716,\n",
      "                        0.8405033946037292,\n",
      "                        0.8467164635658264,\n",
      "                        0.8494759202003479,\n",
      "                        0.8526692390441895],\n",
      "                       [0.5479958653450012,\n",
      "                        0.7060024738311768,\n",
      "                        0.785801112651825,\n",
      "                        0.8226191997528076,\n",
      "                        0.8317535519599915,\n",
      "                        0.8367775082588196,\n",
      "                        0.8474215865135193,\n",
      "                        0.8520781397819519,\n",
      "                        0.8568772673606873,\n",
      "                        0.838481605052948]],\n",
      " 'Training Loss': [[1.2199113368988037,\n",
      "                    0.8238953948020935,\n",
      "                    0.8140604496002197,\n",
      "                    0.6612575650215149,\n",
      "                    0.5891269445419312,\n",
      "                    0.5489311814308167,\n",
      "                    0.5243109464645386,\n",
      "                    0.5257427096366882,\n",
      "                    0.4822337329387665,\n",
      "                    0.4812788963317871],\n",
      "                   [1.2414898872375488,\n",
      "                    0.8262017369270325,\n",
      "                    0.6382282376289368,\n",
      "                    0.5461052060127258,\n",
      "                    0.4916713535785675,\n",
      "                    0.4652392566204071,\n",
      "                    0.4433217942714691,\n",
      "                    0.4317665100097656,\n",
      "                    0.41275760531425476,\n",
      "                    0.39737385511398315],\n",
      "                   [1.2090516090393066,\n",
      "                    0.7668094635009766,\n",
      "                    0.5977632403373718,\n",
      "                    0.5293393731117249,\n",
      "                    0.4845670461654663,\n",
      "                    0.4557161331176758,\n",
      "                    0.45555394887924194,\n",
      "                    0.4468284547328949,\n",
      "                    0.4110006093978882,\n",
      "                    0.3982834815979004],\n",
      "                   [1.2092006206512451,\n",
      "                    0.8092566728591919,\n",
      "                    0.6265895366668701,\n",
      "                    0.5569955706596375,\n",
      "                    0.5083587765693665,\n",
      "                    0.48907148838043213,\n",
      "                    0.45070698857307434,\n",
      "                    0.42844319343566895,\n",
      "                    0.41941890120506287,\n",
      "                    0.4116961359977722],\n",
      "                   [1.1993167400360107,\n",
      "                    0.8371168375015259,\n",
      "                    0.6186240911483765,\n",
      "                    0.5064057111740112,\n",
      "                    0.47568222880363464,\n",
      "                    0.4636588990688324,\n",
      "                    0.43047550320625305,\n",
      "                    0.4140712022781372,\n",
      "                    0.4044637382030487,\n",
      "                    0.44719985127449036]],\n",
      " 'Validation Accuracy': [[0.5845934152603149,\n",
      "                          0.7589366436004639,\n",
      "                          0.763336718082428,\n",
      "                          0.7968699336051941,\n",
      "                          0.8113899230957031,\n",
      "                          0.824776828289032,\n",
      "                          0.8353099822998047,\n",
      "                          0.8273332715034485,\n",
      "                          0.8419532179832458,\n",
      "                          0.8342167139053345],\n",
      "                         [0.5804300308227539,\n",
      "                          0.7500000596046448,\n",
      "                          0.7995333671569824,\n",
      "                          0.8186066150665283,\n",
      "                          0.8291432857513428,\n",
      "                          0.83243328332901,\n",
      "                          0.8466733694076538,\n",
      "                          0.8574434518814087,\n",
      "                          0.8575600385665894,\n",
      "                          0.8598900437355042],\n",
      "                         [0.6294200420379639,\n",
      "                          0.773796796798706,\n",
      "                          0.8008866906166077,\n",
      "                          0.8167833685874939,\n",
      "                          0.8272632956504822,\n",
      "                          0.8431633114814758,\n",
      "                          0.8132733702659607,\n",
      "                          0.8401667475700378,\n",
      "                          0.8521298766136169,\n",
      "                          0.8573265671730042],\n",
      "                         [0.5774765610694885,\n",
      "                          0.7466099262237549,\n",
      "                          0.7914400100708008,\n",
      "                          0.8097634315490723,\n",
      "                          0.8236099481582642,\n",
      "                          0.8071132302284241,\n",
      "                          0.8469867706298828,\n",
      "                          0.8469633460044861,\n",
      "                          0.8509132266044617,\n",
      "                          0.850963294506073],\n",
      "                         [0.658176600933075,\n",
      "                          0.7576767206192017,\n",
      "                          0.8024633526802063,\n",
      "                          0.8272566199302673,\n",
      "                          0.8395199775695801,\n",
      "                          0.842989981174469,\n",
      "                          0.847226619720459,\n",
      "                          0.8484299778938293,\n",
      "                          0.8524566888809204,\n",
      "                          0.8485866189002991]],\n",
      " 'Validation Loss': [0.9526560306549072,\n",
      "                     0.7409301400184631,\n",
      "                     0.5576527118682861,\n",
      "                     0.4896599352359772,\n",
      "                     0.4598071873188019,\n",
      "                     0.44861018657684326,\n",
      "                     0.43317630887031555,\n",
      "                     0.427406907081604,\n",
      "                     0.4147053360939026,\n",
      "                     0.43160486221313477],\n",
      " 'Validation MCC': [[0.27407766797903893,\n",
      "                     0.6123015650708544,\n",
      "                     0.6193780523013811,\n",
      "                     0.6770539817001564,\n",
      "                     0.7021257306596504,\n",
      "                     0.7231404772416286,\n",
      "                     0.7404523511031763,\n",
      "                     0.7288952726802683,\n",
      "                     0.7510067220761678,\n",
      "                     0.7394226366710502],\n",
      "                    [0.261446154297918,\n",
      "                     0.6002505721664882,\n",
      "                     0.6803370003385263,\n",
      "                     0.7157348553500957,\n",
      "                     0.7300022821335957,\n",
      "                     0.738027270697822,\n",
      "                     0.7588654456919578,\n",
      "                     0.7757490589031284,\n",
      "                     0.7762265896982482,\n",
      "                     0.7804957953972158],\n",
      "                    [0.37810307242720664,\n",
      "                     0.6379430699573023,\n",
      "                     0.6856691920903591,\n",
      "                     0.7111052727007491,\n",
      "                     0.7286984228964252,\n",
      "                     0.7532524617672955,\n",
      "                     0.7040849863858883,\n",
      "                     0.7497148181284262,\n",
      "                     0.7682648702349256,\n",
      "                     0.7769358193701656],\n",
      "                    [0.2761600868286866,\n",
      "                     0.5996003032023909,\n",
      "                     0.6747772104145251,\n",
      "                     0.7017358107716648,\n",
      "                     0.725204457047229,\n",
      "                     0.6988434572653764,\n",
      "                     0.7623731305394577,\n",
      "                     0.7631164623462606,\n",
      "                     0.7686793466652558,\n",
      "                     0.769687960547668],\n",
      "                    [0.43309558165324524,\n",
      "                     0.6162863035523496,\n",
      "                     0.6886226791463861,\n",
      "                     0.7288617957785102,\n",
      "                     0.7487055531763378,\n",
      "                     0.7550197677722769,\n",
      "                     0.7616427121445046,\n",
      "                     0.7644922742542495,\n",
      "                     0.7704738098001068,\n",
      "                     0.7649558566089699]]}\n",
      "Training Model: RNN, Fold: 1\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4951 - loss: 1.2416\n",
      "Epoch 1 - MCC: 0.4314\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 54ms/step - accuracy: 0.4958 - loss: 1.2400 - val_accuracy: 0.6576 - val_loss: 0.9643 - mcc: 0.4314\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.6757 - loss: 0.9130\n",
      "Epoch 2 - MCC: 0.5312\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.6759 - loss: 0.9125 - val_accuracy: 0.7101 - val_loss: 0.8335 - mcc: 0.5312\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7180 - loss: 0.8053\n",
      "Epoch 3 - MCC: 0.5959\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.7181 - loss: 0.8052 - val_accuracy: 0.7488 - val_loss: 0.7373 - mcc: 0.5959\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7441 - loss: 0.7478\n",
      "Epoch 4 - MCC: 0.6090\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 31ms/step - accuracy: 0.7441 - loss: 0.7477 - val_accuracy: 0.7551 - val_loss: 0.7057 - mcc: 0.6090\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7452 - loss: 0.7380\n",
      "Epoch 5 - MCC: 0.6418\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.7452 - loss: 0.7378 - val_accuracy: 0.7741 - val_loss: 0.6615 - mcc: 0.6418\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7620 - loss: 0.6958\n",
      "Epoch 6 - MCC: 0.6502\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.7620 - loss: 0.6957 - val_accuracy: 0.7798 - val_loss: 0.6544 - mcc: 0.6502\n",
      "Epoch 7/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7698 - loss: 0.6757\n",
      "Epoch 7 - MCC: 0.6434\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 32ms/step - accuracy: 0.7698 - loss: 0.6756 - val_accuracy: 0.7755 - val_loss: 0.6452 - mcc: 0.6434\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7760 - loss: 0.6521\n",
      "Epoch 8 - MCC: 0.6621\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.7760 - loss: 0.6521 - val_accuracy: 0.7875 - val_loss: 0.6269 - mcc: 0.6621\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7817 - loss: 0.6391\n",
      "Epoch 9 - MCC: 0.6689\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.7817 - loss: 0.6392 - val_accuracy: 0.7921 - val_loss: 0.6167 - mcc: 0.6689\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7769 - loss: 0.6551\n",
      "Epoch 10 - MCC: 0.6633\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.7770 - loss: 0.6550 - val_accuracy: 0.7875 - val_loss: 0.6207 - mcc: 0.6633\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 2\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4974 - loss: 1.2637\n",
      "Epoch 1 - MCC: 0.4194\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 43ms/step - accuracy: 0.4982 - loss: 1.2618 - val_accuracy: 0.6575 - val_loss: 0.9042 - mcc: 0.4194\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.6758 - loss: 0.8743\n",
      "Epoch 2 - MCC: 0.5536\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.6760 - loss: 0.8740 - val_accuracy: 0.7253 - val_loss: 0.7913 - mcc: 0.5536\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7311 - loss: 0.7904\n",
      "Epoch 3 - MCC: 0.5986\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.7312 - loss: 0.7902 - val_accuracy: 0.7506 - val_loss: 0.7403 - mcc: 0.5986\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7501 - loss: 0.7267\n",
      "Epoch 4 - MCC: 0.6179\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.7502 - loss: 0.7266 - val_accuracy: 0.7607 - val_loss: 0.7000 - mcc: 0.6179\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7591 - loss: 0.7026\n",
      "Epoch 5 - MCC: 0.6464\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.7592 - loss: 0.7024 - val_accuracy: 0.7775 - val_loss: 0.6572 - mcc: 0.6464\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7692 - loss: 0.6766\n",
      "Epoch 6 - MCC: 0.6458\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 31ms/step - accuracy: 0.7693 - loss: 0.6764 - val_accuracy: 0.7790 - val_loss: 0.6612 - mcc: 0.6458\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7611 - loss: 0.6957\n",
      "Epoch 7 - MCC: 0.6485\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.7611 - loss: 0.6959 - val_accuracy: 0.7785 - val_loss: 0.6591 - mcc: 0.6485\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7711 - loss: 0.6722\n",
      "Epoch 8 - MCC: 0.6649\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 33ms/step - accuracy: 0.7711 - loss: 0.6721 - val_accuracy: 0.7903 - val_loss: 0.6255 - mcc: 0.6649\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7784 - loss: 0.6517\n",
      "Epoch 9 - MCC: 0.6646\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.7784 - loss: 0.6516 - val_accuracy: 0.7896 - val_loss: 0.6266 - mcc: 0.6646\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7824 - loss: 0.6374\n",
      "Epoch 10 - MCC: 0.6731\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 33ms/step - accuracy: 0.7825 - loss: 0.6374 - val_accuracy: 0.7955 - val_loss: 0.6100 - mcc: 0.6731\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 3\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4927 - loss: 1.2356\n",
      "Epoch 1 - MCC: 0.4098\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 41ms/step - accuracy: 0.4935 - loss: 1.2340 - val_accuracy: 0.6436 - val_loss: 0.9602 - mcc: 0.4098\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.6612 - loss: 0.8978\n",
      "Epoch 2 - MCC: 0.5359\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 35ms/step - accuracy: 0.6614 - loss: 0.8975 - val_accuracy: 0.7161 - val_loss: 0.7991 - mcc: 0.5359\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7305 - loss: 0.7876\n",
      "Epoch 3 - MCC: 0.6112\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.7307 - loss: 0.7872 - val_accuracy: 0.7582 - val_loss: 0.7040 - mcc: 0.6112\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7566 - loss: 0.7172\n",
      "Epoch 4 - MCC: 0.6161\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.7566 - loss: 0.7170 - val_accuracy: 0.7615 - val_loss: 0.6938 - mcc: 0.6161\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7640 - loss: 0.6916\n",
      "Epoch 5 - MCC: 0.6400\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.7640 - loss: 0.6915 - val_accuracy: 0.7735 - val_loss: 0.6644 - mcc: 0.6400\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7705 - loss: 0.6816\n",
      "Epoch 6 - MCC: 0.6270\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.7706 - loss: 0.6814 - val_accuracy: 0.7661 - val_loss: 0.6791 - mcc: 0.6270\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7796 - loss: 0.6522\n",
      "Epoch 7 - MCC: 0.6397\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.7795 - loss: 0.6523 - val_accuracy: 0.7753 - val_loss: 0.6554 - mcc: 0.6397\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7776 - loss: 0.6559\n",
      "Epoch 8 - MCC: 0.6497\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 35ms/step - accuracy: 0.7777 - loss: 0.6558 - val_accuracy: 0.7800 - val_loss: 0.6430 - mcc: 0.6497\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7827 - loss: 0.6408\n",
      "Epoch 9 - MCC: 0.6454\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.7827 - loss: 0.6409 - val_accuracy: 0.7751 - val_loss: 0.6444 - mcc: 0.6454\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7848 - loss: 0.6328\n",
      "Epoch 10 - MCC: 0.6619\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.7848 - loss: 0.6328 - val_accuracy: 0.7866 - val_loss: 0.6230 - mcc: 0.6619\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 4\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.4940 - loss: 1.2353\n",
      "Epoch 1 - MCC: 0.3414\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 41ms/step - accuracy: 0.4944 - loss: 1.2345 - val_accuracy: 0.6146 - val_loss: 1.0169 - mcc: 0.3414\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.6460 - loss: 0.9560\n",
      "Epoch 2 - MCC: 0.5148\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 31ms/step - accuracy: 0.6462 - loss: 0.9554 - val_accuracy: 0.7002 - val_loss: 0.8391 - mcc: 0.5148\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7100 - loss: 0.8237\n",
      "Epoch 3 - MCC: 0.5580\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.7101 - loss: 0.8235 - val_accuracy: 0.7189 - val_loss: 0.7855 - mcc: 0.5580\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7380 - loss: 0.7605\n",
      "Epoch 4 - MCC: 0.6096\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.7381 - loss: 0.7603 - val_accuracy: 0.7532 - val_loss: 0.7454 - mcc: 0.6096\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7589 - loss: 0.7165\n",
      "Epoch 5 - MCC: 0.6203\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.7589 - loss: 0.7164 - val_accuracy: 0.7617 - val_loss: 0.7177 - mcc: 0.6203\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7630 - loss: 0.7026\n",
      "Epoch 6 - MCC: 0.6303\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.7631 - loss: 0.7025 - val_accuracy: 0.7656 - val_loss: 0.6934 - mcc: 0.6303\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7769 - loss: 0.6695\n",
      "Epoch 7 - MCC: 0.6456\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.7769 - loss: 0.6695 - val_accuracy: 0.7753 - val_loss: 0.6683 - mcc: 0.6456\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7770 - loss: 0.6635\n",
      "Epoch 8 - MCC: 0.6376\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.7770 - loss: 0.6635 - val_accuracy: 0.7701 - val_loss: 0.6839 - mcc: 0.6376\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7805 - loss: 0.6558\n",
      "Epoch 9 - MCC: 0.6165\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.7805 - loss: 0.6557 - val_accuracy: 0.7529 - val_loss: 0.7160 - mcc: 0.6165\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7797 - loss: 0.6494\n",
      "Epoch 10 - MCC: 0.6546\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.7797 - loss: 0.6493 - val_accuracy: 0.7815 - val_loss: 0.6423 - mcc: 0.6546\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 5\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.5182 - loss: 1.2524\n",
      "Epoch 1 - MCC: 0.4619\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 43ms/step - accuracy: 0.5188 - loss: 1.2512 - val_accuracy: 0.6754 - val_loss: 0.8864 - mcc: 0.4619\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.6949 - loss: 0.8480\n",
      "Epoch 2 - MCC: 0.5575\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 33ms/step - accuracy: 0.6950 - loss: 0.8477 - val_accuracy: 0.7240 - val_loss: 0.8004 - mcc: 0.5575\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7407 - loss: 0.7435\n",
      "Epoch 3 - MCC: 0.5833\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.7408 - loss: 0.7434 - val_accuracy: 0.7397 - val_loss: 0.7618 - mcc: 0.5833\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7504 - loss: 0.7157\n",
      "Epoch 4 - MCC: 0.5655\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.7505 - loss: 0.7156 - val_accuracy: 0.7279 - val_loss: 0.7912 - mcc: 0.5655\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7599 - loss: 0.7041\n",
      "Epoch 5 - MCC: 0.6227\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.7600 - loss: 0.7039 - val_accuracy: 0.7604 - val_loss: 0.6962 - mcc: 0.6227\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7651 - loss: 0.6864\n",
      "Epoch 6 - MCC: 0.6390\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.7652 - loss: 0.6862 - val_accuracy: 0.7715 - val_loss: 0.6776 - mcc: 0.6390\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7776 - loss: 0.6550\n",
      "Epoch 7 - MCC: 0.6253\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.7775 - loss: 0.6552 - val_accuracy: 0.7631 - val_loss: 0.6969 - mcc: 0.6253\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7755 - loss: 0.6600\n",
      "Epoch 8 - MCC: 0.6476\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.7755 - loss: 0.6599 - val_accuracy: 0.7775 - val_loss: 0.6587 - mcc: 0.6476\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7868 - loss: 0.6292\n",
      "Epoch 9 - MCC: 0.6330\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.7868 - loss: 0.6294 - val_accuracy: 0.7673 - val_loss: 0.6940 - mcc: 0.6330\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.7847 - loss: 0.6406\n",
      "Epoch 10 - MCC: 0.6602\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.7847 - loss: 0.6407 - val_accuracy: 0.7859 - val_loss: 0.6385 - mcc: 0.6602\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': 0.7954666666666667,\n",
      "              'mean': 0.787382,\n",
      "              'min': 0.7814733333333334,\n",
      "              'std': 0.004543737864113385},\n",
      " 'Inference Time (s/sample)': {'max': 0.0006329882144927979,\n",
      "                               'mean': 0.0005574945608774821,\n",
      "                               'min': 0.0004652194182078044,\n",
      "                               'std': 7.28019602646835e-05},\n",
      " 'MCC': {'max': 0.6730863582068596,\n",
      "         'mean': 0.6626166539918614,\n",
      "         'min': 0.6546062256258954,\n",
      "         'std': 0.006008946991829854},\n",
      " 'Parameters': 4549,\n",
      " 'Train Time (s)': {'max': 64.37667417526245,\n",
      "                    'mean': 59.75493602752685,\n",
      "                    'min': 53.56303262710571,\n",
      "                    'std': 4.0121534781740875},\n",
      " 'Training Accuracy': [[0.5484839677810669,\n",
      "                        0.6907209753990173,\n",
      "                        0.723407506942749,\n",
      "                        0.7458631992340088,\n",
      "                        0.7509943842887878,\n",
      "                        0.7654743790626526,\n",
      "                        0.7737928032875061,\n",
      "                        0.7774264812469482,\n",
      "                        0.7804877758026123,\n",
      "                        0.7815757393836975],\n",
      "                       [0.5572782158851624,\n",
      "                        0.689191460609436,\n",
      "                        0.735174298286438,\n",
      "                        0.753462553024292,\n",
      "                        0.763461709022522,\n",
      "                        0.7724200487136841,\n",
      "                        0.7600774168968201,\n",
      "                        0.77433842420578,\n",
      "                        0.780081570148468,\n",
      "                        0.7837731838226318],\n",
      "                       [0.552482545375824,\n",
      "                        0.6796057820320129,\n",
      "                        0.7428153157234192,\n",
      "                        0.7586702704429626,\n",
      "                        0.7665401101112366,\n",
      "                        0.7744534015655518,\n",
      "                        0.7773957252502441,\n",
      "                        0.7802016735076904,\n",
      "                        0.7814944386482239,\n",
      "                        0.7851853370666504],\n",
      "                       [0.5549140572547913,\n",
      "                        0.6622359752655029,\n",
      "                        0.7178391814231873,\n",
      "                        0.7422027587890625,\n",
      "                        0.7599283456802368,\n",
      "                        0.7670283913612366,\n",
      "                        0.7756316661834717,\n",
      "                        0.7775256633758545,\n",
      "                        0.78170245885849,\n",
      "                        0.7824536561965942],\n",
      "                       [0.6049200296401978,\n",
      "                        0.7147066593170166,\n",
      "                        0.7433156371116638,\n",
      "                        0.754499077796936,\n",
      "                        0.7635948657989502,\n",
      "                        0.7702542543411255,\n",
      "                        0.7742568850517273,\n",
      "                        0.7762442231178284,\n",
      "                        0.7817307114601135,\n",
      "                        0.7807596921920776]],\n",
      " 'Training Loss': [[1.1242002248764038,\n",
      "                    0.8764052391052246,\n",
      "                    0.7952025532722473,\n",
      "                    0.7394734025001526,\n",
      "                    0.7245478630065918,\n",
      "                    0.68535977602005,\n",
      "                    0.665034294128418,\n",
      "                    0.6509115695953369,\n",
      "                    0.6444701552391052,\n",
      "                    0.6407039165496826],\n",
      "                   [1.1216267347335815,\n",
      "                    0.8556007146835327,\n",
      "                    0.7772377729415894,\n",
      "                    0.7166440486907959,\n",
      "                    0.6919377446174622,\n",
      "                    0.665859043598175,\n",
      "                    0.7082828283309937,\n",
      "                    0.6599301695823669,\n",
      "                    0.6443592309951782,\n",
      "                    0.63215571641922],\n",
      "                   [1.1128511428833008,\n",
      "                    0.8699373602867126,\n",
      "                    0.7556061148643494,\n",
      "                    0.7059975862503052,\n",
      "                    0.6840683221817017,\n",
      "                    0.6662188172340393,\n",
      "                    0.6574851274490356,\n",
      "                    0.6477542519569397,\n",
      "                    0.6473743319511414,\n",
      "                    0.6333363056182861],\n",
      "                   [1.1117002964019775,\n",
      "                    0.9135579466819763,\n",
      "                    0.8049532175064087,\n",
      "                    0.7511614561080933,\n",
      "                    0.7104578018188477,\n",
      "                    0.6915326118469238,\n",
      "                    0.6693960428237915,\n",
      "                    0.6603326201438904,\n",
      "                    0.6473464369773865,\n",
      "                    0.6431041359901428],\n",
      "                   [1.06252121925354,\n",
      "                    0.8113007545471191,\n",
      "                    0.7397024631500244,\n",
      "                    0.707646906375885,\n",
      "                    0.6895121932029724,\n",
      "                    0.6740896701812744,\n",
      "                    0.6659908294677734,\n",
      "                    0.6568060517311096,\n",
      "                    0.6436370611190796,\n",
      "                    0.6464451551437378]],\n",
      " 'Validation Accuracy': [[0.6576067805290222,\n",
      "                          0.7101300954818726,\n",
      "                          0.7488266825675964,\n",
      "                          0.7551300525665283,\n",
      "                          0.7740901708602905,\n",
      "                          0.7797899842262268,\n",
      "                          0.7755400538444519,\n",
      "                          0.7874600291252136,\n",
      "                          0.7920500040054321,\n",
      "                          0.7875301241874695],\n",
      "                         [0.6575233936309814,\n",
      "                          0.7253402471542358,\n",
      "                          0.7506401538848877,\n",
      "                          0.760673463344574,\n",
      "                          0.7775099873542786,\n",
      "                          0.7790066599845886,\n",
      "                          0.7785367369651794,\n",
      "                          0.7902867197990417,\n",
      "                          0.7896367311477661,\n",
      "                          0.7954667806625366],\n",
      "                         [0.6436300873756409,\n",
      "                          0.7160700559616089,\n",
      "                          0.7581667304039001,\n",
      "                          0.7615334391593933,\n",
      "                          0.773496687412262,\n",
      "                          0.7660933136940002,\n",
      "                          0.7752699851989746,\n",
      "                          0.7799700498580933,\n",
      "                          0.7751134634017944,\n",
      "                          0.7865601181983948],\n",
      "                         [0.6145800352096558,\n",
      "                          0.700243353843689,\n",
      "                          0.7189066410064697,\n",
      "                          0.753206729888916,\n",
      "                          0.7617200613021851,\n",
      "                          0.7656033039093018,\n",
      "                          0.7752834558486938,\n",
      "                          0.7700934410095215,\n",
      "                          0.7529467940330505,\n",
      "                          0.7814733386039734],\n",
      "                         [0.6753500699996948,\n",
      "                          0.7239800095558167,\n",
      "                          0.7396633625030518,\n",
      "                          0.7278866767883301,\n",
      "                          0.7604469060897827,\n",
      "                          0.7715400457382202,\n",
      "                          0.7630932331085205,\n",
      "                          0.7774865031242371,\n",
      "                          0.7672834396362305,\n",
      "                          0.785879909992218]],\n",
      " 'Validation Loss': [0.8863575458526611,\n",
      "                     0.8004065155982971,\n",
      "                     0.7617623209953308,\n",
      "                     0.7912311553955078,\n",
      "                     0.6962324380874634,\n",
      "                     0.6776100993156433,\n",
      "                     0.696904182434082,\n",
      "                     0.6587359309196472,\n",
      "                     0.6940085291862488,\n",
      "                     0.638450026512146],\n",
      " 'Validation MCC': [[0.43139051413042884,\n",
      "                     0.5311837337415694,\n",
      "                     0.5958871566606967,\n",
      "                     0.6090211330597176,\n",
      "                     0.6418440589262434,\n",
      "                     0.6501787832595858,\n",
      "                     0.6434466510250024,\n",
      "                     0.6620952053135374,\n",
      "                     0.6688664236223554,\n",
      "                     0.6632787462988703],\n",
      "                    [0.4193998212891032,\n",
      "                     0.5535793785541732,\n",
      "                     0.598638139269124,\n",
      "                     0.6179093557353192,\n",
      "                     0.6463738082012254,\n",
      "                     0.6458101431391016,\n",
      "                     0.6484553228260829,\n",
      "                     0.6649371071495611,\n",
      "                     0.6645539940792933,\n",
      "                     0.6730863582068596],\n",
      "                    [0.40983876977826744,\n",
      "                     0.5358553405526779,\n",
      "                     0.6112009750274717,\n",
      "                     0.6161212028229922,\n",
      "                     0.6399583747231457,\n",
      "                     0.6270168596260086,\n",
      "                     0.639685034589241,\n",
      "                     0.6496807659886253,\n",
      "                     0.6453532369756664,\n",
      "                     0.6619061801794538],\n",
      "                    [0.3413578302907883,\n",
      "                     0.5148104358417462,\n",
      "                     0.5579670925444445,\n",
      "                     0.6096108504619198,\n",
      "                     0.6203338938986207,\n",
      "                     0.6303387361301844,\n",
      "                     0.6456328203471781,\n",
      "                     0.6376130924245862,\n",
      "                     0.6164698452686929,\n",
      "                     0.6546062256258954],\n",
      "                    [0.4618772042573218,\n",
      "                     0.5574791279482633,\n",
      "                     0.5833093918197823,\n",
      "                     0.5654979269575342,\n",
      "                     0.6226991579957191,\n",
      "                     0.6390208518717133,\n",
      "                     0.6252980295898634,\n",
      "                     0.6476038628448609,\n",
      "                     0.632976618861321,\n",
      "                     0.6602057596482277]]}\n",
      "Training Model: GRU, Fold: 1\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.4636 - loss: 1.4037\n",
      "Epoch 1 - MCC: 0.3977\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.4646 - loss: 1.4015 - val_accuracy: 0.6456 - val_loss: 0.9921 - mcc: 0.3977\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6729 - loss: 0.9256\n",
      "Epoch 2 - MCC: 0.5940\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.6731 - loss: 0.9252 - val_accuracy: 0.7467 - val_loss: 0.7555 - mcc: 0.5940\n",
      "Epoch 3/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7415 - loss: 0.7606\n",
      "Epoch 3 - MCC: 0.6199\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.7418 - loss: 0.7599 - val_accuracy: 0.7615 - val_loss: 0.6914 - mcc: 0.6199\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.7612 - loss: 0.6948\n",
      "Epoch 4 - MCC: 0.6432\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 27ms/step - accuracy: 0.7613 - loss: 0.6947 - val_accuracy: 0.7765 - val_loss: 0.6511 - mcc: 0.6432\n",
      "Epoch 5/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7739 - loss: 0.6567\n",
      "Epoch 5 - MCC: 0.6600\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.7739 - loss: 0.6563 - val_accuracy: 0.7865 - val_loss: 0.6042 - mcc: 0.6600\n",
      "Epoch 6/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7856 - loss: 0.6051\n",
      "Epoch 6 - MCC: 0.6724\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.7856 - loss: 0.6051 - val_accuracy: 0.7937 - val_loss: 0.5713 - mcc: 0.6724\n",
      "Epoch 7/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7889 - loss: 0.5826\n",
      "Epoch 7 - MCC: 0.6775\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.7890 - loss: 0.5825 - val_accuracy: 0.7965 - val_loss: 0.5614 - mcc: 0.6775\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.7958 - loss: 0.5671\n",
      "Epoch 8 - MCC: 0.6902\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 25ms/step - accuracy: 0.7958 - loss: 0.5671 - val_accuracy: 0.8037 - val_loss: 0.5382 - mcc: 0.6902\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8056 - loss: 0.5331\n",
      "Epoch 9 - MCC: 0.6934\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.8055 - loss: 0.5332 - val_accuracy: 0.8054 - val_loss: 0.5293 - mcc: 0.6934\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7988 - loss: 0.5413\n",
      "Epoch 10 - MCC: 0.6963\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.7988 - loss: 0.5412 - val_accuracy: 0.8076 - val_loss: 0.5195 - mcc: 0.6963\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 2\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.5019 - loss: 1.3862\n",
      "Epoch 1 - MCC: 0.4149\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 29ms/step - accuracy: 0.5025 - loss: 1.3841 - val_accuracy: 0.6546 - val_loss: 0.9744 - mcc: 0.4149\n",
      "Epoch 2/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6829 - loss: 0.9091\n",
      "Epoch 2 - MCC: 0.5920\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.6833 - loss: 0.9079 - val_accuracy: 0.7472 - val_loss: 0.7513 - mcc: 0.5920\n",
      "Epoch 3/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7493 - loss: 0.7433\n",
      "Epoch 3 - MCC: 0.6290\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.7493 - loss: 0.7432 - val_accuracy: 0.7687 - val_loss: 0.6900 - mcc: 0.6290\n",
      "Epoch 4/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.7662 - loss: 0.6914\n",
      "Epoch 4 - MCC: 0.6498\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 22ms/step - accuracy: 0.7662 - loss: 0.6914 - val_accuracy: 0.7803 - val_loss: 0.6531 - mcc: 0.6498\n",
      "Epoch 5/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.7787 - loss: 0.6467\n",
      "Epoch 5 - MCC: 0.6539\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.7787 - loss: 0.6466 - val_accuracy: 0.7839 - val_loss: 0.6102 - mcc: 0.6539\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7814 - loss: 0.6243\n",
      "Epoch 6 - MCC: 0.6824\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.7815 - loss: 0.6242 - val_accuracy: 0.7998 - val_loss: 0.5651 - mcc: 0.6824\n",
      "Epoch 7/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7879 - loss: 0.5940\n",
      "Epoch 7 - MCC: 0.6768\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.7879 - loss: 0.5940 - val_accuracy: 0.7966 - val_loss: 0.5788 - mcc: 0.6768\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.7911 - loss: 0.5900\n",
      "Epoch 8 - MCC: 0.6751\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 24ms/step - accuracy: 0.7911 - loss: 0.5899 - val_accuracy: 0.7932 - val_loss: 0.5716 - mcc: 0.6751\n",
      "Epoch 9/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.7965 - loss: 0.5677\n",
      "Epoch 9 - MCC: 0.6989\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.7965 - loss: 0.5677 - val_accuracy: 0.8099 - val_loss: 0.5284 - mcc: 0.6989\n",
      "Epoch 10/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7980 - loss: 0.5622\n",
      "Epoch 10 - MCC: 0.6988\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.7980 - loss: 0.5621 - val_accuracy: 0.8089 - val_loss: 0.5286 - mcc: 0.6988\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 3\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.4651 - loss: 1.4018\n",
      "Epoch 1 - MCC: 0.4214\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 27ms/step - accuracy: 0.4656 - loss: 1.4006 - val_accuracy: 0.6560 - val_loss: 0.9808 - mcc: 0.4214\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.6799 - loss: 0.8962\n",
      "Epoch 2 - MCC: 0.5763\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.6801 - loss: 0.8958 - val_accuracy: 0.7383 - val_loss: 0.7697 - mcc: 0.5763\n",
      "Epoch 3/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7442 - loss: 0.7470\n",
      "Epoch 3 - MCC: 0.6134\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.7443 - loss: 0.7467 - val_accuracy: 0.7584 - val_loss: 0.6872 - mcc: 0.6134\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7546 - loss: 0.6975\n",
      "Epoch 4 - MCC: 0.6334\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.7547 - loss: 0.6973 - val_accuracy: 0.7704 - val_loss: 0.6433 - mcc: 0.6334\n",
      "Epoch 5/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.7717 - loss: 0.6432\n",
      "Epoch 5 - MCC: 0.6549\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 22ms/step - accuracy: 0.7718 - loss: 0.6432 - val_accuracy: 0.7826 - val_loss: 0.6161 - mcc: 0.6549\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7895 - loss: 0.6000\n",
      "Epoch 6 - MCC: 0.6598\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.7895 - loss: 0.6002 - val_accuracy: 0.7864 - val_loss: 0.6031 - mcc: 0.6598\n",
      "Epoch 7/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.7898 - loss: 0.5938\n",
      "Epoch 7 - MCC: 0.6706\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.7898 - loss: 0.5938 - val_accuracy: 0.7927 - val_loss: 0.5826 - mcc: 0.6706\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.7896 - loss: 0.5902\n",
      "Epoch 8 - MCC: 0.6502\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 24ms/step - accuracy: 0.7896 - loss: 0.5902 - val_accuracy: 0.7779 - val_loss: 0.6524 - mcc: 0.6502\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7961 - loss: 0.5739\n",
      "Epoch 9 - MCC: 0.6797\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.7961 - loss: 0.5739 - val_accuracy: 0.7983 - val_loss: 0.5617 - mcc: 0.6797\n",
      "Epoch 10/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7998 - loss: 0.5597\n",
      "Epoch 10 - MCC: 0.6808\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.7999 - loss: 0.5596 - val_accuracy: 0.7992 - val_loss: 0.5584 - mcc: 0.6808\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 4\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.4986 - loss: 1.4132\n",
      "Epoch 1 - MCC: 0.2781\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 22ms/step - accuracy: 0.4989 - loss: 1.4123 - val_accuracy: 0.5856 - val_loss: 1.0694 - mcc: 0.2781\n",
      "Epoch 2/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6522 - loss: 0.9517\n",
      "Epoch 2 - MCC: 0.5742\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.6530 - loss: 0.9500 - val_accuracy: 0.7318 - val_loss: 0.7780 - mcc: 0.5742\n",
      "Epoch 3/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7481 - loss: 0.7429\n",
      "Epoch 3 - MCC: 0.6068\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 21ms/step - accuracy: 0.7482 - loss: 0.7425 - val_accuracy: 0.7500 - val_loss: 0.7153 - mcc: 0.6068\n",
      "Epoch 4/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7556 - loss: 0.6957\n",
      "Epoch 4 - MCC: 0.6356\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.7557 - loss: 0.6955 - val_accuracy: 0.7696 - val_loss: 0.6501 - mcc: 0.6356\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7668 - loss: 0.6609\n",
      "Epoch 5 - MCC: 0.6383\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.7668 - loss: 0.6609 - val_accuracy: 0.7703 - val_loss: 0.6376 - mcc: 0.6383\n",
      "Epoch 6/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7753 - loss: 0.6332\n",
      "Epoch 6 - MCC: 0.6537\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.7755 - loss: 0.6328 - val_accuracy: 0.7803 - val_loss: 0.6140 - mcc: 0.6537\n",
      "Epoch 7/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.7837 - loss: 0.6030\n",
      "Epoch 7 - MCC: 0.6671\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.7838 - loss: 0.6028 - val_accuracy: 0.7877 - val_loss: 0.5940 - mcc: 0.6671\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7924 - loss: 0.5769\n",
      "Epoch 8 - MCC: 0.6674\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.7924 - loss: 0.5769 - val_accuracy: 0.7882 - val_loss: 0.5811 - mcc: 0.6674\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7969 - loss: 0.5623\n",
      "Epoch 9 - MCC: 0.6776\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 22ms/step - accuracy: 0.7969 - loss: 0.5623 - val_accuracy: 0.7935 - val_loss: 0.5675 - mcc: 0.6776\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8016 - loss: 0.5513\n",
      "Epoch 10 - MCC: 0.6895\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 24ms/step - accuracy: 0.8016 - loss: 0.5513 - val_accuracy: 0.8013 - val_loss: 0.5482 - mcc: 0.6895\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 5\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.5100 - loss: 1.3762\n",
      "Epoch 1 - MCC: 0.4331\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.5103 - loss: 1.3750 - val_accuracy: 0.6607 - val_loss: 0.9722 - mcc: 0.4331\n",
      "Epoch 2/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6909 - loss: 0.8818\n",
      "Epoch 2 - MCC: 0.5769\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.6915 - loss: 0.8802 - val_accuracy: 0.7355 - val_loss: 0.7679 - mcc: 0.5769\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7476 - loss: 0.7349\n",
      "Epoch 3 - MCC: 0.6168\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.7476 - loss: 0.7348 - val_accuracy: 0.7593 - val_loss: 0.7152 - mcc: 0.6168\n",
      "Epoch 4/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.7681 - loss: 0.6836\n",
      "Epoch 4 - MCC: 0.6397\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.7681 - loss: 0.6834 - val_accuracy: 0.7730 - val_loss: 0.6505 - mcc: 0.6397\n",
      "Epoch 5/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7785 - loss: 0.6283\n",
      "Epoch 5 - MCC: 0.6532\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.7785 - loss: 0.6281 - val_accuracy: 0.7801 - val_loss: 0.6169 - mcc: 0.6532\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7825 - loss: 0.6041\n",
      "Epoch 6 - MCC: 0.6706\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.7826 - loss: 0.6039 - val_accuracy: 0.7910 - val_loss: 0.5896 - mcc: 0.6706\n",
      "Epoch 7/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7899 - loss: 0.5800\n",
      "Epoch 7 - MCC: 0.6752\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.7901 - loss: 0.5797 - val_accuracy: 0.7937 - val_loss: 0.5726 - mcc: 0.6752\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.7952 - loss: 0.5606\n",
      "Epoch 8 - MCC: 0.6798\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 22ms/step - accuracy: 0.7952 - loss: 0.5606 - val_accuracy: 0.7966 - val_loss: 0.5622 - mcc: 0.6798\n",
      "Epoch 9/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8033 - loss: 0.5379\n",
      "Epoch 9 - MCC: 0.6825\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.8033 - loss: 0.5379 - val_accuracy: 0.7990 - val_loss: 0.5538 - mcc: 0.6825\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8052 - loss: 0.5285\n",
      "Epoch 10 - MCC: 0.6895\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 22ms/step - accuracy: 0.8053 - loss: 0.5285 - val_accuracy: 0.8029 - val_loss: 0.5436 - mcc: 0.6895\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': 0.8089366666666666,\n",
      "              'mean': 0.803994,\n",
      "              'min': 0.7992033333333334,\n",
      "              'std': 0.003716678565003365},\n",
      " 'Inference Time (s/sample)': {'max': 0.0006175875663757324,\n",
      "                               'mean': 0.0004937268098195394,\n",
      "                               'min': 0.0003645193576812744,\n",
      "                               'std': 0.00010770078584188144},\n",
      " 'MCC': {'max': 0.6987943318758064,\n",
      "         'mean': 0.6909799099844613,\n",
      "         'min': 0.6808365193889556,\n",
      "         'std': 0.006266942145358226},\n",
      " 'Parameters': 4170,\n",
      " 'Train Time (s)': {'max': 45.26467275619507,\n",
      "                    'mean': 40.11134071350098,\n",
      "                    'min': 32.89917850494385,\n",
      "                    'std': 4.41152694561341},\n",
      " 'Training Accuracy': [[0.536405086517334,\n",
      "                        0.7002303004264832,\n",
      "                        0.7511997222900391,\n",
      "                        0.7633998394012451,\n",
      "                        0.77632075548172,\n",
      "                        0.7842859625816345,\n",
      "                        0.7928200960159302,\n",
      "                        0.7943235039710999,\n",
      "                        0.801059901714325,\n",
      "                        0.8018800616264343],\n",
      "                       [0.5471858978271484,\n",
      "                        0.7051684260368347,\n",
      "                        0.7491467595100403,\n",
      "                        0.7644090056419373,\n",
      "                        0.7763116955757141,\n",
      "                        0.785389244556427,\n",
      "                        0.7880124449729919,\n",
      "                        0.7934580445289612,\n",
      "                        0.7965750098228455,\n",
      "                        0.8007873892784119],\n",
      "                       [0.5463775396347046,\n",
      "                        0.7056567072868347,\n",
      "                        0.7475898861885071,\n",
      "                        0.760675847530365,\n",
      "                        0.7737033367156982,\n",
      "                        0.7841582894325256,\n",
      "                        0.7910248041152954,\n",
      "                        0.7918217182159424,\n",
      "                        0.7959073185920715,\n",
      "                        0.8017441034317017],\n",
      "                       [0.5336700677871704,\n",
      "                        0.6912140250205994,\n",
      "                        0.7534134387969971,\n",
      "                        0.7657973766326904,\n",
      "                        0.7661234140396118,\n",
      "                        0.7823099493980408,\n",
      "                        0.7867900133132935,\n",
      "                        0.7921661734580994,\n",
      "                        0.7969456911087036,\n",
      "                        0.801145613193512],\n",
      "                       [0.5677700638771057,\n",
      "                        0.7148991823196411,\n",
      "                        0.7517834901809692,\n",
      "                        0.7694474458694458,\n",
      "                        0.7815775275230408,\n",
      "                        0.7876802682876587,\n",
      "                        0.7952909469604492,\n",
      "                        0.7999390363693237,\n",
      "                        0.8036043047904968,\n",
      "                        0.8055310249328613]],\n",
      " 'Training Loss': [[1.2354434728622437,\n",
      "                    0.8566898703575134,\n",
      "                    0.7332720160484314,\n",
      "                    0.6913418769836426,\n",
      "                    0.6410250067710876,\n",
      "                    0.6057667136192322,\n",
      "                    0.5767913460731506,\n",
      "                    0.56864994764328,\n",
      "                    0.5453140735626221,\n",
      "                    0.5362700819969177],\n",
      "                   [1.2295762300491333,\n",
      "                    0.8493836522102356,\n",
      "                    0.7403583526611328,\n",
      "                    0.6909843683242798,\n",
      "                    0.6430026292800903"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ",\n",
      "                    0.6111583709716797,\n",
      "                    0.5953930020332336,\n",
      "                    0.580720067024231,\n",
      "                    0.5673807263374329,\n",
      "                    0.5533567667007446],\n",
      "                   [1.2320468425750732,\n",
      "                    0.8390495181083679,\n",
      "                    0.7294394373893738,\n",
      "                    0.6834112405776978,\n",
      "                    0.6401497721672058,\n",
      "                    0.613895058631897,\n",
      "                    0.5897409319877625,\n",
      "                    0.5881420969963074,\n",
      "                    0.5704762935638428,\n",
      "                    0.5518342852592468],\n",
      "                   [1.271952509880066,\n",
      "                    0.867531955242157,\n",
      "                    0.7258586883544922,\n",
      "                    0.6673148274421692,\n",
      "                    0.6614122986793518,\n",
      "                    0.6130332350730896,\n",
      "                    0.5941289663314819,\n",
      "                    0.5780371427536011,\n",
      "                    0.561547040939331,\n",
      "                    0.5507490038871765],\n",
      "                   [1.1994999647140503,\n",
      "                    0.8212886452674866,\n",
      "                    0.7236409783363342,\n",
      "                    0.672675371170044,\n",
      "                    0.6181477308273315,\n",
      "                    0.5938496589660645,\n",
      "                    0.5676975250244141,\n",
      "                    0.550774097442627,\n",
      "                    0.5374908447265625,\n",
      "                    0.5281600952148438]],\n",
      " 'Validation Accuracy': [[0.6455766558647156,\n",
      "                          0.7466698884963989,\n",
      "                          0.7615000009536743,\n",
      "                          0.7764800786972046,\n",
      "                          0.7865432500839233,\n",
      "                          0.7937332987785339,\n",
      "                          0.7965199947357178,\n",
      "                          0.803679883480072,\n",
      "                          0.8053866028785706,\n",
      "                          0.8076233267784119],\n",
      "                         [0.6546199321746826,\n",
      "                          0.7471833825111389,\n",
      "                          0.7686665654182434,\n",
      "                          0.7803200483322144,\n",
      "                          0.783923327922821,\n",
      "                          0.7997632622718811,\n",
      "                          0.7966299653053284,\n",
      "                          0.7932331562042236,\n",
      "                          0.8098533153533936,\n",
      "                          0.808936595916748],\n",
      "                         [0.6559699773788452,\n",
      "                          0.738319993019104,\n",
      "                          0.7584001421928406,\n",
      "                          0.7703732848167419,\n",
      "                          0.7825900316238403,\n",
      "                          0.7863733768463135,\n",
      "                          0.79271000623703,\n",
      "                          0.7779432535171509,\n",
      "                          0.7983101010322571,\n",
      "                          0.7992032766342163],\n",
      "                         [0.5856167078018188,\n",
      "                          0.7318099737167358,\n",
      "                          0.7500433921813965,\n",
      "                          0.769633412361145,\n",
      "                          0.7702667117118835,\n",
      "                          0.7802598476409912,\n",
      "                          0.7877099514007568,\n",
      "                          0.788173496723175,\n",
      "                          0.7934899926185608,\n",
      "                          0.801276683807373],\n",
      "                         [0.6607232689857483,\n",
      "                          0.7354633808135986,\n",
      "                          0.7592699527740479,\n",
      "                          0.7729833722114563,\n",
      "                          0.7800999283790588,\n",
      "                          0.791016697883606,\n",
      "                          0.7936667203903198,\n",
      "                          0.7966333627700806,\n",
      "                          0.7990333437919617,\n",
      "                          0.8029299378395081]],\n",
      " 'Validation Loss': [0.9721934199333191,\n",
      "                     0.7679105401039124,\n",
      "                     0.7151561975479126,\n",
      "                     0.6505457162857056,\n",
      "                     0.6169150471687317,\n",
      "                     0.5896481275558472,\n",
      "                     0.5725536346435547,\n",
      "                     0.5621995329856873,\n",
      "                     0.5538023114204407,\n",
      "                     0.5436195731163025],\n",
      " 'Validation MCC': [[0.39767303099655216,\n",
      "                     0.5939516906921607,\n",
      "                     0.619879737453573,\n",
      "                     0.6432378113849753,\n",
      "                     0.6600021318696133,\n",
      "                     0.6724436503479495,\n",
      "                     0.6775421980772856,\n",
      "                     0.6901581158587363,\n",
      "                     0.6934250007775881,\n",
      "                     0.6962735748364542],\n",
      "                    [0.4149206345907736,\n",
      "                     0.5919882445780171,\n",
      "                     0.6290018807201735,\n",
      "                     0.6497756126074729,\n",
      "                     0.6538771251426153,\n",
      "                     0.6824173291388742,\n",
      "                     0.6767822109424252,\n",
      "                     0.6750549821996105,\n",
      "                     0.6988516900450031,\n",
      "                     0.6987943318758064],\n",
      "                    [0.42143675564627037,\n",
      "                     0.5763273536274891,\n",
      "                     0.6134321963553985,\n",
      "                     0.6334389367503487,\n",
      "                     0.6549279688806932,\n",
      "                     0.6598163116430634,\n",
      "                     0.6706472476716815,\n",
      "                     0.6501808869103938,\n",
      "                     0.6797077293316124,\n",
      "                     0.6808365193889556],\n",
      "                    [0.2781222042188868,\n",
      "                     0.574186580975962,\n",
      "                     0.6067505438197675,\n",
      "                     0.6356172327932145,\n",
      "                     0.6383478671072325,\n",
      "                     0.6536745309919071,\n",
      "                     0.6671181212035479,\n",
      "                     0.667445616208839,\n",
      "                     0.6776198973828638,\n",
      "                     0.6894687712202215],\n",
      "                    [0.4330860160904689,\n",
      "                     0.5769072542367325,\n",
      "                     0.6167560394791278,\n",
      "                     0.6396631068639571,\n",
      "                     0.6531840258830404,\n",
      "                     0.6705721803716415,\n",
      "                     0.6752115033668042,\n",
      "                     0.6797936975406943,\n",
      "                     0.6824826553494273,\n",
      "                     0.6895263526008691]]}\n",
      "Training Model: FFN, Fold: 1\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4679 - loss: 1.4666\n",
      "Epoch 1 - MCC: 0.2098\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 14ms/step - accuracy: 0.4682 - loss: 1.4658 - val_accuracy: 0.5656 - val_loss: 1.2065 - mcc: 0.2098\n",
      "Epoch 2/10\n",
      "\u001B[1m130/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5616 - loss: 1.2144\n",
      "Epoch 2 - MCC: 0.2049\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.5613 - loss: 1.2148 - val_accuracy: 0.5651 - val_loss: 1.2059 - mcc: 0.2049\n",
      "Epoch 3/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5600 - loss: 1.2170\n",
      "Epoch 3 - MCC: 0.2210\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5600 - loss: 1.2170 - val_accuracy: 0.5654 - val_loss: 1.2055 - mcc: 0.2210\n",
      "Epoch 4/10\n",
      "\u001B[1m146/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5577 - loss: 1.2207\n",
      "Epoch 4 - MCC: 0.2160\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5578 - loss: 1.2206 - val_accuracy: 0.5657 - val_loss: 1.2043 - mcc: 0.2160\n",
      "Epoch 5/10\n",
      "\u001B[1m140/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5601 - loss: 1.2189\n",
      "Epoch 5 - MCC: 0.2108\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.5601 - loss: 1.2188 - val_accuracy: 0.5658 - val_loss: 1.2045 - mcc: 0.2108\n",
      "Epoch 6/10\n",
      "\u001B[1m139/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5572 - loss: 1.2228\n",
      "Epoch 6 - MCC: 0.2156\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.5574 - loss: 1.2224 - val_accuracy: 0.5659 - val_loss: 1.2057 - mcc: 0.2156\n",
      "Epoch 7/10\n",
      "\u001B[1m144/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5598 - loss: 1.2158\n",
      "Epoch 7 - MCC: 0.2072\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.5598 - loss: 1.2160 - val_accuracy: 0.5651 - val_loss: 1.2052 - mcc: 0.2072\n",
      "Epoch 8/10\n",
      "\u001B[1m141/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5594 - loss: 1.2148\n",
      "Epoch 8 - MCC: 0.2065\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.5595 - loss: 1.2149 - val_accuracy: 0.5652 - val_loss: 1.2052 - mcc: 0.2065\n",
      "Epoch 9/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5591 - loss: 1.2171\n",
      "Epoch 9 - MCC: 0.1987\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.5591 - loss: 1.2172 - val_accuracy: 0.5639 - val_loss: 1.2061 - mcc: 0.1987\n",
      "Epoch 10/10\n",
      "\u001B[1m136/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5578 - loss: 1.2250\n",
      "Epoch 10 - MCC: 0.2053\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.5580 - loss: 1.2242 - val_accuracy: 0.5652 - val_loss: 1.2061 - mcc: 0.2053\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: FFN, Fold: 2\n",
      "Epoch 1/10\n",
      "\u001B[1m146/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4936 - loss: 1.4852\n",
      "Epoch 1 - MCC: 0.1087\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 12ms/step - accuracy: 0.4946 - loss: 1.4816 - val_accuracy: 0.5462 - val_loss: 1.2185 - mcc: 0.1087\n",
      "Epoch 2/10\n",
      "\u001B[1m142/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5472 - loss: 1.2303\n",
      "Epoch 2 - MCC: 0.1923\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.5472 - loss: 1.2301 - val_accuracy: 0.5630 - val_loss: 1.2061 - mcc: 0.1923\n",
      "Epoch 3/10\n",
      "\u001B[1m143/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5582 - loss: 1.2238\n",
      "Epoch 3 - MCC: 0.2117\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5582 - loss: 1.2235 - val_accuracy: 0.5660 - val_loss: 1.2046 - mcc: 0.2117\n",
      "Epoch 4/10\n",
      "\u001B[1m144/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5630 - loss: 1.2114\n",
      "Epoch 4 - MCC: 0.2152\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5629 - loss: 1.2117 - val_accuracy: 0.5660 - val_loss: 1.2025 - mcc: 0.2152\n",
      "Epoch 5/10\n",
      "\u001B[1m136/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5623 - loss: 1.2103\n",
      "Epoch 5 - MCC: 0.2116\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.5620 - loss: 1.2110 - val_accuracy: 0.5660 - val_loss: 1.2022 - mcc: 0.2116\n",
      "Epoch 6/10\n",
      "\u001B[1m145/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5604 - loss: 1.2141\n",
      "Epoch 6 - MCC: 0.2029\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.5603 - loss: 1.2143 - val_accuracy: 0.5653 - val_loss: 1.2034 - mcc: 0.2029\n",
      "Epoch 7/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5562 - loss: 1.2205\n",
      "Epoch 7 - MCC: 0.2063\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - accuracy: 0.5562 - loss: 1.2205 - val_accuracy: 0.5657 - val_loss: 1.2029 - mcc: 0.2063\n",
      "Epoch 8/10\n",
      "\u001B[1m140/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5642 - loss: 1.2092\n",
      "Epoch 8 - MCC: 0.2151\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.5639 - loss: 1.2098 - val_accuracy: 0.5660 - val_loss: 1.2018 - mcc: 0.2151\n",
      "Epoch 9/10\n",
      "\u001B[1m142/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5565 - loss: 1.2251\n",
      "Epoch 9 - MCC: 0.2084\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.5567 - loss: 1.2246 - val_accuracy: 0.5658 - val_loss: 1.2030 - mcc: 0.2084\n",
      "Epoch 10/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5623 - loss: 1.2125\n",
      "Epoch 10 - MCC: 0.2105\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5622 - loss: 1.2126 - val_accuracy: 0.5659 - val_loss: 1.2019 - mcc: 0.2105\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: FFN, Fold: 3\n",
      "Epoch 1/10\n",
      "\u001B[1m141/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5232 - loss: 1.4409\n",
      "Epoch 1 - MCC: 0.1965\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 13ms/step - accuracy: 0.5244 - loss: 1.4332 - val_accuracy: 0.5621 - val_loss: 1.2140 - mcc: 0.1965\n",
      "Epoch 2/10\n",
      "\u001B[1m145/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5608 - loss: 1.2124\n",
      "Epoch 2 - MCC: 0.2124\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5608 - loss: 1.2125 - val_accuracy: 0.5604 - val_loss: 1.2147 - mcc: 0.2124\n",
      "Epoch 3/10\n",
      "\u001B[1m141/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5589 - loss: 1.2234\n",
      "Epoch 3 - MCC: 0.2128\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.5591 - loss: 1.2229 - val_accuracy: 0.5602 - val_loss: 1.2152 - mcc: 0.2128\n",
      "Epoch 4/10\n",
      "\u001B[1m141/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5656 - loss: 1.2082\n",
      "Epoch 4 - MCC: 0.1996\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5653 - loss: 1.2087 - val_accuracy: 0.5623 - val_loss: 1.2125 - mcc: 0.1996\n",
      "Epoch 5/10\n",
      "\u001B[1m142/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5603 - loss: 1.2131\n",
      "Epoch 5 - MCC: 0.1991\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5603 - loss: 1.2132 - val_accuracy: 0.5623 - val_loss: 1.2145 - mcc: 0.1991\n",
      "Epoch 6/10\n",
      "\u001B[1m141/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5599 - loss: 1.2200\n",
      "Epoch 6 - MCC: 0.2072\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.5599 - loss: 1.2198 - val_accuracy: 0.5616 - val_loss: 1.2130 - mcc: 0.2072\n",
      "Epoch 7/10\n",
      "\u001B[1m136/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5605 - loss: 1.2176\n",
      "Epoch 7 - MCC: 0.1974\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.5606 - loss: 1.2173 - val_accuracy: 0.5622 - val_loss: 1.2122 - mcc: 0.1974\n",
      "Epoch 8/10\n",
      "\u001B[1m145/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5601 - loss: 1.2179\n",
      "Epoch 8 - MCC: 0.1925\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.5601 - loss: 1.2178 - val_accuracy: 0.5617 - val_loss: 1.2130 - mcc: 0.1925\n",
      "Epoch 9/10\n",
      "\u001B[1m134/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5585 - loss: 1.2183\n",
      "Epoch 9 - MCC: 0.2074\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5587 - loss: 1.2181 - val_accuracy: 0.5616 - val_loss: 1.2128 - mcc: 0.2074\n",
      "Epoch 10/10\n",
      "\u001B[1m137/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5620 - loss: 1.2166\n",
      "Epoch 10 - MCC: 0.2047\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.5619 - loss: 1.2165 - val_accuracy: 0.5620 - val_loss: 1.2129 - mcc: 0.2047\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: FFN, Fold: 4\n",
      "Epoch 1/10\n",
      "\u001B[1m146/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4937 - loss: 1.4661\n",
      "Epoch 1 - MCC: 0.1792\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 12ms/step - accuracy: 0.4949 - loss: 1.4625 - val_accuracy: 0.5518 - val_loss: 1.2353 - mcc: 0.1792\n",
      "Epoch 2/10\n",
      "\u001B[1m146/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5622 - loss: 1.2151\n",
      "Epoch 2 - MCC: 0.1878\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 4ms/step - accuracy: 0.5622 - loss: 1.2151 - val_accuracy: 0.5531 - val_loss: 1.2307 - mcc: 0.1878\n",
      "Epoch 3/10\n",
      "\u001B[1m144/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5616 - loss: 1.2149\n",
      "Epoch 3 - MCC: 0.2023\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - accuracy: 0.5616 - loss: 1.2148 - val_accuracy: 0.5541 - val_loss: 1.2299 - mcc: 0.2023\n",
      "Epoch 4/10\n",
      "\u001B[1m138/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5640 - loss: 1.2068\n",
      "Epoch 4 - MCC: 0.1970\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.5638 - loss: 1.2073 - val_accuracy: 0.5541 - val_loss: 1.2301 - mcc: 0.1970\n",
      "Epoch 5/10\n",
      "\u001B[1m141/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5601 - loss: 1.2151\n",
      "Epoch 5 - MCC: 0.2001\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.5602 - loss: 1.2149 - val_accuracy: 0.5541 - val_loss: 1.2291 - mcc: 0.2001\n",
      "Epoch 6/10\n",
      "\u001B[1m143/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5619 - loss: 1.2162\n",
      "Epoch 6 - MCC: 0.2026\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.5619 - loss: 1.2160 - val_accuracy: 0.5540 - val_loss: 1.2288 - mcc: 0.2026\n",
      "Epoch 7/10\n",
      "\u001B[1m139/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5642 - loss: 1.2107\n",
      "Epoch 7 - MCC: 0.1998\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.5641 - loss: 1.2108 - val_accuracy: 0.5543 - val_loss: 1.2284 - mcc: 0.1998\n",
      "Epoch 8/10\n",
      "\u001B[1m141/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5611 - loss: 1.2163\n",
      "Epoch 8 - MCC: 0.2044\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5612 - loss: 1.2160 - val_accuracy: 0.5537 - val_loss: 1.2288 - mcc: 0.2044\n",
      "Epoch 9/10\n",
      "\u001B[1m145/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5619 - loss: 1.2110\n",
      "Epoch 9 - MCC: 0.2002\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.5619 - loss: 1.2110 - val_accuracy: 0.5542 - val_loss: 1.2288 - mcc: 0.2002\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5648 - loss: 1.2050\n",
      "Epoch 10 - MCC: 0.1923\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.5647 - loss: 1.2051 - val_accuracy: 0.5537 - val_loss: 1.2286 - mcc: 0.1923\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: FFN, Fold: 5\n",
      "Epoch 1/10\n",
      "\u001B[1m145/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5384 - loss: 1.4172\n",
      "Epoch 1 - MCC: 0.2020\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 13ms/step - accuracy: 0.5387 - loss: 1.4129 - val_accuracy: 0.5578 - val_loss: 1.2249 - mcc: 0.2020\n",
      "Epoch 2/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5614 - loss: 1.2182\n",
      "Epoch 2 - MCC: 0.2007\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5614 - loss: 1.2181 - val_accuracy: 0.5577 - val_loss: 1.2234 - mcc: 0.2007\n",
      "Epoch 3/10\n",
      "\u001B[1m137/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5622 - loss: 1.2181\n",
      "Epoch 3 - MCC: 0.2097\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.5620 - loss: 1.2178 - val_accuracy: 0.5576 - val_loss: 1.2237 - mcc: 0.2097\n",
      "Epoch 4/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5599 - loss: 1.2184\n",
      "Epoch 4 - MCC: 0.2029\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.5599 - loss: 1.2183 - val_accuracy: 0.5576 - val_loss: 1.2231 - mcc: 0.2029\n",
      "Epoch 5/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5615 - loss: 1.2108\n",
      "Epoch 5 - MCC: 0.2081\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.5615 - loss: 1.2108 - val_accuracy: 0.5577 - val_loss: 1.2230 - mcc: 0.2081\n",
      "Epoch 6/10\n",
      "\u001B[1m130/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5596 - loss: 1.2190\n",
      "Epoch 6 - MCC: 0.2059\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5599 - loss: 1.2182 - val_accuracy: 0.5579 - val_loss: 1.2227 - mcc: 0.2059\n",
      "Epoch 7/10\n",
      "\u001B[1m146/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5634 - loss: 1.2060\n",
      "Epoch 7 - MCC: 0.2004\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.5634 - loss: 1.2062 - val_accuracy: 0.5578 - val_loss: 1.2236 - mcc: 0.2004\n",
      "Epoch 8/10\n",
      "\u001B[1m144/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5636 - loss: 1.2090\n",
      "Epoch 8 - MCC: 0.1979\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5635 - loss: 1.2093 - val_accuracy: 0.5577 - val_loss: 1.2232 - mcc: 0.1979\n",
      "Epoch 9/10\n",
      "\u001B[1m131/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5605 - loss: 1.2169\n",
      "Epoch 9 - MCC: 0.2098\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5606 - loss: 1.2165 - val_accuracy: 0.5574 - val_loss: 1.2237 - mcc: 0.2098\n",
      "Epoch 10/10\n",
      "\u001B[1m129/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5655 - loss: 1.2096\n",
      "Epoch 10 - MCC: 0.1940\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5650 - loss: 1.2100 - val_accuracy: 0.5572 - val_loss: 1.2246 - mcc: 0.1940\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': 0.5659266666666667,\n",
      "              'mean': 0.5608193333333334,\n",
      "              'min': 0.5536933333333334,\n",
      "              'std': 0.004695582037049994},\n",
      " 'Inference Time (s/sample)': {'max': 0.00035683592160542805,\n",
      "                               'mean': 0.00024469470977783205,\n",
      "                               'min': 0.00018439332644144693,\n",
      "                               'std': 7.209269686743835e-05},\n",
      " 'MCC': {'max': 0.21045891073996031,\n",
      "         'mean': 0.2013379324183838,\n",
      "         'min': 0.19230716278667465,\n",
      "         'std': 0.0069961739893413585},\n",
      " 'Parameters': 4117,\n",
      " 'Train Time (s)': {'max': 15.856249332427979,\n",
      "                    'mean': 14.264165449142457,\n",
      "                    'min': 12.252737760543823,\n",
      "                    'std': 1.3336210124193477},\n",
      " 'Training Accuracy': [[0.5248016715049744,\n",
      "                        0.559714138507843,\n",
      "                        0.5597366690635681,\n",
      "                        0.5599290728569031,\n",
      "                        0.5597491264343262,\n",
      "                        0.5598350167274475,\n",
      "                        0.5595608949661255,\n",
      "                        0.5596126914024353,\n",
      "                        0.5597199201583862,\n",
      "                        0.5598325133323669],\n",
      "                       [0.5241650342941284,\n",
      "                        0.5470575094223022,\n",
      "                        0.5596917271614075,\n",
      "                        0.559906005859375,\n",
      "                        0.5596534013748169,\n",
      "                        0.5597408413887024,\n",
      "                        0.5597917437553406,\n",
      "                        0.5598751902580261,\n",
      "                        0.5595843195915222,\n",
      "                        0.559402585029602],\n",
      "                       [0.5406867265701294,\n",
      "                        0.560698390007019,\n",
      "                        0.5608767867088318,\n",
      "                        0.5608115196228027,\n",
      "                        0.5608308911323547,\n",
      "                        0.5605791807174683,\n",
      "                        0.5607607364654541,\n",
      "                        0.5607824921607971,\n",
      "                        0.560840904712677,\n",
      "                        0.5605283379554749],\n",
      "                       [0.530674934387207,\n",
      "                        0.5625699758529663,\n",
      "                        0.5627282857894897,\n",
      "                        0.5626633763313293,\n",
      "                        0.5625383257865906,\n",
      "                        0.5627990365028381,\n",
      "                        0.5626407265663147,\n",
      "                        0.5626392960548401,\n",
      "                        0.5626425743103027,\n",
      "                        0.5626566410064697],\n",
      "                       [0.5468276143074036,\n",
      "                        0.5616499185562134,\n",
      "                        0.5615742206573486,\n",
      "                        0.5617173314094543,\n",
      "                        0.5615882873535156,\n",
      "                        0.561790943145752,\n",
      "                        0.5619083046913147,\n",
      "                        0.5615583658218384,\n",
      "                        0.5619099736213684,\n",
      "                        0.5621866583824158]],\n",
      " 'Training Loss': [[1.3454385995864868,\n",
      "                    1.217693567276001,\n",
      "                    1.21738600730896,\n",
      "                    1.2176035642623901,\n",
      "                    1.2176975011825562,\n",
      "                    1.2172261476516724,\n",
      "                    1.217742681503296,\n",
      "                    1.217402458190918,\n",
      "                    1.217535138130188,\n",
      "                    1.2165570259094238],\n",
      "                   [1.3741105794906616,\n",
      "                    1.2247803211212158,\n",
      "                    1.219537615776062,\n",
      "                    1.217938780784607,\n",
      "                    1.2183765172958374,\n",
      "                    1.2176517248153687,\n",
      "                    1.2180685997009277,\n",
      "                    1.217986822128296,\n",
      "                    1.217517375946045,\n",
      "                    1.2178199291229248],\n",
      "                   [1.3232970237731934,\n",
      "                    1.2156883478164673,\n",
      "                    1.2161426544189453,\n",
      "                    1.2154191732406616,\n",
      "                    1.2149689197540283,\n",
      "                    1.2156226634979248,\n",
      "                    1.2154555320739746,\n",
      "                    1.2149840593338013,\n",
      "                    1.215327501296997,\n",
      "                    1.215503454208374],\n",
      "                   [1.3549870252609253,\n",
      "                    1.2148834466934204,\n",
      "                    1.2125365734100342,\n",
      "                    1.2121278047561646,\n",
      "                    1.2115954160690308,\n",
      "                    1.2114109992980957,\n",
      "                    1.2116824388504028,\n",
      "                    1.2113419771194458,\n",
      "                    1.2112882137298584,\n",
      "                    1.2114472389221191],\n",
      "                   [1.3083125352859497,\n",
      "                    1.214646577835083,\n",
      "                    1.2137155532836914,\n",
      "                    1.2137348651885986,\n",
      "                    1.2132257223129272,\n",
      "                    1.2133878469467163,\n",
      "                    1.2123898267745972,\n",
      "                    1.2132855653762817,\n",
      "                    1.212693214416504,\n",
      "                    1.212570071220398]],\n",
      " 'Validation Accuracy': [[0.565593421459198,\n",
      "                          0.5651400685310364,\n",
      "                          0.5654333829879761,\n",
      "                          0.5657399892807007,\n",
      "                          0.5657733678817749,\n",
      "                          0.5658633708953857,\n",
      "                          0.5650966763496399,\n",
      "                          0.5652333498001099,\n",
      "                          0.5639432072639465,\n",
      "                          0.5651933550834656],\n",
      "                         [0.5461933612823486,\n",
      "                          0.563040018081665,\n",
      "                          0.5660034418106079,\n",
      "                          0.5660167336463928,\n",
      "                          0.5659966468811035,\n",
      "                          0.5653232932090759,\n",
      "                          0.5656632781028748,\n",
      "                          0.5660133361816406,\n",
      "                          0.565839946269989,\n",
      "                          0.565926730632782],\n",
      "                         [0.5621433258056641,\n",
      "                          0.5604066848754883,\n",
      "                          0.5602232813835144,\n",
      "                          0.5622866749763489,\n",
      "                          0.5622700452804565,\n",
      "                          0.5616366863250732,\n",
      "                          0.5622367262840271,\n",
      "                          0.5617067217826843,\n",
      "                          0.5616300702095032,\n",
      "                          0.5620368123054504],\n",
      "                         [0.5518032908439636,\n",
      "                          0.5531299710273743,\n",
      "                          0.5540832877159119,\n",
      "                          0.554110050201416,\n",
      "                          0.5541366934776306,\n",
      "                          0.5539667010307312,\n",
      "                          0.554276704788208,\n",
      "                          0.5536600351333618,\n",
      "                          0.5542232990264893,\n",
      "                          0.5536933541297913],\n",
      "                         [0.557753324508667,\n",
      "                          0.5576867461204529,\n",
      "                          0.5575833916664124,\n",
      "                          0.5576167702674866,\n",
      "                          0.5576700568199158,\n",
      "                          0.5578734278678894,\n",
      "                          0.5578433871269226,\n",
      "                          0.5576635003089905,\n",
      "                          0.5573834180831909,\n",
      "                          0.5572465658187866]],\n",
      " 'Validation Loss': [1.2248629331588745,\n",
      "                     1.2234456539154053,\n",
      "                     1.2236568927764893,\n",
      "                     1.2231439352035522,\n",
      "                     1.2230249643325806,\n",
      "                     1.2227312326431274,\n",
      "                     1.2236202955245972,\n",
      "                     1.2231512069702148,\n",
      "                     1.2236545085906982,\n",
      "                     1.224577784538269],\n",
      " 'Validation MCC': [[0.20977645165883876,\n",
      "                     0.2048503180743173,\n",
      "                     0.22104726762051594,\n",
      "                     0.21595388246566796,\n",
      "                     0.21080500282423487,\n",
      "                     0.2156084046088139,\n",
      "                     0.20722173366376495,\n",
      "                     0.20648818505705321,\n",
      "                     0.1986943388453731,\n",
      "                     0.2052512979279379],\n",
      "                    [0.10868455382765156,\n",
      "                     0.19227171745749128,\n",
      "                     0.21173835076005013,\n",
      "                     0.21517139428883553,\n",
      "                     0.21161854820738854,\n",
      "                     0.20286389367867214,\n",
      "                     0.20634793140851634,\n",
      "                     0.215061085810737,\n",
      "                     0.20844961607652443,\n",
      "                     0.21045891073996031],\n",
      "                    [0.19647154017463103,\n",
      "                     0.21237577018634032,\n",
      "                     0.21281550900126206,\n",
      "                     0.19964031891400258,\n",
      "                     0.19914709138113432,\n",
      "                     0.20715474724811583,\n",
      "                     0.19743758565770744,\n",
      "                     0.19254550350806326,\n",
      "                     0.2074145807098863,\n",
      "                     0.2046585730525887],\n",
      "                    [0.17918332354756433,\n",
      "                     0.1877900459877328,\n",
      "                     0.20229697587400639,\n",
      "                     0.19701257664643787,\n",
      "                     0.20005926726038248,\n",
      "                     0.20258506264113346,\n",
      "                     0.19982139294351003,\n",
      "                     0.20444381494374114,\n",
      "                     0.20020295968206,\n",
      "                     0.19230716278667465],\n",
      "                    [0.20195811053221868,\n",
      "                     0.20065646383976743,\n",
      "                     0.20970613798589632,\n",
      "                     0.20288472497871685,\n",
      "                     0.20813056593553222,\n",
      "                     0.20586638405112556,\n",
      "                     0.20039852975078842,\n",
      "                     0.19785912178252735,\n",
      "                     0.20976381388923568,\n",
      "                     0.19401371758475736]]}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "all_binary_model_results, trained_models = train_and_evaluate(simple_models_dict, X=all_data_vec, y=label_binary, epochs=10,\n",
    "                                                           dir_name=\"allF_binary\")\n",
    "\n",
    "basePath = \"/content/drive/MyDrive/Colab Notebooks/Bachelor Thesis/Data/Model Comparisons/\"\n",
    "filePath = f\"{basePath}/AllF_Binary_Model_Results.json\"\n",
    "\n",
    "with open(filePath, 'w') as f:\n",
    "        json.dump(all_binary_model_results, f, indent=4)  # indent=4 for pretty formatting"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_TPmM5d-i3D",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738742368326,
     "user_tz": -60,
     "elapsed": 1327274,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     }
    },
    "outputId": "3d14016c-2e22-41dc-a254-e4ecc9d3b1a5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 1\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.6777 - loss: 0.5885\n",
      "Epoch 1 - MCC: 0.6886\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 30ms/step - accuracy: 0.6789 - loss: 0.5871 - val_accuracy: 0.8429 - val_loss: 0.3468 - mcc: 0.6886\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8505 - loss: 0.3371\n",
      "Epoch 2 - MCC: 0.7294\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 20ms/step - accuracy: 0.8505 - loss: 0.3370 - val_accuracy: 0.8647 - val_loss: 0.3033 - mcc: 0.7294\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8640 - loss: 0.3033\n",
      "Epoch 3 - MCC: 0.7519\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 24ms/step - accuracy: 0.8641 - loss: 0.3033 - val_accuracy: 0.8762 - val_loss: 0.2813 - mcc: 0.7519\n",
      "Epoch 4/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8668 - loss: 0.2955\n",
      "Epoch 4 - MCC: 0.7655\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8668 - loss: 0.2954 - val_accuracy: 0.8831 - val_loss: 0.2632 - mcc: 0.7655\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8792 - loss: 0.2697\n",
      "Epoch 5 - MCC: 0.7728\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.8792 - loss: 0.2697 - val_accuracy: 0.8868 - val_loss: 0.2545 - mcc: 0.7728\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8808 - loss: 0.2655\n",
      "Epoch 6 - MCC: 0.7732\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8809 - loss: 0.2654 - val_accuracy: 0.8871 - val_loss: 0.2517 - mcc: 0.7732\n",
      "Epoch 7/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8858 - loss: 0.2563\n",
      "Epoch 7 - MCC: 0.7772\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 27ms/step - accuracy: 0.8858 - loss: 0.2563 - val_accuracy: 0.8890 - val_loss: 0.2485 - mcc: 0.7772\n",
      "Epoch 8/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8897 - loss: 0.2480\n",
      "Epoch 8 - MCC: 0.7856\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8896 - loss: 0.2481 - val_accuracy: 0.8933 - val_loss: 0.2397 - mcc: 0.7856\n",
      "Epoch 9/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8904 - loss: 0.2463\n",
      "Epoch 9 - MCC: 0.7892\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8903 - loss: 0.2463 - val_accuracy: 0.8949 - val_loss: 0.2380 - mcc: 0.7892\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8926 - loss: 0.2400\n",
      "Epoch 10 - MCC: 0.7888\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.8926 - loss: 0.2400 - val_accuracy: 0.8949 - val_loss: 0.2367 - mcc: 0.7888\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 2\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6915 - loss: 0.5793\n",
      "Epoch 1 - MCC: 0.6858\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 24ms/step - accuracy: 0.6926 - loss: 0.5780 - val_accuracy: 0.8433 - val_loss: 0.3518 - mcc: 0.6858\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8471 - loss: 0.3391\n",
      "Epoch 2 - MCC: 0.7248\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.8472 - loss: 0.3389 - val_accuracy: 0.8625 - val_loss: 0.3049 - mcc: 0.7248\n",
      "Epoch 3/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8650 - loss: 0.3000\n",
      "Epoch 3 - MCC: 0.7411\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.8651 - loss: 0.2998 - val_accuracy: 0.8711 - val_loss: 0.2838 - mcc: 0.7411\n",
      "Epoch 4/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8733 - loss: 0.2795\n",
      "Epoch 4 - MCC: 0.7568\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8733 - loss: 0.2795 - val_accuracy: 0.8787 - val_loss: 0.2699 - mcc: 0.7568\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8743 - loss: 0.2771\n",
      "Epoch 5 - MCC: 0.7660\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8743 - loss: 0.2770 - val_accuracy: 0.8828 - val_loss: 0.2576 - mcc: 0.7660\n",
      "Epoch 6/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8831 - loss: 0.2596\n",
      "Epoch 6 - MCC: 0.7690\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 25ms/step - accuracy: 0.8830 - loss: 0.2596 - val_accuracy: 0.8845 - val_loss: 0.2566 - mcc: 0.7690\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8855 - loss: 0.2528\n",
      "Epoch 7 - MCC: 0.7759\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8855 - loss: 0.2528 - val_accuracy: 0.8878 - val_loss: 0.2477 - mcc: 0.7759\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8852 - loss: 0.2539\n",
      "Epoch 8 - MCC: 0.7778\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.8852 - loss: 0.2538 - val_accuracy: 0.8893 - val_loss: 0.2451 - mcc: 0.7778\n",
      "Epoch 9/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8882 - loss: 0.2468\n",
      "Epoch 9 - MCC: 0.7810\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8882 - loss: 0.2468 - val_accuracy: 0.8906 - val_loss: 0.2415 - mcc: 0.7810\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8856 - loss: 0.2509\n",
      "Epoch 10 - MCC: 0.7868\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8857 - loss: 0.2508 - val_accuracy: 0.8937 - val_loss: 0.2371 - mcc: 0.7868\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 3\n",
      "Epoch 1/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7055 - loss: 0.5764\n",
      "Epoch 1 - MCC: 0.6659\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 24ms/step - accuracy: 0.7070 - loss: 0.5743 - val_accuracy: 0.8323 - val_loss: 0.3641 - mcc: 0.6659\n",
      "Epoch 2/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8532 - loss: 0.3306\n",
      "Epoch 2 - MCC: 0.6986\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8532 - loss: 0.3305 - val_accuracy: 0.8498 - val_loss: 0.3349 - mcc: 0.6986\n",
      "Epoch 3/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8619 - loss: 0.3055\n",
      "Epoch 3 - MCC: 0.7277\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.8620 - loss: 0.3053 - val_accuracy: 0.8644 - val_loss: 0.2993 - mcc: 0.7277\n",
      "Epoch 4/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8725 - loss: 0.2816\n",
      "Epoch 4 - MCC: 0.7333\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8726 - loss: 0.2815 - val_accuracy: 0.8672 - val_loss: 0.2901 - mcc: 0.7333\n",
      "Epoch 5/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8772 - loss: 0.2712\n",
      "Epoch 5 - MCC: 0.7410\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.8772 - loss: 0.2711 - val_accuracy: 0.8710 - val_loss: 0.2796 - mcc: 0.7410\n",
      "Epoch 6/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8792 - loss: 0.2677\n",
      "Epoch 6 - MCC: 0.7527\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 27ms/step - accuracy: 0.8793 - loss: 0.2675 - val_accuracy: 0.8770 - val_loss: 0.2697 - mcc: 0.7527\n",
      "Epoch 7/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8850 - loss: 0.2542\n",
      "Epoch 7 - MCC: 0.7531\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8850 - loss: 0.2541 - val_accuracy: 0.8772 - val_loss: 0.2735 - mcc: 0.7531\n",
      "Epoch 8/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8865 - loss: 0.2522\n",
      "Epoch 8 - MCC: 0.7601\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8865 - loss: 0.2521 - val_accuracy: 0.8800 - val_loss: 0.2637 - mcc: 0.7601\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8916 - loss: 0.2407\n",
      "Epoch 9 - MCC: 0.7574\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 25ms/step - accuracy: 0.8916 - loss: 0.2407 - val_accuracy: 0.8793 - val_loss: 0.2632 - mcc: 0.7574\n",
      "Epoch 10/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8926 - loss: 0.2388\n",
      "Epoch 10 - MCC: 0.7660\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 22ms/step - accuracy: 0.8926 - loss: 0.2388 - val_accuracy: 0.8836 - val_loss: 0.2552 - mcc: 0.7660\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 4\n",
      "Epoch 1/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7224 - loss: 0.5651\n",
      "Epoch 1 - MCC: 0.6693\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 22ms/step - accuracy: 0.7241 - loss: 0.5625 - val_accuracy: 0.8339 - val_loss: 0.3735 - mcc: 0.6693\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8430 - loss: 0.3489\n",
      "Epoch 2 - MCC: 0.7119\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 27ms/step - accuracy: 0.8431 - loss: 0.3488 - val_accuracy: 0.8558 - val_loss: 0.3190 - mcc: 0.7119\n",
      "Epoch 3/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8609 - loss: 0.3105\n",
      "Epoch 3 - MCC: 0.7422\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.8609 - loss: 0.3105 - val_accuracy: 0.8718 - val_loss: 0.2889 - mcc: 0.7422\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8688 - loss: 0.2928\n",
      "Epoch 4 - MCC: 0.7536\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.8688 - loss: 0.2927 - val_accuracy: 0.8773 - val_loss: 0.2748 - mcc: 0.7536\n",
      "Epoch 5/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8752 - loss: 0.2772\n",
      "Epoch 5 - MCC: 0.7564\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 25ms/step - accuracy: 0.8752 - loss: 0.2772 - val_accuracy: 0.8786 - val_loss: 0.2681 - mcc: 0.7564\n",
      "Epoch 6/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8800 - loss: 0.2664\n",
      "Epoch 6 - MCC: 0.7669\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.8800 - loss: 0.2663 - val_accuracy: 0.8841 - val_loss: 0.2562 - mcc: 0.7669\n",
      "Epoch 7/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8797 - loss: 0.2643\n",
      "Epoch 7 - MCC: 0.7692\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8797 - loss: 0.2643 - val_accuracy: 0.8852 - val_loss: 0.2542 - mcc: 0.7692\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8863 - loss: 0.2523\n",
      "Epoch 8 - MCC: 0.7693\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8863 - loss: 0.2523 - val_accuracy: 0.8845 - val_loss: 0.2527 - mcc: 0.7693\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8892 - loss: 0.2452\n",
      "Epoch 9 - MCC: 0.7799\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.8892 - loss: 0.2453 - val_accuracy: 0.8904 - val_loss: 0.2459 - mcc: 0.7799\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8889 - loss: 0.2464\n",
      "Epoch 10 - MCC: 0.7794\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8889 - loss: 0.2464 - val_accuracy: 0.8902 - val_loss: 0.2437 - mcc: 0.7794\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 5\n",
      "Epoch 1/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.6869 - loss: 0.5805\n",
      "Epoch 1 - MCC: 0.6819\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.6886 - loss: 0.5783 - val_accuracy: 0.8410 - val_loss: 0.3493 - mcc: 0.6819\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8504 - loss: 0.3320\n",
      "Epoch 2 - MCC: 0.7212\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8504 - loss: 0.3319 - val_accuracy: 0.8609 - val_loss: 0.3070 - mcc: 0.7212\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8694 - loss: 0.2886\n",
      "Epoch 3 - MCC: 0.7412\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.8694 - loss: 0.2886 - val_accuracy: 0.8707 - val_loss: 0.2874 - mcc: 0.7412\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8742 - loss: 0.2766\n",
      "Epoch 4 - MCC: 0.7501\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 25ms/step - accuracy: 0.8742 - loss: 0.2766 - val_accuracy: 0.8754 - val_loss: 0.2735 - mcc: 0.7501\n",
      "Epoch 5/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8810 - loss: 0.2618\n",
      "Epoch 5 - MCC: 0.7456\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8810 - loss: 0.2618 - val_accuracy: 0.8726 - val_loss: 0.2749 - mcc: 0.7456\n",
      "Epoch 6/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8840 - loss: 0.2575\n",
      "Epoch 6 - MCC: 0.7618\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8840 - loss: 0.2575 - val_accuracy: 0.8811 - val_loss: 0.2600 - mcc: 0.7618\n",
      "Epoch 7/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8836 - loss: 0.2557\n",
      "Epoch 7 - MCC: 0.7687\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8836 - loss: 0.2555 - val_accuracy: 0.8847 - val_loss: 0.2548 - mcc: 0.7687\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8892 - loss: 0.2477\n",
      "Epoch 8 - MCC: 0.7646\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 28ms/step - accuracy: 0.8892 - loss: 0.2477 - val_accuracy: 0.8827 - val_loss: 0.2569 - mcc: 0.7646\n",
      "Epoch 9/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8890 - loss: 0.2454\n",
      "Epoch 9 - MCC: 0.7741\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.8890 - loss: 0.2453 - val_accuracy: 0.8874 - val_loss: 0.2480 - mcc: 0.7741\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8939 - loss: 0.2370\n",
      "Epoch 10 - MCC: 0.7766\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 24ms/step - accuracy: 0.8938 - loss: 0.2370 - val_accuracy: 0.8885 - val_loss: 0.2509 - mcc: 0.7766\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': 0.8948733333333333,\n",
      "              'mean': 0.8901939999999999,\n",
      "              'min': 0.8836433333333333,\n",
      "              'std': 0.004006611979660059},\n",
      " 'Inference Time (s/sample)': {'max': 0.0006527165571848551,\n",
      "                               'mean': 0.0005779352188110352,\n",
      "                               'min': 0.00043410936991373697,\n",
      "                               'std': 7.616765535547334e-05},\n",
      " 'MCC': {'max': 0.7888195634786799,\n",
      "         'mean': 0.7795283522767983,\n",
      "         'min': 0.7660304800064799,\n",
      "         'std': 0.008132138113543304},\n",
      " 'Parameters': 7457,\n",
      " 'Train Time (s)': {'max': 47.27640509605408,\n",
      "                    'mean': 42.657781982421874,\n",
      "                    'min': 40.25798439979553,\n",
      "                    'std': 2.436555337947445},\n",
      " 'Training Accuracy': [[0.7684540152549744,\n",
      "                        0.8528773188591003,\n",
      "                        0.8678316473960876,\n",
      "                        0.8743700981140137,\n",
      "                        0.8796499371528625,\n",
      "                        0.8835723996162415,\n",
      "                        0.8853808641433716,\n",
      "                        0.8873332738876343,\n",
      "                        0.8895010352134705,\n",
      "                        0.8896719217300415],\n",
      "                       [0.7722726464271545,\n",
      "                        0.8533200025558472,\n",
      "                        0.866905927658081,\n",
      "                        0.873284101486206,\n",
      "                        0.8776158690452576,\n",
      "                        0.8816891312599182,\n",
      "                        0.8832716941833496,\n",
      "                        0.8862349390983582,\n",
      "                        0.8878293037414551,\n",
      "                        0.8890308737754822],\n",
      "                       [0.7812417149543762,\n",
      "                        0.8538016676902771,\n",
      "                        0.8679109811782837,\n",
      "                        0.8743651509284973,\n",
      "                        0.8811733722686768,\n",
      "                        0.8844724297523499,\n",
      "                        0.8866292238235474,\n",
      "                        0.8884918093681335,\n",
      "                        0.8915897607803345,\n",
      "                        0.8928456902503967],\n",
      "                       [0.7837858200073242,\n",
      "                        0.8460097908973694,\n",
      "                        0.8627116084098816,\n",
      "                        0.8712832927703857,\n",
      "                        0.8761476874351501,\n",
      "                        0.880691409111023,\n",
      "                        0.8832295536994934,\n",
      "                        0.8854930400848389,\n",
      "                        0.8884317278862,\n",
      "                        0.8899217844009399],\n",
      "                       [0.7721250653266907,\n",
      "                        0.8549507856369019,\n",
      "                        0.8692581057548523,\n",
      "                        0.8766276240348816,\n",
      "                        0.8804948925971985,\n",
      "                        0.8841034173965454,\n",
      "                        0.8866849541664124,\n",
      "                        0.8897472023963928,\n",
      "                        0.8911281228065491,\n",
      "                        0.8924592137336731]],\n",
      " 'Training Loss': [[0.4798179566860199,\n",
      "                    0.32848161458969116,\n",
      "                    0.2959578037261963,\n",
      "                    0.280610054731369,\n",
      "                    0.2692098915576935,\n",
      "                    0.2609790563583374,\n",
      "                    0.25565284490585327,\n",
      "                    0.25167161226272583,\n",
      "                    0.24701426923274994,\n",
      "                    0.24631018936634064],\n",
      "                   [0.4767102599143982,\n",
      "                    0.32645559310913086,\n",
      "                    0.2944416105747223,\n",
      "                    0.27908092737197876,\n",
      "                    0.26868516206741333,\n",
      "                    0.26077964901924133,\n",
      "                    0.2563093602657318,\n",
      "                    0.25018393993377686,\n",
      "                    0.24658825993537903,\n",
      "                    0.2434016466140747],\n",
      "                   [0.46970856189727783,\n",
      "                    0.32632240653038025,\n",
      "                    0.2933998703956604,\n",
      "                    0.2781088054180145,\n",
      "                    0.2646663188934326,\n",
      "                    0.25697144865989685,\n",
      "                    0.2507358193397522,\n",
      "                    0.24656392633914948,\n",
      "                    0.24109160900115967,\n",
      "                    0.23754765093326569],\n",
      "                   [0.4686785936355591,\n",
      "                    0.34203049540519714,\n",
      "                    0.3070753812789917,\n",
      "                    0.28760775923728943,\n",
      "                    0.2744690477848053,\n",
      "                    0.2648172080516815,\n",
      "                    0.2582845687866211,\n",
      "                    0.252503365278244,\n",
      "                    0.2476501762866974,\n",
      "                    0.2439487725496292],\n",
      "                   [0.47237956523895264,\n",
      "                    0.32004156708717346,\n",
      "                    0.28903448581695557,\n",
      "                    0.2724040150642395,\n",
      "                    0.263808935880661,\n",
      "                    0.256404846906662,\n",
      "                    0.2502560615539551,\n",
      "                    0.245429128408432,\n",
      "                    0.24141380190849304,\n",
      "                    0.23872850835323334]],\n",
      " 'Validation Accuracy': [[0.8428931832313538,\n",
      "                          0.8646699786186218,\n",
      "                          0.8761968016624451,\n",
      "                          0.8830533623695374,\n",
      "                          0.8867934346199036,\n",
      "                          0.8870899677276611,\n",
      "                          0.8890232443809509,\n",
      "                          0.8932666182518005,\n",
      "                          0.8949232697486877,\n",
      "                          0.8948733806610107],\n",
      "                         [0.8432601094245911,\n",
      "                          0.8624734282493591,\n",
      "                          0.8710700273513794,\n",
      "                          0.8786799311637878,\n",
      "                          0.8828465938568115,\n",
      "                          0.8844699263572693,\n",
      "                          0.8878433108329773,\n",
      "                          0.8892533183097839,\n",
      "                          0.89055997133255,\n",
      "                          0.893746554851532],\n",
      "                         [0.8323233127593994,\n",
      "                          0.8497968316078186,\n",
      "                          0.8643999099731445,\n",
      "                          0.8672400116920471,\n",
      "                          0.8709666132926941,\n",
      "                          0.8769832253456116,\n",
      "                          0.8772266507148743,\n",
      "                          0.8800132274627686,\n",
      "                          0.879319965839386,\n",
      "                          0.883643388748169],\n",
      "                         [0.8338832855224609,\n",
      "                          0.8557600975036621,\n",
      "                          0.8718432784080505,\n",
      "                          0.8773033618927002,\n",
      "                          0.8785797953605652,\n",
      "                          0.8840867877006531,\n",
      "                          0.8852400779724121,\n",
      "                          0.8844533562660217,\n",
      "                          0.8904066681861877,\n",
      "                          0.8901967406272888],\n",
      "                         [0.8409866690635681,\n",
      "                          0.8608798980712891,\n",
      "                          0.870673418045044,\n",
      "                          0.8754466772079468,\n",
      "                          0.872640073299408,\n",
      "                          0.8810766339302063,\n",
      "                          0.8847200274467468,\n",
      "                          0.8826932907104492,\n",
      "                          0.8874166011810303,\n",
      "                          0.8885100483894348]],\n",
      " 'Validation Loss': [0.3493282198905945,\n",
      "                     0.30699148774147034,\n",
      "                     0.2873823940753937,\n",
      "                     0.27347588539123535,\n",
      "                     0.2749294340610504,\n",
      "                     0.25996536016464233,\n",
      "                     0.25482553243637085,\n",
      "                     0.25693872570991516,\n",
      "                     0.2479732483625412,\n",
      "                     0.25088071823120117],\n",
      " 'Validation MCC': [[0.6885822365403078,\n",
      "                     0.7293550401915556,\n",
      "                     0.7519312047036678,\n",
      "                     0.7655314133690261,\n",
      "                     0.7728320782987367,\n",
      "                     0.773204751771443,\n",
      "                     0.7771559786018105,\n",
      "                     0.7856336361891361,\n",
      "                     0.7892048508685694,\n",
      "                     0.7888195634786799],\n",
      "                    [0.6857592986207879,\n",
      "                     0.7248349461555631,\n",
      "                     0.7410931301831193,\n",
      "                     0.7568240879084914,\n",
      "                     0.7660478857062002,\n",
      "                     0.7689997528554968,\n",
      "                     0.7759484291941777,\n",
      "                     0.7778250891387657,\n",
      "                     0.7810242940523988,\n",
      "                     0.7868328205836704],\n",
      "                    [0.6659453890696461,\n",
      "                     0.6986496213072662,\n",
      "                     0.72774916378067,\n",
      "                     0.7332791481410121,\n",
      "                     0.7410495905495997,\n",
      "                     0.752665575764452,\n",
      "                     0.7531060451049665,\n",
      "                     0.7600804959665469,\n",
      "                     0.7574410659182987,\n",
      "                     0.7660304800064799],\n",
      "                    [0.6693324012869338,\n",
      "                     0.7118735196906609,\n",
      "                     0.7421646339326428,\n",
      "                     0.7536043851580687,\n",
      "                     0.7563851814136425,\n",
      "                     0.7668574707039363,\n",
      "                     0.7691838809844691,\n",
      "                     0.76926732208564,\n",
      "                     0.7799169864051577,\n",
      "                     0.7793911370041303],\n",
      "                    [0.6818989524125598,\n",
      "                     0.7211617112955415,\n",
      "                     0.7412316960805773,\n",
      "                     0.7500615245328843,\n",
      "                     0.745622418505831,\n",
      "                     0.7617546315158418,\n",
      "                     0.7686761949818824,\n",
      "                     0.7645993943015057,\n",
      "                     0.7740872654483101,\n",
      "                     0.7765677603110311]]}\n",
      "Training Model: BiLSTM, Fold: 1\n",
      "Epoch 1/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.7265 - loss: 0.5658\n",
      "Epoch 1 - MCC: 0.7454\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 41ms/step - accuracy: 0.7281 - loss: 0.5634 - val_accuracy: 0.8725 - val_loss: 0.2994 - mcc: 0.7454\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8675 - loss: 0.3016\n",
      "Epoch 2 - MCC: 0.7813\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.8676 - loss: 0.3015 - val_accuracy: 0.8911 - val_loss: 0.2544 - mcc: 0.7813\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.8821 - loss: 0.2677\n",
      "Epoch 3 - MCC: 0.7957\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 41ms/step - accuracy: 0.8822 - loss: 0.2676 - val_accuracy: 0.8979 - val_loss: 0.2336 - mcc: 0.7957\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8924 - loss: 0.2458\n",
      "Epoch 4 - MCC: 0.8042\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 35ms/step - accuracy: 0.8924 - loss: 0.2458 - val_accuracy: 0.9022 - val_loss: 0.2251 - mcc: 0.8042\n",
      "Epoch 5/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8976 - loss: 0.2348\n",
      "Epoch 5 - MCC: 0.8096\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 33ms/step - accuracy: 0.8976 - loss: 0.2348 - val_accuracy: 0.9049 - val_loss: 0.2227 - mcc: 0.8096\n",
      "Epoch 6/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9012 - loss: 0.2250\n",
      "Epoch 6 - MCC: 0.8159\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 43ms/step - accuracy: 0.9012 - loss: 0.2250 - val_accuracy: 0.9081 - val_loss: 0.2108 - mcc: 0.8159\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9013 - loss: 0.2251\n",
      "Epoch 7 - MCC: 0.8216\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 34ms/step - accuracy: 0.9013 - loss: 0.2251 - val_accuracy: 0.9112 - val_loss: 0.2057 - mcc: 0.8216\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.9036 - loss: 0.2178\n",
      "Epoch 8 - MCC: 0.8260\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 42ms/step - accuracy: 0.9036 - loss: 0.2178 - val_accuracy: 0.9133 - val_loss: 0.1990 - mcc: 0.8260\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9066 - loss: 0.2113\n",
      "Epoch 9 - MCC: 0.8232\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 36ms/step - accuracy: 0.9066 - loss: 0.2112 - val_accuracy: 0.9113 - val_loss: 0.2048 - mcc: 0.8232\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9099 - loss: 0.2030\n",
      "Epoch 10 - MCC: 0.8317\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 33ms/step - accuracy: 0.9099 - loss: 0.2031 - val_accuracy: 0.9162 - val_loss: 0.1925 - mcc: 0.8317\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 2\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.7130 - loss: 0.5622\n",
      "Epoch 1 - MCC: 0.7403\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 41ms/step - accuracy: 0.7136 - loss: 0.5614 - val_accuracy: 0.8707 - val_loss: 0.3047 - mcc: 0.7403\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8619 - loss: 0.3158\n",
      "Epoch 2 - MCC: 0.7582\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 45ms/step - accuracy: 0.8620 - loss: 0.3155 - val_accuracy: 0.8783 - val_loss: 0.2804 - mcc: 0.7582\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8828 - loss: 0.2717\n",
      "Epoch 3 - MCC: 0.7796\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.8828 - loss: 0.2717 - val_accuracy: 0.8901 - val_loss: 0.2534 - mcc: 0.7796\n",
      "Epoch 4/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8909 - loss: 0.2538\n",
      "Epoch 4 - MCC: 0.7884\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 36ms/step - accuracy: 0.8909 - loss: 0.2538 - val_accuracy: 0.8939 - val_loss: 0.2430 - mcc: 0.7884\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8863 - loss: 0.2558\n",
      "Epoch 5 - MCC: 0.8004\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 34ms/step - accuracy: 0.8864 - loss: 0.2557 - val_accuracy: 0.9006 - val_loss: 0.2278 - mcc: 0.8004\n",
      "Epoch 6/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.9012 - loss: 0.2251\n",
      "Epoch 6 - MCC: 0.8047\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 40ms/step - accuracy: 0.9012 - loss: 0.2252 - val_accuracy: 0.9028 - val_loss: 0.2225 - mcc: 0.8047\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8967 - loss: 0.2331\n",
      "Epoch 7 - MCC: 0.8090\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 33ms/step - accuracy: 0.8967 - loss: 0.2329 - val_accuracy: 0.9047 - val_loss: 0.2150 - mcc: 0.8090\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.9097 - loss: 0.2072\n",
      "Epoch 8 - MCC: 0.8057\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 40ms/step - accuracy: 0.9097 - loss: 0.2073 - val_accuracy: 0.9023 - val_loss: 0.2198 - mcc: 0.8057\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9060 - loss: 0.2117\n",
      "Epoch 9 - MCC: 0.8137\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 36ms/step - accuracy: 0.9060 - loss: 0.2117 - val_accuracy: 0.9068 - val_loss: 0.2095 - mcc: 0.8137\n",
      "Epoch 10/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9056 - loss: 0.2112\n",
      "Epoch 10 - MCC: 0.8223\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 33ms/step - accuracy: 0.9057 - loss: 0.2111 - val_accuracy: 0.9114 - val_loss: 0.2031 - mcc: 0.8223\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 3\n",
      "Epoch 1/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.7229 - loss: 0.5523\n",
      "Epoch 1 - MCC: 0.7066\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 42ms/step - accuracy: 0.7245 - loss: 0.5499 - val_accuracy: 0.8518 - val_loss: 0.3237 - mcc: 0.7066\n",
      "Epoch 2/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8743 - loss: 0.2892\n",
      "Epoch 2 - MCC: 0.7397\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.8743 - loss: 0.2891 - val_accuracy: 0.8692 - val_loss: 0.2974 - mcc: 0.7397\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8835 - loss: 0.2657\n",
      "Epoch 3 - MCC: 0.7536\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 40ms/step - accuracy: 0.8835 - loss: 0.2657 - val_accuracy: 0.8774 - val_loss: 0.2731 - mcc: 0.7536\n",
      "Epoch 4/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8904 - loss: 0.2503\n",
      "Epoch 4 - MCC: 0.7708\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.8904 - loss: 0.2503 - val_accuracy: 0.8858 - val_loss: 0.2588 - mcc: 0.7708\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8955 - loss: 0.2388\n",
      "Epoch 5 - MCC: 0.7740\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 41ms/step - accuracy: 0.8955 - loss: 0.2388 - val_accuracy: 0.8866 - val_loss: 0.2528 - mcc: 0.7740\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9018 - loss: 0.2266\n",
      "Epoch 6 - MCC: 0.7793\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.9018 - loss: 0.2266 - val_accuracy: 0.8902 - val_loss: 0.2429 - mcc: 0.7793\n",
      "Epoch 7/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.9013 - loss: 0.2246\n",
      "Epoch 7 - MCC: 0.7900\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.9013 - loss: 0.2245 - val_accuracy: 0.8956 - val_loss: 0.2327 - mcc: 0.7900\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.9085 - loss: 0.2117\n",
      "Epoch 8 - MCC: 0.7863\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 40ms/step - accuracy: 0.9084 - loss: 0.2118 - val_accuracy: 0.8927 - val_loss: 0.2388 - mcc: 0.7863\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9070 - loss: 0.2112\n",
      "Epoch 9 - MCC: 0.7979\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.9071 - loss: 0.2112 - val_accuracy: 0.8993 - val_loss: 0.2281 - mcc: 0.7979\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9072 - loss: 0.2100\n",
      "Epoch 10 - MCC: 0.7887\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 42ms/step - accuracy: 0.9073 - loss: 0.2100 - val_accuracy: 0.8939 - val_loss: 0.2355 - mcc: 0.7887\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 4\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7428 - loss: 0.5553\n",
      "Epoch 1 - MCC: 0.7330\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 41ms/step - accuracy: 0.7432 - loss: 0.5545 - val_accuracy: 0.8669 - val_loss: 0.3061 - mcc: 0.7330\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8724 - loss: 0.2985\n",
      "Epoch 2 - MCC: 0.7606\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 33ms/step - accuracy: 0.8724 - loss: 0.2984 - val_accuracy: 0.8810 - val_loss: 0.2757 - mcc: 0.7606\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8833 - loss: 0.2722\n",
      "Epoch 3 - MCC: 0.7739\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 41ms/step - accuracy: 0.8833 - loss: 0.2722 - val_accuracy: 0.8873 - val_loss: 0.2585 - mcc: 0.7739\n",
      "Epoch 4/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.8878 - loss: 0.2586\n",
      "Epoch 4 - MCC: 0.7783\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 36ms/step - accuracy: 0.8878 - loss: 0.2585 - val_accuracy: 0.8896 - val_loss: 0.2494 - mcc: 0.7783\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.8931 - loss: 0.2470\n",
      "Epoch 5 - MCC: 0.7884\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 40ms/step - accuracy: 0.8931 - loss: 0.2470 - val_accuracy: 0.8946 - val_loss: 0.2385 - mcc: 0.7884\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8957 - loss: 0.2377\n",
      "Epoch 6 - MCC: 0.7962\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.8958 - loss: 0.2377 - val_accuracy: 0.8986 - val_loss: 0.2317 - mcc: 0.7962\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8998 - loss: 0.2314\n",
      "Epoch 7 - MCC: 0.7966\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 34ms/step - accuracy: 0.8998 - loss: 0.2313 - val_accuracy: 0.8988 - val_loss: 0.2297 - mcc: 0.7966\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.9025 - loss: 0.2233\n",
      "Epoch 8 - MCC: 0.8054\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 45ms/step - accuracy: 0.9025 - loss: 0.2233 - val_accuracy: 0.9033 - val_loss: 0.2203 - mcc: 0.8054\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9047 - loss: 0.2179\n",
      "Epoch 9 - MCC: 0.8041\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 35ms/step - accuracy: 0.9047 - loss: 0.2178 - val_accuracy: 0.9025 - val_loss: 0.2190 - mcc: 0.8041\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.9061 - loss: 0.2136\n",
      "Epoch 10 - MCC: 0.8075\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 45ms/step - accuracy: 0.9061 - loss: 0.2136 - val_accuracy: 0.9041 - val_loss: 0.2147 - mcc: 0.8075\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 5\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.7053 - loss: 0.5716\n",
      "Epoch 1 - MCC: 0.7225\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 46ms/step - accuracy: 0.7065 - loss: 0.5699 - val_accuracy: 0.8617 - val_loss: 0.3180 - mcc: 0.7225\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8750 - loss: 0.2917\n",
      "Epoch 2 - MCC: 0.7549\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.8750 - loss: 0.2917 - val_accuracy: 0.8774 - val_loss: 0.2813 - mcc: 0.7549\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8811 - loss: 0.2713\n",
      "Epoch 3 - MCC: 0.7715\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 41ms/step - accuracy: 0.8812 - loss: 0.2711 - val_accuracy: 0.8861 - val_loss: 0.2629 - mcc: 0.7715\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8959 - loss: 0.2420\n",
      "Epoch 4 - MCC: 0.7834\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 35ms/step - accuracy: 0.8959 - loss: 0.2420 - val_accuracy: 0.8914 - val_loss: 0.2522 - mcc: 0.7834\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8961 - loss: 0.2401\n",
      "Epoch 5 - MCC: 0.7881\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 34ms/step - accuracy: 0.8961 - loss: 0.2400 - val_accuracy: 0.8941 - val_loss: 0.2385 - mcc: 0.7881\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.8993 - loss: 0.2297\n",
      "Epoch 6 - MCC: 0.7945\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 35ms/step - accuracy: 0.8993 - loss: 0.2296 - val_accuracy: 0.8970 - val_loss: 0.2395 - mcc: 0.7945\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9052 - loss: 0.2155\n",
      "Epoch 7 - MCC: 0.7925\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.9052 - loss: 0.2156 - val_accuracy: 0.8961 - val_loss: 0.2324 - mcc: 0.7925\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.9043 - loss: 0.2180\n",
      "Epoch 8 - MCC: 0.8028\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 41ms/step - accuracy: 0.9043 - loss: 0.2180 - val_accuracy: 0.9016 - val_loss: 0.2269 - mcc: 0.8028\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9062 - loss: 0.2125\n",
      "Epoch 9 - MCC: 0.8041\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.9062 - loss: 0.2125 - val_accuracy: 0.9022 - val_loss: 0.2175 - mcc: 0.8041\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9077 - loss: 0.2096\n",
      "Epoch 10 - MCC: 0.8082\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 44ms/step - accuracy: 0.9077 - loss: 0.2096 - val_accuracy: 0.9044 - val_loss: 0.2163 - mcc: 0.8082\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': 0.9162266666666666,\n",
      "              'mean': 0.9059986666666665,\n",
      "              'min': 0.8938566666666666,\n",
      "              'std': 0.007583061416370332},\n",
      " 'Inference Time (s/sample)': {'max': 0.0011786886056264242,\n",
      "                               'mean': 0.0007615924676259359,\n",
      "                               'min': 0.0005896874268849691,\n",
      "                               'std': 0.00021903660858292262},\n",
      " 'MCC': {'max': 0.8317403450676765,\n",
      "         'mean': 0.8116720240510815,\n",
      "         'min': 0.7886971759459119,\n",
      "         'std': 0.014648129071521635},\n",
      " 'Parameters': 8493,\n",
      " 'Train Time (s)': {'max': 85.01595163345337,\n",
      "                    'mean': 76.28683896064759,\n",
      "                    'min': 58.50830626487732,\n",
      "                    'std': 9.285696809541601},\n",
      " 'Training Accuracy': [[0.8076426982879639,\n",
      "                        0.8745482563972473,\n",
      "                        0.8859974145889282,\n",
      "                        0.8932964205741882,\n",
      "                        0.8973481059074402,\n",
      "                        0.9004834890365601,\n",
      "                        0.9035127758979797,\n",
      "                        0.9051981568336487,\n",
      "                        0.9076306223869324,\n",
      "                        0.9082425832748413],\n",
      "                       [0.7989174127578735,\n",
      "                        0.8718319535255432,\n",
      "                        0.8816075921058655,\n",
      "                        0.8891191482543945,\n",
      "                        0.8934303522109985,\n",
      "                        0.8987482786178589,\n",
      "                        0.9014700055122375,\n",
      "                        0.9046664237976074,\n",
      "                        0.9054582715034485,\n",
      "                        0.9071908593177795],\n",
      "                       [0.8054485321044922,\n",
      "                        0.8744398951530457,\n",
      "                        0.8836148977279663,\n",
      "                        0.8905742168426514,\n",
      "                        0.8951590061187744,\n",
      "                        0.9009331464767456,\n",
      "                        0.9036218523979187,\n",
      "                        0.9073116183280945,\n",
      "                        0.9082596898078918,\n",
      "                        0.9110209941864014],\n",
      "                       [0.8134873509407043,\n",
      "                        0.8744449019432068,\n",
      "                        0.8828244209289551,\n",
      "                        0.88937908411026,\n",
      "                        0.8942041993141174,\n",
      "                        0.8966398239135742,\n",
      "                        0.9010299444198608,\n",
      "                        0.902111828327179,\n",
      "                        0.9046314358711243,\n",
      "                        0.9066576361656189],\n",
      "                       [0.796359121799469,\n",
      "                        0.8751807808876038,\n",
      "                        0.8859916925430298,\n",
      "                        0.8932965993881226,\n",
      "                        0.8974114060401917,\n",
      "                        0.9002187848091125,\n",
      "                        0.902701735496521,\n",
      "                        0.9042925238609314,\n",
      "                        0.907254159450531,\n",
      "                        0.9096744060516357]],\n",
      " 'Training Loss': [[0.44212594628334045,\n",
      "                    0.28633955121040344,\n",
      "                    0.25954970717430115,\n",
      "                    0.24356941878795624,\n",
      "                    0.23310402035713196,\n",
      "                    0.22595326602458954,\n",
      "                    0.21983139216899872,\n",
      "                    0.2147880494594574,\n",
      "                    0.209547758102417,\n",
      "                    0.20624741911888123],\n",
      "                   [0.44324639439582825,\n",
      "                    0.2966727316379547,\n",
      "                    0.2730860114097595,\n",
      "                    0.2545869052410126,\n",
      "                    0.24246792495250702,\n",
      "                    0.23015543818473816,\n",
      "                    0.22336052358150482,\n",
      "                    0.2157098948955536,\n",
      "                    0.2132245898246765,\n",
      "                    0.20891989767551422],\n",
      "                   [0.429458349943161,\n",
      "                    0.28713908791542053,\n",
      "                    0.26455801725387573,\n",
      "                    0.24822883307933807,\n",
      "                    0.2395048290491104,\n",
      "                    0.22795666754245758,\n",
      "                    0.22048072516918182,\n",
      "                    0.21232660114765167,\n",
      "                    0.21018590033054352,\n",
      "                    0.20350134372711182],\n",
      "                   [0.43730825185775757,\n",
      "                    0.29226571321487427,\n",
      "                    0.271244615316391,\n",
      "                    0.25436878204345703,\n",
      "                    0.24427694082260132,\n",
      "                    0.23629365861415863,\n",
      "                    0.22760164737701416,\n",
      "                    0.2228577733039856,\n",
      "                    0.2161283642053604,\n",
      "                    0.21247877180576324],\n",
      "                   [0.44806721806526184,\n",
      "                    0.28902778029441833,\n",
      "                    0.2612173855304718,\n",
      "                    0.2460339069366455,\n",
      "                    0.234901562333107,\n",
      "                    0.22719386219978333,\n",
      "                    0.22127562761306763,\n",
      "                    0.21698836982250214,\n",
      "                    0.21024735271930695,\n",
      "                    0.20604492723941803]],\n",
      " 'Validation Accuracy': [[0.8724932670593262,\n",
      "                          0.8910866379737854,\n",
      "                          0.89791339635849,\n",
      "                          0.9022267460823059,\n",
      "                          0.9049100875854492,\n",
      "                          0.9081065654754639,\n",
      "                          0.911163330078125,\n",
      "                          0.9133166670799255,\n",
      "                          0.9112898707389832,\n",
      "                          0.9162268042564392],\n",
      "                         [0.8706531524658203,\n",
      "                          0.8782501220703125,\n",
      "                          0.8901166915893555,\n",
      "                          0.8938767313957214,\n",
      "                          0.9005999565124512,\n",
      "                          0.9027668237686157,\n",
      "                          0.9047334790229797,\n",
      "                          0.902346670627594,\n",
      "                          0.906756579875946,\n",
      "                          0.9114133715629578],\n",
      "                         [0.8517699837684631,\n",
      "                          0.8692232370376587,\n",
      "                          0.8773600459098816,\n",
      "                          0.8858299851417542,\n",
      "                          0.8865600824356079,\n",
      "                          0.8901866674423218,\n",
      "                          0.8955502510070801,\n",
      "                          0.8927034735679626,\n",
      "                          0.8993099927902222,\n",
      "                          0.8938567042350769],\n",
      "                         [0.8668934106826782,\n",
      "                          0.8809999823570251,\n",
      "                          0.8873100876808167,\n",
      "                          0.8895799517631531,\n",
      "                          0.8946433663368225,\n",
      "                          0.8985933661460876,\n",
      "                          0.8988400101661682,\n",
      "                          0.9032500386238098,\n",
      "                          0.9025101661682129,\n",
      "                          0.9041299223899841],\n",
      "                         [0.8616566061973572,\n",
      "                          0.8774166703224182,\n",
      "                          0.8861466646194458,\n",
      "                          0.891436755657196,\n",
      "                          0.894103467464447,\n",
      "                          0.8970298171043396,\n",
      "                          0.8961299657821655,\n",
      "                          0.9016333222389221,\n",
      "                          0.9022200703620911,\n",
      "                          0.904366672039032]],\n",
      " 'Validation Loss': [0.3179643750190735,\n",
      "                     0.28127577900886536,\n",
      "                     0.2628591060638428,\n",
      "                     0.2522434890270233,\n",
      "                     0.2384999543428421,\n",
      "                     0.23952916264533997,\n",
      "                     0.2324412763118744,\n",
      "                     0.22685813903808594,\n",
      "                     0.21748967468738556,\n",
      "                     0.21629276871681213],\n",
      " 'Validation MCC': [[0.7453617462603569,\n",
      "                     0.7812632763546045,\n",
      "                     0.7957179163276917,\n",
      "                     0.8041939916071237,\n",
      "                     0.8096034235670896,\n",
      "                     0.8158928093005554,\n",
      "                     0.8215843123084285,\n",
      "                     0.8259744906224862,\n",
      "                     0.8232134811092153,\n",
      "                     0.8317403450676765],\n",
      "                    [0.740256863631695,\n",
      "                     0.7582129346489482,\n",
      "                     0.7795520811578905,\n",
      "                     0.7883781897280985,\n",
      "                     0.8003547814960481,\n",
      "                     0.8047080285081452,\n",
      "                     0.8090348017651325,\n",
      "                     0.8057115259525293,\n",
      "                     0.8136957533248087,\n",
      "                     0.8222749974584123],\n",
      "                    [0.7065661682830849,\n",
      "                     0.7396618311694882,\n",
      "                     0.7535623774598041,\n",
      "                     0.7707787219661503,\n",
      "                     0.7739575152122732,\n",
      "                     0.7793183641398875,\n",
      "                     0.7900204684382045,\n",
      "                     0.7862758404393488,\n",
      "                     0.797938596242411,\n",
      "                     0.7886971759459119],\n",
      "                    [0.7329652574249129,\n",
      "                     0.7605892915819668,\n",
      "                     0.7738637628269213,\n",
      "                     0.7783411366200352,\n",
      "                     0.7884262942550851,\n",
      "                     0.7962138348179042,\n",
      "                     0.7966468983521613,\n",
      "                     0.8053905410895729,\n",
      "                     0.8041254534503489,\n",
      "                     0.8074947229725457],\n",
      "                    [0.7224854217114624,\n",
      "                     0.7549370007734788,\n",
      "                     0.7715483850982159,\n",
      "                     0.7833656421080339,\n",
      "                     0.7881170761874592,\n",
      "                     0.7944644260082883,\n",
      "                     0.7924826713466409,\n",
      "                     0.8027944337768478,\n",
      "                     0.804137724275488,\n",
      "                     0.8081528788108612]]}\n",
      "Training Model: RNN, Fold: 1\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.7226 - loss: 0.5359\n",
      "Epoch 1 - MCC: 0.6794\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 53ms/step - accuracy: 0.7235 - loss: 0.5346 - val_accuracy: 0.8397 - val_loss: 0.3600 - mcc: 0.6794\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8478 - loss: 0.3489\n",
      "Epoch 2 - MCC: 0.7106\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 39ms/step - accuracy: 0.8478 - loss: 0.3489 - val_accuracy: 0.8555 - val_loss: 0.3313 - mcc: 0.7106\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8495 - loss: 0.3376\n",
      "Epoch 3 - MCC: 0.7169\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.8495 - loss: 0.3375 - val_accuracy: 0.8587 - val_loss: 0.3216 - mcc: 0.7169\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8617 - loss: 0.3142\n",
      "Epoch 4 - MCC: 0.7186\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 40ms/step - accuracy: 0.8617 - loss: 0.3142 - val_accuracy: 0.8573 - val_loss: 0.3154 - mcc: 0.7186\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8631 - loss: 0.3116\n",
      "Epoch 5 - MCC: 0.7313\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.8631 - loss: 0.3116 - val_accuracy: 0.8661 - val_loss: 0.2980 - mcc: 0.7313\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8648 - loss: 0.3018\n",
      "Epoch 6 - MCC: 0.7450\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8648 - loss: 0.3018 - val_accuracy: 0.8729 - val_loss: 0.2846 - mcc: 0.7450\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8711 - loss: 0.2898\n",
      "Epoch 7 - MCC: 0.7448\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 38ms/step - accuracy: 0.8711 - loss: 0.2899 - val_accuracy: 0.8729 - val_loss: 0.2859 - mcc: 0.7448\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8698 - loss: 0.2901\n",
      "Epoch 8 - MCC: 0.7541\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8698 - loss: 0.2901 - val_accuracy: 0.8774 - val_loss: 0.2764 - mcc: 0.7541\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8714 - loss: 0.2870\n",
      "Epoch 9 - MCC: 0.7590\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 38ms/step - accuracy: 0.8714 - loss: 0.2870 - val_accuracy: 0.8798 - val_loss: 0.2687 - mcc: 0.7590\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8724 - loss: 0.2841\n",
      "Epoch 10 - MCC: 0.7371\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8724 - loss: 0.2841 - val_accuracy: 0.8669 - val_loss: 0.2936 - mcc: 0.7371\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 2\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.7313 - loss: 0.5192\n",
      "Epoch 1 - MCC: 0.6930\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 53ms/step - accuracy: 0.7322 - loss: 0.5180 - val_accuracy: 0.8472 - val_loss: 0.3499 - mcc: 0.6930\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8416 - loss: 0.3566\n",
      "Epoch 2 - MCC: 0.7100\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 38ms/step - accuracy: 0.8416 - loss: 0.3565 - val_accuracy: 0.8546 - val_loss: 0.3357 - mcc: 0.7100\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8488 - loss: 0.3390\n",
      "Epoch 3 - MCC: 0.7279\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 40ms/step - accuracy: 0.8489 - loss: 0.3389 - val_accuracy: 0.8645 - val_loss: 0.3085 - mcc: 0.7279\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8579 - loss: 0.3194\n",
      "Epoch 4 - MCC: 0.7277\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 36ms/step - accuracy: 0.8578 - loss: 0.3195 - val_accuracy: 0.8643 - val_loss: 0.3067 - mcc: 0.7277\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8612 - loss: 0.3104\n",
      "Epoch 5 - MCC: 0.7339\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.8612 - loss: 0.3104 - val_accuracy: 0.8675 - val_loss: 0.2972 - mcc: 0.7339\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8625 - loss: 0.3066\n",
      "Epoch 6 - MCC: 0.7339\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 39ms/step - accuracy: 0.8625 - loss: 0.3065 - val_accuracy: 0.8670 - val_loss: 0.2977 - mcc: 0.7339\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8654 - loss: 0.2983\n",
      "Epoch 7 - MCC: 0.7421\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8654 - loss: 0.2983 - val_accuracy: 0.8706 - val_loss: 0.2831 - mcc: 0.7421\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8678 - loss: 0.2927\n",
      "Epoch 8 - MCC: 0.7368\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8678 - loss: 0.2927 - val_accuracy: 0.8681 - val_loss: 0.2912 - mcc: 0.7368\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8743 - loss: 0.2816\n",
      "Epoch 9 - MCC: 0.7477\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8743 - loss: 0.2816 - val_accuracy: 0.8744 - val_loss: 0.2789 - mcc: 0.7477\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8726 - loss: 0.2842\n",
      "Epoch 10 - MCC: 0.7484\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 38ms/step - accuracy: 0.8725 - loss: 0.2842 - val_accuracy: 0.8746 - val_loss: 0.2777 - mcc: 0.7484\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 3\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.7560 - loss: 0.4998\n",
      "Epoch 1 - MCC: 0.6764\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 52ms/step - accuracy: 0.7564 - loss: 0.4993 - val_accuracy: 0.8391 - val_loss: 0.3691 - mcc: 0.6764\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8452 - loss: 0.3540\n",
      "Epoch 2 - MCC: 0.6924\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 38ms/step - accuracy: 0.8452 - loss: 0.3539 - val_accuracy: 0.8468 - val_loss: 0.3451 - mcc: 0.6924\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8596 - loss: 0.3222\n",
      "Epoch 3 - MCC: 0.7045\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.8596 - loss: 0.3222 - val_accuracy: 0.8531 - val_loss: 0.3317 - mcc: 0.7045\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8570 - loss: 0.3232\n",
      "Epoch 4 - MCC: 0.7045\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 38ms/step - accuracy: 0.8570 - loss: 0.3232 - val_accuracy: 0.8531 - val_loss: 0.3292 - mcc: 0.7045\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8634 - loss: 0.3098\n",
      "Epoch 5 - MCC: 0.7155\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8634 - loss: 0.3098 - val_accuracy: 0.8577 - val_loss: 0.3217 - mcc: 0.7155\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8666 - loss: 0.3005\n",
      "Epoch 6 - MCC: 0.7121\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 39ms/step - accuracy: 0.8666 - loss: 0.3006 - val_accuracy: 0.8566 - val_loss: 0.3183 - mcc: 0.7121\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8657 - loss: 0.3033\n",
      "Epoch 7 - MCC: 0.7240\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8657 - loss: 0.3032 - val_accuracy: 0.8622 - val_loss: 0.3017 - mcc: 0.7240\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8635 - loss: 0.3012\n",
      "Epoch 8 - MCC: 0.7217\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.8635 - loss: 0.3012 - val_accuracy: 0.8616 - val_loss: 0.3069 - mcc: 0.7217\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8678 - loss: 0.2929\n",
      "Epoch 9 - MCC: 0.7054\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.8679 - loss: 0.2928 - val_accuracy: 0.8497 - val_loss: 0.3141 - mcc: 0.7054\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8745 - loss: 0.2792\n",
      "Epoch 10 - MCC: 0.7333\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 40ms/step - accuracy: 0.8745 - loss: 0.2792 - val_accuracy: 0.8673 - val_loss: 0.2886 - mcc: 0.7333\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 4\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.7596 - loss: 0.4903\n",
      "Epoch 1 - MCC: 0.6903\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 49ms/step - accuracy: 0.7603 - loss: 0.4893 - val_accuracy: 0.8454 - val_loss: 0.3541 - mcc: 0.6903\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8452 - loss: 0.3513\n",
      "Epoch 2 - MCC: 0.7143\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 39ms/step - accuracy: 0.8453 - loss: 0.3512 - val_accuracy: 0.8580 - val_loss: 0.3299 - mcc: 0.7143\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8542 - loss: 0.3306\n",
      "Epoch 3 - MCC: 0.6977\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.8542 - loss: 0.3306 - val_accuracy: 0.8468 - val_loss: 0.3320 - mcc: 0.6977\n",
      "Epoch 4/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8614 - loss: 0.3153\n",
      "Epoch 4 - MCC: 0.6877\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 39ms/step - accuracy: 0.8613 - loss: 0.3154 - val_accuracy: 0.8447 - val_loss: 0.3572 - mcc: 0.6877\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8550 - loss: 0.3305\n",
      "Epoch 5 - MCC: 0.7038\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8550 - loss: 0.3305 - val_accuracy: 0.8523 - val_loss: 0.3300 - mcc: 0.7038\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8582 - loss: 0.3201\n",
      "Epoch 6 - MCC: 0.7023\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8583 - loss: 0.3200 - val_accuracy: 0.8504 - val_loss: 0.3270 - mcc: 0.7023\n",
      "Epoch 7/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8559 - loss: 0.3212\n",
      "Epoch 7 - MCC: 0.7290\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 39ms/step - accuracy: 0.8559 - loss: 0.3211 - val_accuracy: 0.8644 - val_loss: 0.3115 - mcc: 0.7290\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8619 - loss: 0.3095\n",
      "Epoch 8 - MCC: 0.7337\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 39ms/step - accuracy: 0.8619 - loss: 0.3094 - val_accuracy: 0.8674 - val_loss: 0.2978 - mcc: 0.7337\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8669 - loss: 0.2954\n",
      "Epoch 9 - MCC: 0.7322\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 40ms/step - accuracy: 0.8669 - loss: 0.2955 - val_accuracy: 0.8669 - val_loss: 0.2990 - mcc: 0.7322\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8678 - loss: 0.2939\n",
      "Epoch 10 - MCC: 0.7418\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8678 - loss: 0.2939 - val_accuracy: 0.8717 - val_loss: 0.2883 - mcc: 0.7418\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 5\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.7557 - loss: 0.4950\n",
      "Epoch 1 - MCC: 0.6841\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 54ms/step - accuracy: 0.7561 - loss: 0.4945 - val_accuracy: 0.8415 - val_loss: 0.3604 - mcc: 0.6841\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8448 - loss: 0.3495\n",
      "Epoch 2 - MCC: 0.6990\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 40ms/step - accuracy: 0.8449 - loss: 0.3494 - val_accuracy: 0.8491 - val_loss: 0.3362 - mcc: 0.6990\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8547 - loss: 0.3285\n",
      "Epoch 3 - MCC: 0.7127\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8547 - loss: 0.3285 - val_accuracy: 0.8560 - val_loss: 0.3241 - mcc: 0.7127\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8600 - loss: 0.3135\n",
      "Epoch 4 - MCC: 0.7013\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 40ms/step - accuracy: 0.8600 - loss: 0.3135 - val_accuracy: 0.8509 - val_loss: 0.3273 - mcc: 0.7013\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8559 - loss: 0.3193\n",
      "Epoch 5 - MCC: 0.7191\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 38ms/step - accuracy: 0.8559 - loss: 0.3192 - val_accuracy: 0.8591 - val_loss: 0.3103 - mcc: 0.7191\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8689 - loss: 0.2935\n",
      "Epoch 6 - MCC: 0.7205\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.8689 - loss: 0.2936 - val_accuracy: 0.8604 - val_loss: 0.3104 - mcc: 0.7205\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8666 - loss: 0.2965\n",
      "Epoch 7 - MCC: 0.7313\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 38ms/step - accuracy: 0.8665 - loss: 0.2966 - val_accuracy: 0.8660 - val_loss: 0.2960 - mcc: 0.7313\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8659 - loss: 0.2962\n",
      "Epoch 8 - MCC: 0.7351\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 40ms/step - accuracy: 0.8659 - loss: 0.2962 - val_accuracy: 0.8678 - val_loss: 0.2927 - mcc: 0.7351\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8733 - loss: 0.2803\n",
      "Epoch 9 - MCC: 0.7351\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 40ms/step - accuracy: 0.8733 - loss: 0.2804 - val_accuracy: 0.8675 - val_loss: 0.2911 - mcc: 0.7351\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8717 - loss: 0.2845\n",
      "Epoch 10 - MCC: 0.7407\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.8717 - loss: 0.2846 - val_accuracy: 0.8707 - val_loss: 0.2891 - mcc: 0.7407\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': 0.87458,\n",
      "              'mean': 0.8702500000000001,\n",
      "              'min': 0.86695,\n",
      "              'std': 0.0028459686888259615},\n",
      " 'Inference Time (s/sample)': {'max': 0.0011670049031575521,\n",
      "                               'mean': 0.0008080498377482096,\n",
      "                               'min': 0.0006300946076711019,\n",
      "                               'std': 0.00018521860951913087},\n",
      " 'MCC': {'max': 0.7483713720169508,\n",
      "         'mean': 0.7402644796044191,\n",
      "         'min': 0.7333038001796771,\n",
      "         'std': 0.005038821012144968},\n",
      " 'Parameters': 5825,\n",
      " 'Train Time (s)': {'max': 99.38103771209717,\n",
      "                    'mean': 84.28101744651795,\n",
      "                    'min': 76.88398170471191,\n",
      "                    'std': 8.348316899958721},\n",
      " 'Training Accuracy': [[0.7929831743240356,\n",
      "                        0.8464660048484802,\n",
      "                        0.8540005683898926,\n",
      "                        0.8592624068260193,\n",
      "                        0.8637555837631226,\n",
      "                        0.8648558259010315,\n",
      "                        0.8679998517036438,\n",
      "                        0.8695791363716125,\n",
      "                        0.8709125518798828,\n",
      "                        0.8726682662963867],\n",
      "                       [0.7985392212867737,\n",
      "                        0.845238983631134,\n",
      "                        0.8535892963409424,\n",
      "                        0.8550952076911926,\n",
      "                        0.8615057468414307,\n",
      "                        0.8649317622184753,\n",
      "                        0.8666449785232544,\n",
      "                        0.8664959669113159,\n",
      "                        0.871849775314331,\n",
      "                        0.8718467354774475],\n",
      "                       [0.8068340420722961,\n",
      "                        0.8483707308769226,\n",
      "                        0.857200026512146,\n",
      "                        0.8579808473587036,\n",
      "                        0.8641151785850525,\n",
      "                        0.8634442090988159,\n",
      "                        0.866266667842865,\n",
      "                        0.8648285865783691,\n",
      "                        0.8706158399581909,\n",
      "                        0.8740540742874146],\n",
      "                       [0.8098490834236145,\n",
      "                        0.8488833904266357,\n",
      "                        0.8543899655342102,\n",
      "                        0.8572475910186768,\n",
      "                        0.8541982769966125,\n",
      "                        0.858539342880249,\n",
      "                        0.8617476224899292,\n",
      "                        0.864919126033783,\n",
      "                        0.8661466240882874,\n",
      "                        0.8677412867546082],\n",
      "                       [0.8083823919296265,\n",
      "                        0.8463509678840637,\n",
      "                        0.8540599346160889,\n",
      "                        0.8577609062194824,\n",
      "                        0.8583925366401672,\n",
      "                        0.8653618097305298,\n",
      "                        0.8639034032821655,\n",
      "                        0.8664233684539795,\n",
      "                        0.8699092864990234,\n",
      "                        0.870377779006958]],\n",
      " 'Training Loss': [[0.4402712881565094,\n",
      "                    0.3489684462547302,\n",
      "                    0.3309670686721802,\n",
      "                    0.3184463381767273,\n",
      "                    0.308073490858078,\n",
      "                    0.3033372759819031,\n",
      "                    0.2948111593723297,\n",
      "                    0.29063063859939575,\n",
      "                    0.28740018606185913,\n",
      "                    0.28324198722839355],\n",
      "                   [0.429413765668869,\n",
      "                    0.348471462726593,\n",
      "                    0.3293587863445282,\n",
      "                    0.32593443989753723,\n",
      "                    0.31051117181777954,\n",
      "                    0.30184581875801086,\n",
      "                    0.29644766449928284,\n",
      "                    0.29547029733657837,\n",
      "                    0.28504329919815063,\n",
      "                    0.2855205833911896],\n",
      "                   [0.4236263930797577,\n",
      "                    0.3457320034503937,\n",
      "                    0.3245827257633209,\n",
      "                    0.3209383487701416,\n",
      "                    0.3079080283641815,\n",
      "                    0.3057382106781006,\n",
      "                    0.3005421459674835,\n",
      "                    0.30085498094558716,\n",
      "                    0.28850114345550537,\n",
      "                    0.2799435555934906],\n",
      "                   [0.4171241819858551,\n",
      "                    0.34346991777420044,\n",
      "                    0.32986894249916077,\n",
      "                    0.3228703439235687,\n",
      "                    0.33035966753959656,\n",
      "                    0.3181076943874359,\n",
      "                    0.31073278188705444,\n",
      "                    0.3028950095176697,\n",
      "                    0.2980763912200928,\n",
      "                    0.29391834139823914],\n",
      "                   [0.4180467426776886,\n",
      "                    0.34615880250930786,\n",
      "                    0.32882317900657654,\n",
      "                    0.31706374883651733,\n",
      "                    0.3144761919975281,\n",
      "                    0.2995791733264923,\n",
      "                    0.3017269968986511,\n",
      "                    0.29546910524368286,\n",
      "                    0.28678449988365173,\n",
      "                    0.28776228427886963]],\n",
      " 'Validation Accuracy': [[0.8397232890129089,\n",
      "                          0.8555368185043335,\n",
      "                          0.8586801290512085,\n",
      "                          0.8573201298713684,\n",
      "                          0.8660868406295776,\n",
      "                          0.8728699684143066,\n",
      "                          0.8728765845298767,\n",
      "                          0.877436637878418,\n",
      "                          0.8798468112945557,\n",
      "                          0.8669499754905701],\n",
      "                         [0.8471700549125671,\n",
      "                          0.8546134233474731,\n",
      "                          0.8644700050354004,\n",
      "                          0.8643267750740051,\n",
      "                          0.8674967288970947,\n",
      "                          0.8670066595077515,\n",
      "                          0.8705734014511108,\n",
      "                          0.8681133985519409,\n",
      "                          0.8743700385093689,\n",
      "                          0.8745799660682678],\n",
      "                         [0.8390933871269226,\n",
      "                          0.8467500805854797,\n",
      "                          0.8530732989311218,\n",
      "                          0.8531100749969482,\n",
      "                          0.857683539390564,\n",
      "                          0.856636643409729,\n",
      "                          0.8622133135795593,\n",
      "                          0.861606776714325,\n",
      "                          0.8496767282485962,\n",
      "                          0.8673133254051208],\n",
      "                         [0.8454433679580688,\n",
      "                          0.8579967021942139,\n",
      "                          0.8467767834663391,\n",
      "                          0.8447033762931824,\n",
      "                          0.8523134589195251,\n",
      "                          0.850350022315979,\n",
      "                          0.864386796951294,\n",
      "                          0.8673566579818726,\n",
      "                          0.8668932914733887,\n",
      "                          0.8716601729393005],\n",
      "                         [0.8414700031280518,\n",
      "                          0.8491201400756836,\n",
      "                          0.855973482131958,\n",
      "                          0.8509367108345032,\n",
      "                          0.8590532541275024,\n",
      "                          0.8604101538658142,\n",
      "                          0.8660266995429993,\n",
      "                          0.8678233623504639,\n",
      "                          0.8675033450126648,\n",
      "                          0.8707468509674072]],\n",
      " 'Validation Loss': [0.3603668212890625,\n",
      "                     0.33622246980667114,\n",
      "                     0.324110746383667,\n",
      "                     0.3273160755634308,\n",
      "                     0.31030574440956116,\n",
      "                     0.31040528416633606,\n",
      "                     0.29595911502838135,\n",
      "                     0.29267480969429016,\n",
      "                     0.2911018431186676,\n",
      "                     0.2890760898590088],\n",
      " 'Validation MCC': [[0.6794357503553937,\n",
      "                     0.7105726364075599,\n",
      "                     0.7169062356649878,\n",
      "                     0.7186242917501878,\n",
      "                     0.7312564263395498,\n",
      "                     0.7450199906429746,\n",
      "                     0.7448138049437997,\n",
      "                     0.7541311868527641,\n",
      "                     0.7590385986291932,\n",
      "                     0.7370853983617646],\n",
      "                    [0.6929900190169157,\n",
      "                     0.7099907186297382,\n",
      "                     0.7279163945778547,\n",
      "                     0.7276530027553131,\n",
      "                     0.7338772560678355,\n",
      "                     0.7339435600139848,\n",
      "                     0.7421440828645998,\n",
      "                     0.7368307217995044,\n",
      "                     0.7476537651511396,\n",
      "                     0.7483713720169508],\n",
      "                    [0.6764129516818391,\n",
      "                     0.6924312714298153,\n",
      "                     0.7044879950014513,\n",
      "                     0.704543511616812,\n",
      "                     0.7154795362932866,\n",
      "                     0.7121249186110987,\n",
      "                     0.723974037312186,\n",
      "                     0.7216538644718806,\n",
      "                     0.7054205763127729,\n",
      "                     0.7333038001796771],\n",
      "                    [0.6903433917435848,\n",
      "                     0.7143101559122986,\n",
      "                     0.6977161910460025,\n",
      "                     0.6877063812920325,\n",
      "                     0.7038345689249983,\n",
      "                     0.7022852586395752,\n",
      "                     0.7290090606934454,\n",
      "                     0.733716674135915,\n",
      "                     0.7321532724781273,\n",
      "                     0.7418299989263164],\n",
      "                    [0.6841372562642563,\n",
      "                     0.6989634235634458,\n",
      "                     0.7126525247910402,\n",
      "                     0.7013000991502751,\n",
      "                     0.7191493366771352,\n",
      "                     0.720458541873906,\n",
      "                     0.7313166758685801,\n",
      "                     0.7351495099183377,\n",
      "                     0.7350987141399049,\n",
      "                     0.7407318285373866]]}\n",
      "Training Model: GRU, Fold: 1\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.6807 - loss: 0.6089\n",
      "Epoch 1 - MCC: 0.6505\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 29ms/step - accuracy: 0.6812 - loss: 0.6083 - val_accuracy: 0.8257 - val_loss: 0.3842 - mcc: 0.6505\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8325 - loss: 0.3673\n",
      "Epoch 2 - MCC: 0.7111\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.8325 - loss: 0.3672 - val_accuracy: 0.8562 - val_loss: 0.3180 - mcc: 0.7111\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8547 - loss: 0.3209\n",
      "Epoch 3 - MCC: 0.7307\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8547 - loss: 0.3208 - val_accuracy: 0.8659 - val_loss: 0.2941 - mcc: 0.7307\n",
      "Epoch 4/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.8653 - loss: 0.2968\n",
      "Epoch 4 - MCC: 0.7475\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 27ms/step - accuracy: 0.8653 - loss: 0.2967 - val_accuracy: 0.8743 - val_loss: 0.2770 - mcc: 0.7475\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8670 - loss: 0.2910\n",
      "Epoch 5 - MCC: 0.7578\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8671 - loss: 0.2909 - val_accuracy: 0.8794 - val_loss: 0.2668 - mcc: 0.7578\n",
      "Epoch 6/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8777 - loss: 0.2731\n",
      "Epoch 6 - MCC: 0.7662\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8776 - loss: 0.2731 - val_accuracy: 0.8836 - val_loss: 0.2579 - mcc: 0.7662\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8813 - loss: 0.2658\n",
      "Epoch 7 - MCC: 0.7703\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 26ms/step - accuracy: 0.8813 - loss: 0.2658 - val_accuracy: 0.8856 - val_loss: 0.2520 - mcc: 0.7703\n",
      "Epoch 8/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8799 - loss: 0.2647\n",
      "Epoch 8 - MCC: 0.7732\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.8799 - loss: 0.2646 - val_accuracy: 0.8871 - val_loss: 0.2471 - mcc: 0.7732\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8848 - loss: 0.2565\n",
      "Epoch 9 - MCC: 0.7805\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8848 - loss: 0.2565 - val_accuracy: 0.8904 - val_loss: 0.2438 - mcc: 0.7805\n",
      "Epoch 10/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8848 - loss: 0.2549\n",
      "Epoch 10 - MCC: 0.7835\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8848 - loss: 0.2549 - val_accuracy: 0.8922 - val_loss: 0.2391 - mcc: 0.7835\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 2\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.6467 - loss: 0.6086\n",
      "Epoch 1 - MCC: 0.6570\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 26ms/step - accuracy: 0.6480 - loss: 0.6074 - val_accuracy: 0.8288 - val_loss: 0.3783 - mcc: 0.6570\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8278 - loss: 0.3759\n",
      "Epoch 2 - MCC: 0.7077\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.8278 - loss: 0.3757 - val_accuracy: 0.8545 - val_loss: 0.3274 - mcc: 0.7077\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8562 - loss: 0.3183\n",
      "Epoch 3 - MCC: 0.7327\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8562 - loss: 0.3183 - val_accuracy: 0.8670 - val_loss: 0.2978 - mcc: 0.7327\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8595 - loss: 0.3080\n",
      "Epoch 4 - MCC: 0.7440\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.8595 - loss: 0.3078 - val_accuracy: 0.8724 - val_loss: 0.2839 - mcc: 0.7440\n",
      "Epoch 5/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8679 - loss: 0.2908\n",
      "Epoch 5 - MCC: 0.7487\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8679 - loss: 0.2907 - val_accuracy: 0.8749 - val_loss: 0.2779 - mcc: 0.7487\n",
      "Epoch 6/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8726 - loss: 0.2818\n",
      "Epoch 6 - MCC: 0.7571\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 22ms/step - accuracy: 0.8726 - loss: 0.2818 - val_accuracy: 0.8786 - val_loss: 0.2708 - mcc: 0.7571\n",
      "Epoch 7/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8741 - loss: 0.2778\n",
      "Epoch 7 - MCC: 0.7629\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 24ms/step - accuracy: 0.8741 - loss: 0.2778 - val_accuracy: 0.8819 - val_loss: 0.2655 - mcc: 0.7629\n",
      "Epoch 8/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8718 - loss: 0.2814\n",
      "Epoch 8 - MCC: 0.7708\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8720 - loss: 0.2811 - val_accuracy: 0.8859 - val_loss: 0.2575 - mcc: 0.7708\n",
      "Epoch 9/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8838 - loss: 0.2568\n",
      "Epoch 9 - MCC: 0.7724\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.8837 - loss: 0.2569 - val_accuracy: 0.8864 - val_loss: 0.2546 - mcc: 0.7724\n",
      "Epoch 10/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8828 - loss: 0.2595\n",
      "Epoch 10 - MCC: 0.7737\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 25ms/step - accuracy: 0.8828 - loss: 0.2594 - val_accuracy: 0.8863 - val_loss: 0.2543 - mcc: 0.7737\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 3\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6848 - loss: 0.5962\n",
      "Epoch 1 - MCC: 0.6281\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 24ms/step - accuracy: 0.6857 - loss: 0.5950 - val_accuracy: 0.8149 - val_loss: 0.4033 - mcc: 0.6281\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8273 - loss: 0.3827\n",
      "Epoch 2 - MCC: 0.6896\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8274 - loss: 0.3826 - val_accuracy: 0.8456 - val_loss: 0.3403 - mcc: 0.6896\n",
      "Epoch 3/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8586 - loss: 0.3142\n",
      "Epoch 3 - MCC: 0.7162\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 25ms/step - accuracy: 0.8587 - loss: 0.3141 - val_accuracy: 0.8588 - val_loss: 0.3116 - mcc: 0.7162\n",
      "Epoch 4/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8726 - loss: 0.2847\n",
      "Epoch 4 - MCC: 0.7229\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 23ms/step - accuracy: 0.8725 - loss: 0.2848 - val_accuracy: 0.8616 - val_loss: 0.2994 - mcc: 0.7229\n",
      "Epoch 5/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8726 - loss: 0.2835\n",
      "Epoch 5 - MCC: 0.7275\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 27ms/step - accuracy: 0.8726 - loss: 0.2834 - val_accuracy: 0.8645 - val_loss: 0.2963 - mcc: 0.7275\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8778 - loss: 0.2717\n",
      "Epoch 6 - MCC: 0.7409\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8778 - loss: 0.2717 - val_accuracy: 0.8711 - val_loss: 0.2828 - mcc: 0.7409\n",
      "Epoch 7/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8829 - loss: 0.2599\n",
      "Epoch 7 - MCC: 0.7466\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.8829 - loss: 0.2600 - val_accuracy: 0.8738 - val_loss: 0.2771 - mcc: 0.7466\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8796 - loss: 0.2655\n",
      "Epoch 8 - MCC: 0.7537\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8797 - loss: 0.2654 - val_accuracy: 0.8772 - val_loss: 0.2695 - mcc: 0.7537\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8888 - loss: 0.2479\n",
      "Epoch 9 - MCC: 0.7538\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.8888 - loss: 0.2479 - val_accuracy: 0.8776 - val_loss: 0.2653 - mcc: 0.7538\n",
      "Epoch 10/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8905 - loss: 0.2431\n",
      "Epoch 10 - MCC: 0.7594\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8905 - loss: 0.2432 - val_accuracy: 0.8803 - val_loss: 0.2615 - mcc: 0.7594\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 4\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.6668 - loss: 0.6075\n",
      "Epoch 1 - MCC: 0.6605\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 30ms/step - accuracy: 0.6679 - loss: 0.6062 - val_accuracy: 0.8309 - val_loss: 0.3706 - mcc: 0.6605\n",
      "Epoch 2/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8390 - loss: 0.3567\n",
      "Epoch 2 - MCC: 0.6902\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.8390 - loss: 0.3566 - val_accuracy: 0.8443 - val_loss: 0.3392 - mcc: 0.6902\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8521 - loss: 0.3261\n",
      "Epoch 3 - MCC: 0.7271\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.8522 - loss: 0.3261 - val_accuracy: 0.8640 - val_loss: 0.2997 - mcc: 0.7271\n",
      "Epoch 4/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8639 - loss: 0.3016\n",
      "Epoch 4 - MCC: 0.7445\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8639 - loss: 0.3015 - val_accuracy: 0.8729 - val_loss: 0.2829 - mcc: 0.7445\n",
      "Epoch 5/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8703 - loss: 0.2877\n",
      "Epoch 5 - MCC: 0.7521\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 25ms/step - accuracy: 0.8704 - loss: 0.2875 - val_accuracy: 0.8768 - val_loss: 0.2727 - mcc: 0.7521\n",
      "Epoch 6/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8754 - loss: 0.2754\n",
      "Epoch 6 - MCC: 0.7615\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8755 - loss: 0.2753 - val_accuracy: 0.8812 - val_loss: 0.2633 - mcc: 0.7615\n",
      "Epoch 7/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8814 - loss: 0.2629\n",
      "Epoch 7 - MCC: 0.7661\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8814 - loss: 0.2629 - val_accuracy: 0.8837 - val_loss: 0.2589 - mcc: 0.7661\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8816 - loss: 0.2615\n",
      "Epoch 8 - MCC: 0.7745\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8816 - loss: 0.2615 - val_accuracy: 0.8879 - val_loss: 0.2491 - mcc: 0.7745\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8842 - loss: 0.2574\n",
      "Epoch 9 - MCC: 0.7739\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.8842 - loss: 0.2573 - val_accuracy: 0.8873 - val_loss: 0.2493 - mcc: 0.7739\n",
      "Epoch 10/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8856 - loss: 0.2531\n",
      "Epoch 10 - MCC: 0.7801\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8857 - loss: 0.2530 - val_accuracy: 0.8907 - val_loss: 0.2416 - mcc: 0.7801\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 5\n",
      "Epoch 1/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.6780 - loss: 0.6033\n",
      "Epoch 1 - MCC: 0.6447\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 30ms/step - accuracy: 0.6796 - loss: 0.6015 - val_accuracy: 0.8228 - val_loss: 0.3930 - mcc: 0.6447\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8264 - loss: 0.3824\n",
      "Epoch 2 - MCC: 0.6639\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8264 - loss: 0.3823 - val_accuracy: 0.8309 - val_loss: 0.3682 - mcc: 0.6639\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8365 - loss: 0.3606\n",
      "Epoch 3 - MCC: 0.6888\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8365 - loss: 0.3606 - val_accuracy: 0.8438 - val_loss: 0.3415 - mcc: 0.6888\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8533 - loss: 0.3228\n",
      "Epoch 4 - MCC: 0.7252\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8534 - loss: 0.3227 - val_accuracy: 0.8631 - val_loss: 0.3043 - mcc: 0.7252\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8689 - loss: 0.2907\n",
      "Epoch 5 - MCC: 0.7349\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 22ms/step - accuracy: 0.8689 - loss: 0.2907 - val_accuracy: 0.8678 - val_loss: 0.2927 - mcc: 0.7349\n",
      "Epoch 6/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8687 - loss: 0.2876\n",
      "Epoch 6 - MCC: 0.7435\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.8688 - loss: 0.2875 - val_accuracy: 0.8721 - val_loss: 0.2821 - mcc: 0.7435\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8759 - loss: 0.2738\n",
      "Epoch 7 - MCC: 0.7468\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.8759 - loss: 0.2738 - val_accuracy: 0.8738 - val_loss: 0.2785 - mcc: 0.7468\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8796 - loss: 0.2671\n",
      "Epoch 8 - MCC: 0.7540\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 25ms/step - accuracy: 0.8796 - loss: 0.2671 - val_accuracy: 0.8773 - val_loss: 0.2726 - mcc: 0.7540\n",
      "Epoch 9/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8804 - loss: 0.2650\n",
      "Epoch 9 - MCC: 0.7595\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.8805 - loss: 0.2649 - val_accuracy: 0.8800 - val_loss: 0.2666 - mcc: 0.7595\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8815 - loss: 0.2610\n",
      "Epoch 10 - MCC: 0.7617\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 23ms/step - accuracy: 0.8815 - loss: 0.2610 - val_accuracy: 0.8812 - val_loss: 0.2632 - mcc: 0.7617\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': 0.8921766666666666,\n",
      "              'mean': 0.8861246666666667,\n",
      "              'min': 0.8803366666666667,\n",
      "              'std': 0.004795190924248998},\n",
      " 'Inference Time (s/sample)': {'max': 0.0006888802846272787,\n",
      "                               'mean': 0.0006434527238210043,\n",
      "                               'min': 0.0005845733483632406,\n",
      "                               'std': 3.4126251537663214e-05},\n",
      " 'MCC': {'max': 0.7834730171813694,\n",
      "         'mean': 0.7716636605707381,\n",
      "         'min': 0.7594072673048219,\n",
      "         'std': 0.009638646643073092},\n",
      " 'Parameters': 6546,\n",
      " 'Train Time (s)': {'max': 44.595046281814575,\n",
      "                    'mean': 42.50478277206421,\n",
      "                    'min': 39.94254994392395,\n",
      "                    'std': 1.8008323441290104},\n",
      " 'Training Accuracy': [[0.7579765915870667,\n",
      "                        0.8395026922225952,\n",
      "                        0.8572682738304138,\n",
      "                        0.8661991357803345,\n",
      "                        0.8705857396125793,\n",
      "                        0.8752058148384094,\n",
      "                        0.8798791766166687,\n",
      "                        0.8818281888961792,\n",
      "                        0.8848575949668884,\n",
      "                        0.8854007124900818],\n",
      "                       [0.7404364943504333,\n",
      "                        0.837842583656311,\n",
      "                        0.8565242290496826,\n",
      "                        0.864841639995575,\n",
      "                        0.8691357374191284,\n",
      "                        0.8734350800514221,\n",
      "                        0.8765067458152771,\n",
      "                        0.8789541721343994,\n",
      "                        0.8806979656219482,\n",
      "                        0.8836466670036316],\n",
      "                       [0.7555733323097229,\n",
      "                        0.8366599678993225,\n",
      "                        0.8613884449005127,\n",
      "                        0.8699499368667603,\n",
      "                        0.8737974166870117,\n",
      "                        0.8775498270988464,\n",
      "                        0.8810141086578369,\n",
      "                        0.8840309381484985,\n",
      "                        0.8856990337371826,\n",
      "                        0.8881099224090576],\n",
      "                       [0.755815863609314,\n",
      "                        0.8411183953285217,\n",
      "                        0.8563150763511658,\n",
      "                        0.8669757843017578,\n",
      "                        0.8731300830841064,\n",
      "                        0.8770450949668884,\n",
      "                        0.8806682229042053,\n",
      "                        0.8833508491516113,\n",
      "                        0.8864425420761108,\n",
      "                        0.888379693031311],\n",
      "                       [0.7552007436752319,\n",
      "                        0.8286312222480774,\n",
      "                        0.8403432965278625,\n",
      "                        0.8563291430473328,\n",
      "                        0.8676566481590271,\n",
      "                        0.8723666667938232,\n",
      "                        0.8757118582725525,\n",
      "                        0.8794315457344055,\n",
      "                        0.8817465305328369,\n",
      "                        0.8833965063095093]],\n",
      " 'Training Loss': [[0.510410487651825,\n",
      "                    0.3538847863674164,\n",
      "                    0.31414079666137695,\n",
      "                    0.29510337114334106,\n",
      "                    0.28451696038246155,\n",
      "                    0.27536994218826294,\n",
      "                    0.2666204869747162,\n",
      "                    0.26133233308792114,\n",
      "                    0.25494900345802307,\n",
      "                    0.253098726272583],\n",
      "                   [0.5155478119850159,\n",
      "                    0.35613059997558594,\n",
      "                    0.31688421964645386,\n",
      "                    0.29758137464523315,\n",
      "                    0.288534015417099,\n",
      "                    0.2797365188598633,\n",
      "                    0.27248889207839966,\n",
      "                    0.2679702639579773,\n",
      "                    0.2629815936088562,\n",
      "                    0.25747883319854736],\n",
      "                   [0.5055442452430725,\n",
      "                    0.3625175356864929,\n",
      "                    0.30851250886917114,\n",
      "                    0.2887001931667328,\n",
      "                    0.2800292670726776,\n",
      "                    0.27145498991012573,\n",
      "                    0.26381394267082214,\n",
      "                    0.2572765052318573,\n",
      "                    0.2540051341056824,\n",
      "                    0.24814368784427643],\n",
      "                   [0.5069835186004639,\n",
      "                    0.3505825996398926,\n",
      "                    0.3179856836795807,\n",
      "                    0.29439777135849,\n",
      "                    0.28126344084739685,\n",
      "                    0.2716270387172699,\n",
      "                    0.26279962062835693,\n",
      "                    0.25752875208854675,\n",
      "                    0.25197046995162964,\n",
      "                    0.24683906137943268],\n",
      "                   [0.510371208190918,\n",
      "                    0.37769630551338196,\n",
      "                    0.35117214918136597,\n",
      "                    0.31666314601898193,\n",
      "                    0.29222041368484497,\n",
      "                    0.2808161675930023,\n",
      "                    0.27353477478027344,\n",
      "                    0.2669605314731598,\n",
      "                    0.2616332769393921,\n",
      "                    0.25785309076309204]],\n",
      " 'Validation Accuracy': [[0.8256800770759583,\n",
      "                          0.8561933636665344,\n",
      "                          0.8659499287605286,\n",
      "                          0.8743200898170471,\n",
      "                          0.8794466257095337,\n",
      "                          0.8835999369621277,\n",
      "                          0.885646641254425,\n",
      "                          0.8870700001716614,\n",
      "                          0.8904067873954773,\n",
      "                          0.8921766877174377],\n",
      "                         [0.8288200497627258,\n",
      "                          0.8545132279396057,\n",
      "                          0.8669500946998596,\n",
      "                          0.8723732233047485,\n",
      "                          0.8748933672904968,\n",
      "                          0.8785998821258545,\n",
      "                          0.8818667531013489,\n",
      "                          0.8858700394630432,\n",
      "                          0.8864499926567078,\n",
      "                          0.8862566947937012],\n",
      "                         [0.8148599863052368,\n",
      "                          0.8455801010131836,\n",
      "                          0.8588100075721741,\n",
      "                          0.861643373966217,\n",
      "                          0.8645333051681519,\n",
      "                          0.8710665702819824,\n",
      "                          0.8738099932670593,\n",
      "                          0.8771564960479736,\n",
      "                          0.8775699734687805,\n",
      "                          0.8803367018699646],\n",
      "                         [0.8309199810028076,\n",
      "                          0.844290018081665,\n",
      "                          0.8640033006668091,\n",
      "                          0.8728966116905212,\n",
      "                          0.8767999410629272,\n",
      "                          0.8811598420143127,\n",
      "                          0.8836567401885986,\n",
      "                          0.8879333734512329,\n",
      "                          0.8873199224472046,\n",
      "                          0.8906567096710205],\n",
      "                         [0.8228366374969482,\n",
      "                          0.8309199213981628,\n",
      "                          0.8437633514404297,\n",
      "                          0.8630666136741638,\n",
      "                          0.8677766919136047,\n",
      "                          0.8720566630363464,\n",
      "                          0.8737998604774475,\n",
      "                          0.8773230910301208,\n",
      "                          0.8800265789031982,\n",
      "                          0.8811966776847839]],\n",
      " 'Validation Loss': [0.3930496871471405,\n",
      "                     0.3682134747505188,\n",
      "                     0.3414512872695923,\n",
      "                     0.3043476343154907,\n",
      "                     0.2927127480506897,\n",
      "                     0.2820672392845154,\n",
      "                     0.27850669622421265,\n",
      "                     0.27257147431373596,\n",
      "                     0.26658526062965393,\n",
      "                     0.2631547749042511],\n",
      " 'Validation MCC': [[0.6505080276311953,\n",
      "                     0.7111112625354065,\n",
      "                     0.7306804147018918,\n",
      "                     0.7475474112653583,\n",
      "                     0.757814145302961,\n",
      "                     0.7662481065167212,\n",
      "                     0.7703417595024425,\n",
      "                     0.7732164895360562,\n",
      "                     0.780483836688664,\n",
      "                     0.7834730171813694],\n",
      "                    [0.6569567926535296,\n",
      "                     0.7076998694691669,\n",
      "                     0.7327143268936955,\n",
      "                     0.7439503396820605,\n",
      "                     0.7486826344449702,\n",
      "                     0.757060755576424,\n",
      "                     0.7629477933732778,\n",
      "                     0.7708425316653538,\n",
      "                     0.7724486162185691,\n",
      "                     0.773653629473513],\n",
      "                    [0.6281002377612404,\n",
      "                     0.6896078334363742,\n",
      "                     0.7161657824815423,\n",
      "                     0.7229443986941747,\n",
      "                     0.7275487866867957,\n",
      "                     0.7409046337604861,\n",
      "                     0.7466002570290446,\n",
      "                     0.7537237763195977,\n",
      "                     0.7537947805942881,\n",
      "                     0.7594072673048219],\n",
      "                    [0.6605298998817247,\n",
      "                     0.6901878556522225,\n",
      "                     0.7271107548787654,\n",
      "                     0.7444947322530915,\n",
      "                     0.7521234031750172,\n",
      "                     0.7614733653774144,\n",
      "                     0.766088830196829,\n",
      "                     0.774535947070435,\n",
      "                     0.7738864805818292,\n",
      "                     0.7801032522014011],\n",
      "                    [0.6446639947892938,\n",
      "                     0.663947106058705,\n",
      "                     0.6887547899742731,\n",
      "                     0.7252284252871818,\n",
      "                     0.7349265734966709,\n",
      "                     0.7434910544642207,\n",
      "                     0.7467956149921945,\n",
      "                     0.7539913460212834,\n",
      "                     0.7595278744243732,\n",
      "                     0.7616811366925851]]}\n",
      "Training Model: FFN, Fold: 1\n",
      "Epoch 1/10\n",
      "\u001B[1m136/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6858 - loss: 0.6077\n",
      "Epoch 1 - MCC: 0.6976\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.6942 - loss: 0.5966 - val_accuracy: 0.8495 - val_loss: 0.3324 - mcc: 0.6976\n",
      "Epoch 2/10\n",
      "\u001B[1m134/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8520 - loss: 0.3256\n",
      "Epoch 2 - MCC: 0.7237\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8525 - loss: 0.3248 - val_accuracy: 0.8619 - val_loss: 0.3072 - mcc: 0.7237\n",
      "Epoch 3/10\n",
      "\u001B[1m134/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8631 - loss: 0.3050\n",
      "Epoch 3 - MCC: 0.7324\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8630 - loss: 0.3050 - val_accuracy: 0.8654 - val_loss: 0.3011 - mcc: 0.7324\n",
      "Epoch 4/10\n",
      "\u001B[1m133/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8676 - loss: 0.2970\n",
      "Epoch 4 - MCC: 0.7342\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8673 - loss: 0.2974 - val_accuracy: 0.8677 - val_loss: 0.2942 - mcc: 0.7342\n",
      "Epoch 5/10\n",
      "\u001B[1m132/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8657 - loss: 0.2977\n",
      "Epoch 5 - MCC: 0.7402\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8657 - loss: 0.2978 - val_accuracy: 0.8704 - val_loss: 0.2893 - mcc: 0.7402\n",
      "Epoch 6/10\n",
      "\u001B[1m135/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8676 - loss: 0.2968\n",
      "Epoch 6 - MCC: 0.7417\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8677 - loss: 0.2964 - val_accuracy: 0.8713 - val_loss: 0.2870 - mcc: 0.7417\n",
      "Epoch 7/10\n",
      "\u001B[1m146/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8685 - loss: 0.2915\n",
      "Epoch 7 - MCC: 0.7443\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8685 - loss: 0.2915 - val_accuracy: 0.8718 - val_loss: 0.2869 - mcc: 0.7443\n",
      "Epoch 8/10\n",
      "\u001B[1m144/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8677 - loss: 0.2942\n",
      "Epoch 8 - MCC: 0.7472\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8678 - loss: 0.2940 - val_accuracy: 0.8736 - val_loss: 0.2837 - mcc: 0.7472\n",
      "Epoch 9/10\n",
      "\u001B[1m146/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8730 - loss: 0.2837\n",
      "Epoch 9 - MCC: 0.7518\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8729 - loss: 0.2838 - val_accuracy: 0.8756 - val_loss: 0.2804 - mcc: 0.7518\n",
      "Epoch 10/10\n",
      "\u001B[1m136/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8717 - loss: 0.2868\n",
      "Epoch 10 - MCC: 0.7518\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8717 - loss: 0.2866 - val_accuracy: 0.8760 - val_loss: 0.2784 - mcc: 0.7518\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: FFN, Fold: 2\n",
      "Epoch 1/10\n",
      "\u001B[1m136/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6996 - loss: 0.5746\n",
      "Epoch 1 - MCC: 0.7030\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 13ms/step - accuracy: 0.7078 - loss: 0.5642 - val_accuracy: 0.8516 - val_loss: 0.3288 - mcc: 0.7030\n",
      "Epoch 2/10\n",
      "\u001B[1m136/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8555 - loss: 0.3232\n",
      "Epoch 2 - MCC: 0.7298\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8558 - loss: 0.3224 - val_accuracy: 0.8654 - val_loss: 0.2993 - mcc: 0.7298\n",
      "Epoch 3/10\n",
      "\u001B[1m133/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8635 - loss: 0.3046\n",
      "Epoch 3 - MCC: 0.7341\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8637 - loss: 0.3044 - val_accuracy: 0.8677 - val_loss: 0.2943 - mcc: 0.7341\n",
      "Epoch 4/10\n",
      "\u001B[1m136/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8657 - loss: 0.3001\n",
      "Epoch 4 - MCC: 0.7330\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8659 - loss: 0.2997 - val_accuracy: 0.8628 - val_loss: 0.3050 - mcc: 0.7330\n",
      "Epoch 5/10\n",
      "\u001B[1m133/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8700 - loss: 0.2890\n",
      "Epoch 5 - MCC: 0.7428\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8698 - loss: 0.2896 - val_accuracy: 0.8711 - val_loss: 0.2858 - mcc: 0.7428\n",
      "Epoch 6/10\n",
      "\u001B[1m145/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8717 - loss: 0.2883\n",
      "Epoch 6 - MCC: 0.7467\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - accuracy: 0.8716 - loss: 0.2884 - val_accuracy: 0.8738 - val_loss: 0.2810 - mcc: 0.7467\n",
      "Epoch 7/10\n",
      "\u001B[1m146/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8694 - loss: 0.2918\n",
      "Epoch 7 - MCC: 0.7482\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8695 - loss: 0.2917 - val_accuracy: 0.8731 - val_loss: 0.2829 - mcc: 0.7482\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8719 - loss: 0.2873\n",
      "Epoch 8 - MCC: 0.7490\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8719 - loss: 0.2872 - val_accuracy: 0.8748 - val_loss: 0.2771 - mcc: 0.7490\n",
      "Epoch 9/10\n",
      "\u001B[1m132/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8759 - loss: 0.2792\n",
      "Epoch 9 - MCC: 0.7515\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8756 - loss: 0.2795 - val_accuracy: 0.8758 - val_loss: 0.2757 - mcc: 0.7515\n",
      "Epoch 10/10\n",
      "\u001B[1m135/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8712 - loss: 0.2874\n",
      "Epoch 10 - MCC: 0.7515\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8715 - loss: 0.2868 - val_accuracy: 0.8754 - val_loss: 0.2762 - mcc: 0.7515\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: FFN, Fold: 3\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6924 - loss: 0.5763\n",
      "Epoch 1 - MCC: 0.6866\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 14ms/step - accuracy: 0.6929 - loss: 0.5756 - val_accuracy: 0.8411 - val_loss: 0.3536 - mcc: 0.6866\n",
      "Epoch 2/10\n",
      "\u001B[1m135/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8526 - loss: 0.3295\n",
      "Epoch 2 - MCC: 0.7181\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8531 - loss: 0.3284 - val_accuracy: 0.8594 - val_loss: 0.3137 - mcc: 0.7181\n",
      "Epoch 3/10\n",
      "\u001B[1m133/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8629 - loss: 0.3055\n",
      "Epoch 3 - MCC: 0.7223\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8632 - loss: 0.3048 - val_accuracy: 0.8618 - val_loss: 0.3069 - mcc: 0.7223\n",
      "Epoch 4/10\n",
      "\u001B[1m130/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8759 - loss: 0.2779\n",
      "Epoch 4 - MCC: 0.7249\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8749 - loss: 0.2800 - val_accuracy: 0.8632 - val_loss: 0.3036 - mcc: 0.7249\n",
      "Epoch 5/10\n",
      "\u001B[1m141/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8694 - loss: 0.2927\n",
      "Epoch 5 - MCC: 0.7206\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8694 - loss: 0.2926 - val_accuracy: 0.8610 - val_loss: 0.3040 - mcc: 0.7206\n",
      "Epoch 6/10\n",
      "\u001B[1m136/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8711 - loss: 0.2896\n",
      "Epoch 6 - MCC: 0.7337\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8711 - loss: 0.2895 - val_accuracy: 0.8660 - val_loss: 0.3000 - mcc: 0.7337\n",
      "Epoch 7/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8739 - loss: 0.2813\n",
      "Epoch 7 - MCC: 0.7361\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8738 - loss: 0.2813 - val_accuracy: 0.8677 - val_loss: 0.2953 - mcc: 0.7361\n",
      "Epoch 8/10\n",
      "\u001B[1m137/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8721 - loss: 0.2849\n",
      "Epoch 8 - MCC: 0.7349\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8721 - loss: 0.2849 - val_accuracy: 0.8681 - val_loss: 0.2928 - mcc: 0.7349\n",
      "Epoch 9/10\n",
      "\u001B[1m136/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8695 - loss: 0.2894\n",
      "Epoch 9 - MCC: 0.7372\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8700 - loss: 0.2883 - val_accuracy: 0.8670 - val_loss: 0.2967 - mcc: 0.7372\n",
      "Epoch 10/10\n",
      "\u001B[1m138/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8735 - loss: 0.2817\n",
      "Epoch 10 - MCC: 0.7392\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8736 - loss: 0.2813 - val_accuracy: 0.8701 - val_loss: 0.2885 - mcc: 0.7392\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: FFN, Fold: 4\n",
      "Epoch 1/10\n",
      "\u001B[1m138/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7082 - loss: 0.5805\n",
      "Epoch 1 - MCC: 0.6989\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 13ms/step - accuracy: 0.7147 - loss: 0.5713 - val_accuracy: 0.8502 - val_loss: 0.3325 - mcc: 0.6989\n",
      "Epoch 2/10\n",
      "\u001B[1m138/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8552 - loss: 0.3223\n",
      "Epoch 2 - MCC: 0.7231\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8553 - loss: 0.3220 - val_accuracy: 0.8624 - val_loss: 0.3082 - mcc: 0.7231\n",
      "Epoch 3/10\n",
      "\u001B[1m139/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8625 - loss: 0.3047\n",
      "Epoch 3 - MCC: 0.7347\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8624 - loss: 0.3049 - val_accuracy: 0.8673 - val_loss: 0.2991 - mcc: 0.7347\n",
      "Epoch 4/10\n",
      "\u001B[1m144/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8679 - loss: 0.2927\n",
      "Epoch 4 - MCC: 0.7377\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8678 - loss: 0.2930 - val_accuracy: 0.8680 - val_loss: 0.2981 - mcc: 0.7377\n",
      "Epoch 5/10\n",
      "\u001B[1m143/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8680 - loss: 0.2934\n",
      "Epoch 5 - MCC: 0.7300\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8680 - loss: 0.2935 - val_accuracy: 0.8651 - val_loss: 0.2982 - mcc: 0.7300\n",
      "Epoch 6/10\n",
      "\u001B[1m139/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8711 - loss: 0.2872\n",
      "Epoch 6 - MCC: 0.7349\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8709 - loss: 0.2876 - val_accuracy: 0.8680 - val_loss: 0.2936 - mcc: 0.7349\n",
      "Epoch 7/10\n",
      "\u001B[1m146/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8732 - loss: 0.2832\n",
      "Epoch 7 - MCC: 0.7407\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8731 - loss: 0.2834 - val_accuracy: 0.8711 - val_loss: 0.2882 - mcc: 0.7407\n",
      "Epoch 8/10\n",
      "\u001B[1m137/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8710 - loss: 0.2881\n",
      "Epoch 8 - MCC: 0.7481\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8709 - loss: 0.2880 - val_accuracy: 0.8747 - val_loss: 0.2818 - mcc: 0.7481\n",
      "Epoch 9/10\n",
      "\u001B[1m133/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8693 - loss: 0.2875\n",
      "Epoch 9 - MCC: 0.7496\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8694 - loss: 0.2874 - val_accuracy: 0.8754 - val_loss: 0.2804 - mcc: 0.7496\n",
      "Epoch 10/10\n",
      "\u001B[1m135/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8719 - loss: 0.2840\n",
      "Epoch 10 - MCC: 0.7493\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8719 - loss: 0.2839 - val_accuracy: 0.8754 - val_loss: 0.2790 - mcc: 0.7493\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: FFN, Fold: 5\n",
      "Epoch 1/10\n",
      "\u001B[1m135/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6785 - loss: 0.5898\n",
      "Epoch 1 - MCC: 0.7096\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 14ms/step - accuracy: 0.6888 - loss: 0.5777 - val_accuracy: 0.8547 - val_loss: 0.3241 - mcc: 0.7096\n",
      "Epoch 2/10\n",
      "\u001B[1m135/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8563 - loss: 0.3217\n",
      "Epoch 2 - MCC: 0.7280\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8568 - loss: 0.3206 - val_accuracy: 0.8627 - val_loss: 0.3050 - mcc: 0.7280\n",
      "Epoch 3/10\n",
      "\u001B[1m144/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8683 - loss: 0.2942\n",
      "Epoch 3 - MCC: 0.7300\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.8682 - loss: 0.2943 - val_accuracy: 0.8654 - val_loss: 0.2984 - mcc: 0.7300\n",
      "Epoch 4/10\n",
      "\u001B[1m146/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8666 - loss: 0.2960\n",
      "Epoch 4 - MCC: 0.7299\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8667 - loss: 0.2959 - val_accuracy: 0.8652 - val_loss: 0.2973 - mcc: 0.7299\n",
      "Epoch 5/10\n",
      "\u001B[1m144/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8688 - loss: 0.2925\n",
      "Epoch 5 - MCC: 0.7395\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8689 - loss: 0.2924 - val_accuracy: 0.8693 - val_loss: 0.2904 - mcc: 0.7395\n",
      "Epoch 6/10\n",
      "\u001B[1m138/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8760 - loss: 0.2790\n",
      "Epoch 6 - MCC: 0.7440\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8757 - loss: 0.2796 - val_accuracy: 0.8717 - val_loss: 0.2842 - mcc: 0.7440\n",
      "Epoch 7/10\n",
      "\u001B[1m133/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8789 - loss: 0.2711\n",
      "Epoch 7 - MCC: 0.7472\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8784 - loss: 0.2721 - val_accuracy: 0.8732 - val_loss: 0.2808 - mcc: 0.7472\n",
      "Epoch 8/10\n",
      "\u001B[1m136/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8708 - loss: 0.2857\n",
      "Epoch 8 - MCC: 0.7457\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8712 - loss: 0.2850 - val_accuracy: 0.8732 - val_loss: 0.2802 - mcc: 0.7457\n",
      "Epoch 9/10\n",
      "\u001B[1m135/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8781 - loss: 0.2721\n",
      "Epoch 9 - MCC: 0.7490\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8778 - loss: 0.2726 - val_accuracy: 0.8743 - val_loss: 0.2771 - mcc: 0.7490\n",
      "Epoch 10/10\n",
      "\u001B[1m134/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8766 - loss: 0.2724\n",
      "Epoch 10 - MCC: 0.7466\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8764 - loss: 0.2729 - val_accuracy: 0.8709 - val_loss: 0.2839 - mcc: 0.7466\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': 0.8760366666666667,\n",
      "              'mean': 0.8735573333333333,\n",
      "              'min': 0.8700566666666667,\n",
      "              'std': 0.002543676604182727},\n",
      " 'Inference Time (s/sample)': {'max': 0.0003952936331431071,\n",
      "                               'mean': 0.0002770737012227376,\n",
      "                               'min': 0.00024331251780192057,\n",
      "                               'std': 5.917718655970826e-05},\n",
      " 'MCC': {'max': 0.7518154229988196,\n",
      "         'mean': 0.7476840223246175,\n",
      "         'min': 0.7391602516522487,\n",
      "         'std': 0.004653695825672912},\n",
      " 'Parameters': 5585,\n",
      " 'Train Time (s)': {'max': 14.646459341049194,\n",
      "                    'mean': 14.276570510864257,\n",
      "                    'min': 13.96598219871521,\n",
      "                    'std': 0.23330843147317679},\n",
      " 'Training Accuracy': [[0.7730276584625244,\n",
      "                        0.8553931713104248,\n",
      "                        0.8622990846633911,\n",
      "                        0.8648591041564941,\n",
      "                        0.8666584491729736,\n",
      "                        0.8688651323318481,\n",
      "                        0.8692417144775391,\n",
      "                        0.8699470162391663,\n",
      "                        0.871123731136322,\n",
      "                        0.8715344071388245],\n",
      "                       [0.7852294445037842,\n",
      "                        0.857470691204071,\n",
      "                        0.8644593358039856,\n",
      "                        0.8676415085792542,\n",
      "                        0.8685609698295593,\n",
      "                        0.8699567914009094,\n",
      "                        0.8718474507331848,\n",
      "                        0.872283399105072,\n",
      "                        0.8737058639526367,\n",
      "                        0.874801754951477],\n",
      "                       [0.7771402597427368,\n",
      "                        0.8576701879501343,\n",
      "                        0.8650622367858887,\n",
      "                        0.8680660724639893,\n",
      "                        0.869767427444458,\n",
      "                        0.8711310029029846,\n",
      "                        0.8727949261665344,\n",
      "                        0.8724349737167358,\n",
      "                        0.8751815557479858,\n",
      "                        0.8750816583633423],\n",
      "                       [0.7855400443077087,\n",
      "                        0.85662442445755,\n",
      "                        0.861514151096344,\n",
      "                        0.8654298782348633,\n",
      "                        0.8670893311500549,\n",
      "                        0.8678752779960632,\n",
      "                        0.8693568110466003,\n",
      "                        0.8706908226013184,\n",
      "                        0.87054842710495,\n",
      "                        0.872772753238678],\n",
      "                       [0.780074417591095,\n",
      "                        0.8613256812095642,\n",
      "                        0.8665655255317688,\n",
      "                        0.8691059350967407,\n",
      "                        0.8709974884986877,\n",
      "                        0.8715700507164001,\n",
      "                        0.8742717504501343,\n",
      "                        0.8743703365325928,\n",
      "                        0.874649167060852,\n",
      "                        0.8756316304206848]],\n",
      " 'Training Loss': [[0.4896738827228546,\n",
      "                    0.3203832507133484,\n",
      "                    0.3058907091617584,\n",
      "                    0.30068734288215637,\n",
      "                    0.2966962456703186,\n",
      "                    0.2928968369960785,\n",
      "                    0.2907443344593048,\n",
      "                    0.28915056586265564,\n",
      "                    0.28670158982276917,\n",
      "                    0.2854727804660797],\n",
      "                   [0.4642370045185089,\n",
      "                    0.3174617886543274,\n",
      "                    0.30283451080322266,\n",
      "                    0.2957386076450348,\n",
      "                    0.29347479343414307,\n",
      "                    0.2905939519405365,\n",
      "                    0.2868753671646118,\n",
      "                    0.28559473156929016,\n",
      "                    0.2822781503200531,\n",
      "                    0.280173659324646],\n",
      "                   [0.477640837430954,\n",
      "                    0.31772637367248535,\n",
      "                    0.30102166533470154,\n",
      "                    0.2942928671836853,\n",
      "                    0.29044970870018005,\n",
      "                    0.2882702052593231,\n",
      "                    0.2843003571033478,\n",
      "                    0.28416678309440613,\n",
      "                    0.27866217494010925,\n",
      "                    0.27794942259788513],\n",
      "                   [0.46886417269706726,\n",
      "                    0.3180452585220337,\n",
      "                    0.3070688843727112,\n",
      "                    0.2989862561225891,\n",
      "                    0.29551008343696594,\n",
      "                    0.29330188035964966,\n",
      "                    0.2908279001712799,\n",
      "                    0.287345290184021,\n",
      "                    0.28673887252807617,\n",
      "                    0.28277161717414856],\n",
      "                   [0.46835067868232727,\n",
      "                    0.31051692366600037,\n",
      "                    0.2975267171859741,\n",
      "                    0.2927403748035431,\n",
      "                    0.28869760036468506,\n",
      "                    0.2865537106990814,\n",
      "                    0.2804422378540039,\n",
      "                    0.27907896041870117,\n",
      "                    0.27773579955101013,\n",
      "                    0.27541908621788025]],\n",
      " 'Validation Accuracy': [[0.8495100140571594,\n",
      "                          0.8618767261505127,\n",
      "                          0.8654432892799377,\n",
      "                          0.8677133917808533,\n",
      "                          0.8704266548156738,\n",
      "                          0.8713099956512451,\n",
      "                          0.8718366622924805,\n",
      "                          0.873626708984375,\n",
      "                          0.8755900859832764,\n",
      "                          0.8760367035865784],\n",
      "                         [0.8516368269920349,\n",
      "                          0.8654100298881531,\n",
      "                          0.8676534295082092,\n",
      "                          0.8627933859825134,\n",
      "                          0.8711101412773132,\n",
      "                          0.873796820640564,\n",
      "                          0.8730632662773132,\n",
      "                          0.8748165965080261,\n",
      "                          0.8758366703987122,\n",
      "                          0.8754332661628723],\n",
      "                         [0.8410567045211792,\n",
      "                          0.8594301342964172,\n",
      "                          0.8618366718292236,\n",
      "                          0.8631598949432373,\n",
      "                          0.860960066318512,\n",
      "                          0.8660069704055786,\n",
      "                          0.8677065968513489,\n",
      "                          0.868090033531189,\n",
      "                          0.8669767379760742,\n",
      "                          0.8700567483901978],\n",
      "                         [0.8502300977706909,\n",
      "                          0.8623899221420288,\n",
      "                          0.8672866821289062,\n",
      "                          0.8679599165916443,\n",
      "                          0.8651466965675354,\n",
      "                          0.8680300116539001,\n",
      "                          0.8711434006690979,\n",
      "                          0.8746833205223083,\n",
      "                          0.8753601312637329,\n",
      "                          0.8753734230995178],\n",
      "                         [0.8547468185424805,\n",
      "                          0.862726628780365,\n",
      "                          0.8653767704963684,\n",
      "                          0.8651599884033203,\n",
      "                          0.8692933320999146,\n",
      "                          0.8717300295829773,\n",
      "                          0.8732433319091797,\n",
      "                          0.8731568455696106,\n",
      "                          0.8743434548377991,\n",
      "                          0.8708868622779846]],\n",
      " 'Validation Loss': [0.3240596652030945,\n",
      "                     0.3049612045288086,\n",
      "                     0.2984464764595032,\n",
      "                     0.297341525554657,\n",
      "                     0.2904251217842102,\n",
      "                     0.2841528058052063,\n",
      "                     0.2808442711830139,\n",
      "                     0.2802425026893616,\n",
      "                     0.2770705223083496,\n",
      "                     0.28393301367759705],\n",
      " 'Validation MCC': [[0.6975997940042505,\n",
      "                     0.7237157014916966,\n",
      "                     0.7324386050919712,\n",
      "                     0.7342145652217563,\n",
      "                     0.7402153773863345,\n",
      "                     0.7417189853522017,\n",
      "                     0.7443106116976907,\n",
      "                     0.7471872909135487,\n",
      "                     0.7517810858497679,\n",
      "                     0.7518154229988196],\n",
      "                    [0.7030014285869846,\n",
      "                     0.7297682599809795,\n",
      "                     0.7341409159352,\n",
      "                     0.7329548049111789,\n",
      "                     0.7427593640476021,\n",
      "                     0.7466659773314961,\n",
      "                     0.7481590932770151,\n",
      "                     0.7490222503450361,\n",
      "                     0.7514918868863629,\n",
      "                     0.7515322087522641],\n",
      "                    [0.6866071162932786,\n",
      "                     0.7180790548808409,\n",
      "                     0.7222918706617694,\n",
      "                     0.7248739823497315,\n",
      "                     0.7206453724838658,\n",
      "                     0.7337373024931382,\n",
      "                     0.7360957320782411,\n",
      "                     0.7349430644851118,\n",
      "                     0.7372331297656136,\n",
      "                     0.7391602516522487],\n",
      "                    [0.6988913993571292,\n",
      "                     0.7230766583614823,\n",
      "                     0.7347004038773287,\n",
      "                     0.7377228776479298,\n",
      "                     0.7299576433562248,\n",
      "                     0.734940789916349,\n",
      "                     0.7407060365254441,\n",
      "                     0.7481128041007172,\n",
      "                     0.7495932254475925,\n",
      "                     0.7492986265907058],\n",
      "                    [0.7095826238674784,\n",
      "                     0.7279818632713482,\n",
      "                     0.7299881514143148,\n",
      "                     0.7299361059797409,\n",
      "                     0.7394953139101373,\n",
      "                     0.7440328124253668,\n",
      "                     0.7472328017508707,\n",
      "                     0.7456595143311631,\n",
      "                     0.7489696269942958,\n",
      "                     0.7466136016290489]]}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "hilbert_binary_model_results, trained_models = train_and_evaluate(simple_models_dict, X=hilbert_data_vec, y=label_binary, epochs=10,\n",
    "                                                           dir_name=\"hilbert_binary\")\n",
    "\n",
    "basePath = \"/content/drive/MyDrive/Colab Notebooks/Bachelor Thesis/Data/Model Comparisons/\"\n",
    "filePath = f\"{basePath}/Hilbert_Binary_Model_Results.json\"\n",
    "\n",
    "with open(filePath, 'w') as f:\n",
    "        json.dump(hilbert_binary_model_results, f, indent=4)  # indent=4 for pretty formatting"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "InB7xVXoJmde",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738697210637,
     "user_tz": -60,
     "elapsed": 1274234,
     "user": {
      "displayName": "Jasper Angl",
      "userId": "13853951665807648258"
     }
    },
    "outputId": "77e01f36-155d-49ec-d980-bcf3c57c21f3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 1\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6560 - loss: 0.6141\n",
      "Epoch 1 - MCC: 0.6221\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 23ms/step - accuracy: 0.6570 - loss: 0.6129 - val_accuracy: 0.8080 - val_loss: 0.4002 - mcc: 0.6221\n",
      "Epoch 2/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8243 - loss: 0.3807\n",
      "Epoch 2 - MCC: 0.7010\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.8246 - loss: 0.3802 - val_accuracy: 0.8511 - val_loss: 0.3283 - mcc: 0.7010\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8541 - loss: 0.3218\n",
      "Epoch 3 - MCC: 0.7200\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 26ms/step - accuracy: 0.8541 - loss: 0.3218 - val_accuracy: 0.8606 - val_loss: 0.3065 - mcc: 0.7200\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8567 - loss: 0.3148\n",
      "Epoch 4 - MCC: 0.7283\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.8567 - loss: 0.3147 - val_accuracy: 0.8647 - val_loss: 0.2938 - mcc: 0.7283\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8652 - loss: 0.2969\n",
      "Epoch 5 - MCC: 0.7391\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8652 - loss: 0.2969 - val_accuracy: 0.8695 - val_loss: 0.2897 - mcc: 0.7391\n",
      "Epoch 6/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8701 - loss: 0.2869\n",
      "Epoch 6 - MCC: 0.7523\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 26ms/step - accuracy: 0.8701 - loss: 0.2869 - val_accuracy: 0.8766 - val_loss: 0.2731 - mcc: 0.7523\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8720 - loss: 0.2803\n",
      "Epoch 7 - MCC: 0.7424\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8720 - loss: 0.2803 - val_accuracy: 0.8716 - val_loss: 0.2809 - mcc: 0.7424\n",
      "Epoch 8/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8780 - loss: 0.2680\n",
      "Epoch 8 - MCC: 0.7570\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.8779 - loss: 0.2683 - val_accuracy: 0.8789 - val_loss: 0.2631 - mcc: 0.7570\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8705 - loss: 0.2805\n",
      "Epoch 9 - MCC: 0.7534\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8706 - loss: 0.2804 - val_accuracy: 0.8766 - val_loss: 0.2681 - mcc: 0.7534\n",
      "Epoch 10/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8759 - loss: 0.2714\n",
      "Epoch 10 - MCC: 0.7626\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.8759 - loss: 0.2714 - val_accuracy: 0.8818 - val_loss: 0.2594 - mcc: 0.7626\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 2\n",
      "Epoch 1/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6694 - loss: 0.5914\n",
      "Epoch 1 - MCC: 0.6436\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.6709 - loss: 0.5897 - val_accuracy: 0.8226 - val_loss: 0.3926 - mcc: 0.6436\n",
      "Epoch 2/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8230 - loss: 0.3834\n",
      "Epoch 2 - MCC: 0.6890\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8231 - loss: 0.3832 - val_accuracy: 0.8452 - val_loss: 0.3433 - mcc: 0.6890\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8411 - loss: 0.3448\n",
      "Epoch 3 - MCC: 0.7141\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 24ms/step - accuracy: 0.8412 - loss: 0.3448 - val_accuracy: 0.8563 - val_loss: 0.3190 - mcc: 0.7141\n",
      "Epoch 4/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8550 - loss: 0.3181\n",
      "Epoch 4 - MCC: 0.7289\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8551 - loss: 0.3179 - val_accuracy: 0.8647 - val_loss: 0.2962 - mcc: 0.7289\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8643 - loss: 0.2987\n",
      "Epoch 5 - MCC: 0.7352\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8643 - loss: 0.2987 - val_accuracy: 0.8677 - val_loss: 0.2927 - mcc: 0.7352\n",
      "Epoch 6/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8675 - loss: 0.2926\n",
      "Epoch 6 - MCC: 0.7475\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 25ms/step - accuracy: 0.8675 - loss: 0.2926 - val_accuracy: 0.8742 - val_loss: 0.2810 - mcc: 0.7475\n",
      "Epoch 7/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8705 - loss: 0.2854\n",
      "Epoch 7 - MCC: 0.7562\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.8705 - loss: 0.2854 - val_accuracy: 0.8786 - val_loss: 0.2727 - mcc: 0.7562\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8712 - loss: 0.2825\n",
      "Epoch 8 - MCC: 0.7583\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8712 - loss: 0.2825 - val_accuracy: 0.8797 - val_loss: 0.2696 - mcc: 0.7583\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8725 - loss: 0.2808\n",
      "Epoch 9 - MCC: 0.7599\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8725 - loss: 0.2808 - val_accuracy: 0.8805 - val_loss: 0.2671 - mcc: 0.7599\n",
      "Epoch 10/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8721 - loss: 0.2823\n",
      "Epoch 10 - MCC: 0.7598\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 22ms/step - accuracy: 0.8722 - loss: 0.2821 - val_accuracy: 0.8799 - val_loss: 0.2681 - mcc: 0.7598\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 3\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7134 - loss: 0.5896\n",
      "Epoch 1 - MCC: 0.6280\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 23ms/step - accuracy: 0.7141 - loss: 0.5884 - val_accuracy: 0.8113 - val_loss: 0.4014 - mcc: 0.6280\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8332 - loss: 0.3624\n",
      "Epoch 2 - MCC: 0.6893\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 27ms/step - accuracy: 0.8332 - loss: 0.3623 - val_accuracy: 0.8455 - val_loss: 0.3354 - mcc: 0.6893\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8630 - loss: 0.3052\n",
      "Epoch 3 - MCC: 0.7142\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.8630 - loss: 0.3052 - val_accuracy: 0.8579 - val_loss: 0.3118 - mcc: 0.7142\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8688 - loss: 0.2919\n",
      "Epoch 4 - MCC: 0.7231\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.8688 - loss: 0.2919 - val_accuracy: 0.8623 - val_loss: 0.3018 - mcc: 0.7231\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8678 - loss: 0.2918\n",
      "Epoch 5 - MCC: 0.7150\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 25ms/step - accuracy: 0.8678 - loss: 0.2918 - val_accuracy: 0.8582 - val_loss: 0.3094 - mcc: 0.7150\n",
      "Epoch 6/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8730 - loss: 0.2826\n",
      "Epoch 6 - MCC: 0.7297\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8730 - loss: 0.2826 - val_accuracy: 0.8656 - val_loss: 0.2906 - mcc: 0.7297\n",
      "Epoch 7/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8757 - loss: 0.2726\n",
      "Epoch 7 - MCC: 0.7343\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8757 - loss: 0.2726 - val_accuracy: 0.8676 - val_loss: 0.2884 - mcc: 0.7343\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8806 - loss: 0.2663\n",
      "Epoch 8 - MCC: 0.7388\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 22ms/step - accuracy: 0.8806 - loss: 0.2663 - val_accuracy: 0.8701 - val_loss: 0.2821 - mcc: 0.7388\n",
      "Epoch 9/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8832 - loss: 0.2572\n",
      "Epoch 9 - MCC: 0.7407\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 24ms/step - accuracy: 0.8831 - loss: 0.2573 - val_accuracy: 0.8711 - val_loss: 0.2804 - mcc: 0.7407\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8752 - loss: 0.2713\n",
      "Epoch 10 - MCC: 0.7386\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.8752 - loss: 0.2712 - val_accuracy: 0.8697 - val_loss: 0.2842 - mcc: 0.7386\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 4\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.6954 - loss: 0.5851\n",
      "Epoch 1 - MCC: 0.6511\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 29ms/step - accuracy: 0.6958 - loss: 0.5844 - val_accuracy: 0.8229 - val_loss: 0.3812 - mcc: 0.6511\n",
      "Epoch 2/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8350 - loss: 0.3610\n",
      "Epoch 2 - MCC: 0.6934\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8350 - loss: 0.3608 - val_accuracy: 0.8457 - val_loss: 0.3299 - mcc: 0.6934\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8505 - loss: 0.3241\n",
      "Epoch 3 - MCC: 0.7140\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8505 - loss: 0.3241 - val_accuracy: 0.8578 - val_loss: 0.3074 - mcc: 0.7140\n",
      "Epoch 4/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8556 - loss: 0.3134\n",
      "Epoch 4 - MCC: 0.7301\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8557 - loss: 0.3133 - val_accuracy: 0.8658 - val_loss: 0.2955 - mcc: 0.7301\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8639 - loss: 0.2983\n",
      "Epoch 5 - MCC: 0.7313\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 24ms/step - accuracy: 0.8639 - loss: 0.2983 - val_accuracy: 0.8665 - val_loss: 0.2895 - mcc: 0.7313\n",
      "Epoch 6/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8660 - loss: 0.2946\n",
      "Epoch 6 - MCC: 0.7445\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8660 - loss: 0.2945 - val_accuracy: 0.8730 - val_loss: 0.2796 - mcc: 0.7445\n",
      "Epoch 7/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8727 - loss: 0.2812\n",
      "Epoch 7 - MCC: 0.7494\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.8727 - loss: 0.2812 - val_accuracy: 0.8755 - val_loss: 0.2721 - mcc: 0.7494\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8743 - loss: 0.2765\n",
      "Epoch 8 - MCC: 0.7557\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 26ms/step - accuracy: 0.8743 - loss: 0.2765 - val_accuracy: 0.8786 - val_loss: 0.2701 - mcc: 0.7557\n",
      "Epoch 9/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8754 - loss: 0.2734\n",
      "Epoch 9 - MCC: 0.7568\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 20ms/step - accuracy: 0.8754 - loss: 0.2733 - val_accuracy: 0.8791 - val_loss: 0.2665 - mcc: 0.7568\n",
      "Epoch 10/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8774 - loss: 0.2708\n",
      "Epoch 10 - MCC: 0.7565\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 18ms/step - accuracy: 0.8775 - loss: 0.2707 - val_accuracy: 0.8788 - val_loss: 0.2665 - mcc: 0.7565\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: LSTM, Fold: 5\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.6667 - loss: 0.6119\n",
      "Epoch 1 - MCC: 0.6569\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 29ms/step - accuracy: 0.6677 - loss: 0.6106 - val_accuracy: 0.8291 - val_loss: 0.3725 - mcc: 0.6569\n",
      "Epoch 2/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8360 - loss: 0.3569\n",
      "Epoch 2 - MCC: 0.6815\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.8360 - loss: 0.3568 - val_accuracy: 0.8395 - val_loss: 0.3463 - mcc: 0.6815\n",
      "Epoch 3/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8440 - loss: 0.3372\n",
      "Epoch 3 - MCC: 0.7079\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8441 - loss: 0.3370 - val_accuracy: 0.8541 - val_loss: 0.3168 - mcc: 0.7079\n",
      "Epoch 4/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8552 - loss: 0.3157\n",
      "Epoch 4 - MCC: 0.7121\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8552 - loss: 0.3156 - val_accuracy: 0.8560 - val_loss: 0.3164 - mcc: 0.7121\n",
      "Epoch 5/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8623 - loss: 0.3028\n",
      "Epoch 5 - MCC: 0.7227\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 22ms/step - accuracy: 0.8623 - loss: 0.3027 - val_accuracy: 0.8610 - val_loss: 0.3012 - mcc: 0.7227\n",
      "Epoch 6/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8691 - loss: 0.2874\n",
      "Epoch 6 - MCC: 0.7317\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.8691 - loss: 0.2874 - val_accuracy: 0.8659 - val_loss: 0.2932 - mcc: 0.7317\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8699 - loss: 0.2872\n",
      "Epoch 7 - MCC: 0.7497\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 24ms/step - accuracy: 0.8700 - loss: 0.2872 - val_accuracy: 0.8752 - val_loss: 0.2791 - mcc: 0.7497\n",
      "Epoch 8/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8704 - loss: 0.2841\n",
      "Epoch 8 - MCC: 0.7463\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8705 - loss: 0.2839 - val_accuracy: 0.8735 - val_loss: 0.2793 - mcc: 0.7463\n",
      "Epoch 9/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8806 - loss: 0.2657\n",
      "Epoch 9 - MCC: 0.7500\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8805 - loss: 0.2658 - val_accuracy: 0.8754 - val_loss: 0.2761 - mcc: 0.7500\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8793 - loss: 0.2666\n",
      "Epoch 10 - MCC: 0.7545\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8793 - loss: 0.2666 - val_accuracy: 0.8772 - val_loss: 0.2720 - mcc: 0.7545\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': 0.8818333333333334,\n",
      "              'mean': 0.8775000000000001,\n",
      "              'min': 0.8697233333333333,\n",
      "              'std': 0.004170789959814455},\n",
      " 'Inference Time (s/sample)': {'max': 0.0005940433343251546,\n",
      "                               'mean': 0.0005259210268656413,\n",
      "                               'min': 0.0003465306758880615,\n",
      "                               'std': 9.566330125008072e-05},\n",
      " 'MCC': {'max': 0.7626060585214626,\n",
      "         'mean': 0.7544030166940769,\n",
      "         'min': 0.738590629924663,\n",
      "         'std': 0.008382744808606093},\n",
      " 'Parameters': 4897,\n",
      " 'Train Time (s)': {'max': 44.61317443847656,\n",
      "                    'mean': 41.79472851753235,\n",
      "                    'min': 39.90839338302612,\n",
      "                    'std': 1.694173267454396},\n",
      " 'Training Accuracy': [[0.7342041730880737,\n",
      "                        0.8339634537696838,\n",
      "                        0.8514416813850403,\n",
      "                        0.8590488433837891,\n",
      "                        0.8656450510025024,\n",
      "                        0.8691300749778748,\n",
      "                        0.8722498416900635,\n",
      "                        0.8734942674636841,\n",
      "                        0.8747867941856384,\n",
      "                        0.8768048286437988],\n",
      "                       [0.7488489747047424,\n",
      "                        0.8269294500350952,\n",
      "                        0.8472164869308472,\n",
      "                        0.858063280582428,\n",
      "                        0.8637991547584534,\n",
      "                        0.8670533299446106,\n",
      "                        0.8705182671546936,\n",
      "                        0.8729501366615295,\n",
      "                        0.8747089505195618,\n",
      "                        0.87589031457901],\n",
      "                       [0.7689284682273865,\n",
      "                        0.841697633266449,\n",
      "                        0.8603134155273438,\n",
      "                        0.8676607012748718,\n",
      "                        0.8715832233428955,\n",
      "                        0.8740283250808716,\n",
      "                        0.8770784735679626,\n",
      "                        0.8788408637046814,\n",
      "                        0.8802993893623352,\n",
      "                        0.8812565207481384],\n",
      "                       [0.7604634165763855,\n",
      "                        0.835970938205719,\n",
      "                        0.8514552712440491,\n",
      "                        0.8578848242759705,\n",
      "                        0.8642189502716064,\n",
      "                        0.8681870698928833,\n",
      "                        0.8725185394287109,\n",
      "                        0.8751944899559021,\n",
      "                        0.8775618672370911,\n",
      "                        0.8786410689353943],\n",
      "                       [0.7422534823417664,\n",
      "                        0.8364880084991455,\n",
      "                        0.8499557971954346,\n",
      "                        0.8587548732757568,\n",
      "                        0.864495038986206,\n",
      "                        0.8674089312553406,\n",
      "                        0.8721951246261597,\n",
      "                        0.8741623759269714,\n",
      "                        0.8764306902885437,\n",
      "                        0.8785099387168884]],\n",
      " 'Training Loss': [[0.5214751958847046,\n",
      "                    0.36110419034957886,\n",
      "                    0.32490450143814087,\n",
      "                    0.30972152948379517,\n",
      "                    0.29435306787490845,\n",
      "                    0.2873322665691376,\n",
      "                    0.2797957956790924,\n",
      "                    0.2763214111328125,\n",
      "                    0.2737085223197937,\n",
      "                    0.2698110044002533],\n",
      "                   [0.5016065239906311,\n",
      "                    0.37313368916511536,\n",
      "                    0.33338868618011475,\n",
      "                    0.31283730268478394,\n",
      "                    0.29863235354423523,\n",
      "                    0.291674941778183,\n",
      "                    0.28529253602027893,\n",
      "                    0.27905014157295227,\n",
      "                    0.27628543972969055,\n",
      "                    0.2735191285610199],\n",
      "                   [0.4950956106185913,\n",
      "                    0.34624385833740234,\n",
      "                    0.3093565106391907,\n",
      "                    0.29359012842178345,\n",
      "                    0.2844908833503723,\n",
      "                    0.27943161129951477,\n",
      "                    0.27104872465133667,\n",
      "                    0.26795199513435364,\n",
      "                    0.2636086940765381,\n",
      "                    0.2610355019569397],\n",
      "                   [0.4924260377883911,\n",
      "                    0.3545808792114258,\n",
      "                    0.3227855861186981,\n",
      "                    0.30889710783958435,\n",
      "                    0.2977175712585449,\n",
      "                    0.28957808017730713,\n",
      "                    0.2806667983531952,\n",
      "                    0.27522438764572144,\n",
      "                    0.26946666836738586,\n",
      "                    0.26865753531455994],\n",
      "                   [0.5128178596496582,\n",
      "                    0.3533055782318115,\n",
      "                    0.3264499604701996,\n",
      "                    0.30891507863998413,\n",
      "                    0.2982425093650818,\n",
      "                    0.2907571494579315,\n",
      "                    0.28272420167922974,\n",
      "                    0.27711549401283264,\n",
      "                    0.2717571556568146,\n",
      "                    0.267833948135376]],\n",
      " 'Validation Accuracy': [[0.8079566359519958,\n",
      "                          0.8511333465576172,\n",
      "                          0.8606398701667786,\n",
      "                          0.864703357219696,\n",
      "                          0.8695032000541687,\n",
      "                          0.8766499757766724,\n",
      "                          0.8716167211532593,\n",
      "                          0.8788633346557617,\n",
      "                          0.8765533566474915,\n",
      "                          0.8818333148956299],\n",
      "                         [0.8225600123405457,\n",
      "                          0.8452266454696655,\n",
      "                          0.8563232421875,\n",
      "                          0.8647333979606628,\n",
      "                          0.8676766157150269,\n",
      "                          "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8742033839225769,\n",
      "                          0.8786066770553589,\n",
      "                          0.8796566724777222,\n",
      "                          0.8804634809494019,\n",
      "                          0.8799267411231995],\n",
      "                         [0.8112832903862,\n",
      "                          0.8454834222793579,\n",
      "                          0.8578999042510986,\n",
      "                          0.862333357334137,\n",
      "                          0.8581697344779968,\n",
      "                          0.8656034469604492,\n",
      "                          0.8676100373268127,\n",
      "                          0.8701332807540894,\n",
      "                          0.8710566163063049,\n",
      "                          0.8697232007980347],\n",
      "                         [0.8229433298110962,\n",
      "                          0.8457266092300415,\n",
      "                          0.8577865362167358,\n",
      "                          0.8658067584037781,\n",
      "                          0.866473376750946,\n",
      "                          0.873003363609314,\n",
      "                          0.8754532933235168,\n",
      "                          0.8785767555236816,\n",
      "                          0.8790767192840576,\n",
      "                          0.8788200616836548],\n",
      "                         [0.8290632963180542,\n",
      "                          0.839460015296936,\n",
      "                          0.8540700078010559,\n",
      "                          0.8559966087341309,\n",
      "                          0.8610268235206604,\n",
      "                          0.8658733367919922,\n",
      "                          0.8752465844154358,\n",
      "                          0.8734599947929382,\n",
      "                          0.8754266500473022,\n",
      "                          0.8771966695785522]],\n",
      " 'Validation Loss': [0.3724639117717743,\n",
      "                     0.34634050726890564,\n",
      "                     0.3167848587036133,\n",
      "                     0.31640878319740295,\n",
      "                     0.30124223232269287,\n",
      "                     0.2931853234767914,\n",
      "                     0.279121994972229,\n",
      "                     0.27930039167404175,\n",
      "                     0.2761164903640747,\n",
      "                     0.2719775140285492],\n",
      " 'Validation MCC': [[0.6220903472045332,\n",
      "                     0.7009653339207629,\n",
      "                     0.7199872158687278,\n",
      "                     0.7283484055574344,\n",
      "                     0.7390633561495451,\n",
      "                     0.7522674879558122,\n",
      "                     0.742386340837644,\n",
      "                     0.7570106001299862,\n",
      "                     0.753416137390264,\n",
      "                     0.7626060585214626],\n",
      "                    [0.6435793227041884,\n",
      "                     0.6890228582105488,\n",
      "                     0.714117721119145,\n",
      "                     0.7288530849144472,\n",
      "                     0.7351908182940162,\n",
      "                     0.7475106704089738,\n",
      "                     0.7562414172940052,\n",
      "                     0.7582595420110558,\n",
      "                     0.7598797938323478,\n",
      "                     0.7598414893854691],\n",
      "                    [0.6280448647147802,\n",
      "                     0.6893360861105019,\n",
      "                     0.7141914451107719,\n",
      "                     0.7231425198653773,\n",
      "                     0.7149601904692502,\n",
      "                     0.7297056388593703,\n",
      "                     0.7342617881234487,\n",
      "                     0.7388298337036623,\n",
      "                     0.7407075059811057,\n",
      "                     0.738590629924663],\n",
      "                    [0.65107956388441,\n",
      "                     0.6933740897913073,\n",
      "                     0.7139869345310225,\n",
      "                     0.7301498829615147,\n",
      "                     0.7313036772028604,\n",
      "                     0.744465514715046,\n",
      "                     0.7493946646251743,\n",
      "                     0.7557350758657934,\n",
      "                     0.7567526599022742,\n",
      "                     0.7565124776443811],\n",
      "                    [0.6568831372402805,\n",
      "                     0.6815158769392151,\n",
      "                     0.7078544751129227,\n",
      "                     0.7121024148393866,\n",
      "                     0.7226755385197742,\n",
      "                     0.7316722281166663,\n",
      "                     0.7497373457644172,\n",
      "                     0.7463229818811986,\n",
      "                     0.7500206145248981,\n",
      "                     0.754464427994409]]}\n",
      "Training Model: BiLSTM, Fold: 1\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.6913 - loss: 0.5879\n",
      "Epoch 1 - MCC: 0.6884\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 39ms/step - accuracy: 0.6923 - loss: 0.5865 - val_accuracy: 0.8447 - val_loss: 0.3409 - mcc: 0.6884\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8489 - loss: 0.3318\n",
      "Epoch 2 - MCC: 0.7394\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 41ms/step - accuracy: 0.8490 - loss: 0.3317 - val_accuracy: 0.8697 - val_loss: 0.2929 - mcc: 0.7394\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8707 - loss: 0.2911\n",
      "Epoch 3 - MCC: 0.7714\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.8708 - loss: 0.2910 - val_accuracy: 0.8862 - val_loss: 0.2610 - mcc: 0.7714\n",
      "Epoch 4/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8774 - loss: 0.2753\n",
      "Epoch 4 - MCC: 0.7921\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 44ms/step - accuracy: 0.8774 - loss: 0.2752 - val_accuracy: 0.8965 - val_loss: 0.2393 - mcc: 0.7921\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8889 - loss: 0.2513\n",
      "Epoch 5 - MCC: 0.8008\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 33ms/step - accuracy: 0.8890 - loss: 0.2512 - val_accuracy: 0.9007 - val_loss: 0.2277 - mcc: 0.8008\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.8920 - loss: 0.2438\n",
      "Epoch 6 - MCC: 0.8044\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.8921 - loss: 0.2437 - val_accuracy: 0.9022 - val_loss: 0.2230 - mcc: 0.8044\n",
      "Epoch 7/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8933 - loss: 0.2392\n",
      "Epoch 7 - MCC: 0.8104\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 33ms/step - accuracy: 0.8933 - loss: 0.2391 - val_accuracy: 0.9056 - val_loss: 0.2165 - mcc: 0.8104\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.9006 - loss: 0.2258\n",
      "Epoch 8 - MCC: 0.8114\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 40ms/step - accuracy: 0.9005 - loss: 0.2258 - val_accuracy: 0.9060 - val_loss: 0.2138 - mcc: 0.8114\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9017 - loss: 0.2214\n",
      "Epoch 9 - MCC: 0.8154\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.9017 - loss: 0.2214 - val_accuracy: 0.9078 - val_loss: 0.2112 - mcc: 0.8154\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8984 - loss: 0.2296\n",
      "Epoch 10 - MCC: 0.8197\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 40ms/step - accuracy: 0.8984 - loss: 0.2294 - val_accuracy: 0.9102 - val_loss: 0.2047 - mcc: 0.8197\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 2\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.6948 - loss: 0.5939\n",
      "Epoch 1 - MCC: 0.6995\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 37ms/step - accuracy: 0.6953 - loss: 0.5932 - val_accuracy: 0.8500 - val_loss: 0.3411 - mcc: 0.6995\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.8505 - loss: 0.3333\n",
      "Epoch 2 - MCC: 0.7413\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8506 - loss: 0.3332 - val_accuracy: 0.8712 - val_loss: 0.2895 - mcc: 0.7413\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8691 - loss: 0.2950\n",
      "Epoch 3 - MCC: 0.7612\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 32ms/step - accuracy: 0.8692 - loss: 0.2949 - val_accuracy: 0.8810 - val_loss: 0.2685 - mcc: 0.7612\n",
      "Epoch 4/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8783 - loss: 0.2733\n",
      "Epoch 4 - MCC: 0.7751\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.8783 - loss: 0.2732 - val_accuracy: 0.8881 - val_loss: 0.2496 - mcc: 0.7751\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8881 - loss: 0.2542\n",
      "Epoch 5 - MCC: 0.7959\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.8881 - loss: 0.2542 - val_accuracy: 0.8984 - val_loss: 0.2315 - mcc: 0.7959\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8929 - loss: 0.2423\n",
      "Epoch 6 - MCC: 0.7961\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 36ms/step - accuracy: 0.8929 - loss: 0.2423 - val_accuracy: 0.8985 - val_loss: 0.2269 - mcc: 0.7961\n",
      "Epoch 7/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8989 - loss: 0.2300\n",
      "Epoch 7 - MCC: 0.8056\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 34ms/step - accuracy: 0.8989 - loss: 0.2300 - val_accuracy: 0.9032 - val_loss: 0.2207 - mcc: 0.8056\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8981 - loss: 0.2307\n",
      "Epoch 8 - MCC: 0.8071\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 40ms/step - accuracy: 0.8981 - loss: 0.2306 - val_accuracy: 0.9039 - val_loss: 0.2176 - mcc: 0.8071\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9020 - loss: 0.2226\n",
      "Epoch 9 - MCC: 0.8029\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.9020 - loss: 0.2226 - val_accuracy: 0.9015 - val_loss: 0.2197 - mcc: 0.8029\n",
      "Epoch 10/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9016 - loss: 0.2241\n",
      "Epoch 10 - MCC: 0.8137\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 36ms/step - accuracy: 0.9016 - loss: 0.2240 - val_accuracy: 0.9073 - val_loss: 0.2110 - mcc: 0.8137\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 3\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.6666 - loss: 0.6177\n",
      "Epoch 1 - MCC: 0.6861\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 36ms/step - accuracy: 0.6672 - loss: 0.6170 - val_accuracy: 0.8438 - val_loss: 0.3510 - mcc: 0.6861\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8603 - loss: 0.3202\n",
      "Epoch 2 - MCC: 0.7369\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 40ms/step - accuracy: 0.8603 - loss: 0.3201 - val_accuracy: 0.8692 - val_loss: 0.2933 - mcc: 0.7369\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.8782 - loss: 0.2767\n",
      "Epoch 3 - MCC: 0.7582\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 35ms/step - accuracy: 0.8783 - loss: 0.2766 - val_accuracy: 0.8798 - val_loss: 0.2697 - mcc: 0.7582\n",
      "Epoch 4/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8878 - loss: 0.2545\n",
      "Epoch 4 - MCC: 0.7697\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.8879 - loss: 0.2544 - val_accuracy: 0.8851 - val_loss: 0.2571 - mcc: 0.7697\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.8986 - loss: 0.2343\n",
      "Epoch 5 - MCC: 0.7700\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 40ms/step - accuracy: 0.8986 - loss: 0.2343 - val_accuracy: 0.8847 - val_loss: 0.2520 - mcc: 0.7700\n",
      "Epoch 6/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9031 - loss: 0.2219\n",
      "Epoch 6 - MCC: 0.7850\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.9031 - loss: 0.2219 - val_accuracy: 0.8930 - val_loss: 0.2383 - mcc: 0.7850\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9012 - loss: 0.2236\n",
      "Epoch 7 - MCC: 0.7910\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.9013 - loss: 0.2236 - val_accuracy: 0.8959 - val_loss: 0.2373 - mcc: 0.7910\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9080 - loss: 0.2119\n",
      "Epoch 8 - MCC: 0.7871\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 38ms/step - accuracy: 0.9080 - loss: 0.2120 - val_accuracy: 0.8939 - val_loss: 0.2338 - mcc: 0.7871\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9053 - loss: 0.2123\n",
      "Epoch 9 - MCC: 0.7988\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 40ms/step - accuracy: 0.9053 - loss: 0.2123 - val_accuracy: 0.8999 - val_loss: 0.2259 - mcc: 0.7988\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9101 - loss: 0.2043\n",
      "Epoch 10 - MCC: 0.7972\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.9101 - loss: 0.2043 - val_accuracy: 0.8989 - val_loss: 0.2288 - mcc: 0.7972\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 4\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.6925 - loss: 0.5890\n",
      "Epoch 1 - MCC: 0.6862\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 47ms/step - accuracy: 0.6931 - loss: 0.5883 - val_accuracy: 0.8409 - val_loss: 0.3514 - mcc: 0.6862\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8498 - loss: 0.3339\n",
      "Epoch 2 - MCC: 0.7410\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 34ms/step - accuracy: 0.8499 - loss: 0.3338 - val_accuracy: 0.8713 - val_loss: 0.2886 - mcc: 0.7410\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.8731 - loss: 0.2873\n",
      "Epoch 3 - MCC: 0.7636\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 40ms/step - accuracy: 0.8731 - loss: 0.2872 - val_accuracy: 0.8825 - val_loss: 0.2679 - mcc: 0.7636\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8817 - loss: 0.2663\n",
      "Epoch 4 - MCC: 0.7771\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.8817 - loss: 0.2662 - val_accuracy: 0.8886 - val_loss: 0.2500 - mcc: 0.7771\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8882 - loss: 0.2515\n",
      "Epoch 5 - MCC: 0.7862\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 40ms/step - accuracy: 0.8882 - loss: 0.2514 - val_accuracy: 0.8936 - val_loss: 0.2441 - mcc: 0.7862\n",
      "Epoch 6/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.8940 - loss: 0.2434\n",
      "Epoch 6 - MCC: 0.7980\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 35ms/step - accuracy: 0.8940 - loss: 0.2434 - val_accuracy: 0.8995 - val_loss: 0.2304 - mcc: 0.7980\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.8979 - loss: 0.2338\n",
      "Epoch 7 - MCC: 0.7967\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 42ms/step - accuracy: 0.8980 - loss: 0.2338 - val_accuracy: 0.8984 - val_loss: 0.2281 - mcc: 0.7967\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8992 - loss: 0.2288\n",
      "Epoch 8 - MCC: 0.8035\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.8992 - loss: 0.2287 - val_accuracy: 0.9023 - val_loss: 0.2207 - mcc: 0.8035\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9024 - loss: 0.2228\n",
      "Epoch 9 - MCC: 0.8082\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 34ms/step - accuracy: 0.9024 - loss: 0.2228 - val_accuracy: 0.9046 - val_loss: 0.2173 - mcc: 0.8082\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9037 - loss: 0.2177\n",
      "Epoch 10 - MCC: 0.8022\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.9037 - loss: 0.2177 - val_accuracy: 0.9008 - val_loss: 0.2212 - mcc: 0.8022\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: BiLSTM, Fold: 5\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.6957 - loss: 0.5909\n",
      "Epoch 1 - MCC: 0.6888\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 42ms/step - accuracy: 0.6967 - loss: 0.5895 - val_accuracy: 0.8445 - val_loss: 0.3454 - mcc: 0.6888\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8583 - loss: 0.3172\n",
      "Epoch 2 - MCC: 0.7416\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 33ms/step - accuracy: 0.8584 - loss: 0.3171 - val_accuracy: 0.8703 - val_loss: 0.2939 - mcc: 0.7416\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8781 - loss: 0.2768\n",
      "Epoch 3 - MCC: 0.7678\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 41ms/step - accuracy: 0.8781 - loss: 0.2767 - val_accuracy: 0.8843 - val_loss: 0.2652 - mcc: 0.7678\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.8838 - loss: 0.2648\n",
      "Epoch 4 - MCC: 0.7697\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 33ms/step - accuracy: 0.8838 - loss: 0.2647 - val_accuracy: 0.8839 - val_loss: 0.2570 - mcc: 0.7697\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.8938 - loss: 0.2410\n",
      "Epoch 5 - MCC: 0.7921\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 41ms/step - accuracy: 0.8938 - loss: 0.2409 - val_accuracy: 0.8963 - val_loss: 0.2374 - mcc: 0.7921\n",
      "Epoch 6/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.8946 - loss: 0.2384\n",
      "Epoch 6 - MCC: 0.7959\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 42ms/step - accuracy: 0.8946 - loss: 0.2384 - val_accuracy: 0.8982 - val_loss: 0.2322 - mcc: 0.7959\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9046 - loss: 0.2193\n",
      "Epoch 7 - MCC: 0.8030\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 33ms/step - accuracy: 0.9046 - loss: 0.2194 - val_accuracy: 0.9017 - val_loss: 0.2257 - mcc: 0.8030\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9045 - loss: 0.2154\n",
      "Epoch 8 - MCC: 0.8050\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 38ms/step - accuracy: 0.9045 - loss: 0.2154 - val_accuracy: 0.9025 - val_loss: 0.2249 - mcc: 0.8050\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9073 - loss: 0.2127\n",
      "Epoch 9 - MCC: 0.8039\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 33ms/step - accuracy: 0.9073 - loss: 0.2128 - val_accuracy: 0.9016 - val_loss: 0.2259 - mcc: 0.8039\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.9076 - loss: 0.2111\n",
      "Epoch 10 - MCC: 0.8103\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 32ms/step - accuracy: 0.9076 - loss: 0.2111 - val_accuracy: 0.9054 - val_loss: 0.2168 - mcc: 0.8103\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': 0.9102133333333333,\n",
      "              'mean': 0.904522,\n",
      "              'min': 0.8988666666666667,\n",
      "              'std': 0.004154104583287329},\n",
      " 'Inference Time (s/sample)': {'max': 0.001170128583908081,\n",
      "                               'mean': 0.000710318644841512,\n",
      "                               'min': 0.000510702927907308,\n",
      "                               'std': 0.00023613676703191679},\n",
      " 'MCC': {'max': 0.8197041117524011,\n",
      "         'mean': 0.8086076112032984,\n",
      "         'min': 0.7971602995967009,\n",
      "         'std': 0.008061748834592234},\n",
      " 'Parameters': 4973,\n",
      " 'Train Time (s)': {'max': 73.3216643333435,\n",
      "                    'mean': 67.64546756744384,\n",
      "                    'min': 61.83921432495117,\n",
      "                    'std': 4.242841918373575},\n",
      " 'Training Accuracy': [[0.76541668176651,\n",
      "                        0.8537633419036865,\n",
      "                        0.8720842599868774,\n",
      "                        0.8839575052261353,\n",
      "                        0.8911390900611877,\n",
      "                        0.8957401514053345,\n",
      "                        0.8973166942596436,\n",
      "                        0.8996267914772034,\n",
      "                        0.9022225141525269,\n",
      "                        0.9031415581703186],\n",
      "                       [0.7702108025550842,\n",
      "                        0.8561546802520752,\n",
      "                        0.8722666501998901,\n",
      "                        0.883475661277771,\n",
      "                        0.8900742530822754,\n",
      "                        0.8942626714706421,\n",
      "                        0.899056077003479,\n",
      "                        0.8989790081977844,\n",
      "                        0.9016067385673523,\n",
      "                        0.9039400219917297],\n",
      "                       [0.7617377042770386,\n",
      "                        0.8666996359825134,\n",
      "                        0.882927656173706,\n",
      "                        0.8912016749382019,\n",
      "                        0.8978241086006165,\n",
      "                        0.9014949798583984,\n",
      "                        0.9038317799568176,\n",
      "                        0.9060225486755371,\n",
      "                        0.9067935943603516,\n",
      "                        0.9086949825286865],\n",
      "                       [0.7732158303260803,\n",
      "                        0.8579533696174622,\n",
      "                        0.8753909468650818,\n",
      "                        0.8855675458908081,\n",
      "                        0.8915449976921082,\n",
      "                        0.8964044451713562,\n",
      "                        0.898972749710083,\n",
      "                        0.9007301926612854,\n",
      "                        0.9030649662017822,\n",
      "                        0.904008150100708],\n",
      "                       [0.7741991281509399,\n",
      "                        0.862309992313385,\n",
      "                        0.8791074752807617,\n",
      "                        0.888785719871521,\n",
      "                        0.8952086567878723,\n",
      "                        0.8993085622787476,\n",
      "                        0.901415228843689,\n",
      "                        0.9038058519363403,\n",
      "                        0.9055790305137634,\n",
      "                        0.9066138863563538]],\n",
      " 'Training Loss': [[0.4847835302352905,\n",
      "                    0.3233582079410553,\n",
      "                    0.286598801612854,\n",
      "                    0.2621890604496002,\n",
      "                    0.24609896540641785,\n",
      "                    0.23670437932014465,\n",
      "                    0.23110385239124298,\n",
      "                    0.2264598309993744,\n",
      "                    0.22014276683330536,\n",
      "                    0.21896657347679138],\n",
      "                   [0.48540958762168884,\n",
      "                    0.3220466673374176,\n",
      "                    0.28698253631591797,\n",
      "                    0.26456794142723083,\n",
      "                    0.24889317154884338,\n",
      "                    0.24006162583827972,\n",
      "                    0.22984011471271515,\n",
      "                    0.22808538377285004,\n",
      "                    0.22258704900741577,\n",
      "                    0.2181677520275116],\n",
      "                   [0.5024288892745972,\n",
      "                    0.3044321835041046,\n",
      "                    0.26759904623031616,\n",
      "                    0.2480020374059677,\n",
      "                    0.23483164608478546,\n",
      "                    0.22384460270404816,\n",
      "                    0.21837270259857178,\n",
      "                    0.21504244208335876,\n",
      "                    0.21079371869564056,\n",
      "                    0.20766563713550568],\n",
      "                   [0.48428410291671753,\n",
      "                    0.31906870007514954,\n",
      "                    0.28130456805229187,\n",
      "                    0.2592763900756836,\n",
      "                    0.24625617265701294,\n",
      "                    0.23695959150791168,\n",
      "                    0.2310785949230194,\n",
      "                    0.22539125382900238,\n",
      "                    0.22114990651607513,\n",
      "                    0.21763719618320465],\n",
      "                   [0.4790225625038147,\n",
      "                    0.3085521161556244,\n",
      "                    0.273446261882782,\n",
      "                    0.25350961089134216,\n",
      "                    0.2384679615497589,\n",
      "                    0.22918294370174408,\n",
      "                    0.22536791861057281,\n",
      "                    0.2179069221019745,\n",
      "                    0.21506831049919128,\n",
      "                    0.2122865617275238]],\n",
      " 'Validation Accuracy': [[0.8447365164756775,\n",
      "                          0.8696965575218201,\n",
      "                          0.8861833810806274,\n",
      "                          0.8964866399765015,\n",
      "                          0.9007300734519958,\n",
      "                          0.902213454246521,\n",
      "                          0.9055800437927246,\n",
      "                          0.9060467481613159,\n",
      "                          0.9077633619308472,\n",
      "                          0.9102132320404053],\n",
      "                         [0.8500334024429321,\n",
      "                          0.8712100386619568,\n",
      "                          0.8810201287269592,\n",
      "                          0.8880501389503479,\n",
      "                          0.898383378982544,\n",
      "                          0.8984567523002625,\n",
      "                          0.9031832814216614,\n",
      "                          0.9039332270622253,\n",
      "                          0.9014700055122375,\n",
      "                          0.907260000705719],\n",
      "                         [0.8437932729721069,\n",
      "                          0.8691900372505188,\n",
      "                          0.8797768354415894,\n",
      "                          0.88510662317276,\n",
      "                          0.8847132325172424,\n",
      "                          0.8930000066757202,\n",
      "                          0.8958766460418701,\n",
      "                          0.8938767313957214,\n",
      "                          0.8999032378196716,\n",
      "                          0.8988666534423828],\n",
      "                         [0.8409433364868164,\n",
      "                          0.8712534308433533,\n",
      "                          0.882473349571228,\n",
      "                          0.8886334300041199,\n",
      "                          0.893643319606781,\n",
      "                          0.8995198607444763,\n",
      "                          0.8983898758888245,\n",
      "                          0.9022932648658752,\n",
      "                          0.9046332836151123,\n",
      "                          0.9008365869522095],\n",
      "                         [0.8444766402244568,\n",
      "                          0.8702799677848816,\n",
      "                          0.8842698931694031,\n",
      "                          0.8839133977890015,\n",
      "                          0.8962633013725281,\n",
      "                          0.8981500267982483,\n",
      "                          0.9016968011856079,\n",
      "                          0.9025434255599976,\n",
      "                          0.9015933275222778,\n",
      "                          0.9054332375526428]],\n",
      " 'Validation Loss': [0.34544169902801514,\n",
      "                     "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.2938918173313141,\n",
      "                     0.2652190327644348,\n",
      "                     0.25698617100715637,\n",
      "                     0.23742513358592987,\n",
      "                     0.23220908641815186,\n",
      "                     0.22574763000011444,\n",
      "                     0.22489725053310394,\n",
      "                     0.22588378190994263,\n",
      "                     0.21679309010505676],\n",
      " 'Validation MCC': [[0.6883706075045878,\n",
      "                     0.739359353987138,\n",
      "                     0.7713946939408746,\n",
      "                     0.7920627149741716,\n",
      "                     0.8007507798862075,\n",
      "                     0.8043823220040335,\n",
      "                     0.8104116921979564,\n",
      "                     0.8114328369839684,\n",
      "                     0.8154429127953386,\n",
      "                     0.8197041117524011],\n",
      "                    [0.6995382471473633,\n",
      "                     0.7412843738417675,\n",
      "                     0.7612281065715529,\n",
      "                     0.7751307420234939,\n",
      "                     0.7959142238430956,\n",
      "                     0.7960929764928488,\n",
      "                     0.8055721912895856,\n",
      "                     0.8070513142834937,\n",
      "                     0.802949241554229,\n",
      "                     0.8137411819257987],\n",
      "                    [0.6861127525329962,\n",
      "                     0.7369230494861764,\n",
      "                     0.7582405127459448,\n",
      "                     0.7696601271911828,\n",
      "                     0.76998013183976,\n",
      "                     0.7849718978895177,\n",
      "                     0.7910197513929353,\n",
      "                     0.7870604681611559,\n",
      "                     0.7987756128439565,\n",
      "                     0.7971602995967009],\n",
      "                    [0.6862170194448642,\n",
      "                     0.7409553808965454,\n",
      "                     0.7635702769926218,\n",
      "                     0.7771305738803038,\n",
      "                     0.7862014278311181,\n",
      "                     0.7979887370426774,\n",
      "                     0.7967065842777702,\n",
      "                     0.8035321456433393,\n",
      "                     0.8082316637281334,\n",
      "                     0.8021545346479991],\n",
      "                    [0.6887792069780566,\n",
      "                     0.7415501528591482,\n",
      "                     0.7678148337005885,\n",
      "                     0.7696593200987711,\n",
      "                     0.792139003791672,\n",
      "                     0.7959265074431452,\n",
      "                     0.8029770205512168,\n",
      "                     0.8049774056563578,\n",
      "                     0.8038838029618637,\n",
      "                     0.8102779280935926]]}\n",
      "Training Model: RNN, Fold: 1\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.7470 - loss: 0.5081\n",
      "Epoch 1 - MCC: 0.6564\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 53ms/step - accuracy: 0.7473 - loss: 0.5077 - val_accuracy: 0.8280 - val_loss: 0.3765 - mcc: 0.6564\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8281 - loss: 0.3779\n",
      "Epoch 2 - MCC: 0.6915\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 38ms/step - accuracy: 0.8281 - loss: 0.3779 - val_accuracy: 0.8465 - val_loss: 0.3473 - mcc: 0.6915\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8384 - loss: 0.3561\n",
      "Epoch 3 - MCC: 0.6851\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 39ms/step - accuracy: 0.8384 - loss: 0.3561 - val_accuracy: 0.8426 - val_loss: 0.3486 - mcc: 0.6851\n",
      "Epoch 4/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8413 - loss: 0.3493\n",
      "Epoch 4 - MCC: 0.7062\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.8413 - loss: 0.3493 - val_accuracy: 0.8536 - val_loss: 0.3323 - mcc: 0.7062\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8206 - loss: 0.3929\n",
      "Epoch 5 - MCC: 0.6726\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8206 - loss: 0.3929 - val_accuracy: 0.8370 - val_loss: 0.3637 - mcc: 0.6726\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8394 - loss: 0.3575\n",
      "Epoch 6 - MCC: 0.6834\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 39ms/step - accuracy: 0.8394 - loss: 0.3575 - val_accuracy: 0.8424 - val_loss: 0.3473 - mcc: 0.6834\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8363 - loss: 0.3589\n",
      "Epoch 7 - MCC: 0.6854\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8363 - loss: 0.3588 - val_accuracy: 0.8434 - val_loss: 0.3426 - mcc: 0.6854\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8428 - loss: 0.3457\n",
      "Epoch 8 - MCC: 0.6993\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 38ms/step - accuracy: 0.8428 - loss: 0.3457 - val_accuracy: 0.8491 - val_loss: 0.3399 - mcc: 0.6993\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8454 - loss: 0.3412\n",
      "Epoch 9 - MCC: 0.7032\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8454 - loss: 0.3412 - val_accuracy: 0.8523 - val_loss: 0.3291 - mcc: 0.7032\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8487 - loss: 0.3331\n",
      "Epoch 10 - MCC: 0.7066\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 38ms/step - accuracy: 0.8487 - loss: 0.3331 - val_accuracy: 0.8540 - val_loss: 0.3256 - mcc: 0.7066\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 2\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.7018 - loss: 0.5458\n",
      "Epoch 1 - MCC: 0.6468\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 51ms/step - accuracy: 0.7028 - loss: 0.5447 - val_accuracy: 0.8220 - val_loss: 0.3993 - mcc: 0.6468\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8260 - loss: 0.3855\n",
      "Epoch 2 - MCC: 0.6762\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 37ms/step - accuracy: 0.8260 - loss: 0.3855 - val_accuracy: 0.8387 - val_loss: 0.3576 - mcc: 0.6762\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8337 - loss: 0.3673\n",
      "Epoch 3 - MCC: 0.6742\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8337 - loss: 0.3672 - val_accuracy: 0.8379 - val_loss: 0.3563 - mcc: 0.6742\n",
      "Epoch 4/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8426 - loss: 0.3505\n",
      "Epoch 4 - MCC: 0.6967\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8426 - loss: 0.3505 - val_accuracy: 0.8490 - val_loss: 0.3336 - mcc: 0.6967\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8509 - loss: 0.3318\n",
      "Epoch 5 - MCC: 0.7090\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8508 - loss: 0.3319 - val_accuracy: 0.8550 - val_loss: 0.3234 - mcc: 0.7090\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8455 - loss: 0.3405\n",
      "Epoch 6 - MCC: 0.7155\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.8456 - loss: 0.3404 - val_accuracy: 0.8572 - val_loss: 0.3233 - mcc: 0.7155\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8493 - loss: 0.3325\n",
      "Epoch 7 - MCC: 0.7000\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8493 - loss: 0.3326 - val_accuracy: 0.8497 - val_loss: 0.3385 - mcc: 0.7000\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8490 - loss: 0.3356\n",
      "Epoch 8 - MCC: 0.7057\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.8490 - loss: 0.3356 - val_accuracy: 0.8533 - val_loss: 0.3304 - mcc: 0.7057\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8446 - loss: 0.3406\n",
      "Epoch 9 - MCC: 0.7072\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.8447 - loss: 0.3405 - val_accuracy: 0.8542 - val_loss: 0.3222 - mcc: 0.7072\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8555 - loss: 0.3220\n",
      "Epoch 10 - MCC: 0.6335\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8555 - loss: 0.3221 - val_accuracy: 0.8137 - val_loss: 0.3913 - mcc: 0.6335\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 3\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.7343 - loss: 0.5312\n",
      "Epoch 1 - MCC: 0.6299\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 51ms/step - accuracy: 0.7350 - loss: 0.5302 - val_accuracy: 0.8144 - val_loss: 0.4059 - mcc: 0.6299\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8274 - loss: 0.3860\n",
      "Epoch 2 - MCC: 0.6536\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8274 - loss: 0.3859 - val_accuracy: 0.8278 - val_loss: 0.3824 - mcc: 0.6536\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8348 - loss: 0.3679\n",
      "Epoch 3 - MCC: 0.6692\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8348 - loss: 0.3679 - val_accuracy: 0.8354 - val_loss: 0.3675 - mcc: 0.6692\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8423 - loss: 0.3528\n",
      "Epoch 4 - MCC: 0.6677\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8423 - loss: 0.3528 - val_accuracy: 0.8313 - val_loss: 0.3814 - mcc: 0.6677\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8402 - loss: 0.3565\n",
      "Epoch 5 - MCC: 0.6724\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8403 - loss: 0.3563 - val_accuracy: 0.8364 - val_loss: 0.3589 - mcc: 0.6724\n",
      "Epoch 6/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8342 - loss: 0.3644\n",
      "Epoch 6 - MCC: 0.6693\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.8342 - loss: 0.3644 - val_accuracy: 0.8354 - val_loss: 0.3636 - mcc: 0.6693\n",
      "Epoch 7/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8422 - loss: 0.3492\n",
      "Epoch 7 - MCC: 0.6850\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 39ms/step - accuracy: 0.8422 - loss: 0.3491 - val_accuracy: 0.8429 - val_loss: 0.3484 - mcc: 0.6850\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8544 - loss: 0.3268\n",
      "Epoch 8 - MCC: 0.6915\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 36ms/step - accuracy: 0.8544 - loss: 0.3269 - val_accuracy: 0.8463 - val_loss: 0.3392 - mcc: 0.6915\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8552 - loss: 0.3213\n",
      "Epoch 9 - MCC: 0.6844\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 39ms/step - accuracy: 0.8552 - loss: 0.3213 - val_accuracy: 0.8428 - val_loss: 0.3362 - mcc: 0.6844\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8526 - loss: 0.3226\n",
      "Epoch 10 - MCC: 0.6933\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.8527 - loss: 0.3226 - val_accuracy: 0.8469 - val_loss: 0.3281 - mcc: 0.6933\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 4\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.7014 - loss: 0.5589\n",
      "Epoch 1 - MCC: 0.6550\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 48ms/step - accuracy: 0.7019 - loss: 0.5583 - val_accuracy: 0.8286 - val_loss: 0.3850 - mcc: 0.6550\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8228 - loss: 0.3939\n",
      "Epoch 2 - MCC: 0.6581\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 38ms/step - accuracy: 0.8229 - loss: 0.3937 - val_accuracy: 0.8263 - val_loss: 0.3750 - mcc: 0.6581\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8404 - loss: 0.3597\n",
      "Epoch 3 - MCC: 0.6767\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 39ms/step - accuracy: 0.8404 - loss: 0.3598 - val_accuracy: 0.8392 - val_loss: 0.3540 - mcc: 0.6767\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8357 - loss: 0.3660\n",
      "Epoch 4 - MCC: 0.6894\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8357 - loss: 0.3659 - val_accuracy: 0.8451 - val_loss: 0.3466 - mcc: 0.6894\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8459 - loss: 0.3428\n",
      "Epoch 5 - MCC: 0.6904\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8459 - loss: 0.3429 - val_accuracy: 0.8459 - val_loss: 0.3409 - mcc: 0.6904\n",
      "Epoch 6/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8507 - loss: 0.3316\n",
      "Epoch 6 - MCC: 0.6971\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.8507 - loss: 0.3317 - val_accuracy: 0.8493 - val_loss: 0.3332 - mcc: 0.6971\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8441 - loss: 0.3460\n",
      "Epoch 7 - MCC: 0.7010\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8440 - loss: 0.3461 - val_accuracy: 0.8514 - val_loss: 0.3288 - mcc: 0.7010\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8425 - loss: 0.3505\n",
      "Epoch 8 - MCC: 0.6881\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8425 - loss: 0.3506 - val_accuracy: 0.8449 - val_loss: 0.3455 - mcc: 0.6881\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8475 - loss: 0.3415\n",
      "Epoch 9 - MCC: 0.6829\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8475 - loss: 0.3415 - val_accuracy: 0.8411 - val_loss: 0.3470 - mcc: 0.6829\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8504 - loss: 0.3341\n",
      "Epoch 10 - MCC: 0.6825\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8504 - loss: 0.3342 - val_accuracy: 0.8402 - val_loss: 0.3437 - mcc: 0.6825\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: RNN, Fold: 5\n",
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.7189 - loss: 0.5326\n",
      "Epoch 1 - MCC: 0.6437\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 44ms/step - accuracy: 0.7193 - loss: 0.5321 - val_accuracy: 0.8206 - val_loss: 0.3974 - mcc: 0.6437\n",
      "Epoch 2/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8297 - loss: 0.3817\n",
      "Epoch 2 - MCC: 0.6714\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8297 - loss: 0.3817 - val_accuracy: 0.8362 - val_loss: 0.3699 - mcc: 0.6714\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8359 - loss: 0.3666\n",
      "Epoch 3 - MCC: 0.6896\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 39ms/step - accuracy: 0.8359 - loss: 0.3665 - val_accuracy: 0.8443 - val_loss: 0.3522 - mcc: 0.6896\n",
      "Epoch 4/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8441 - loss: 0.3452\n",
      "Epoch 4 - MCC: 0.6888\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.8441 - loss: 0.3451 - val_accuracy: 0.8446 - val_loss: 0.3482 - mcc: 0.6888\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8434 - loss: 0.3437\n",
      "Epoch 5 - MCC: 0.6815\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.8434 - loss: 0.3436 - val_accuracy: 0.8413 - val_loss: 0.3437 - mcc: 0.6815\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8484 - loss: 0.3341\n",
      "Epoch 6 - MCC: 0.6903\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 38ms/step - accuracy: 0.8484 - loss: 0.3341 - val_accuracy: 0.8446 - val_loss: 0.3409 - mcc: 0.6903\n",
      "Epoch 7/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8540 - loss: 0.3216\n",
      "Epoch 7 - MCC: 0.7102\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 37ms/step - accuracy: 0.8540 - loss: 0.3217 - val_accuracy: 0.8556 - val_loss: 0.3184 - mcc: 0.7102\n",
      "Epoch 8/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8505 - loss: 0.3279\n",
      "Epoch 8 - MCC: 0.7105\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 38ms/step - accuracy: 0.8505 - loss: 0.3280 - val_accuracy: 0.8557 - val_loss: 0.3165 - mcc: 0.7105\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8494 - loss: 0.3312\n",
      "Epoch 9 - MCC: 0.7131\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 38ms/step - accuracy: 0.8494 - loss: 0.3312 - val_accuracy: 0.8570 - val_loss: 0.3182 - mcc: 0.7131\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8587 - loss: 0.3127\n",
      "Epoch 10 - MCC: 0.7072\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 37ms/step - accuracy: 0.8587 - loss: 0.3127 - val_accuracy: 0.8535 - val_loss: 0.3229 - mcc: 0.7072\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': 0.85396,\n",
      "              'mean': 0.8416426666666667,\n",
      "              'min': 0.8136833333333333,\n",
      "              'std': 0.014854408309394974},\n",
      " 'Inference Time (s/sample)': {'max': 0.0011658779780069988,\n",
      "                               'mean': 0.0006989960670471193,\n",
      "                               'min': 0.0004337040583292643,\n",
      "                               'std': 0.00024698655497711817},\n",
      " 'MCC': {'max': 0.7071954608055184,\n",
      "         'mean': 0.6846184478333898,\n",
      "         'min': 0.6335431255724576,\n",
      "         'std': 0.02712623361421829},\n",
      " 'Parameters': 4545,\n",
      " 'Train Time (s)': {'max': 94.28943228721619,\n",
      "                    'mean': 85.90589017868042,\n",
      "                    'min': 82.20142102241516,\n",
      "                    'std': 4.3623734700921775},\n",
      " 'Training Accuracy': [[0.7939860224723816,\n",
      "                        0.8289244174957275,\n",
      "                        0.8357285857200623,\n",
      "                        0.8385558128356934,\n",
      "                        0.822562575340271,\n",
      "                        0.8367108106613159,\n",
      "                        0.8397743701934814,\n",
      "                        0.8400790691375732,\n",
      "                        0.8441384434700012,\n",
      "                        0.8454534411430359],\n",
      "                       [0.7747066020965576,\n",
      "                        0.8290085792541504,\n",
      "                        0.8384465575218201,\n",
      "                        0.8409773111343384,\n",
      "                        0.8464634418487549,\n",
      "                        0.8489308953285217,\n",
      "                        0.8474966883659363,\n",
      "                        0.8488442897796631,\n",
      "                        0.8511805534362793,\n",
      "                        0.8502524495124817],\n",
      "                       [0.7875416874885559,\n",
      "                        0.8298442363739014,\n",
      "                        0.8376144766807556,\n",
      "                        0.8433825373649597,\n",
      "                        0.845420241355896,\n",
      "                        0.8357125520706177,\n",
      "                        0.8472967743873596,\n",
      "                        0.8531917929649353,\n",
      "                        0.8540024757385254,\n",
      "                        0.8558335304260254],\n",
      "                       [0.773270845413208,\n",
      "                        0.8295210003852844,\n",
      "                        0.8383191823959351,\n",
      "                        0.838790774345398,\n",
      "                        0.8437516689300537,\n",
      "                        0.8455809950828552,\n",
      "                        0.8416250348091125,\n",
      "                        0.8415598273277283,\n",
      "                        0.8467884063720703,\n",
      "                        0.8481277823448181],\n",
      "                       [0.7817591428756714,\n",
      "                        0.8308093547821045,\n",
      "                        0.8399044871330261,\n",
      "                        0.8444468975067139,\n",
      "                        0.845711886882782,\n",
      "                        0.8473785519599915,\n",
      "                        0.851729691028595,\n",
      "                        0.8502242565155029,\n",
      "                        0.8523534536361694,\n",
      "                        0.8565176129341125]],\n",
      " 'Training Loss': [[0.4420318007469177,\n",
      "                    0.37537285685539246,\n",
      "                    0.3592210114002228,\n",
      "                    0.35395705699920654,\n",
      "                    0.39179763197898865,\n",
      "                    0.3602524697780609,\n",
      "                    0.3529747426509857,\n",
      "                    0.3516421616077423,\n",
      "                    0.3435460031032562,\n",
      "                    0.3396436274051666],\n",
      "                   [0.46235060691833496,\n",
      "                    0.37945830821990967,\n",
      "                    0.3594784736633301,\n",
      "                    0.3524850010871887,\n",
      "                    0.3399510383605957,\n",
      "                    0.33406057953834534,\n",
      "                    0.338176965713501,\n",
      "                    0.33480244874954224,\n",
      "                    0.3282901644706726,\n",
      "                    0.33232346177101135],\n",
      "                   [0.45583415031433105,\n",
      "                    0.3808388113975525,\n",
      "                    0.36371490359306335,\n",
      "                    0.35093146562576294,\n",
      "                    0.3464348316192627,\n",
      "                    0.36148571968078613,\n",
      "                    0.3400209844112396,\n",
      "                    0.3281693458557129,\n",
      "                    0.3231425881385803,\n",
      "                    0.318225622177124],\n",
      "                   [0.470181941986084,\n",
      "                    0.3819897472858429,\n",
      "                    0.3613722026348114,\n",
      "                    0.35897406935691833,\n",
      "                    0.34638291597366333,\n",
      "                    0.3411550223827362,\n",
      "                    0.3501613438129425,\n",
      "                    0.3546451926231384,\n",
      "                    0.3422704339027405,\n",
      "                    0.33779481053352356],\n",
      "                   [0.45621800422668457,\n",
      "                    0.37821701169013977,\n",
      "                    "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.3578236401081085,\n",
      "                    0.3437623977661133,\n",
      "                    0.3400873839855194,\n",
      "                    0.33614686131477356,\n",
      "                    0.32502609491348267,\n",
      "                    0.3296433687210083,\n",
      "                    0.3264400362968445,\n",
      "                    0.31617704033851624]],\n",
      " 'Validation Accuracy': [[0.8280000686645508,\n",
      "                          0.8464766144752502,\n",
      "                          0.8426201343536377,\n",
      "                          0.8536467552185059,\n",
      "                          0.837043285369873,\n",
      "                          0.8423799872398376,\n",
      "                          0.843410074710846,\n",
      "                          0.8490935564041138,\n",
      "                          0.8522633910179138,\n",
      "                          0.8539600372314453],\n",
      "                         [0.8219634294509888,\n",
      "                          0.8387001156806946,\n",
      "                          0.8378667831420898,\n",
      "                          0.8490399718284607,\n",
      "                          0.8550033569335938,\n",
      "                          0.8572066426277161,\n",
      "                          0.8497133255004883,\n",
      "                          0.8532935380935669,\n",
      "                          0.8542367815971375,\n",
      "                          0.813683271408081],\n",
      "                         [0.8143799304962158,\n",
      "                          0.8278234601020813,\n",
      "                          0.8354367017745972,\n",
      "                          0.8312767744064331,\n",
      "                          0.8363866209983826,\n",
      "                          0.8354465961456299,\n",
      "                          0.842930018901825,\n",
      "                          0.8462766408920288,\n",
      "                          0.8428300023078918,\n",
      "                          0.8468834757804871],\n",
      "                         [0.8285768032073975,\n",
      "                          0.8263499736785889,\n",
      "                          0.8392399549484253,\n",
      "                          0.8451166152954102,\n",
      "                          0.8459433913230896,\n",
      "                          0.8492599725723267,\n",
      "                          0.8513533473014832,\n",
      "                          0.8449400663375854,\n",
      "                          0.8410767912864685,\n",
      "                          0.8402000665664673],\n",
      "                         [0.820580005645752,\n",
      "                          0.836243212223053,\n",
      "                          0.8442966938018799,\n",
      "                          0.8445667624473572,\n",
      "                          0.8413099050521851,\n",
      "                          0.8445600867271423,\n",
      "                          0.8555899262428284,\n",
      "                          0.8556867241859436,\n",
      "                          0.8569534420967102,\n",
      "                          0.8534867167472839]],\n",
      " 'Validation Loss': [0.3974034786224365,\n",
      "                     0.3698977530002594,\n",
      "                     0.35221198201179504,\n",
      "                     0.34819158911705017,\n",
      "                     0.34373655915260315,\n",
      "                     0.3408578336238861,\n",
      "                     0.318355917930603,\n",
      "                     0.31652823090553284,\n",
      "                     0.31819820404052734,\n",
      "                     0.32294464111328125],\n",
      " 'Validation MCC': [[0.6563839617599094,\n",
      "                     0.6915408297230429,\n",
      "                     0.6851334543962383,\n",
      "                     0.7061676882054252,\n",
      "                     0.6725834196603637,\n",
      "                     0.6834237769789595,\n",
      "                     0.6853806212127348,\n",
      "                     0.6993129274355334,\n",
      "                     0.703152006592502,\n",
      "                     0.7065578415614523],\n",
      "                    [0.64683872914762,\n",
      "                     0.6762313088873698,\n",
      "                     0.6742288817910871,\n",
      "                     0.6966976308773918,\n",
      "                     0.7089531248089201,\n",
      "                     0.7154969711931124,\n",
      "                     0.6999507740579015,\n",
      "                     0.7057296251507227,\n",
      "                     0.7072084469784329,\n",
      "                     0.6335431255724576],\n",
      "                    [0.6299065048496234,\n",
      "                     0.6535982391330721,\n",
      "                     0.6692373890305185,\n",
      "                     0.6676628485854708,\n",
      "                     0.6724187869511861,\n",
      "                     0.6692517565736888,\n",
      "                     0.6850149431059128,\n",
      "                     0.6914894342805948,\n",
      "                     0.6844287856433361,\n",
      "                     0.6932787051752837],\n",
      "                    [0.6549623763257542,\n",
      "                     0.6581003181801394,\n",
      "                     0.6767150732356123,\n",
      "                     0.689368836714277,\n",
      "                     0.6903666133898705,\n",
      "                     0.6971000003250043,\n",
      "                     0.7009658588499132,\n",
      "                     0.6880615443083686,\n",
      "                     0.682884363683238,\n",
      "                     0.682517106052237],\n",
      "                    [0.6437001642510122,\n",
      "                     0.6713702077048648,\n",
      "                     0.6895973341874275,\n",
      "                     0.6888248870377085,\n",
      "                     0.6814832923070229,\n",
      "                     0.6903131197504432,\n",
      "                     0.7102468133870824,\n",
      "                     0.7104549610788868,\n",
      "                     0.7131380139459146,\n",
      "                     0.7071954608055184]]}\n",
      "Training Model: GRU, Fold: 1\n",
      "Epoch 1/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6461 - loss: 0.6243\n",
      "Epoch 1 - MCC: 0.6377\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 26ms/step - accuracy: 0.6479 - loss: 0.6225 - val_accuracy: 0.8197 - val_loss: 0.3972 - mcc: 0.6377\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8235 - loss: 0.3893\n",
      "Epoch 2 - MCC: 0.6680\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - accuracy: 0.8235 - loss: 0.3893 - val_accuracy: 0.8346 - val_loss: 0.3615 - mcc: 0.6680\n",
      "Epoch 3/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8365 - loss: 0.3585\n",
      "Epoch 3 - MCC: 0.6899\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8365 - loss: 0.3585 - val_accuracy: 0.8455 - val_loss: 0.3411 - mcc: 0.6899\n",
      "Epoch 4/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8437 - loss: 0.3446\n",
      "Epoch 4 - MCC: 0.7090\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8438 - loss: 0.3445 - val_accuracy: 0.8551 - val_loss: 0.3231 - mcc: 0.7090\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8502 - loss: 0.3277\n",
      "Epoch 5 - MCC: 0.7368\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8502 - loss: 0.3277 - val_accuracy: 0.8687 - val_loss: 0.2920 - mcc: 0.7368\n",
      "Epoch 6/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8666 - loss: 0.2956\n",
      "Epoch 6 - MCC: 0.7495\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8666 - loss: 0.2956 - val_accuracy: 0.8752 - val_loss: 0.2778 - mcc: 0.7495\n",
      "Epoch 7/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8678 - loss: 0.2897\n",
      "Epoch 7 - MCC: 0.7533\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8679 - loss: 0.2896 - val_accuracy: 0.8771 - val_loss: 0.2716 - mcc: 0.7533\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8718 - loss: 0.2800\n",
      "Epoch 8 - MCC: 0.7573\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.8718 - loss: 0.2800 - val_accuracy: 0.8792 - val_loss: 0.2670 - mcc: 0.7573\n",
      "Epoch 9/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8770 - loss: 0.2709\n",
      "Epoch 9 - MCC: 0.7613\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.8769 - loss: 0.2710 - val_accuracy: 0.8809 - val_loss: 0.2655 - mcc: 0.7613\n",
      "Epoch 10/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8772 - loss: 0.2708\n",
      "Epoch 10 - MCC: 0.7595\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.8771 - loss: 0.2708 - val_accuracy: 0.8802 - val_loss: 0.2647 - mcc: 0.7595\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 2\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.6920 - loss: 0.6073\n",
      "Epoch 1 - MCC: 0.6550\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 27ms/step - accuracy: 0.6929 - loss: 0.6061 - val_accuracy: 0.8282 - val_loss: 0.3819 - mcc: 0.6550\n",
      "Epoch 2/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8253 - loss: 0.3838\n",
      "Epoch 2 - MCC: 0.6727\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.8253 - loss: 0.3838 - val_accuracy: 0.8370 - val_loss: 0.3611 - mcc: 0.6727\n",
      "Epoch 3/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8295 - loss: 0.3704\n",
      "Epoch 3 - MCC: 0.7016\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 21ms/step - accuracy: 0.8296 - loss: 0.3701 - val_accuracy: 0.8515 - val_loss: 0.3274 - mcc: 0.7016\n",
      "Epoch 4/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8518 - loss: 0.3276\n",
      "Epoch 4 - MCC: 0.7235\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.8519 - loss: 0.3275 - val_accuracy: 0.8623 - val_loss: 0.3037 - mcc: 0.7235\n",
      "Epoch 5/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8616 - loss: 0.3052\n",
      "Epoch 5 - MCC: 0.7342\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.8615 - loss: 0.3052 - val_accuracy: 0.8675 - val_loss: 0.2933 - mcc: 0.7342\n",
      "Epoch 6/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8634 - loss: 0.2996\n",
      "Epoch 6 - MCC: 0.7395\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8635 - loss: 0.2996 - val_accuracy: 0.8701 - val_loss: 0.2885 - mcc: 0.7395\n",
      "Epoch 7/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8665 - loss: 0.2942\n",
      "Epoch 7 - MCC: 0.7482\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 28ms/step - accuracy: 0.8665 - loss: 0.2942 - val_accuracy: 0.8746 - val_loss: 0.2807 - mcc: 0.7482\n",
      "Epoch 8/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8698 - loss: 0.2873\n",
      "Epoch 8 - MCC: 0.7459\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8698 - loss: 0.2874 - val_accuracy: 0.8735 - val_loss: 0.2805 - mcc: 0.7459\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8692 - loss: 0.2867\n",
      "Epoch 9 - MCC: 0.7530\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8692 - loss: 0.2867 - val_accuracy: 0.8770 - val_loss: 0.2734 - mcc: 0.7530\n",
      "Epoch 10/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8674 - loss: 0.2874\n",
      "Epoch 10 - MCC: 0.7545\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8676 - loss: 0.2872 - val_accuracy: 0.8777 - val_loss: 0.2723 - mcc: 0.7545\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 3\n",
      "Epoch 1/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.6768 - loss: 0.6283\n",
      "Epoch 1 - MCC: 0.6242\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 26ms/step - accuracy: 0.6787 - loss: 0.6258 - val_accuracy: 0.8127 - val_loss: 0.4096 - mcc: 0.6242\n",
      "Epoch 2/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8191 - loss: 0.3967\n",
      "Epoch 2 - MCC: 0.6478\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8193 - loss: 0.3963 - val_accuracy: 0.8242 - val_loss: 0.3812 - mcc: 0.6478\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8378 - loss: 0.3583\n",
      "Epoch 3 - MCC: 0.6714\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.8379 - loss: 0.3582 - val_accuracy: 0.8366 - val_loss: 0.3573 - mcc: 0.6714\n",
      "Epoch 4/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8487 - loss: 0.3366\n",
      "Epoch 4 - MCC: 0.6935\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 26ms/step - accuracy: 0.8487 - loss: 0.3366 - val_accuracy: 0.8472 - val_loss: 0.3361 - mcc: 0.6935\n",
      "Epoch 5/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8611 - loss: 0.3098\n",
      "Epoch 5 - MCC: 0.7155\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.8611 - loss: 0.3096 - val_accuracy: 0.8585 - val_loss: 0.3097 - mcc: 0.7155\n",
      "Epoch 6/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8648 - loss: 0.2984\n",
      "Epoch 6 - MCC: 0.7226\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8649 - loss: 0.2982 - val_accuracy: 0.8616 - val_loss: 0.3045 - mcc: 0.7226\n",
      "Epoch 7/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8697 - loss: 0.2857\n",
      "Epoch 7 - MCC: 0.7268\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 27ms/step - accuracy: 0.8697 - loss: 0.2857 - val_accuracy: 0.8641 - val_loss: 0.2956 - mcc: 0.7268\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8737 - loss: 0.2778\n",
      "Epoch 8 - MCC: 0.7219\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.8737 - loss: 0.2778 - val_accuracy: 0.8615 - val_loss: 0.3008 - mcc: 0.7219\n",
      "Epoch 9/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8734 - loss: 0.2783\n",
      "Epoch 9 - MCC: 0.7309\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.8735 - loss: 0.2783 - val_accuracy: 0.8660 - val_loss: 0.2908 - mcc: 0.7309\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8810 - loss: 0.2630\n",
      "Epoch 10 - MCC: 0.7306\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - accuracy: 0.8809 - loss: 0.2630 - val_accuracy: 0.8660 - val_loss: 0.2901 - mcc: 0.7306\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 4\n",
      "Epoch 1/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6457 - loss: 0.6339\n",
      "Epoch 1 - MCC: 0.6380\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 21ms/step - accuracy: 0.6468 - loss: 0.6327 - val_accuracy: 0.8198 - val_loss: 0.4005 - mcc: 0.6380\n",
      "Epoch 2/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8222 - loss: 0.3897\n",
      "Epoch 2 - MCC: 0.6648\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.8224 - loss: 0.3893 - val_accuracy: 0.8314 - val_loss: 0.3686 - mcc: 0.6648\n",
      "Epoch 3/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8419 - loss: 0.3520\n",
      "Epoch 3 - MCC: 0.7057\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 28ms/step - accuracy: 0.8419 - loss: 0.3519 - val_accuracy: 0.8537 - val_loss: 0.3242 - mcc: 0.7057\n",
      "Epoch 4/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8562 - loss: 0.3179\n",
      "Epoch 4 - MCC: 0.7226\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8562 - loss: 0.3179 - val_accuracy: 0.8622 - val_loss: 0.3051 - mcc: 0.7226\n",
      "Epoch 5/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8621 - loss: 0.3059\n",
      "Epoch 5 - MCC: 0.7308\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8621 - loss: 0.3058 - val_accuracy: 0.8661 - val_loss: 0.2954 - mcc: 0.7308\n",
      "Epoch 6/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8653 - loss: 0.2976\n",
      "Epoch 6 - MCC: 0.7351\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8653 - loss: 0.2975 - val_accuracy: 0.8683 - val_loss: 0.2883 - mcc: 0.7351\n",
      "Epoch 7/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8685 - loss: 0.2907\n",
      "Epoch 7 - MCC: 0.7404\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8685 - loss: 0.2907 - val_accuracy: 0.8710 - val_loss: 0.2833 - mcc: 0.7404\n",
      "Epoch 8/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8745 - loss: 0.2777\n",
      "Epoch 8 - MCC: 0.7478\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.8744 - loss: 0.2778 - val_accuracy: 0.8746 - val_loss: 0.2760 - mcc: 0.7478\n",
      "Epoch 9/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8734 - loss: 0.2773\n",
      "Epoch 9 - MCC: 0.7530\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - accuracy: 0.8734 - loss: 0.2773 - val_accuracy: 0.8772 - val_loss: 0.2703 - mcc: 0.7530\n",
      "Epoch 10/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8706 - loss: 0.2826\n",
      "Epoch 10 - MCC: 0.7479\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 25ms/step - accuracy: 0.8707 - loss: 0.2825 - val_accuracy: 0.8745 - val_loss: 0.2737 - mcc: 0.7479\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: GRU, Fold: 5\n",
      "Epoch 1/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6870 - loss: 0.6178\n",
      "Epoch 1 - MCC: 0.6414\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 21ms/step - accuracy: 0.6891 - loss: 0.6153 - val_accuracy: 0.8212 - val_loss: 0.3947 - mcc: 0.6414\n",
      "Epoch 2/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8269 - loss: 0.3844\n",
      "Epoch 2 - MCC: 0.6667\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8270 - loss: 0.3843 - val_accuracy: 0.8336 - val_loss: 0.3699 - mcc: 0.6667\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8437 - loss: 0.3507\n",
      "Epoch 3 - MCC: 0.6859\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 24ms/step - accuracy: 0.8437 - loss: 0.3508 - val_accuracy: 0.8432 - val_loss: 0.3500 - mcc: 0.6859\n",
      "Epoch 4/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8416 - loss: 0.3498\n",
      "Epoch 4 - MCC: 0.7009\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.8417 - loss: 0.3496 - val_accuracy: 0.8510 - val_loss: 0.3300 - mcc: 0.7009\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8542 - loss: 0.3227\n",
      "Epoch 5 - MCC: 0.7246\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.8542 - loss: 0.3226 - val_accuracy: 0.8627 - val_loss: 0.3032 - mcc: 0.7246\n",
      "Epoch 6/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8661 - loss: 0.2961\n",
      "Epoch 6 - MCC: 0.7302\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 25ms/step - accuracy: 0.8661 - loss: 0.2961 - val_accuracy: 0.8656 - val_loss: 0.2967 - mcc: 0.7302\n",
      "Epoch 7/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8698 - loss: 0.2878\n",
      "Epoch 7 - MCC: 0.7381\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - accuracy: 0.8698 - loss: 0.2878 - val_accuracy: 0.8695 - val_loss: 0.2873 - mcc: 0.7381\n",
      "Epoch 8/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8708 - loss: 0.2843\n",
      "Epoch 8 - MCC: 0.7404\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 19ms/step - accuracy: 0.8708 - loss: 0.2843 - val_accuracy: 0.8706 - val_loss: 0.2836 - mcc: 0.7404\n",
      "Epoch 9/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8772 - loss: 0.2729\n",
      "Epoch 9 - MCC: 0.7408\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 25ms/step - accuracy: 0.8771 - loss: 0.2731 - val_accuracy: 0.8704 - val_loss: 0.2851 - mcc: 0.7408\n",
      "Epoch 10/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8754 - loss: 0.2746\n",
      "Epoch 10 - MCC: 0.7482\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.8753 - loss: 0.2747 - val_accuracy: 0.8745 - val_loss: 0.2776 - mcc: 0.7482\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': 0.88022,\n",
      "              'mean': 0.874592,\n",
      "              'min': 0.86604,\n",
      "              'std': 0.0047829254646084484},\n",
      " 'Inference Time (s/sample)': {'max': 0.0006152749061584473,\n",
      "                               'mean': 0.0005710442066192628,\n",
      "                               'min': 0.000462570587793986,\n",
      "                               'std': 5.501560321346291e-05},\n",
      " 'MCC': {'max': 0.7595377807664301,\n",
      "         'mean': 0.7481312887653814,\n",
      "         'min': 0.7306193698903458,\n",
      "         'std': 0.009766177021455599},\n",
      " 'Parameters': 4446,\n",
      " 'Train Time (s)': {'max': 44.24406981468201,\n",
      "                    'mean': 42.40113792419434,\n",
      "                    'min': 40.40162539482117,\n",
      "                    'std': 1.2436639068146835},\n",
      " 'Training Accuracy': [[0.7364609241485596,\n",
      "                        0.8263841271400452,\n",
      "                        0.8374225497245789,\n",
      "                        0.8455708026885986,\n",
      "                        0.8560609221458435,\n",
      "                        0.8660784959793091,\n",
      "                        0.8703575730323792,\n",
      "                        0.8717342019081116,\n",
      "                        0.8740140795707703,\n",
      "                        0.8754450678825378],\n",
      "                       [0.7609126567840576,\n",
      "                        0.8254117965698242,\n",
      "                        0.8375991582870483,\n",
      "                        0.8536398410797119,\n",
      "                        0.8604018092155457,\n",
      "                        0.8651317358016968,\n",
      "                        0.8677327632904053,\n",
      "                        0.8695222735404968,\n",
      "                        0.8710776567459106,\n",
      "                        0.8717890381813049],\n",
      "                       [0.7514315247535706,\n",
      "                        0.8272291421890259,\n",
      "                        0.8401023745536804,\n",
      "                        0.8507948517799377,\n",
      "                        0.8627182245254517,\n",
      "                        0.8695007562637329,\n",
      "                        0.872484028339386,\n",
      "                        0.8736608028411865,\n",
      "                        0.87579745054245,\n",
      "                        0.8770470023155212],\n",
      "                       [0.7335658669471741,\n",
      "                        0.8288474678993225,\n",
      "                        0.8441207408905029,\n",
      "                        0.8564141988754272,\n",
      "                        0.8621222972869873,\n",
      "                        0.8666217923164368,\n",
      "                        0.8693701028823853,\n",
      "                        0.8719090819358826,\n",
      "                        0.8744997978210449,\n",
      "                        0.8764817118644714],\n",
      "                       [0.7638658881187439,\n",
      "                        0.8288856744766235,\n",
      "                        0.8402109146118164,\n",
      "                        0.8473297357559204,\n",
      "                        0.8586658835411072,\n",
      "                        0.8651373386383057,\n",
      "                        0.8682443499565125,\n",
      "                        0.8707776665687561,\n",
      "                        0.8727433085441589,\n",
      "                        0.8746140599250793]],\n",
      " 'Training Loss': [[0.5323905348777771,\n",
      "                    0.381234735250473,\n",
      "                    0.3575761914253235,\n",
      "                    0.3411196172237396,\n",
      "                    0.31639620661735535,\n",
      "                    0.2949903607368469,\n",
      "                    0.2853328585624695,\n",
      "                    0.28039777278900146,\n",
      "                    0.2767810523509979,\n",
      "                    0.2730378210544586],\n",
      "                   [0.5153565406799316,\n",
      "                    0.3812546133995056,\n",
      "                    0.35572320222854614,\n",
      "                    0.3230690658092499,\n",
      "                    0.3066938519477844,\n",
      "                    0.29763177037239075,\n",
      "                    0.29191359877586365,\n",
      "                    0.28837546706199646,\n",
      "                    0.2837751805782318,\n",
      "                    0.2814086973667145],\n",
      "                   [0.5310516357421875,\n",
      "                    0.3815469741821289,\n",
      "                    0.3542862832546234,\n",
      "                    0.33215075731277466,\n",
      "                    0.30443814396858215,\n",
      "                    0.2886735796928406,\n",
      "                    0.28151968121528625,\n",
      "                    0.27892014384269714,\n",
      "                    0.27451449632644653,\n",
      "                    0.2714693546295166],\n",
      "                   [0.5390071868896484,\n",
      "                    0.3763231337070465,\n",
      "                    0.3460550606250763,\n",
      "                    0.31680601835250854,\n",
      "                    0.30417194962501526,\n",
      "                    0.2940252125263214,\n",
      "                    0.28741714358329773,\n",
      "                    0.28156256675720215,\n",
      "                    0.27565184235572815,\n",
      "                    0.27160343527793884],\n",
      "                   [0.5199711322784424,\n",
      "                    0.37929123640060425,\n",
      "                    0.3549034595489502,\n",
      "                    0.33868664503097534,\n",
      "                    0.31402766704559326,\n",
      "                    0.29742589592933655,\n",
      "                    0.29053160548210144,\n",
      "                    0.28459692001342773,\n",
      "                    0.28001904487609863,\n",
      "                    0.2768186926841736]],\n",
      " 'Validation Accuracy': [[0.8196966648101807,\n",
      "                          0.8345733284950256,\n",
      "                          0.845546543598175,\n",
      "                          0.8551433086395264,\n",
      "                          0.8687232732772827,\n",
      "                          0.8752432465553284,\n",
      "                          0.8771200776100159,\n",
      "                          0.8791767358779907,\n",
      "                          0.8808733224868774,\n",
      "                          0.8802199363708496],\n",
      "                         [0.8281865119934082,\n",
      "                          0.8370299935340881,\n",
      "                          0.8514934778213501,\n",
      "                          0.8623166680335999,\n",
      "                          0.8675499558448792,\n",
      "                          0.8701033592224121,\n",
      "                          0.8745933175086975,\n",
      "                          0.873533308506012,\n",
      "                          0.876966655254364,\n",
      "                          0.8776834011077881],\n",
      "                         [0.8127133250236511,\n",
      "                          0.8241966366767883,\n",
      "                          0.8366400599479675,\n",
      "                          0.8472467064857483,\n",
      "                          0.8585367798805237,\n",
      "                          0.8615933060646057,\n",
      "                          0.8641166090965271,\n",
      "                          0.8615102171897888,\n",
      "                          0.865993320941925,\n",
      "                          0.866040050983429],\n",
      "                         [0.8197533488273621,\n",
      "                          0.8313700556755066,\n",
      "                          0.8537366986274719,\n",
      "                          0.8621566891670227,\n",
      "                          0.8660933375358582,\n",
      "                          0.8683300018310547,\n",
      "                          0.8709632158279419,\n",
      "                          0.8746365308761597,\n",
      "                          0.8772165775299072,\n",
      "                          0.874523401260376],\n",
      "                         [0.821169912815094,\n",
      "                          0.8336433172225952,\n",
      "                          0.8431699275970459,\n",
      "                          0.8509700298309326,\n",
      "                          0.8626999855041504,\n",
      "                          0.8655667304992676,\n",
      "                          0.8695000410079956,\n",
      "                          0.8706032037734985,\n",
      "                          0.8703800439834595,\n",
      "                          0.8744933009147644]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "],\n",
      " 'Validation Loss': [0.39466944336891174,\n",
      "                     0.3699377775192261,\n",
      "                     0.3499649465084076,\n",
      "                     0.3300350308418274,\n",
      "                     0.3031657040119171,\n",
      "                     0.2966882884502411,\n",
      "                     0.2873092293739319,\n",
      "                     0.28362351655960083,\n",
      "                     0.28509512543678284,\n",
      "                     0.27756384015083313],\n",
      " 'Validation MCC': [[0.637661888978394,\n",
      "                     0.6680320159382181,\n",
      "                     0.6899470905519427,\n",
      "                     0.708993093901546,\n",
      "                     0.7368358329194866,\n",
      "                     0.7494548132825455,\n",
      "                     0.7532760481135546,\n",
      "                     0.7572744346267933,\n",
      "                     0.7612718533449259,\n",
      "                     0.7595377807664301],\n",
      "                    [0.655041559628198,\n",
      "                     0.6726923537477599,\n",
      "                     0.7016487176023807,\n",
      "                     0.7234946618658562,\n",
      "                     0.7341765612875004,\n",
      "                     0.7394744767711587,\n",
      "                     0.7482084454561168,\n",
      "                     0.7459489379780713,\n",
      "                     0.7529580649792612,\n",
      "                     0.754458805317232],\n",
      "                    [0.6242477931652205,\n",
      "                     0.6477948579284556,\n",
      "                     0.6713739797361694,\n",
      "                     0.6935454252024863,\n",
      "                     0.7154734888351495,\n",
      "                     0.7225559137131199,\n",
      "                     0.7267715393850332,\n",
      "                     0.721942627235359,\n",
      "                     0.7308848475713535,\n",
      "                     0.7306193698903458],\n",
      "                    [0.637984621039254,\n",
      "                     0.6648274532936318,\n",
      "                     0.7057434883206055,\n",
      "                     0.7226186358671113,\n",
      "                     0.7308379179580616,\n",
      "                     0.7350793828676441,\n",
      "                     0.7403524283097567,\n",
      "                     0.7477587698900401,\n",
      "                     0.753031502381017,\n",
      "                     0.7478565704866802],\n",
      "                    [0.6414148775017933,\n",
      "                     0.6666799619757424,\n",
      "                     0.6859454760197831,\n",
      "                     0.7009477439116829,\n",
      "                     0.7246342872315589,\n",
      "                     0.7302174142854567,\n",
      "                     0.7381317571466166,\n",
      "                     0.7403687580308487,\n",
      "                     0.7408388966833485,\n",
      "                     0.7481839173662187]]}\n",
      "Training Model: FFN, Fold: 1\n",
      "Epoch 1/10\n",
      "\u001B[1m146/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6707 - loss: 0.6160\n",
      "Epoch 1 - MCC: 0.6271\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 13ms/step - accuracy: 0.6731 - loss: 0.6133 - val_accuracy: 0.8137 - val_loss: 0.4049 - mcc: 0.6271\n",
      "Epoch 2/10\n",
      "\u001B[1m145/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8146 - loss: 0.3969\n",
      "Epoch 2 - MCC: 0.6487\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.8145 - loss: 0.3970 - val_accuracy: 0.8224 - val_loss: 0.3881 - mcc: 0.6487\n",
      "Epoch 3/10\n",
      "\u001B[1m139/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8118 - loss: 0.3948\n",
      "Epoch 3 - MCC: 0.6384\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8122 - loss: 0.3941 - val_accuracy: 0.8201 - val_loss: 0.3795 - mcc: 0.6384\n",
      "Epoch 4/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8184 - loss: 0.3832\n",
      "Epoch 4 - MCC: 0.6510\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8184 - loss: 0.3832 - val_accuracy: 0.8258 - val_loss: 0.3753 - mcc: 0.6510\n",
      "Epoch 5/10\n",
      "\u001B[1m142/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8205 - loss: 0.3778\n",
      "Epoch 5 - MCC: 0.6529\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8204 - loss: 0.3780 - val_accuracy: 0.8265 - val_loss: 0.3728 - mcc: 0.6529\n",
      "Epoch 6/10\n",
      "\u001B[1m141/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8239 - loss: 0.3723\n",
      "Epoch 6 - MCC: 0.6543\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8236 - loss: 0.3727 - val_accuracy: 0.8275 - val_loss: 0.3693 - mcc: 0.6543\n",
      "Epoch 7/10\n",
      "\u001B[1m143/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8204 - loss: 0.3776\n",
      "Epoch 7 - MCC: 0.6554\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8205 - loss: 0.3775 - val_accuracy: 0.8282 - val_loss: 0.3677 - mcc: 0.6554\n",
      "Epoch 8/10\n",
      "\u001B[1m143/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8246 - loss: 0.3683\n",
      "Epoch 8 - MCC: 0.6482\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8245 - loss: 0.3686 - val_accuracy: 0.8250 - val_loss: 0.3692 - mcc: 0.6482\n",
      "Epoch 9/10\n",
      "\u001B[1m142/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8201 - loss: 0.3758\n",
      "Epoch 9 - MCC: 0.6593\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8202 - loss: 0.3757 - val_accuracy: 0.8281 - val_loss: 0.3679 - mcc: 0.6593\n",
      "Epoch 10/10\n",
      "\u001B[1m140/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8196 - loss: 0.3751\n",
      "Epoch 10 - MCC: 0.6548\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8198 - loss: 0.3748 - val_accuracy: 0.8281 - val_loss: 0.3644 - mcc: 0.6548\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: FFN, Fold: 2\n",
      "Epoch 1/10\n",
      "\u001B[1m138/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6576 - loss: 0.6039\n",
      "Epoch 1 - MCC: 0.6235\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 15ms/step - accuracy: 0.6646 - loss: 0.5969 - val_accuracy: 0.8084 - val_loss: 0.4081 - mcc: 0.6235\n",
      "Epoch 2/10\n",
      "\u001B[1m142/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8125 - loss: 0.3959\n",
      "Epoch 2 - MCC: 0.6405\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 5ms/step - accuracy: 0.8126 - loss: 0.3957 - val_accuracy: 0.8201 - val_loss: 0.3844 - mcc: 0.6405\n",
      "Epoch 3/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8203 - loss: 0.3808\n",
      "Epoch 3 - MCC: 0.6399\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8203 - loss: 0.3808 - val_accuracy: 0.8208 - val_loss: 0.3799 - mcc: 0.6399\n",
      "Epoch 4/10\n",
      "\u001B[1m137/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8191 - loss: 0.3822\n",
      "Epoch 4 - MCC: 0.6422\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8193 - loss: 0.3819 - val_accuracy: 0.8220 - val_loss: 0.3768 - mcc: 0.6422\n",
      "Epoch 5/10\n",
      "\u001B[1m148/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8212 - loss: 0.3778\n",
      "Epoch 5 - MCC: 0.6451\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8212 - loss: 0.3778 - val_accuracy: 0.8234 - val_loss: 0.3745 - mcc: 0.6451\n",
      "Epoch 6/10\n",
      "\u001B[1m144/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8185 - loss: 0.3795\n",
      "Epoch 6 - MCC: 0.6475\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8186 - loss: 0.3793 - val_accuracy: 0.8235 - val_loss: 0.3722 - mcc: 0.6475\n",
      "Epoch 7/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8219 - loss: 0.3759\n",
      "Epoch 7 - MCC: 0.6410\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8219 - loss: 0.3758 - val_accuracy: 0.8210 - val_loss: 0.3756 - mcc: 0.6410\n",
      "Epoch 8/10\n",
      "\u001B[1m141/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8245 - loss: 0.3703\n",
      "Epoch 8 - MCC: 0.6499\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8245 - loss: 0.3704 - val_accuracy: 0.8214 - val_loss: 0.3752 - mcc: 0.6499\n",
      "Epoch 9/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8245 - loss: 0.3710\n",
      "Epoch 9 - MCC: 0.6494\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8244 - loss: 0.3710 - val_accuracy: 0.8223 - val_loss: 0.3712 - mcc: 0.6494\n",
      "Epoch 10/10\n",
      "\u001B[1m142/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8233 - loss: 0.3724\n",
      "Epoch 10 - MCC: 0.6501\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8233 - loss: 0.3723 - val_accuracy: 0.8245 - val_loss: 0.3669 - mcc: 0.6501\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: FFN, Fold: 3\n",
      "Epoch 1/10\n",
      "\u001B[1m146/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6612 - loss: 0.6262\n",
      "Epoch 1 - MCC: 0.6045\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 11ms/step - accuracy: 0.6636 - loss: 0.6235 - val_accuracy: 0.8035 - val_loss: 0.4122 - mcc: 0.6045\n",
      "Epoch 2/10\n",
      "\u001B[1m146/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8160 - loss: 0.3945\n",
      "Epoch 2 - MCC: 0.6229\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8161 - loss: 0.3943 - val_accuracy: 0.8119 - val_loss: 0.3963 - mcc: 0.6229\n",
      "Epoch 3/10\n",
      "\u001B[1m146/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8175 - loss: 0.3888\n",
      "Epoch 3 - MCC: 0.6000\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8176 - loss: 0.3885 - val_accuracy: 0.7982 - val_loss: 0.4106 - mcc: 0.6000\n",
      "Epoch 4/10\n",
      "\u001B[1m143/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8210 - loss: 0.3792\n",
      "Epoch 4 - MCC: 0.6287\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8210 - loss: 0.3791 - val_accuracy: 0.8140 - val_loss: 0.3907 - mcc: 0.6287\n",
      "Epoch 5/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8174 - loss: 0.3835\n",
      "Epoch 5 - MCC: 0.6279\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8175 - loss: 0.3833 - val_accuracy: 0.8139 - val_loss: 0.3877 - mcc: 0.6279\n",
      "Epoch 6/10\n",
      "\u001B[1m142/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8253 - loss: 0.3690\n",
      "Epoch 6 - MCC: 0.6284\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8252 - loss: 0.3692 - val_accuracy: 0.8149 - val_loss: 0.3860 - mcc: 0.6284\n",
      "Epoch 7/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8255 - loss: 0.3693\n",
      "Epoch 7 - MCC: 0.6245\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8255 - loss: 0.3694 - val_accuracy: 0.8133 - val_loss: 0.3860 - mcc: 0.6245\n",
      "Epoch 8/10\n",
      "\u001B[1m145/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8291 - loss: 0.3624\n",
      "Epoch 8 - MCC: 0.6192\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8290 - loss: 0.3627 - val_accuracy: 0.8104 - val_loss: 0.3907 - mcc: 0.6192\n",
      "Epoch 9/10\n",
      "\u001B[1m140/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8269 - loss: 0.3657\n",
      "Epoch 9 - MCC: 0.6305\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8267 - loss: 0.3660 - val_accuracy: 0.8123 - val_loss: 0.3893 - mcc: 0.6305\n",
      "Epoch 10/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8220 - loss: 0.3733\n",
      "Epoch 10 - MCC: 0.6301\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8221 - loss: 0.3732 - val_accuracy: 0.8106 - val_loss: 0.3925 - mcc: 0.6301\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: FFN, Fold: 4\n",
      "Epoch 1/10\n",
      "\u001B[1m146/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6320 - loss: 0.6186\n",
      "Epoch 1 - MCC: 0.6263\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 10ms/step - accuracy: 0.6350 - loss: 0.6160 - val_accuracy: 0.8143 - val_loss: 0.4018 - mcc: 0.6263\n",
      "Epoch 2/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8095 - loss: 0.4041\n",
      "Epoch 2 - MCC: 0.6400\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8095 - loss: 0.4040 - val_accuracy: 0.8212 - val_loss: 0.3797 - mcc: 0.6400\n",
      "Epoch 3/10\n",
      "\u001B[1m141/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8203 - loss: 0.3839\n",
      "Epoch 3 - MCC: 0.6454\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8201 - loss: 0.3842 - val_accuracy: 0.8234 - val_loss: 0.3755 - mcc: 0.6454\n",
      "Epoch 4/10\n",
      "\u001B[1m144/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8177 - loss: 0.3866\n",
      "Epoch 4 - MCC: 0.6448\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8178 - loss: 0.3865 - val_accuracy: 0.8236 - val_loss: 0.3736 - mcc: 0.6448\n",
      "Epoch 5/10\n",
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8186 - loss: 0.3809\n",
      "Epoch 5 - MCC: 0.6475\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8186 - loss: 0.3809 - val_accuracy: 0.8249 - val_loss: 0.3697 - mcc: 0.6475\n",
      "Epoch 6/10\n",
      "\u001B[1m138/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8191 - loss: 0.3807\n",
      "Epoch 6 - MCC: 0.6348\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8193 - loss: 0.3804 - val_accuracy: 0.8174 - val_loss: 0.3781 - mcc: 0.6348\n",
      "Epoch 7/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8210 - loss: 0.3772\n",
      "Epoch 7 - MCC: 0.6459\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8210 - loss: 0.3772 - val_accuracy: 0.8240 - val_loss: 0.3691 - mcc: 0.6459\n",
      "Epoch 8/10\n",
      "\u001B[1m140/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8236 - loss: 0.3733\n",
      "Epoch 8 - MCC: 0.6490\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8235 - loss: 0.3735 - val_accuracy: 0.8256 - val_loss: 0.3654 - mcc: 0.6490\n",
      "Epoch 9/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8194 - loss: 0.3777\n",
      "Epoch 9 - MCC: 0.6467\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8195 - loss: 0.3777 - val_accuracy: 0.8245 - val_loss: 0.3659 - mcc: 0.6467\n",
      "Epoch 10/10\n",
      "\u001B[1m142/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8251 - loss: 0.3689\n",
      "Epoch 10 - MCC: 0.6560\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - accuracy: 0.8249 - loss: 0.3693 - val_accuracy: 0.8265 - val_loss: 0.3670 - mcc: 0.6560\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Model: FFN, Fold: 5\n",
      "Epoch 1/10\n",
      "\u001B[1m145/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6235 - loss: 0.6190\n",
      "Epoch 1 - MCC: 0.6197\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 11ms/step - accuracy: 0.6274 - loss: 0.6160 - val_accuracy: 0.8093 - val_loss: 0.4139 - mcc: 0.6197\n",
      "Epoch 2/10\n",
      "\u001B[1m146/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8091 - loss: 0.4068\n",
      "Epoch 2 - MCC: 0.6412\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8093 - loss: 0.4065 - val_accuracy: 0.8191 - val_loss: 0.3876 - mcc: 0.6412\n",
      "Epoch 3/10\n",
      "\u001B[1m136/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8155 - loss: 0.3913\n",
      "Epoch 3 - MCC: 0.6430\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8157 - loss: 0.3908 - val_accuracy: 0.8214 - val_loss: 0.3802 - mcc: 0.6430\n",
      "Epoch 4/10\n",
      "\u001B[1m147/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8192 - loss: 0.3839\n",
      "Epoch 4 - MCC: 0.6451\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8193 - loss: 0.3838 - val_accuracy: 0.8224 - val_loss: 0.3769 - mcc: 0.6451\n",
      "Epoch 5/10\n",
      "\u001B[1m144/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8168 - loss: 0.3851\n",
      "Epoch 5 - MCC: 0.6438\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8170 - loss: 0.3847 - val_accuracy: 0.8221 - val_loss: 0.3750 - mcc: 0.6438\n",
      "Epoch 6/10\n",
      "\u001B[1m142/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8292 - loss: 0.3658\n",
      "Epoch 6 - MCC: 0.6332\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8287 - loss: 0.3665 - val_accuracy: 0.8169 - val_loss: 0.3795 - mcc: 0.6332\n",
      "Epoch 7/10\n",
      "\u001B[1m141/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8228 - loss: 0.3749\n",
      "Epoch 7 - MCC: 0.6490\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8228 - loss: 0.3749 - val_accuracy: 0.8219 - val_loss: 0.3747 - mcc: 0.6490\n",
      "Epoch 8/10\n",
      "\u001B[1m138/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8214 - loss: 0.3738\n",
      "Epoch 8 - MCC: 0.6242\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8215 - loss: 0.3737 - val_accuracy: 0.8102 - val_loss: 0.3901 - mcc: 0.6242\n",
      "Epoch 9/10\n",
      "\u001B[1m136/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8197 - loss: 0.3809\n",
      "Epoch 9 - MCC: 0.6304\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8198 - loss: 0.3805 - val_accuracy: 0.8150 - val_loss: 0.3801 - mcc: 0.6304\n",
      "Epoch 10/10\n",
      "\u001B[1m144/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8237 - loss: 0.3724\n",
      "Epoch 10 - MCC: 0.6483\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8236 - loss: 0.3725 - val_accuracy: 0.8242 - val_loss: 0.3681 - mcc: 0.6483\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Accuracy': {'max': 0.8281466666666667,\n",
      "              'mean': 0.822786,\n",
      "              'min': 0.8105766666666666,\n",
      "              'std': 0.0062684371257914285},\n",
      " 'Inference Time (s/sample)': {'max': 0.0003861121336619059,\n",
      "                               'mean': 0.0003136016527811686,\n",
      "                               'min': 0.0001863551139831543,\n",
      "                               'std': 7.591929779999738e-05},\n",
      " 'MCC': {'max': 0.6560390143039783,\n",
      "         'mean': 0.6478863229405225,\n",
      "         'min': 0.630088646598591,\n",
      "         'std': 0.0093476145518534},\n",
      " 'Parameters': 4305,\n",
      " 'Train Time (s)': {'max': 16.060234546661377,\n",
      "                    'mean': 14.167105054855346,\n",
      "                    'min': 12.807628870010376,\n",
      "                    'std': 1.1062535996150167},\n",
      " 'Training Accuracy': [[0.7417033910751343,\n",
      "                        0.8108367323875427,\n",
      "                        0.8162415623664856,\n",
      "                        0.8173166513442993,\n",
      "                        0.8187927007675171,\n",
      "                        0.8204076290130615,\n",
      "                        0.820834219455719,\n",
      "                        0.8213000893592834,\n",
      "                        0.8215411305427551,\n",
      "                        0.8220257759094238],\n",
      "                       [0.7419191598892212,\n",
      "                        0.8141584396362305,\n",
      "                        0.8181209564208984,\n",
      "                        0.8205502033233643,\n",
      "                        0.8205641508102417,\n",
      "                        0.8211634159088135,\n",
      "                        0.8220717310905457,\n",
      "                        0.8236650228500366,\n",
      "                        0.8225159645080566,\n",
      "                        0.8236323595046997],\n",
      "                       [0.7359158992767334,\n",
      "                        0.8175326585769653,\n",
      "                        0.8210707902908325,\n",
      "                        0.8224682211875916,\n",
      "                        0.8231625556945801,\n",
      "                        0.8235133290290833,\n",
      "                        0.8241543769836426,\n",
      "                        0.8249632716178894,\n",
      "                        0.8248790502548218,\n",
      "                        0.8252002000808716],\n",
      "                       [0.7246576547622681,\n",
      "                        0.8110883831977844,\n",
      "                        0.8173207640647888,\n",
      "                        0.8190940618515015,\n",
      "                        0.8195683360099792,\n",
      "                        0.8212618231773376,\n",
      "                        0.821898341178894,\n",
      "                        0.8224067687988281,\n",
      "                        0.8215760588645935,\n",
      "                        0.8216601014137268],\n",
      "                       [0.7221419215202332,\n",
      "                        0.8143310546875,\n",
      "                        0.818376898765564,\n",
      "                        0.8200927376747131,\n",
      "                        0.8212076425552368,\n",
      "                        0.8212342262268066,\n",
      "                        0.8228077292442322,\n",
      "                        0.821897566318512,\n",
      "                        0.8216426372528076,\n",
      "                        0.8215891122817993]],\n",
      " 'Training Loss': [[0.5339492559432983,\n",
      "                    0.3977110981941223,\n",
      "                    0.3871901333332062,\n",
      "                    0.38411206007003784,\n",
      "                    0.3802988827228546,\n",
      "                    0.37750178575515747,\n",
      "                    0.3760359585285187,\n",
      "                    0.37432989478111267,\n",
      "                    0.3729743957519531,\n",
      "                    0.37153321504592896],\n",
      "                   [0.5170440077781677,\n",
      "                    0.3933783769607544,\n",
      "                    0.3849935531616211,\n",
      "                    0.3798963725566864,\n",
      "                    0.3778924345970154,\n",
      "                    0.37532752752304077,\n",
      "                    0.3738464117050171,\n",
      "                    0.3706294298171997,\n",
      "                    0.37087392807006836,\n",
      "                    0.36961013078689575],\n",
      "                   [0.5415555834770203,\n",
      "                    0.3888583779335022,\n",
      "                    0.38097599148750305,\n",
      "                    0.37697672843933105,\n",
      "                    0.3743385970592499,\n",
      "                    0.37246277928352356,\n",
      "                    0.37126973271369934,\n",
      "                    0.3697422742843628,\n",
      "                    0.3688218295574188,\n",
      "                    0.36755049228668213],\n",
      "                   [0.5390318036079407,\n",
      "                    0.3995167911052704,\n",
      "                    0.3875443935394287,\n",
      "                    0.383701354265213,\n",
      "                    0.38107001781463623,\n",
      "                    0.3779231905937195,\n",
      "                    0.3763139545917511,\n",
      "                    0.3751772344112396,\n",
      "                    0.37534475326538086,\n",
      "                    0.37514933943748474],\n",
      "                   [0.5407474040985107,\n",
      "                    0.3953537344932556,\n",
      "                    0.3847881257534027,\n",
      "                    0.3817284405231476,\n",
      "                    0.3776381313800812,\n",
      "                    0.37710896134376526,\n",
      "                    0.3740953207015991,\n",
      "                    0.3739687204360962,\n",
      "                    0.3746991753578186,\n",
      "                    0.3735879957675934]],\n",
      " 'Validation Accuracy': [[0.8136667609214783,\n",
      "                          0.8224334120750427,\n",
      "                          0.8200932741165161,\n",
      "                          0.8258200287818909,\n",
      "                          0.8264699578285217,\n",
      "                          0.8275367617607117,\n",
      "                          0.8282133936882019,\n",
      "                          0.8249866962432861,\n",
      "                          0.8281267285346985,\n",
      "                          0.8281466960906982],\n",
      "                         [0.8083866834640503,\n",
      "                          0.82013338804245,\n",
      "                          0.8208335041999817,\n",
      "                          0.8219500780105591,\n",
      "                          0.8234033584594727,\n",
      "                          0.8235368132591248,\n",
      "                          0.8209734559059143,\n",
      "                          0.8214432597160339,\n",
      "                          0.822306752204895,\n",
      "                          0.8245301246643066],\n",
      "                         [0.8034632802009583,\n",
      "                          0.8119166493415833,\n",
      "                          0.7981633543968201,\n",
      "                          0.8140333890914917,\n",
      "                          0.8138866424560547,\n",
      "                          0.8149099349975586,\n",
      "                          0.8133000731468201,\n",
      "                          0.8103933930397034,\n",
      "                          0.8122766017913818,\n",
      "                          0.8105767369270325],\n",
      "                         [0.814323365688324,\n",
      "                          0.8212100863456726,\n",
      "                          0.8234334588050842,\n",
      "                          0.8235766887664795,\n",
      "                          0.8248734474182129,\n",
      "                          0.8173500299453735,\n",
      "                          0.8240467309951782,\n",
      "                          0.8255600333213806,\n",
      "                          0.8245300054550171,\n",
      "                          0.8264766931533813],\n",
      "                         [0.809293270111084,\n",
      "                          0.8190767168998718,\n",
      "                          0.8214266896247864,\n",
      "                          0.8223767876625061,\n",
      "                          0.8220733404159546,\n",
      "                          0.8169333338737488,\n",
      "                          0.8219366669654846,\n",
      "                          0.8102266192436218,\n",
      "                          0.8149566650390625,\n",
      "                          0.824199914932251]],\n",
      " 'Validation Loss': [0.41394558548927307,\n",
      "                     0.3875746726989746,\n",
      "                     0.38023343682289124,\n",
      "                     0.37689849734306335,\n",
      "                     0.3750191032886505,\n",
      "                     0.3795323967933655,\n",
      "                     0.37474325299263,\n",
      "                     0.3900827467441559,\n",
      "                     0.38014742732048035,\n",
      "                     0.36814558506011963],\n",
      " 'Validation MCC': [[0.627070929102362,\n",
      "                     0.6486928385565476,\n",
      "                     0.6384101571119545,\n",
      "                     0.6509704117715246,\n",
      "                     0.652918818133873,\n",
      "                     0.6543124387832466,\n",
      "                     0.6554364334805111,\n",
      "                     0.6482455864872825,\n",
      "                     0.6592896680694236,\n",
      "                     0.6548465928686387],\n",
      "                    [0.6234955243680879,\n",
      "                     0.640536933978755,\n",
      "                     0.6399404125221033,\n",
      "                     0.6421779701059027,\n",
      "                     0.6451012988488882,\n",
      "                     0.6474904842853288,\n",
      "                     0.6409768448137079,\n",
      "                     0.6498725103521238,\n",
      "                     0.6494072676614626,\n",
      "                     0.650127742334302],\n",
      "                    [0.6044799479342324,\n",
      "                     0.6228640335679485,\n",
      "                     0.5999866093010161,\n",
      "                     0.6286522299877412,\n",
      "                     0.6278535589608142,\n",
      "                     0.6283965303172638,\n",
      "                     0.6244835552959048,\n",
      "                     0.6192019573369658,\n",
      "                     0.6305405929717273,\n",
      "                     0.630088646598591],\n",
      "                    [0.6262654017894451,\n",
      "                     0.6400355411961683,\n",
      "                     0.6454374379513411,\n",
      "                     0.6448052184327027,\n",
      "                     0.6474939152507535,\n",
      "                     0.6347654046411393,\n",
      "                     0.6458532220453781,\n",
      "                     0.6490497535553522,\n",
      "                     0.6467309887071585,\n",
      "                     0.6560390143039783],\n",
      "                    [0.6196623098725613,\n",
      "                     0.6412276406418231,\n",
      "                     0.6430135070893309,\n",
      "                     0.6450762994246887,\n",
      "                     0.6437995109322578,\n",
      "                     0.6331731831992329,\n",
      "                     0.6490169800947639,\n",
      "                     0.6242309316495944,\n",
      "                     0.6303721339452523,\n",
      "                     0.6483296185971028]]}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaQotIXc5Bqh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## k-fold with Noise Level Performance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yee8zcei5Gkh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "from collections import defaultdict\n",
    "\n",
    "# Assume we have a noise label array (same length as X)\n",
    "# Example: noise_labels = np.random.randint(0, 3, len(X))  # Simulating 3 noise levels: 0, 1, 2\n",
    "noise_labels = ...  # This should be an array of shape (len(X),)\n",
    "\n",
    "# Create directory for model storage\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "# Define model architectures\n",
    "model_dict = {\n",
    "    \"Simple_LSTM\": lambda input_shape, num_classes: tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(32, return_sequences=True, input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Number of folds\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize results storage\n",
    "model_results = {model_name: {} for model_name in model_dict.keys()}\n",
    "trained_models = {model_name: [] for model_name in model_dict.keys()}\n",
    "\n",
    "# Convert y to a format compatible with StratifiedKFold\n",
    "y_flat = np.argmax(y, axis=-1) if y.ndim == 3 else y  # Ensure shape (samples,)\n",
    "\n",
    "for model_name, model_fn in model_dict.items():\n",
    "    acc_scores, mcc_scores, train_times, infer_times = [], [], [], []\n",
    "    noise_performance = defaultdict(lambda: {\"acc\": [], \"mcc\": []})  # Store per noise level\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y_flat[:, 0])):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        val_noise_levels = noise_labels[val_idx]  # Get noise levels for validation set\n",
    "\n",
    "        # Build and compile model\n",
    "        model = model_fn(input_shape=X.shape[1:], num_classes=5)\n",
    "\n",
    "        # Train model and measure time\n",
    "        start_train = time.time()\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_val, y_val), verbose=1)\n",
    "        train_time = time.time() - start_train\n",
    "\n",
    "        # Inference speed measurement\n",
    "        start_infer = time.time()\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        infer_time = (time.time() - start_infer) / len(X_val)  # Time per sample\n",
    "\n",
    "        # Compute metrics\n",
    "        y_pred = np.argmax(y_pred_probs, axis=-1).flatten()\n",
    "        y_true = y_val.flatten()\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "        acc_scores.append(acc)\n",
    "        mcc_scores.append(mcc)\n",
    "        train_times.append(train_time)\n",
    "        infer_times.append(infer_time)\n",
    "\n",
    "        # Save model for this fold\n",
    "        model_save_path = f\"saved_models/{model_name}_fold_{fold+1}.h5\"\n",
    "        model.save(model_save_path)\n",
    "        trained_models[model_name].append(model_save_path)\n",
    "\n",
    "        # **Noise-Level Performance Tracking**\n",
    "        for noise_level in np.unique(val_noise_levels):\n",
    "            mask = val_noise_levels == noise_level  # Get indices of this noise level\n",
    "            y_true_noise = y_true[mask]\n",
    "            y_pred_noise = y_pred[mask]\n",
    "\n",
    "            if len(y_true_noise) > 0:  # Avoid empty cases\n",
    "                acc_noise = accuracy_score(y_true_noise, y_pred_noise)\n",
    "                mcc_noise = matthews_corrcoef(y_true_noise, y_pred_noise)\n",
    "\n",
    "                noise_performance[noise_level][\"acc\"].append(acc_noise)\n",
    "                noise_performance[noise_level][\"mcc\"].append(mcc_noise)\n",
    "\n",
    "    # Store aggregated results\n",
    "    model_results[model_name] = {\n",
    "        \"Accuracy\": {\"mean\": np.mean(acc_scores), \"std\": np.std(acc_scores), \"min\": np.min(acc_scores), \"max\": np.max(acc_scores)},\n",
    "        \"MCC\": {\"mean\": np.mean(mcc_scores), \"std\": np.std(mcc_scores), \"min\": np.min(mcc_scores), \"max\": np.max(mcc_scores)},\n",
    "        \"Train Time (s)\": {\"mean\": np.mean(train_times), \"std\": np.std(train_times), \"min\": np.min(train_times), \"max\": np.max(train_times)},\n",
    "        \"Inference Time (s/sample)\": {\"mean\": np.mean(infer_times), \"std\": np.std(infer_times), \"min\": np.min(infer_times), \"max\": np.max(infer_times)},\n",
    "        \"Noise Performance\": {\n",
    "            noise_level: {\n",
    "                \"Accuracy\": {\"mean\": np.mean(scores[\"acc\"]), \"std\": np.std(scores[\"acc\"])},\n",
    "                \"MCC\": {\"mean\": np.mean(scores[\"mcc\"]), \"std\": np.std(scores[\"mcc\"])}\n",
    "            } for noise_level, scores in noise_performance.items()\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save the final trained model from the last fold\n",
    "    final_model_save_path = f\"saved_models/{model_name}_final.h5\"\n",
    "    model.save(final_model_save_path)\n",
    "\n",
    "# Print results\n",
    "import pprint\n",
    "pprint.pprint(model_results)\n",
    "\n",
    "# Save results as JSON\n",
    "import json\n",
    "with open(\"model_results.json\", \"w\") as f:\n",
    "    json.dump(model_results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOMZpon3uxRc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualize Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kBU92PtSuy4m",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names, title=\"Confusion Matrix\"):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpIZsmrqvfRf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names, title=\"Confusion Matrix\"):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHFU5WeGvhAf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Loss curve\n",
    "def plot_loss_curves(history):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss Curves')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JieiAj4uvy0N",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Result Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ttc7Vezv0cX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Model\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"MAE\": [],\n",
    "    \"F1-Score\": [],\n",
    "    \"Training Time (s)\": [],\n",
    "    \"Inference Time (s)\": []\n",
    "}\n",
    "\n",
    "# Assuming `models` is a list of your models\n",
    "for model_name, model in models.items():\n",
    "    metrics = evaluate_model(model, X_train, y_train, X_val, y_val)\n",
    "    inference_time = measure_inference_time(model, X_test)\n",
    "\n",
    "    results[\"Model\"].append(model_name)\n",
    "    results[\"Accuracy\"].append(metrics[\"accuracy\"])\n",
    "    results[\"MAE\"].append(metrics[\"mae\"])\n",
    "    results[\"F1-Score\"].append(metrics[\"f1\"])\n",
    "    results[\"Training Time (s)\"].append(metrics[\"training_time\"])\n",
    "    results[\"Inference Time (s)\"].append(inference_time)\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "GNiL1F-2M1XE",
    "zs3IQP22uoB4",
    "kOMZpon3uxRc",
    "JieiAj4uvy0N"
   ],
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyMCAi2Zagx4IxZwYBINRIEl"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}